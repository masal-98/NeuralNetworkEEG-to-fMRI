{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0f89d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 14:26:29.427352: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-08 14:26:32.817632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:/home/malfonzo/miniconda3/lib/\n",
      "2023-04-08 14:26:32.817711: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:/home/malfonzo/miniconda3/lib/\n",
      "2023-04-08 14:26:32.817721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "import keras\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics \n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "from tensorflow_addons.metrics import RSquare\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from wandb.keras import WandbCallback\n",
    "import wandb\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fb264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 14:26:39.275296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-08 14:26:39.305868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-08 14:26:39.306194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "F1_test=8\n",
    "D_test=2\n",
    "F2_test=16\n",
    "Drop_test=0.25 #originally 0.5\n",
    "KernLength_test=64 #Originally 64 \n",
    "batch_test=16\n",
    "\n",
    "N_chan=31\n",
    "N_samples_long=251\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b87d49ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_CLASSES: 2\n",
      "New shape for X: (6480, 31, 251, 1)\n",
      "New shape for y: (6480,)\n",
      "Train index for this split: [   1    3    5 ... 6476 6477 6479]\n",
      "Number of samples for train set: 5184\n",
      "Test index for this split: [   0    2    4 ... 6472 6474 6478]\n",
      "Number of samples for test set: 1296\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_321\" is incompatible with the layer: expected shape=(None, 31, 50, 1), found shape=(16, 31, 251, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 109\u001b[0m\n\u001b[1;32m    101\u001b[0m optimizer\u001b[38;5;241m=\u001b[39m optimizers\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m    102\u001b[0m learning_rate\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m,\n\u001b[1;32m    103\u001b[0m weight_decay\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    105\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m    106\u001b[0m                loss\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m    107\u001b[0m                metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 109\u001b[0m evaluation\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m              )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Iteration = fold, i am just saving the model for that fold\u001b[39;00m\n\u001b[1;32m    116\u001b[0m iteration\u001b[38;5;241m.\u001b[39mappend(model)\n",
      "File \u001b[0;32m~/akulejo/lib/python3.10/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cbk \u001b[38;5;129;01min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/akulejo/lib/python3.10/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cbk \u001b[38;5;129;01min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/akulejo/lib/python3.10/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cbk \u001b[38;5;129;01min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/akulejo/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9mrgeu5j.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/malfonzo/akulejo/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_321\" is incompatible with the layer: expected shape=(None, 31, 50, 1), found shape=(16, 31, 251, 1)\n"
     ]
    }
   ],
   "source": [
    "# PER SUB \n",
    "# SUBJECTS=[1,2,3,4,5,6,7,8,9,11,12,13,14,16,17]\n",
    "# for temp_sub in SUBJECTS:\n",
    "CLASSES= [2,3]\n",
    "#questa va applicata a for loop di subject che deve essere il più esterno \n",
    "sub=\"{:02d}\".format(temp_sub)\n",
    "for n_classes in CLASSES:\n",
    "    #Define loss function\n",
    "    loss_fn= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    LABELS= list(range(0,n_classes))\n",
    "    numero_classi=n_classes\n",
    "\n",
    "#     dir0= os.path.join(\"FINAL_motor_imagery_classification/2_sec_windows/raw/\"+str(n_classes)+\"class/output/\", \"sub_\"+str(sub))\n",
    "    dir0= os.path.join(\"FINAL_motor_imagery_classification/2_sec_windows/raw/\"+str(n_classes)+\"class/output/\", \"all\")\n",
    "\n",
    "#     os.mkdir(dir0)\n",
    "    dir_input=(\"FINAL_motor_imagery_classification/2_sec_windows/raw/\"+str(n_classes)+\"class/input\")\n",
    "\n",
    "    evaluation=[]\n",
    "    iteration=[]\n",
    "    confusion_matrix_x_test=[]\n",
    "    confusion_matrix_y_test= []\n",
    "    validation_acc=[]\n",
    "    PERFORMANCE=[]\n",
    "\n",
    "#     print(\"SUBJECT: \"+ str(sub))\n",
    "    print(\"N_CLASSES: \"+ str(n_classes))\n",
    "\n",
    "#     X=sio.loadmat(dir_input+\"/sub_\"+str(sub)+ \"_X.mat\")[\"array_X\"]\n",
    "#     y= sio.loadmat(dir_input+\"/sub_\"+str(sub)+\"_y.mat\")[\"array_y\"]\n",
    "\n",
    "    X=sio.loadmat(dir_input+\"/all_X.mat\")[\"array_X\"]\n",
    "    y= sio.loadmat(dir_input+\"/all_y.mat\")[\"array_y\"]\n",
    "    X= X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    y=y.flatten()\n",
    "    print(\"New shape for X: \" + str(X.shape))\n",
    "    print(\"New shape for y: \"+str(y.shape))\n",
    "\n",
    "    dir1=os.path.join(dir0, \"comparison\")\n",
    "    dir2=os.path.join(dir0, \"temporal_convolution\")\n",
    "    dir3=os.path.join(dir0, \"spatial_convolution\")\n",
    "#     os.mkdir(dir1)\n",
    "#     os.mkdir(dir2)\n",
    "#     os.mkdir(dir3)\n",
    "\n",
    "    ################################################################################################################################################################################################################################################################################\n",
    "\n",
    "    n_folds = 5\n",
    "    seed = 21\n",
    "    shuffle_test = True\n",
    "    EPOCHS=250\n",
    "\n",
    "    kfold = KFold(n_splits = n_folds, shuffle = shuffle_test, random_state = seed)\n",
    "    count=0\n",
    "    sommatoria=0\n",
    "\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        count=count+1\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        print(\"Train index for this split: \"+ str(train_index)) \n",
    "        print(\"Number of samples for train set: \"+str(train_index.shape[0]))\n",
    "        print(\"Test index for this split: \"+ str(test_index))\n",
    "        print(\"Number of samples for test set: \"+str(test_index.shape[0]))\n",
    "\n",
    "        # Define the model architecture - \n",
    "\n",
    "        model=Sequential()\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "        model.add(Conv2D(8, (1, 64), padding = 'same',\n",
    "                                       input_shape = (N_chan, N_samples_long, 1),\n",
    "                                       use_bias = False, name=\"temporal_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_1\"))\n",
    "        model.add(DepthwiseConv2D((31, 1), use_bias = False, \n",
    "                                       depth_multiplier = 2,\n",
    "                                       depthwise_constraint = max_norm(1.), name=\"spatial_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_2\"))\n",
    "        model.add(Activation('elu', name=\"activation_1\"))\n",
    "        model.add(AveragePooling2D((1, 4), name=\"pooling_layer_1\"))\n",
    "        model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "\n",
    "        model.add(SeparableConv2D(16, (1, 16),\n",
    "                                       use_bias = False, padding = 'same', name=\"separable_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_3\"))\n",
    "        model.add(Activation('elu', name=\"activation_2\"))\n",
    "        model.add(AveragePooling2D((1, 8), name=\"pooling_layer_2\"))\n",
    "        model.add(Dropout(0.5, name=\"drpout_2\")) #QUI DROPOUT E' LASCIATO A 0.5 come in eegnet paper\n",
    "\n",
    "        model.add(Flatten(name = 'flatten'))\n",
    "\n",
    "        model.add(Dense(numero_classi, name = 'dense', \n",
    "                                 kernel_constraint = max_norm(0.25)))\n",
    "        model.add(Activation('softmax', name = 'softmax'))\n",
    "\n",
    "\n",
    "        # Define the optimizer\n",
    "        optimizer= optimizers.Adam(\n",
    "        learning_rate= 1e-3,\n",
    "        weight_decay= 0\n",
    "        )\n",
    "        model.compile(optimizer=optimizer,\n",
    "                       loss=loss_fn,\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "        evaluation.append(model.fit(X_train, y_train, batch_size=16,\n",
    "                  epochs=EPOCHS, \n",
    "                  validation_data=(X_test, y_test), \n",
    "                  verbose=2, workers=1)\n",
    "                     )\n",
    "\n",
    "        # Iteration = fold, i am just saving the model for that fold\n",
    "        iteration.append(model)\n",
    "\n",
    "        confusion_matrix_x_test.append(X_test)\n",
    "        confusion_matrix_y_test.append(y_test)\n",
    "\n",
    "        #Plotting confusion matrix\n",
    "        pred=model.predict(X_test)\n",
    "        y_test_pred= np.argmax(pred, axis=1)\n",
    "\n",
    "        confusion_matrix= metrics.confusion_matrix(y_test, y_test_pred, normalize='true')\n",
    "        plt.figure()\n",
    "        metrics.ConfusionMatrixDisplay(confusion_matrix).plot()\n",
    "        plt.savefig(dir1+\"/confusion_matrix_kfold_\"+str(count))\n",
    "        plt.close()\n",
    "\n",
    "        validation_acc.append(np.sum(y_test==y_test_pred)/y_test.shape[0])\n",
    "\n",
    "        PERFORMANCE.append(classification_report(y_test, y_test_pred, labels=LABELS, output_dict=True))\n",
    "\n",
    "        #Salvo risultati di singolo fold\n",
    "        sio.savemat(dir1+\"/y_pred_test_kfold\"+str(count), {\"array\": y_test_pred})\n",
    "        sio.savemat(dir1+\"/y_test_kfold\"+str(count), {\"array\": y_test})\n",
    "\n",
    "\n",
    "        # PLOTTO FILTRI TEMPORALI E SPAZIALI E LI SALVO\n",
    "        var= (model.get_layer(\"temporal_conv\").weights)\n",
    "        for lallo in range(8):\n",
    "            plt.figure()\n",
    "            plt.title(\"temp_conv_\"+str(lallo))\n",
    "            plt.plot(var[0][0,:,0][:,lallo]) #this way i access the temporal filters, cambiando ultimo zero\n",
    "            plt.savefig(dir2+\"/temp_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo))\n",
    "            temp= (var[0][0,:,0][:,lallo]).numpy()\n",
    "            sio.savemat(dir2+\"/temp_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo), {\"array\": temp})\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "        var_2= (model.get_layer(\"spatial_conv\").weights)\n",
    "        reshaped_var_2=tf.reshape(var_2[0][:,0,:,:],(31,16))\n",
    "        for lallo in range(16):\n",
    "            nump= reshaped_var_2[:,lallo].numpy()\n",
    "            sio.savemat(dir3+\"/spat_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo), {\"array\": nump})\n",
    "\n",
    "    ###################################################################################################################\n",
    "\n",
    "    #plot accuracy and loss function across epochs\n",
    "    epoch_vec=np.linspace(1,EPOCHS,EPOCHS)\n",
    "    min_temp_loss=10\n",
    "    min_temp_acc=10\n",
    "    max_temp_loss=0\n",
    "    max_temp_acc=0\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        if (np.min(evaluation[idx].history['loss'])<min_temp_loss):\n",
    "            min_temp_loss=np.min(evaluation[idx].history['loss'])\n",
    "        if (np.min(evaluation[idx].history['val_loss'])<min_temp_loss):\n",
    "            min_temp_loss=np.min(evaluation[idx].history['val_loss'])\n",
    "        if (np.max(evaluation[idx].history['loss'])>max_temp_loss):\n",
    "            max_temp_loss=np.max(evaluation[idx].history['loss'])\n",
    "        if (np.max(evaluation[idx].history['val_loss'])>max_temp_loss):\n",
    "            max_temp_loss=np.max(evaluation[idx].history['val_loss'])\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        if (np.min(evaluation[idx].history['accuracy'])<min_temp_acc):\n",
    "            min_temp_acc=np.min(evaluation[idx].history['accuracy'])\n",
    "        if (np.min(evaluation[idx].history['val_accuracy'])<min_temp_acc):\n",
    "            min_temp_acc=np.min(evaluation[idx].history['val_accuracy'])\n",
    "        if (np.max(evaluation[idx].history['accuracy'])>max_temp_acc):\n",
    "            max_temp_acc=np.max(evaluation[idx].history['accuracy'])\n",
    "        if (np.max(evaluation[idx].history['val_accuracy'])>max_temp_acc):\n",
    "            max_temp_acc=np.max(evaluation[idx].history['val_accuracy'])\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        loss_vec_train= evaluation[idx].history['loss']\n",
    "        loss_vec_test= evaluation[idx].history['val_loss']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epoch_vec,loss_vec_test,'b-', label= 'test');\n",
    "        plt.plot(epoch_vec,loss_vec_train,'r-', label='train');\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss across epochs for fold: '+str(idx))\n",
    "        plt.ylim([min_temp_loss, max_temp_loss])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(dir1+\"/loss_kfold_\"+str(idx))\n",
    "        plt.close()\n",
    "\n",
    "    #plot accuracy and loss function across epochs\n",
    "    epoch_vec=np.linspace(1,EPOCHS,EPOCHS)\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        loss_vec_train= evaluation[idx].history['accuracy']\n",
    "        loss_vec_test= evaluation[idx].history['val_accuracy']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epoch_vec,loss_vec_test,'b-', label= 'test');\n",
    "        plt.plot(epoch_vec,loss_vec_train,'r-', label='train');\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy across epochs for fold: '+str(idx))\n",
    "        plt.ylim([min_temp_acc, max_temp_acc])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(dir1+\"/accuracy_kfold_\"+str(idx))\n",
    "        plt.close()\n",
    "\n",
    "    #SALVO VARIABILI STATISTICHE E MODELLO IN MODO DA PLOTTARLO\n",
    "\n",
    "#         acc_temp=[]\n",
    "    accuratezza=np.zeros(n_classes*2)\n",
    "#         for idx in range(n_folds):\n",
    "#             acc_temp.append(PERFORMANCE[idx][\"accuracy\"])\n",
    "    accuratezza[0]=(np.mean(validation_acc))\n",
    "    accuratezza[1]=(statistics.pstdev(validation_acc))\n",
    "\n",
    "\n",
    "    precisione=[]\n",
    "    recall=[]\n",
    "    f1_score=[]\n",
    "    support=[]\n",
    "    for classe in range(numero_classi):\n",
    "        precision_temp=[]\n",
    "        recall_temp=[]\n",
    "        f1_score_temp=[]\n",
    "        support_temp=[]\n",
    "        for idx in range(n_folds):\n",
    "            precision_temp.append(PERFORMANCE[idx][str(classe)][\"precision\"])\n",
    "            recall_temp.append(PERFORMANCE[idx][str(classe)][\"recall\"])\n",
    "            f1_score_temp.append(PERFORMANCE[idx][str(classe)][\"f1-score\"])\n",
    "            support_temp.append(PERFORMANCE[idx][str(classe)][\"support\"])\n",
    "\n",
    "        precisione.append(np.mean(precision_temp))\n",
    "        precisione.append(statistics.pstdev(precision_temp))\n",
    "        recall.append(np.mean(recall_temp))\n",
    "        recall.append(statistics.pstdev(recall_temp))\n",
    "        f1_score.append(np.mean(f1_score_temp))\n",
    "        f1_score.append(statistics.pstdev(f1_score_temp))    \n",
    "        support.append(np.mean(support_temp))\n",
    "        support.append(statistics.pstdev(support_temp)) \n",
    "\n",
    "    sommario=[]\n",
    "    sommario=np.vstack((accuratezza,precisione,recall,f1_score,support))\n",
    "    sio.savemat(dir0+\"/sommario.mat\", {\"array\": sommario})\n",
    "\n",
    "    gianfranco=model.predict(X)\n",
    "    gianfranco2=np.argmax(gianfranco, axis=1)\n",
    "    sio.savemat(dir0+\"/predizione_totale.mat\", {\"array\": gianfranco2})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2f93996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_CLASSES: 2\n",
      "New shape for X: (4080, 31, 251, 1)\n",
      "New shape for y: (4080,)\n",
      "Train index for this split: [   0    1    3 ... 4077 4078 4079]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   2   10   16   18   21   23   28   29   32   36   38   39   40   42\n",
      "   43   58   65   72   75   76   86   87   88   99  102  103  110  117\n",
      "  124  128  133  136  137  142  153  155  157  159  160  169  190  193\n",
      "  200  204  209  210  212  215  216  217  219  221  224  232  244  258\n",
      "  259  267  269  270  278  282  286  292  297  303  304  309  311  316\n",
      "  319  324  328  332  333  335  342  346  347  351  360  362  365  369\n",
      "  375  383  392  394  395  398  401  403  405  406  423  430  452  453\n",
      "  455  457  459  465  467  469  480  484  487  490  497  504  512  513\n",
      "  521  522  525  527  533  537  542  546  553  554  558  564  568  571\n",
      "  574  575  579  581  592  601  607  615  616  622  637  642  646  657\n",
      "  659  662  664  665  676  679  685  693  698  701  705  713  715  719\n",
      "  721  730  731  732  742  743  746  748  754  756  759  766  769  786\n",
      "  789  795  797  801  808  812  816  817  818  824  842  853  854  859\n",
      "  861  862  864  868  874  876  879  890  904  912  913  915  916  920\n",
      "  924  927  934  945  949  950  957  960  964  966  976  978  983  991\n",
      " 1002 1005 1007 1013 1016 1021 1043 1049 1057 1058 1059 1061 1065 1068\n",
      " 1069 1071 1075 1081 1090 1092 1097 1100 1104 1111 1112 1116 1121 1125\n",
      " 1130 1134 1139 1143 1145 1149 1151 1152 1158 1170 1181 1182 1187 1189\n",
      " 1196 1198 1201 1202 1211 1213 1215 1216 1219 1220 1221 1225 1235 1240\n",
      " 1242 1247 1256 1259 1261 1268 1271 1273 1274 1276 1279 1290 1293 1298\n",
      " 1300 1316 1317 1328 1331 1333 1343 1347 1369 1376 1380 1381 1383 1384\n",
      " 1385 1389 1390 1391 1392 1393 1404 1411 1412 1416 1429 1432 1435 1436\n",
      " 1445 1449 1454 1474 1483 1485 1489 1491 1495 1496 1502 1505 1518 1536\n",
      " 1541 1549 1553 1555 1556 1557 1558 1561 1564 1565 1566 1570 1571 1581\n",
      " 1584 1585 1602 1603 1604 1612 1627 1628 1633 1643 1652 1655 1662 1671\n",
      " 1673 1683 1684 1696 1701 1714 1718 1730 1737 1746 1753 1761 1762 1779\n",
      " 1788 1790 1793 1794 1802 1804 1810 1811 1819 1822 1828 1829 1833 1836\n",
      " 1839 1840 1853 1854 1859 1863 1869 1870 1873 1880 1882 1886 1897 1908\n",
      " 1916 1918 1937 1941 1943 1948 1950 1955 1957 1982 1988 1996 2006 2010\n",
      " 2014 2016 2018 2020 2030 2034 2041 2042 2044 2058 2060 2061 2063 2065\n",
      " 2069 2073 2084 2085 2090 2092 2093 2094 2098 2102 2107 2110 2115 2120\n",
      " 2127 2131 2141 2145 2147 2149 2157 2161 2174 2179 2185 2188 2190 2194\n",
      " 2195 2201 2204 2210 2224 2226 2228 2229 2264 2266 2270 2272 2276 2278\n",
      " 2279 2283 2294 2299 2300 2301 2312 2314 2320 2321 2324 2327 2330 2336\n",
      " 2339 2341 2350 2357 2359 2362 2363 2364 2368 2375 2378 2383 2385 2396\n",
      " 2408 2414 2417 2419 2422 2423 2427 2428 2431 2443 2444 2448 2456 2457\n",
      " 2459 2466 2478 2482 2486 2487 2491 2501 2503 2508 2509 2511 2512 2513\n",
      " 2519 2531 2534 2553 2557 2560 2566 2567 2573 2580 2583 2585 2588 2590\n",
      " 2592 2593 2596 2614 2617 2619 2623 2633 2637 2641 2647 2649 2658 2661\n",
      " 2666 2667 2671 2673 2685 2698 2700 2710 2716 2721 2723 2728 2730 2733\n",
      " 2756 2759 2764 2768 2771 2786 2802 2803 2804 2816 2819 2820 2827 2836\n",
      " 2837 2838 2859 2860 2876 2885 2886 2889 2891 2896 2898 2911 2912 2917\n",
      " 2920 2922 2923 2926 2932 2938 2939 2949 2955 2958 2961 2964 2989 2995\n",
      " 2998 3002 3016 3019 3025 3029 3031 3037 3039 3040 3041 3042 3055 3056\n",
      " 3058 3064 3075 3081 3086 3087 3088 3091 3104 3110 3112 3116 3117 3118\n",
      " 3119 3124 3131 3132 3133 3138 3143 3163 3165 3172 3182 3184 3189 3199\n",
      " 3200 3203 3204 3207 3213 3222 3226 3241 3242 3244 3257 3273 3282 3288\n",
      " 3290 3294 3296 3304 3312 3320 3324 3326 3332 3339 3340 3343 3344 3345\n",
      " 3347 3348 3353 3360 3361 3364 3365 3382 3391 3398 3403 3406 3407 3419\n",
      " 3422 3434 3438 3440 3441 3452 3453 3454 3465 3466 3477 3490 3493 3497\n",
      " 3502 3505 3507 3511 3513 3524 3525 3526 3529 3531 3534 3536 3545 3556\n",
      " 3558 3560 3564 3565 3573 3579 3580 3583 3593 3596 3597 3603 3610 3613\n",
      " 3614 3619 3631 3633 3647 3649 3652 3663 3666 3667 3671 3680 3685 3689\n",
      " 3690 3698 3708 3714 3721 3727 3729 3733 3736 3742 3744 3745 3751 3760\n",
      " 3762 3767 3777 3780 3781 3787 3795 3799 3809 3816 3823 3829 3831 3833\n",
      " 3845 3847 3850 3857 3874 3875 3880 3884 3885 3887 3891 3894 3895 3898\n",
      " 3906 3922 3932 3934 3939 3946 3947 3955 3957 3958 3959 3960 3961 3964\n",
      " 3970 3975 3982 3983 3985 3991 4015 4017 4024 4025 4032 4034 4040 4041\n",
      " 4049 4053 4070 4076]\n",
      "Number of samples for test set: 816\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 08:58:25.683467: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_356/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6939 - accuracy: 0.5074 - val_loss: 0.6912 - val_accuracy: 0.5196 - 3s/epoch - 13ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6908 - accuracy: 0.5199 - val_loss: 0.6854 - val_accuracy: 0.5613 - 944ms/epoch - 5ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6698 - accuracy: 0.5809 - val_loss: 0.6605 - val_accuracy: 0.6140 - 947ms/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6456 - accuracy: 0.6333 - val_loss: 0.6526 - val_accuracy: 0.6078 - 963ms/epoch - 5ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6410 - accuracy: 0.6425 - val_loss: 0.6382 - val_accuracy: 0.6483 - 918ms/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6254 - accuracy: 0.6621 - val_loss: 0.6330 - val_accuracy: 0.6458 - 924ms/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6201 - accuracy: 0.6584 - val_loss: 0.6278 - val_accuracy: 0.6507 - 940ms/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6149 - accuracy: 0.6731 - val_loss: 0.6236 - val_accuracy: 0.6605 - 947ms/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6087 - accuracy: 0.6893 - val_loss: 0.6211 - val_accuracy: 0.6679 - 928ms/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.5983 - accuracy: 0.6893 - val_loss: 0.6196 - val_accuracy: 0.6556 - 938ms/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6021 - accuracy: 0.6945 - val_loss: 0.6171 - val_accuracy: 0.6789 - 967ms/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.5960 - accuracy: 0.6985 - val_loss: 0.6178 - val_accuracy: 0.6728 - 988ms/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.5985 - accuracy: 0.6964 - val_loss: 0.6168 - val_accuracy: 0.6618 - 940ms/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.5944 - accuracy: 0.6930 - val_loss: 0.6141 - val_accuracy: 0.6691 - 971ms/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.5909 - accuracy: 0.7022 - val_loss: 0.6092 - val_accuracy: 0.6801 - 937ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.5904 - accuracy: 0.7065 - val_loss: 0.6089 - val_accuracy: 0.6740 - 933ms/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.5826 - accuracy: 0.7169 - val_loss: 0.6096 - val_accuracy: 0.6826 - 957ms/epoch - 5ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.5858 - accuracy: 0.7044 - val_loss: 0.6095 - val_accuracy: 0.6875 - 954ms/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.5731 - accuracy: 0.7105 - val_loss: 0.6040 - val_accuracy: 0.6838 - 953ms/epoch - 5ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.5801 - accuracy: 0.7050 - val_loss: 0.5979 - val_accuracy: 0.6838 - 959ms/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.5700 - accuracy: 0.7142 - val_loss: 0.5954 - val_accuracy: 0.6936 - 933ms/epoch - 5ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.5811 - accuracy: 0.7071 - val_loss: 0.6037 - val_accuracy: 0.6777 - 943ms/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.5745 - accuracy: 0.7194 - val_loss: 0.5975 - val_accuracy: 0.6973 - 971ms/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.5745 - accuracy: 0.7160 - val_loss: 0.6031 - val_accuracy: 0.6838 - 949ms/epoch - 5ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.5665 - accuracy: 0.7197 - val_loss: 0.5978 - val_accuracy: 0.6961 - 932ms/epoch - 5ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.5680 - accuracy: 0.7160 - val_loss: 0.5932 - val_accuracy: 0.6814 - 961ms/epoch - 5ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.5640 - accuracy: 0.7261 - val_loss: 0.5950 - val_accuracy: 0.6875 - 942ms/epoch - 5ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.5639 - accuracy: 0.7148 - val_loss: 0.5995 - val_accuracy: 0.6850 - 953ms/epoch - 5ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.5570 - accuracy: 0.7276 - val_loss: 0.5882 - val_accuracy: 0.7034 - 940ms/epoch - 5ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.5644 - accuracy: 0.7163 - val_loss: 0.5925 - val_accuracy: 0.7083 - 921ms/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.5630 - accuracy: 0.7286 - val_loss: 0.5915 - val_accuracy: 0.7047 - 949ms/epoch - 5ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.5569 - accuracy: 0.7237 - val_loss: 0.5886 - val_accuracy: 0.6912 - 941ms/epoch - 5ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.5542 - accuracy: 0.7405 - val_loss: 0.5898 - val_accuracy: 0.6765 - 963ms/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.5596 - accuracy: 0.7261 - val_loss: 0.5859 - val_accuracy: 0.7022 - 960ms/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.5546 - accuracy: 0.7292 - val_loss: 0.5903 - val_accuracy: 0.7034 - 938ms/epoch - 5ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.5525 - accuracy: 0.7331 - val_loss: 0.5881 - val_accuracy: 0.6936 - 916ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.5528 - accuracy: 0.7233 - val_loss: 0.5873 - val_accuracy: 0.7010 - 951ms/epoch - 5ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.5480 - accuracy: 0.7356 - val_loss: 0.5898 - val_accuracy: 0.6900 - 942ms/epoch - 5ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.5510 - accuracy: 0.7289 - val_loss: 0.5842 - val_accuracy: 0.6887 - 951ms/epoch - 5ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.5401 - accuracy: 0.7362 - val_loss: 0.5936 - val_accuracy: 0.6850 - 961ms/epoch - 5ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.5450 - accuracy: 0.7319 - val_loss: 0.5854 - val_accuracy: 0.7071 - 966ms/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.5409 - accuracy: 0.7377 - val_loss: 0.5827 - val_accuracy: 0.7047 - 966ms/epoch - 5ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.5479 - accuracy: 0.7264 - val_loss: 0.5886 - val_accuracy: 0.6887 - 978ms/epoch - 5ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.5464 - accuracy: 0.7374 - val_loss: 0.5869 - val_accuracy: 0.6936 - 964ms/epoch - 5ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.5417 - accuracy: 0.7371 - val_loss: 0.5882 - val_accuracy: 0.7145 - 939ms/epoch - 5ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.5385 - accuracy: 0.7451 - val_loss: 0.5849 - val_accuracy: 0.6936 - 968ms/epoch - 5ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.5378 - accuracy: 0.7442 - val_loss: 0.5929 - val_accuracy: 0.6900 - 929ms/epoch - 5ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.5428 - accuracy: 0.7347 - val_loss: 0.5874 - val_accuracy: 0.7022 - 940ms/epoch - 5ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.5395 - accuracy: 0.7365 - val_loss: 0.5821 - val_accuracy: 0.7108 - 944ms/epoch - 5ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.5363 - accuracy: 0.7377 - val_loss: 0.5843 - val_accuracy: 0.6961 - 939ms/epoch - 5ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.5288 - accuracy: 0.7521 - val_loss: 0.5891 - val_accuracy: 0.6863 - 944ms/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.5389 - accuracy: 0.7420 - val_loss: 0.5806 - val_accuracy: 0.6961 - 975ms/epoch - 5ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.5331 - accuracy: 0.7457 - val_loss: 0.5812 - val_accuracy: 0.6961 - 941ms/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.5355 - accuracy: 0.7423 - val_loss: 0.5882 - val_accuracy: 0.6875 - 933ms/epoch - 5ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.5364 - accuracy: 0.7439 - val_loss: 0.5809 - val_accuracy: 0.6961 - 964ms/epoch - 5ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.5319 - accuracy: 0.7381 - val_loss: 0.5779 - val_accuracy: 0.7010 - 942ms/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.5318 - accuracy: 0.7451 - val_loss: 0.5843 - val_accuracy: 0.7010 - 880ms/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.5279 - accuracy: 0.7469 - val_loss: 0.5809 - val_accuracy: 0.6949 - 951ms/epoch - 5ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.5343 - accuracy: 0.7528 - val_loss: 0.5843 - val_accuracy: 0.7022 - 966ms/epoch - 5ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.5361 - accuracy: 0.7304 - val_loss: 0.5810 - val_accuracy: 0.6949 - 968ms/epoch - 5ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.5224 - accuracy: 0.7475 - val_loss: 0.5830 - val_accuracy: 0.6912 - 975ms/epoch - 5ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.5259 - accuracy: 0.7506 - val_loss: 0.5798 - val_accuracy: 0.6949 - 970ms/epoch - 5ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.5213 - accuracy: 0.7534 - val_loss: 0.5794 - val_accuracy: 0.6863 - 953ms/epoch - 5ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.5186 - accuracy: 0.7546 - val_loss: 0.5722 - val_accuracy: 0.7010 - 940ms/epoch - 5ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.5244 - accuracy: 0.7417 - val_loss: 0.5788 - val_accuracy: 0.7010 - 964ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.5184 - accuracy: 0.7525 - val_loss: 0.5759 - val_accuracy: 0.7022 - 958ms/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.5291 - accuracy: 0.7426 - val_loss: 0.5786 - val_accuracy: 0.6838 - 946ms/epoch - 5ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.5221 - accuracy: 0.7537 - val_loss: 0.5766 - val_accuracy: 0.6985 - 945ms/epoch - 5ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.5177 - accuracy: 0.7506 - val_loss: 0.5808 - val_accuracy: 0.6936 - 960ms/epoch - 5ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.5236 - accuracy: 0.7494 - val_loss: 0.5655 - val_accuracy: 0.7059 - 958ms/epoch - 5ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.5163 - accuracy: 0.7503 - val_loss: 0.5677 - val_accuracy: 0.7108 - 979ms/epoch - 5ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.5282 - accuracy: 0.7457 - val_loss: 0.5767 - val_accuracy: 0.6949 - 977ms/epoch - 5ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.5245 - accuracy: 0.7515 - val_loss: 0.5753 - val_accuracy: 0.7096 - 953ms/epoch - 5ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.5288 - accuracy: 0.7485 - val_loss: 0.5825 - val_accuracy: 0.6863 - 960ms/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.5270 - accuracy: 0.7466 - val_loss: 0.5779 - val_accuracy: 0.6924 - 961ms/epoch - 5ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.5248 - accuracy: 0.7463 - val_loss: 0.5825 - val_accuracy: 0.6863 - 957ms/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.5153 - accuracy: 0.7555 - val_loss: 0.5785 - val_accuracy: 0.6949 - 886ms/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.5095 - accuracy: 0.7525 - val_loss: 0.5683 - val_accuracy: 0.6949 - 956ms/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.5218 - accuracy: 0.7451 - val_loss: 0.5718 - val_accuracy: 0.7010 - 943ms/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.5152 - accuracy: 0.7472 - val_loss: 0.5733 - val_accuracy: 0.6936 - 944ms/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.5143 - accuracy: 0.7525 - val_loss: 0.5750 - val_accuracy: 0.6900 - 945ms/epoch - 5ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.5160 - accuracy: 0.7503 - val_loss: 0.5751 - val_accuracy: 0.6875 - 967ms/epoch - 5ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.5023 - accuracy: 0.7610 - val_loss: 0.5870 - val_accuracy: 0.6875 - 946ms/epoch - 5ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.5187 - accuracy: 0.7475 - val_loss: 0.5711 - val_accuracy: 0.7071 - 946ms/epoch - 5ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.5164 - accuracy: 0.7546 - val_loss: 0.5716 - val_accuracy: 0.6924 - 946ms/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.5142 - accuracy: 0.7546 - val_loss: 0.5741 - val_accuracy: 0.6924 - 934ms/epoch - 5ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.5247 - accuracy: 0.7423 - val_loss: 0.5748 - val_accuracy: 0.6949 - 943ms/epoch - 5ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.5161 - accuracy: 0.7518 - val_loss: 0.5767 - val_accuracy: 0.6961 - 958ms/epoch - 5ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.5189 - accuracy: 0.7512 - val_loss: 0.5754 - val_accuracy: 0.6985 - 936ms/epoch - 5ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.5039 - accuracy: 0.7592 - val_loss: 0.5716 - val_accuracy: 0.6887 - 923ms/epoch - 5ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.5138 - accuracy: 0.7567 - val_loss: 0.5755 - val_accuracy: 0.7022 - 943ms/epoch - 5ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.5077 - accuracy: 0.7558 - val_loss: 0.5720 - val_accuracy: 0.6998 - 947ms/epoch - 5ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.5225 - accuracy: 0.7485 - val_loss: 0.5754 - val_accuracy: 0.7034 - 953ms/epoch - 5ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.5197 - accuracy: 0.7567 - val_loss: 0.5749 - val_accuracy: 0.7083 - 937ms/epoch - 5ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.5091 - accuracy: 0.7626 - val_loss: 0.5763 - val_accuracy: 0.6998 - 969ms/epoch - 5ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.5085 - accuracy: 0.7577 - val_loss: 0.5783 - val_accuracy: 0.6961 - 959ms/epoch - 5ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.5057 - accuracy: 0.7564 - val_loss: 0.5758 - val_accuracy: 0.6924 - 924ms/epoch - 5ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.5138 - accuracy: 0.7534 - val_loss: 0.5793 - val_accuracy: 0.7047 - 930ms/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.5110 - accuracy: 0.7555 - val_loss: 0.5696 - val_accuracy: 0.6838 - 963ms/epoch - 5ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.5099 - accuracy: 0.7497 - val_loss: 0.5780 - val_accuracy: 0.6985 - 961ms/epoch - 5ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.5024 - accuracy: 0.7540 - val_loss: 0.5695 - val_accuracy: 0.7034 - 984ms/epoch - 5ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.5129 - accuracy: 0.7592 - val_loss: 0.5748 - val_accuracy: 0.6887 - 945ms/epoch - 5ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.5066 - accuracy: 0.7589 - val_loss: 0.5738 - val_accuracy: 0.6973 - 961ms/epoch - 5ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.5010 - accuracy: 0.7583 - val_loss: 0.5743 - val_accuracy: 0.7047 - 973ms/epoch - 5ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.5047 - accuracy: 0.7534 - val_loss: 0.5729 - val_accuracy: 0.6998 - 996ms/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.5139 - accuracy: 0.7512 - val_loss: 0.5702 - val_accuracy: 0.6936 - 971ms/epoch - 5ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.5042 - accuracy: 0.7564 - val_loss: 0.5771 - val_accuracy: 0.6949 - 994ms/epoch - 5ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.5131 - accuracy: 0.7641 - val_loss: 0.5767 - val_accuracy: 0.6912 - 949ms/epoch - 5ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.5059 - accuracy: 0.7534 - val_loss: 0.5682 - val_accuracy: 0.7059 - 965ms/epoch - 5ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.4985 - accuracy: 0.7619 - val_loss: 0.5738 - val_accuracy: 0.6998 - 974ms/epoch - 5ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.5084 - accuracy: 0.7564 - val_loss: 0.5660 - val_accuracy: 0.7059 - 997ms/epoch - 5ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.5046 - accuracy: 0.7623 - val_loss: 0.5684 - val_accuracy: 0.7010 - 991ms/epoch - 5ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.5072 - accuracy: 0.7659 - val_loss: 0.5712 - val_accuracy: 0.7010 - 991ms/epoch - 5ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.5115 - accuracy: 0.7589 - val_loss: 0.5702 - val_accuracy: 0.7010 - 967ms/epoch - 5ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.5050 - accuracy: 0.7537 - val_loss: 0.5637 - val_accuracy: 0.7120 - 979ms/epoch - 5ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.5081 - accuracy: 0.7570 - val_loss: 0.5673 - val_accuracy: 0.7096 - 992ms/epoch - 5ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.5033 - accuracy: 0.7598 - val_loss: 0.5735 - val_accuracy: 0.7059 - 966ms/epoch - 5ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.5085 - accuracy: 0.7531 - val_loss: 0.5679 - val_accuracy: 0.7169 - 934ms/epoch - 5ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.5171 - accuracy: 0.7491 - val_loss: 0.5721 - val_accuracy: 0.7083 - 945ms/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.5062 - accuracy: 0.7607 - val_loss: 0.5668 - val_accuracy: 0.6985 - 960ms/epoch - 5ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.4932 - accuracy: 0.7616 - val_loss: 0.5695 - val_accuracy: 0.7071 - 931ms/epoch - 5ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.4935 - accuracy: 0.7656 - val_loss: 0.5669 - val_accuracy: 0.7047 - 956ms/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.5144 - accuracy: 0.7616 - val_loss: 0.5760 - val_accuracy: 0.6863 - 972ms/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.4991 - accuracy: 0.7678 - val_loss: 0.5715 - val_accuracy: 0.6973 - 959ms/epoch - 5ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.5071 - accuracy: 0.7583 - val_loss: 0.5735 - val_accuracy: 0.6949 - 946ms/epoch - 5ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.5090 - accuracy: 0.7549 - val_loss: 0.5706 - val_accuracy: 0.6949 - 933ms/epoch - 5ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.5015 - accuracy: 0.7662 - val_loss: 0.5729 - val_accuracy: 0.7010 - 978ms/epoch - 5ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.5028 - accuracy: 0.7558 - val_loss: 0.5698 - val_accuracy: 0.7059 - 970ms/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.5022 - accuracy: 0.7549 - val_loss: 0.5663 - val_accuracy: 0.7120 - 916ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.4991 - accuracy: 0.7641 - val_loss: 0.5719 - val_accuracy: 0.6912 - 953ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.5062 - accuracy: 0.7534 - val_loss: 0.5727 - val_accuracy: 0.7059 - 948ms/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.4969 - accuracy: 0.7696 - val_loss: 0.5701 - val_accuracy: 0.7022 - 960ms/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.5006 - accuracy: 0.7604 - val_loss: 0.5794 - val_accuracy: 0.6973 - 963ms/epoch - 5ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.4964 - accuracy: 0.7641 - val_loss: 0.5729 - val_accuracy: 0.7083 - 917ms/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.5095 - accuracy: 0.7586 - val_loss: 0.5820 - val_accuracy: 0.7034 - 927ms/epoch - 5ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.5034 - accuracy: 0.7684 - val_loss: 0.5735 - val_accuracy: 0.6924 - 915ms/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.5056 - accuracy: 0.7656 - val_loss: 0.5746 - val_accuracy: 0.7083 - 935ms/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.4920 - accuracy: 0.7733 - val_loss: 0.5671 - val_accuracy: 0.7034 - 968ms/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.4989 - accuracy: 0.7632 - val_loss: 0.5681 - val_accuracy: 0.7096 - 959ms/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.5047 - accuracy: 0.7626 - val_loss: 0.5700 - val_accuracy: 0.7108 - 941ms/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.4967 - accuracy: 0.7595 - val_loss: 0.5718 - val_accuracy: 0.7010 - 955ms/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.5021 - accuracy: 0.7638 - val_loss: 0.5744 - val_accuracy: 0.7010 - 936ms/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.4927 - accuracy: 0.7662 - val_loss: 0.5695 - val_accuracy: 0.6961 - 941ms/epoch - 5ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.4936 - accuracy: 0.7632 - val_loss: 0.5779 - val_accuracy: 0.6887 - 959ms/epoch - 5ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.5039 - accuracy: 0.7598 - val_loss: 0.5624 - val_accuracy: 0.7047 - 934ms/epoch - 5ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.5068 - accuracy: 0.7567 - val_loss: 0.5822 - val_accuracy: 0.6875 - 865ms/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.4987 - accuracy: 0.7702 - val_loss: 0.5735 - val_accuracy: 0.6985 - 952ms/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.5050 - accuracy: 0.7540 - val_loss: 0.5678 - val_accuracy: 0.7096 - 933ms/epoch - 5ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.4942 - accuracy: 0.7693 - val_loss: 0.5773 - val_accuracy: 0.6850 - 954ms/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.4929 - accuracy: 0.7675 - val_loss: 0.5779 - val_accuracy: 0.6949 - 937ms/epoch - 5ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.4997 - accuracy: 0.7669 - val_loss: 0.5693 - val_accuracy: 0.6985 - 960ms/epoch - 5ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.4926 - accuracy: 0.7669 - val_loss: 0.5663 - val_accuracy: 0.7120 - 927ms/epoch - 5ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.4973 - accuracy: 0.7748 - val_loss: 0.5670 - val_accuracy: 0.7047 - 964ms/epoch - 5ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.4975 - accuracy: 0.7641 - val_loss: 0.5685 - val_accuracy: 0.7010 - 965ms/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.4915 - accuracy: 0.7721 - val_loss: 0.5668 - val_accuracy: 0.7022 - 918ms/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.4932 - accuracy: 0.7653 - val_loss: 0.5725 - val_accuracy: 0.6949 - 938ms/epoch - 5ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.5020 - accuracy: 0.7531 - val_loss: 0.5773 - val_accuracy: 0.6875 - 953ms/epoch - 5ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.5058 - accuracy: 0.7488 - val_loss: 0.5650 - val_accuracy: 0.7132 - 939ms/epoch - 5ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.4936 - accuracy: 0.7684 - val_loss: 0.5730 - val_accuracy: 0.6887 - 925ms/epoch - 5ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.4979 - accuracy: 0.7644 - val_loss: 0.5743 - val_accuracy: 0.7096 - 932ms/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.5065 - accuracy: 0.7570 - val_loss: 0.5697 - val_accuracy: 0.6961 - 952ms/epoch - 5ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.4897 - accuracy: 0.7613 - val_loss: 0.5620 - val_accuracy: 0.6973 - 944ms/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.4945 - accuracy: 0.7672 - val_loss: 0.5692 - val_accuracy: 0.7047 - 959ms/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.4969 - accuracy: 0.7583 - val_loss: 0.5728 - val_accuracy: 0.6936 - 961ms/epoch - 5ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.4900 - accuracy: 0.7760 - val_loss: 0.5671 - val_accuracy: 0.7120 - 961ms/epoch - 5ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.5109 - accuracy: 0.7595 - val_loss: 0.5662 - val_accuracy: 0.6998 - 911ms/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.4888 - accuracy: 0.7736 - val_loss: 0.5654 - val_accuracy: 0.7047 - 956ms/epoch - 5ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.5138 - accuracy: 0.7503 - val_loss: 0.5650 - val_accuracy: 0.7071 - 959ms/epoch - 5ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.4902 - accuracy: 0.7616 - val_loss: 0.5697 - val_accuracy: 0.7083 - 980ms/epoch - 5ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.4872 - accuracy: 0.7714 - val_loss: 0.5670 - val_accuracy: 0.7083 - 976ms/epoch - 5ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.4901 - accuracy: 0.7672 - val_loss: 0.5796 - val_accuracy: 0.6936 - 956ms/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.4920 - accuracy: 0.7659 - val_loss: 0.5759 - val_accuracy: 0.7059 - 975ms/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.4930 - accuracy: 0.7690 - val_loss: 0.5634 - val_accuracy: 0.7034 - 970ms/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.4905 - accuracy: 0.7708 - val_loss: 0.5722 - val_accuracy: 0.6985 - 961ms/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.5030 - accuracy: 0.7580 - val_loss: 0.5750 - val_accuracy: 0.6961 - 952ms/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.5000 - accuracy: 0.7690 - val_loss: 0.5711 - val_accuracy: 0.6912 - 962ms/epoch - 5ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.5064 - accuracy: 0.7619 - val_loss: 0.5870 - val_accuracy: 0.6961 - 949ms/epoch - 5ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.4964 - accuracy: 0.7672 - val_loss: 0.5765 - val_accuracy: 0.6924 - 952ms/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.4953 - accuracy: 0.7635 - val_loss: 0.5727 - val_accuracy: 0.6936 - 970ms/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.4745 - accuracy: 0.7684 - val_loss: 0.5796 - val_accuracy: 0.7010 - 960ms/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.4933 - accuracy: 0.7638 - val_loss: 0.5651 - val_accuracy: 0.7157 - 962ms/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.4953 - accuracy: 0.7626 - val_loss: 0.5685 - val_accuracy: 0.7071 - 974ms/epoch - 5ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.4942 - accuracy: 0.7632 - val_loss: 0.5772 - val_accuracy: 0.7047 - 954ms/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.4930 - accuracy: 0.7659 - val_loss: 0.5825 - val_accuracy: 0.6789 - 954ms/epoch - 5ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.4853 - accuracy: 0.7641 - val_loss: 0.5678 - val_accuracy: 0.7047 - 933ms/epoch - 5ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.4970 - accuracy: 0.7619 - val_loss: 0.5723 - val_accuracy: 0.7010 - 952ms/epoch - 5ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.4927 - accuracy: 0.7632 - val_loss: 0.5766 - val_accuracy: 0.6936 - 965ms/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.4874 - accuracy: 0.7662 - val_loss: 0.5839 - val_accuracy: 0.6789 - 953ms/epoch - 5ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.4939 - accuracy: 0.7675 - val_loss: 0.5704 - val_accuracy: 0.6936 - 950ms/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.4914 - accuracy: 0.7702 - val_loss: 0.5799 - val_accuracy: 0.6936 - 946ms/epoch - 5ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.4905 - accuracy: 0.7736 - val_loss: 0.5649 - val_accuracy: 0.7059 - 966ms/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.4932 - accuracy: 0.7632 - val_loss: 0.5691 - val_accuracy: 0.6961 - 935ms/epoch - 5ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.4923 - accuracy: 0.7638 - val_loss: 0.5743 - val_accuracy: 0.6887 - 921ms/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.4996 - accuracy: 0.7601 - val_loss: 0.5728 - val_accuracy: 0.6961 - 944ms/epoch - 5ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.4897 - accuracy: 0.7638 - val_loss: 0.5828 - val_accuracy: 0.6949 - 963ms/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.4922 - accuracy: 0.7601 - val_loss: 0.5698 - val_accuracy: 0.6985 - 948ms/epoch - 5ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.4906 - accuracy: 0.7613 - val_loss: 0.5710 - val_accuracy: 0.7083 - 949ms/epoch - 5ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.4957 - accuracy: 0.7656 - val_loss: 0.5755 - val_accuracy: 0.6887 - 927ms/epoch - 5ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.4942 - accuracy: 0.7681 - val_loss: 0.5730 - val_accuracy: 0.6924 - 936ms/epoch - 5ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.4907 - accuracy: 0.7665 - val_loss: 0.5753 - val_accuracy: 0.7047 - 958ms/epoch - 5ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.5008 - accuracy: 0.7626 - val_loss: 0.5722 - val_accuracy: 0.6973 - 953ms/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.4881 - accuracy: 0.7650 - val_loss: 0.5745 - val_accuracy: 0.6936 - 962ms/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.4864 - accuracy: 0.7721 - val_loss: 0.5675 - val_accuracy: 0.7034 - 963ms/epoch - 5ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.4886 - accuracy: 0.7699 - val_loss: 0.5701 - val_accuracy: 0.6936 - 934ms/epoch - 5ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.4895 - accuracy: 0.7696 - val_loss: 0.5794 - val_accuracy: 0.6924 - 974ms/epoch - 5ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.4993 - accuracy: 0.7632 - val_loss: 0.5802 - val_accuracy: 0.6838 - 944ms/epoch - 5ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.4865 - accuracy: 0.7705 - val_loss: 0.5697 - val_accuracy: 0.7120 - 938ms/epoch - 5ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.4893 - accuracy: 0.7675 - val_loss: 0.5740 - val_accuracy: 0.6985 - 971ms/epoch - 5ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.4920 - accuracy: 0.7659 - val_loss: 0.5741 - val_accuracy: 0.7034 - 972ms/epoch - 5ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.4925 - accuracy: 0.7635 - val_loss: 0.5728 - val_accuracy: 0.7022 - 953ms/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.4979 - accuracy: 0.7604 - val_loss: 0.5627 - val_accuracy: 0.7145 - 927ms/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.4888 - accuracy: 0.7745 - val_loss: 0.5661 - val_accuracy: 0.7181 - 949ms/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.4885 - accuracy: 0.7714 - val_loss: 0.5719 - val_accuracy: 0.6985 - 979ms/epoch - 5ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.4834 - accuracy: 0.7635 - val_loss: 0.5747 - val_accuracy: 0.6900 - 974ms/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.4893 - accuracy: 0.7672 - val_loss: 0.5719 - val_accuracy: 0.6924 - 946ms/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.5021 - accuracy: 0.7598 - val_loss: 0.5728 - val_accuracy: 0.6936 - 960ms/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.4916 - accuracy: 0.7619 - val_loss: 0.5739 - val_accuracy: 0.7022 - 933ms/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.4869 - accuracy: 0.7684 - val_loss: 0.5707 - val_accuracy: 0.7022 - 958ms/epoch - 5ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.4903 - accuracy: 0.7638 - val_loss: 0.5754 - val_accuracy: 0.6912 - 958ms/epoch - 5ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.4822 - accuracy: 0.7779 - val_loss: 0.5798 - val_accuracy: 0.6961 - 951ms/epoch - 5ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.4842 - accuracy: 0.7788 - val_loss: 0.5645 - val_accuracy: 0.7120 - 958ms/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.4904 - accuracy: 0.7656 - val_loss: 0.5768 - val_accuracy: 0.6949 - 939ms/epoch - 5ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.4824 - accuracy: 0.7702 - val_loss: 0.5733 - val_accuracy: 0.6973 - 933ms/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.4853 - accuracy: 0.7678 - val_loss: 0.5738 - val_accuracy: 0.7022 - 889ms/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.4894 - accuracy: 0.7714 - val_loss: 0.5659 - val_accuracy: 0.7096 - 939ms/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.4885 - accuracy: 0.7675 - val_loss: 0.5673 - val_accuracy: 0.7010 - 975ms/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.4767 - accuracy: 0.7754 - val_loss: 0.5761 - val_accuracy: 0.6949 - 944ms/epoch - 5ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.4928 - accuracy: 0.7592 - val_loss: 0.5744 - val_accuracy: 0.6985 - 946ms/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.4881 - accuracy: 0.7635 - val_loss: 0.5747 - val_accuracy: 0.7071 - 901ms/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.5030 - accuracy: 0.7589 - val_loss: 0.5661 - val_accuracy: 0.7010 - 967ms/epoch - 5ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.4864 - accuracy: 0.7659 - val_loss: 0.5836 - val_accuracy: 0.6912 - 983ms/epoch - 5ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.4818 - accuracy: 0.7751 - val_loss: 0.5809 - val_accuracy: 0.6838 - 977ms/epoch - 5ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.4807 - accuracy: 0.7754 - val_loss: 0.5733 - val_accuracy: 0.6900 - 976ms/epoch - 5ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.4904 - accuracy: 0.7619 - val_loss: 0.5761 - val_accuracy: 0.7010 - 955ms/epoch - 5ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.4866 - accuracy: 0.7791 - val_loss: 0.5766 - val_accuracy: 0.6924 - 943ms/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.4931 - accuracy: 0.7604 - val_loss: 0.5658 - val_accuracy: 0.7059 - 926ms/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.4855 - accuracy: 0.7702 - val_loss: 0.5808 - val_accuracy: 0.6924 - 954ms/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.4905 - accuracy: 0.7626 - val_loss: 0.5811 - val_accuracy: 0.6973 - 961ms/epoch - 5ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.4774 - accuracy: 0.7763 - val_loss: 0.5723 - val_accuracy: 0.6936 - 951ms/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.4878 - accuracy: 0.7718 - val_loss: 0.5872 - val_accuracy: 0.6740 - 956ms/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.4911 - accuracy: 0.7693 - val_loss: 0.5723 - val_accuracy: 0.6973 - 935ms/epoch - 5ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.4886 - accuracy: 0.7718 - val_loss: 0.5814 - val_accuracy: 0.6936 - 983ms/epoch - 5ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.4975 - accuracy: 0.7525 - val_loss: 0.5695 - val_accuracy: 0.7132 - 962ms/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.4885 - accuracy: 0.7662 - val_loss: 0.5807 - val_accuracy: 0.6900 - 974ms/epoch - 5ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.4899 - accuracy: 0.7718 - val_loss: 0.5742 - val_accuracy: 0.7059 - 946ms/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.4967 - accuracy: 0.7650 - val_loss: 0.5772 - val_accuracy: 0.7059 - 950ms/epoch - 5ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.4912 - accuracy: 0.7672 - val_loss: 0.5730 - val_accuracy: 0.7083 - 963ms/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.4875 - accuracy: 0.7727 - val_loss: 0.5783 - val_accuracy: 0.6900 - 920ms/epoch - 5ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.4871 - accuracy: 0.7638 - val_loss: 0.5830 - val_accuracy: 0.6912 - 951ms/epoch - 5ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.4839 - accuracy: 0.7669 - val_loss: 0.5705 - val_accuracy: 0.6985 - 960ms/epoch - 5ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "Train index for this split: [   0    1    2 ... 4074 4076 4079]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   4   12   14   19   35   44   46   54   68   71   85   91  109  116\n",
      "  118  119  123  125  127  139  146  162  171  172  174  184  187  188\n",
      "  195  201  213  242  254  265  266  271  272  273  275  276  279  284\n",
      "  287  293  294  295  305  310  315  340  350  358  367  368  370  371\n",
      "  374  384  387  391  393  396  399  404  407  410  413  416  418  419\n",
      "  420  425  428  441  450  451  458  466  475  482  492  494  500  505\n",
      "  507  511  523  528  535  540  548  550  551  552  555  556  557  566\n",
      "  584  590  595  596  597  598  602  606  611  617  621  623  624  632\n",
      "  633  635  647  649  658  660  666  668  669  672  675  677  684  694\n",
      "  695  697  703  706  707  708  710  712  717  718  724  726  727  734\n",
      "  736  738  740  770  774  784  787  791  794  802  809  811  819  826\n",
      "  832  835  836  847  851  856  860  871  875  882  885  891  899  901\n",
      "  909  911  921  925  930  937  939  942  944  946  947  948  956  965\n",
      "  968  969  971  977  979  984  988  996  997 1006 1008 1012 1017 1018\n",
      " 1019 1023 1040 1051 1054 1066 1070 1074 1076 1078 1082 1087 1089 1091\n",
      " 1103 1108 1113 1120 1126 1127 1147 1156 1161 1166 1177 1186 1194 1200\n",
      " 1204 1209 1210 1214 1223 1227 1228 1233 1237 1248 1257 1260 1264 1267\n",
      " 1270 1275 1280 1294 1296 1297 1299 1302 1312 1313 1314 1321 1323 1339\n",
      " 1342 1345 1346 1348 1354 1355 1360 1362 1365 1371 1377 1378 1386 1396\n",
      " 1397 1407 1418 1422 1434 1438 1439 1447 1450 1457 1460 1462 1467 1468\n",
      " 1469 1472 1476 1479 1484 1492 1493 1497 1499 1501 1504 1520 1523 1526\n",
      " 1528 1532 1542 1543 1544 1545 1547 1548 1560 1562 1574 1577 1586 1587\n",
      " 1594 1598 1601 1607 1629 1631 1634 1635 1636 1638 1639 1641 1647 1648\n",
      " 1656 1660 1661 1664 1668 1670 1678 1679 1690 1693 1702 1703 1705 1706\n",
      " 1709 1711 1713 1720 1721 1724 1728 1732 1735 1738 1741 1743 1750 1752\n",
      " 1760 1763 1764 1771 1774 1777 1778 1782 1786 1791 1801 1803 1812 1818\n",
      " 1826 1830 1838 1842 1843 1846 1849 1856 1860 1865 1866 1872 1884 1899\n",
      " 1909 1917 1932 1938 1946 1954 1962 1968 1969 1974 1978 1979 1983 1984\n",
      " 1985 1991 1994 1995 2005 2013 2015 2023 2035 2039 2043 2046 2054 2067\n",
      " 2068 2072 2075 2077 2078 2079 2097 2101 2111 2116 2117 2123 2125 2132\n",
      " 2142 2143 2144 2151 2152 2155 2166 2175 2176 2178 2180 2192 2200 2203\n",
      " 2213 2217 2220 2227 2231 2236 2237 2244 2247 2248 2249 2259 2261 2275\n",
      " 2286 2289 2290 2295 2297 2302 2305 2313 2318 2323 2325 2326 2338 2348\n",
      " 2349 2360 2367 2370 2372 2376 2381 2384 2386 2388 2398 2404 2405 2411\n",
      " 2412 2424 2429 2436 2438 2439 2440 2451 2453 2460 2469 2470 2473 2474\n",
      " 2475 2477 2490 2500 2518 2520 2522 2528 2533 2535 2538 2548 2551 2552\n",
      " 2556 2564 2568 2582 2584 2595 2599 2600 2603 2606 2609 2620 2622 2635\n",
      " 2638 2652 2657 2662 2665 2674 2675 2678 2679 2689 2691 2692 2693 2697\n",
      " 2701 2703 2712 2714 2725 2736 2743 2746 2747 2750 2757 2763 2772 2777\n",
      " 2781 2798 2814 2833 2834 2845 2851 2856 2863 2869 2873 2874 2878 2887\n",
      " 2888 2902 2905 2907 2908 2909 2910 2914 2915 2937 2950 2951 2960 2963\n",
      " 2976 2978 2987 2990 2991 2993 2996 3005 3006 3018 3026 3033 3034 3046\n",
      " 3047 3049 3057 3061 3062 3071 3072 3073 3077 3083 3090 3095 3097 3100\n",
      " 3101 3115 3121 3125 3140 3146 3147 3148 3158 3160 3173 3177 3178 3180\n",
      " 3185 3188 3190 3192 3196 3197 3198 3212 3216 3229 3236 3243 3253 3255\n",
      " 3258 3263 3266 3275 3277 3285 3287 3291 3302 3305 3306 3307 3308 3313\n",
      " 3327 3334 3346 3350 3358 3366 3368 3369 3371 3383 3384 3386 3395 3396\n",
      " 3410 3411 3416 3421 3435 3436 3443 3444 3446 3447 3449 3455 3461 3468\n",
      " 3470 3472 3473 3475 3479 3480 3482 3492 3495 3498 3499 3501 3503 3508\n",
      " 3512 3516 3517 3518 3523 3542 3544 3546 3548 3549 3550 3554 3557 3567\n",
      " 3570 3575 3577 3586 3587 3588 3589 3590 3595 3598 3601 3604 3605 3609\n",
      " 3618 3629 3630 3632 3635 3640 3641 3644 3648 3650 3653 3654 3655 3657\n",
      " 3658 3660 3661 3662 3668 3670 3676 3678 3679 3686 3692 3693 3697 3699\n",
      " 3700 3711 3718 3726 3734 3750 3753 3759 3763 3768 3776 3782 3786 3798\n",
      " 3808 3813 3822 3832 3841 3842 3843 3844 3855 3858 3862 3863 3867 3878\n",
      " 3881 3890 3900 3904 3909 3913 3915 3918 3919 3926 3929 3944 3948 3950\n",
      " 3952 3968 3971 3978 3987 3988 3994 3997 3999 4001 4004 4008 4010 4011\n",
      " 4014 4018 4020 4022 4035 4036 4037 4042 4044 4051 4054 4059 4060 4063\n",
      " 4066 4075 4077 4078]\n",
      "Number of samples for test set: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:02:27.084176: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_357/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6946 - accuracy: 0.5119 - val_loss: 0.6885 - val_accuracy: 0.5196 - 3s/epoch - 12ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6878 - accuracy: 0.5487 - val_loss: 0.6751 - val_accuracy: 0.6054 - 927ms/epoch - 5ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6696 - accuracy: 0.5907 - val_loss: 0.6422 - val_accuracy: 0.6446 - 933ms/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6465 - accuracy: 0.6403 - val_loss: 0.6308 - val_accuracy: 0.6630 - 936ms/epoch - 5ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6348 - accuracy: 0.6458 - val_loss: 0.6226 - val_accuracy: 0.6765 - 960ms/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6318 - accuracy: 0.6532 - val_loss: 0.6178 - val_accuracy: 0.6826 - 970ms/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6285 - accuracy: 0.6566 - val_loss: 0.6122 - val_accuracy: 0.6850 - 949ms/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6221 - accuracy: 0.6664 - val_loss: 0.6147 - val_accuracy: 0.6850 - 948ms/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6224 - accuracy: 0.6703 - val_loss: 0.6068 - val_accuracy: 0.6973 - 958ms/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.6193 - accuracy: 0.6743 - val_loss: 0.6064 - val_accuracy: 0.6924 - 939ms/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6135 - accuracy: 0.6765 - val_loss: 0.6075 - val_accuracy: 0.6838 - 954ms/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.6104 - accuracy: 0.6860 - val_loss: 0.6027 - val_accuracy: 0.6875 - 934ms/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.6061 - accuracy: 0.6743 - val_loss: 0.5998 - val_accuracy: 0.7047 - 946ms/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.6053 - accuracy: 0.6850 - val_loss: 0.6023 - val_accuracy: 0.6985 - 957ms/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.6100 - accuracy: 0.6716 - val_loss: 0.5991 - val_accuracy: 0.6887 - 954ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.6051 - accuracy: 0.6829 - val_loss: 0.5976 - val_accuracy: 0.6924 - 934ms/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.6038 - accuracy: 0.6896 - val_loss: 0.5937 - val_accuracy: 0.6998 - 952ms/epoch - 5ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.6009 - accuracy: 0.6835 - val_loss: 0.5979 - val_accuracy: 0.6961 - 963ms/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.5935 - accuracy: 0.6887 - val_loss: 0.5926 - val_accuracy: 0.7108 - 958ms/epoch - 5ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.5996 - accuracy: 0.6832 - val_loss: 0.5931 - val_accuracy: 0.7010 - 929ms/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.5953 - accuracy: 0.6921 - val_loss: 0.5928 - val_accuracy: 0.7059 - 938ms/epoch - 5ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.5887 - accuracy: 0.6988 - val_loss: 0.5875 - val_accuracy: 0.7169 - 925ms/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.5868 - accuracy: 0.7007 - val_loss: 0.5812 - val_accuracy: 0.7181 - 941ms/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.5783 - accuracy: 0.7181 - val_loss: 0.5798 - val_accuracy: 0.7108 - 949ms/epoch - 5ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.5797 - accuracy: 0.7016 - val_loss: 0.5819 - val_accuracy: 0.7181 - 935ms/epoch - 5ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.5733 - accuracy: 0.7163 - val_loss: 0.5889 - val_accuracy: 0.7022 - 931ms/epoch - 5ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.5855 - accuracy: 0.7025 - val_loss: 0.5859 - val_accuracy: 0.7034 - 911ms/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.5750 - accuracy: 0.7123 - val_loss: 0.5841 - val_accuracy: 0.7010 - 947ms/epoch - 5ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.5732 - accuracy: 0.7089 - val_loss: 0.5800 - val_accuracy: 0.7022 - 942ms/epoch - 5ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.5756 - accuracy: 0.7120 - val_loss: 0.5775 - val_accuracy: 0.7071 - 968ms/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.5731 - accuracy: 0.7138 - val_loss: 0.5777 - val_accuracy: 0.7034 - 940ms/epoch - 5ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.5673 - accuracy: 0.7184 - val_loss: 0.5789 - val_accuracy: 0.7096 - 950ms/epoch - 5ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.5642 - accuracy: 0.7163 - val_loss: 0.5721 - val_accuracy: 0.7096 - 937ms/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.5632 - accuracy: 0.7191 - val_loss: 0.5719 - val_accuracy: 0.7022 - 927ms/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.5616 - accuracy: 0.7206 - val_loss: 0.5736 - val_accuracy: 0.7157 - 922ms/epoch - 5ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.5606 - accuracy: 0.7218 - val_loss: 0.5724 - val_accuracy: 0.7108 - 948ms/epoch - 5ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.5599 - accuracy: 0.7286 - val_loss: 0.5644 - val_accuracy: 0.7279 - 939ms/epoch - 5ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.5575 - accuracy: 0.7304 - val_loss: 0.5695 - val_accuracy: 0.7145 - 948ms/epoch - 5ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.5660 - accuracy: 0.7206 - val_loss: 0.5700 - val_accuracy: 0.7243 - 933ms/epoch - 5ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.5532 - accuracy: 0.7233 - val_loss: 0.5742 - val_accuracy: 0.7096 - 957ms/epoch - 5ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.5541 - accuracy: 0.7218 - val_loss: 0.5676 - val_accuracy: 0.7230 - 940ms/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.5510 - accuracy: 0.7319 - val_loss: 0.5641 - val_accuracy: 0.7145 - 926ms/epoch - 5ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.5481 - accuracy: 0.7252 - val_loss: 0.5653 - val_accuracy: 0.7157 - 970ms/epoch - 5ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.5538 - accuracy: 0.7224 - val_loss: 0.5703 - val_accuracy: 0.7034 - 943ms/epoch - 5ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.5487 - accuracy: 0.7230 - val_loss: 0.5771 - val_accuracy: 0.7034 - 934ms/epoch - 5ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.5467 - accuracy: 0.7264 - val_loss: 0.5693 - val_accuracy: 0.7096 - 947ms/epoch - 5ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.5426 - accuracy: 0.7426 - val_loss: 0.5664 - val_accuracy: 0.7145 - 946ms/epoch - 5ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.5515 - accuracy: 0.7313 - val_loss: 0.5655 - val_accuracy: 0.7230 - 945ms/epoch - 5ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.5402 - accuracy: 0.7292 - val_loss: 0.5695 - val_accuracy: 0.7206 - 920ms/epoch - 5ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.5409 - accuracy: 0.7341 - val_loss: 0.5755 - val_accuracy: 0.7145 - 938ms/epoch - 5ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.5440 - accuracy: 0.7279 - val_loss: 0.5728 - val_accuracy: 0.7022 - 954ms/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.5382 - accuracy: 0.7426 - val_loss: 0.5598 - val_accuracy: 0.7292 - 944ms/epoch - 5ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.5379 - accuracy: 0.7365 - val_loss: 0.5644 - val_accuracy: 0.7169 - 938ms/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.5363 - accuracy: 0.7282 - val_loss: 0.5645 - val_accuracy: 0.7194 - 955ms/epoch - 5ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.5369 - accuracy: 0.7417 - val_loss: 0.5708 - val_accuracy: 0.7157 - 928ms/epoch - 5ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.5402 - accuracy: 0.7316 - val_loss: 0.5671 - val_accuracy: 0.7010 - 901ms/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.5446 - accuracy: 0.7347 - val_loss: 0.5630 - val_accuracy: 0.7243 - 888ms/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.5377 - accuracy: 0.7359 - val_loss: 0.5711 - val_accuracy: 0.6961 - 890ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.5421 - accuracy: 0.7310 - val_loss: 0.5570 - val_accuracy: 0.7194 - 899ms/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.5398 - accuracy: 0.7237 - val_loss: 0.5654 - val_accuracy: 0.7194 - 945ms/epoch - 5ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.5378 - accuracy: 0.7417 - val_loss: 0.5651 - val_accuracy: 0.7157 - 932ms/epoch - 5ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.5393 - accuracy: 0.7381 - val_loss: 0.5729 - val_accuracy: 0.7096 - 947ms/epoch - 5ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.5445 - accuracy: 0.7273 - val_loss: 0.5676 - val_accuracy: 0.7132 - 941ms/epoch - 5ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.5322 - accuracy: 0.7463 - val_loss: 0.5663 - val_accuracy: 0.7157 - 913ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.5412 - accuracy: 0.7353 - val_loss: 0.5601 - val_accuracy: 0.7157 - 944ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.5293 - accuracy: 0.7417 - val_loss: 0.5589 - val_accuracy: 0.7120 - 934ms/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.5293 - accuracy: 0.7420 - val_loss: 0.5617 - val_accuracy: 0.7132 - 928ms/epoch - 5ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.5313 - accuracy: 0.7408 - val_loss: 0.5691 - val_accuracy: 0.7047 - 950ms/epoch - 5ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.5350 - accuracy: 0.7371 - val_loss: 0.5652 - val_accuracy: 0.7341 - 966ms/epoch - 5ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.5353 - accuracy: 0.7338 - val_loss: 0.5641 - val_accuracy: 0.7157 - 946ms/epoch - 5ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.5354 - accuracy: 0.7393 - val_loss: 0.5602 - val_accuracy: 0.7279 - 944ms/epoch - 5ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.5303 - accuracy: 0.7451 - val_loss: 0.5572 - val_accuracy: 0.7181 - 934ms/epoch - 5ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.5350 - accuracy: 0.7408 - val_loss: 0.5649 - val_accuracy: 0.7108 - 937ms/epoch - 5ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.5305 - accuracy: 0.7362 - val_loss: 0.5588 - val_accuracy: 0.7206 - 944ms/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.5198 - accuracy: 0.7512 - val_loss: 0.5615 - val_accuracy: 0.7206 - 927ms/epoch - 5ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.5328 - accuracy: 0.7390 - val_loss: 0.5601 - val_accuracy: 0.7206 - 942ms/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.5334 - accuracy: 0.7316 - val_loss: 0.5635 - val_accuracy: 0.6998 - 922ms/epoch - 5ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.5174 - accuracy: 0.7451 - val_loss: 0.5659 - val_accuracy: 0.7083 - 935ms/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.5254 - accuracy: 0.7384 - val_loss: 0.5564 - val_accuracy: 0.7169 - 931ms/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.5252 - accuracy: 0.7488 - val_loss: 0.5595 - val_accuracy: 0.7169 - 959ms/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.5279 - accuracy: 0.7405 - val_loss: 0.5557 - val_accuracy: 0.7230 - 956ms/epoch - 5ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.5241 - accuracy: 0.7417 - val_loss: 0.5658 - val_accuracy: 0.6900 - 932ms/epoch - 5ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.5306 - accuracy: 0.7371 - val_loss: 0.5531 - val_accuracy: 0.7157 - 911ms/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.5210 - accuracy: 0.7521 - val_loss: 0.5515 - val_accuracy: 0.7169 - 934ms/epoch - 5ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.5273 - accuracy: 0.7457 - val_loss: 0.5662 - val_accuracy: 0.7047 - 961ms/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.5224 - accuracy: 0.7518 - val_loss: 0.5670 - val_accuracy: 0.7047 - 946ms/epoch - 5ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.5181 - accuracy: 0.7451 - val_loss: 0.5576 - val_accuracy: 0.7194 - 950ms/epoch - 5ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.5208 - accuracy: 0.7497 - val_loss: 0.5585 - val_accuracy: 0.7132 - 922ms/epoch - 5ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.5302 - accuracy: 0.7479 - val_loss: 0.5617 - val_accuracy: 0.7083 - 940ms/epoch - 5ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.5165 - accuracy: 0.7500 - val_loss: 0.5615 - val_accuracy: 0.7047 - 939ms/epoch - 5ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.5249 - accuracy: 0.7430 - val_loss: 0.5598 - val_accuracy: 0.7169 - 948ms/epoch - 5ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.5178 - accuracy: 0.7451 - val_loss: 0.5588 - val_accuracy: 0.7132 - 940ms/epoch - 5ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.5244 - accuracy: 0.7439 - val_loss: 0.5768 - val_accuracy: 0.7071 - 930ms/epoch - 5ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.5144 - accuracy: 0.7546 - val_loss: 0.5554 - val_accuracy: 0.7181 - 950ms/epoch - 5ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.5197 - accuracy: 0.7509 - val_loss: 0.5653 - val_accuracy: 0.7157 - 965ms/epoch - 5ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.5241 - accuracy: 0.7442 - val_loss: 0.5623 - val_accuracy: 0.7145 - 951ms/epoch - 5ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.5237 - accuracy: 0.7506 - val_loss: 0.5613 - val_accuracy: 0.7206 - 935ms/epoch - 5ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.5104 - accuracy: 0.7518 - val_loss: 0.5556 - val_accuracy: 0.7206 - 932ms/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.5195 - accuracy: 0.7503 - val_loss: 0.5555 - val_accuracy: 0.7034 - 934ms/epoch - 5ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.5212 - accuracy: 0.7457 - val_loss: 0.5589 - val_accuracy: 0.7132 - 928ms/epoch - 5ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.5148 - accuracy: 0.7570 - val_loss: 0.5573 - val_accuracy: 0.7218 - 932ms/epoch - 5ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.5156 - accuracy: 0.7417 - val_loss: 0.5689 - val_accuracy: 0.7022 - 946ms/epoch - 5ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.5153 - accuracy: 0.7531 - val_loss: 0.5567 - val_accuracy: 0.7120 - 918ms/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.5107 - accuracy: 0.7497 - val_loss: 0.5592 - val_accuracy: 0.7206 - 930ms/epoch - 5ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.5195 - accuracy: 0.7457 - val_loss: 0.5633 - val_accuracy: 0.7083 - 923ms/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.5200 - accuracy: 0.7439 - val_loss: 0.5550 - val_accuracy: 0.7218 - 947ms/epoch - 5ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.5186 - accuracy: 0.7509 - val_loss: 0.5618 - val_accuracy: 0.7132 - 939ms/epoch - 5ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.5086 - accuracy: 0.7463 - val_loss: 0.5563 - val_accuracy: 0.7279 - 937ms/epoch - 5ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.5156 - accuracy: 0.7494 - val_loss: 0.5609 - val_accuracy: 0.7083 - 904ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.5103 - accuracy: 0.7613 - val_loss: 0.5597 - val_accuracy: 0.7071 - 916ms/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.5129 - accuracy: 0.7512 - val_loss: 0.5624 - val_accuracy: 0.7120 - 934ms/epoch - 5ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.5152 - accuracy: 0.7494 - val_loss: 0.5660 - val_accuracy: 0.7059 - 934ms/epoch - 5ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.5203 - accuracy: 0.7482 - val_loss: 0.5541 - val_accuracy: 0.7145 - 939ms/epoch - 5ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.5138 - accuracy: 0.7509 - val_loss: 0.5612 - val_accuracy: 0.7120 - 920ms/epoch - 5ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.5107 - accuracy: 0.7570 - val_loss: 0.5565 - val_accuracy: 0.7279 - 942ms/epoch - 5ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.5142 - accuracy: 0.7460 - val_loss: 0.5578 - val_accuracy: 0.7292 - 940ms/epoch - 5ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.5085 - accuracy: 0.7607 - val_loss: 0.5556 - val_accuracy: 0.7230 - 938ms/epoch - 5ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.5095 - accuracy: 0.7561 - val_loss: 0.5544 - val_accuracy: 0.7132 - 950ms/epoch - 5ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.5222 - accuracy: 0.7500 - val_loss: 0.5467 - val_accuracy: 0.7132 - 933ms/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.5098 - accuracy: 0.7598 - val_loss: 0.5555 - val_accuracy: 0.7206 - 947ms/epoch - 5ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.5107 - accuracy: 0.7564 - val_loss: 0.5498 - val_accuracy: 0.7181 - 923ms/epoch - 5ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.5058 - accuracy: 0.7546 - val_loss: 0.5621 - val_accuracy: 0.7059 - 950ms/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.5137 - accuracy: 0.7454 - val_loss: 0.5590 - val_accuracy: 0.7022 - 939ms/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.5087 - accuracy: 0.7534 - val_loss: 0.5581 - val_accuracy: 0.7083 - 896ms/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.5144 - accuracy: 0.7558 - val_loss: 0.5595 - val_accuracy: 0.7169 - 924ms/epoch - 5ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.5051 - accuracy: 0.7518 - val_loss: 0.5630 - val_accuracy: 0.7071 - 923ms/epoch - 5ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.5118 - accuracy: 0.7521 - val_loss: 0.5527 - val_accuracy: 0.7157 - 956ms/epoch - 5ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.5027 - accuracy: 0.7656 - val_loss: 0.5601 - val_accuracy: 0.7132 - 937ms/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.5077 - accuracy: 0.7546 - val_loss: 0.5602 - val_accuracy: 0.6998 - 919ms/epoch - 5ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.5097 - accuracy: 0.7577 - val_loss: 0.5629 - val_accuracy: 0.6936 - 931ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.5062 - accuracy: 0.7629 - val_loss: 0.5607 - val_accuracy: 0.7120 - 928ms/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.5032 - accuracy: 0.7555 - val_loss: 0.5623 - val_accuracy: 0.6949 - 955ms/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.5136 - accuracy: 0.7540 - val_loss: 0.5568 - val_accuracy: 0.7194 - 960ms/epoch - 5ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.5059 - accuracy: 0.7561 - val_loss: 0.5722 - val_accuracy: 0.7145 - 914ms/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.5085 - accuracy: 0.7601 - val_loss: 0.5604 - val_accuracy: 0.7194 - 955ms/epoch - 5ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.5061 - accuracy: 0.7491 - val_loss: 0.5572 - val_accuracy: 0.7157 - 943ms/epoch - 5ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.5089 - accuracy: 0.7497 - val_loss: 0.5569 - val_accuracy: 0.7132 - 952ms/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.5159 - accuracy: 0.7546 - val_loss: 0.5577 - val_accuracy: 0.7096 - 919ms/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.5131 - accuracy: 0.7567 - val_loss: 0.5597 - val_accuracy: 0.7120 - 955ms/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.5126 - accuracy: 0.7567 - val_loss: 0.5598 - val_accuracy: 0.7206 - 933ms/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.5018 - accuracy: 0.7629 - val_loss: 0.5486 - val_accuracy: 0.7145 - 924ms/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.5122 - accuracy: 0.7528 - val_loss: 0.5649 - val_accuracy: 0.7145 - 919ms/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.5040 - accuracy: 0.7525 - val_loss: 0.5499 - val_accuracy: 0.7181 - 940ms/epoch - 5ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.5105 - accuracy: 0.7460 - val_loss: 0.5515 - val_accuracy: 0.7010 - 933ms/epoch - 5ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.5090 - accuracy: 0.7589 - val_loss: 0.5566 - val_accuracy: 0.7243 - 950ms/epoch - 5ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.5115 - accuracy: 0.7479 - val_loss: 0.5621 - val_accuracy: 0.7108 - 938ms/epoch - 5ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.5129 - accuracy: 0.7503 - val_loss: 0.5519 - val_accuracy: 0.7120 - 940ms/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.5034 - accuracy: 0.7546 - val_loss: 0.5602 - val_accuracy: 0.7059 - 948ms/epoch - 5ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.5126 - accuracy: 0.7485 - val_loss: 0.5599 - val_accuracy: 0.7194 - 934ms/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.5010 - accuracy: 0.7638 - val_loss: 0.5586 - val_accuracy: 0.7157 - 951ms/epoch - 5ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.5121 - accuracy: 0.7528 - val_loss: 0.5630 - val_accuracy: 0.7169 - 969ms/epoch - 5ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.5101 - accuracy: 0.7558 - val_loss: 0.5660 - val_accuracy: 0.7132 - 955ms/epoch - 5ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.5121 - accuracy: 0.7479 - val_loss: 0.5558 - val_accuracy: 0.7083 - 919ms/epoch - 5ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.5052 - accuracy: 0.7506 - val_loss: 0.5569 - val_accuracy: 0.7181 - 910ms/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.5094 - accuracy: 0.7509 - val_loss: 0.5573 - val_accuracy: 0.7206 - 946ms/epoch - 5ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.4973 - accuracy: 0.7687 - val_loss: 0.5566 - val_accuracy: 0.7157 - 920ms/epoch - 5ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.5121 - accuracy: 0.7500 - val_loss: 0.5657 - val_accuracy: 0.7047 - 916ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.5197 - accuracy: 0.7485 - val_loss: 0.5686 - val_accuracy: 0.7071 - 909ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.4861 - accuracy: 0.7699 - val_loss: 0.5572 - val_accuracy: 0.7083 - 934ms/epoch - 5ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.5037 - accuracy: 0.7558 - val_loss: 0.5592 - val_accuracy: 0.7169 - 879ms/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.5145 - accuracy: 0.7610 - val_loss: 0.5656 - val_accuracy: 0.7181 - 936ms/epoch - 5ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.5033 - accuracy: 0.7613 - val_loss: 0.5681 - val_accuracy: 0.7071 - 930ms/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.5078 - accuracy: 0.7549 - val_loss: 0.5573 - val_accuracy: 0.7132 - 927ms/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.4987 - accuracy: 0.7665 - val_loss: 0.5618 - val_accuracy: 0.7047 - 925ms/epoch - 5ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.4955 - accuracy: 0.7626 - val_loss: 0.5611 - val_accuracy: 0.7108 - 924ms/epoch - 5ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.5010 - accuracy: 0.7613 - val_loss: 0.5599 - val_accuracy: 0.7132 - 937ms/epoch - 5ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.5011 - accuracy: 0.7512 - val_loss: 0.5632 - val_accuracy: 0.7145 - 977ms/epoch - 5ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.5106 - accuracy: 0.7546 - val_loss: 0.5638 - val_accuracy: 0.7194 - 963ms/epoch - 5ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.5000 - accuracy: 0.7656 - val_loss: 0.5666 - val_accuracy: 0.7157 - 948ms/epoch - 5ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.5070 - accuracy: 0.7521 - val_loss: 0.5636 - val_accuracy: 0.7230 - 956ms/epoch - 5ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.5051 - accuracy: 0.7629 - val_loss: 0.5568 - val_accuracy: 0.7181 - 959ms/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.4972 - accuracy: 0.7589 - val_loss: 0.5618 - val_accuracy: 0.7194 - 943ms/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.5122 - accuracy: 0.7558 - val_loss: 0.5534 - val_accuracy: 0.7243 - 968ms/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.5016 - accuracy: 0.7567 - val_loss: 0.5616 - val_accuracy: 0.7132 - 964ms/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.4999 - accuracy: 0.7718 - val_loss: 0.5623 - val_accuracy: 0.7194 - 939ms/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.5062 - accuracy: 0.7598 - val_loss: 0.5621 - val_accuracy: 0.7194 - 948ms/epoch - 5ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.5034 - accuracy: 0.7549 - val_loss: 0.5581 - val_accuracy: 0.7181 - 971ms/epoch - 5ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.4915 - accuracy: 0.7696 - val_loss: 0.5465 - val_accuracy: 0.7279 - 943ms/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.4965 - accuracy: 0.7558 - val_loss: 0.5560 - val_accuracy: 0.7194 - 958ms/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.5118 - accuracy: 0.7525 - val_loss: 0.5581 - val_accuracy: 0.7230 - 941ms/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.5081 - accuracy: 0.7583 - val_loss: 0.5488 - val_accuracy: 0.7292 - 942ms/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.5070 - accuracy: 0.7558 - val_loss: 0.5663 - val_accuracy: 0.7169 - 948ms/epoch - 5ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.4992 - accuracy: 0.7626 - val_loss: 0.5549 - val_accuracy: 0.7218 - 951ms/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.4997 - accuracy: 0.7702 - val_loss: 0.5577 - val_accuracy: 0.7157 - 944ms/epoch - 5ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.5158 - accuracy: 0.7494 - val_loss: 0.5571 - val_accuracy: 0.7169 - 941ms/epoch - 5ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.5017 - accuracy: 0.7604 - val_loss: 0.5541 - val_accuracy: 0.7206 - 946ms/epoch - 5ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.4949 - accuracy: 0.7595 - val_loss: 0.5691 - val_accuracy: 0.7071 - 930ms/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.5021 - accuracy: 0.7583 - val_loss: 0.5639 - val_accuracy: 0.7083 - 938ms/epoch - 5ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.4980 - accuracy: 0.7583 - val_loss: 0.5582 - val_accuracy: 0.7181 - 959ms/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.5093 - accuracy: 0.7531 - val_loss: 0.5491 - val_accuracy: 0.7243 - 958ms/epoch - 5ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.4982 - accuracy: 0.7543 - val_loss: 0.5608 - val_accuracy: 0.7132 - 944ms/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.4979 - accuracy: 0.7675 - val_loss: 0.5571 - val_accuracy: 0.7267 - 922ms/epoch - 5ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.4943 - accuracy: 0.7696 - val_loss: 0.5552 - val_accuracy: 0.7218 - 937ms/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.4965 - accuracy: 0.7623 - val_loss: 0.5633 - val_accuracy: 0.7194 - 936ms/epoch - 5ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.5132 - accuracy: 0.7482 - val_loss: 0.5610 - val_accuracy: 0.7279 - 976ms/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.5031 - accuracy: 0.7521 - val_loss: 0.5625 - val_accuracy: 0.7120 - 973ms/epoch - 5ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.5024 - accuracy: 0.7604 - val_loss: 0.5630 - val_accuracy: 0.7230 - 947ms/epoch - 5ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.5017 - accuracy: 0.7644 - val_loss: 0.5698 - val_accuracy: 0.7047 - 944ms/epoch - 5ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.4945 - accuracy: 0.7684 - val_loss: 0.5572 - val_accuracy: 0.7083 - 952ms/epoch - 5ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.5057 - accuracy: 0.7491 - val_loss: 0.5663 - val_accuracy: 0.7132 - 917ms/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.5063 - accuracy: 0.7472 - val_loss: 0.5587 - val_accuracy: 0.7218 - 918ms/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.4892 - accuracy: 0.7702 - val_loss: 0.5540 - val_accuracy: 0.7169 - 948ms/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.4910 - accuracy: 0.7693 - val_loss: 0.5703 - val_accuracy: 0.7132 - 956ms/epoch - 5ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.4962 - accuracy: 0.7610 - val_loss: 0.5605 - val_accuracy: 0.7096 - 958ms/epoch - 5ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.4970 - accuracy: 0.7528 - val_loss: 0.5573 - val_accuracy: 0.7071 - 950ms/epoch - 5ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.4997 - accuracy: 0.7647 - val_loss: 0.5589 - val_accuracy: 0.7157 - 929ms/epoch - 5ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.4940 - accuracy: 0.7610 - val_loss: 0.5507 - val_accuracy: 0.7157 - 900ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.4962 - accuracy: 0.7592 - val_loss: 0.5558 - val_accuracy: 0.7034 - 955ms/epoch - 5ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.4888 - accuracy: 0.7690 - val_loss: 0.5505 - val_accuracy: 0.7108 - 940ms/epoch - 5ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.5031 - accuracy: 0.7574 - val_loss: 0.5528 - val_accuracy: 0.7157 - 921ms/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.5008 - accuracy: 0.7623 - val_loss: 0.5574 - val_accuracy: 0.7194 - 948ms/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.5047 - accuracy: 0.7546 - val_loss: 0.5616 - val_accuracy: 0.7145 - 949ms/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.4899 - accuracy: 0.7659 - val_loss: 0.5651 - val_accuracy: 0.7194 - 962ms/epoch - 5ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.4883 - accuracy: 0.7696 - val_loss: 0.5576 - val_accuracy: 0.7047 - 936ms/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.4948 - accuracy: 0.7665 - val_loss: 0.5609 - val_accuracy: 0.7145 - 957ms/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.4940 - accuracy: 0.7718 - val_loss: 0.5607 - val_accuracy: 0.7083 - 929ms/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.4997 - accuracy: 0.7656 - val_loss: 0.5611 - val_accuracy: 0.7230 - 920ms/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.5008 - accuracy: 0.7598 - val_loss: 0.5622 - val_accuracy: 0.7316 - 934ms/epoch - 5ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.4988 - accuracy: 0.7567 - val_loss: 0.5604 - val_accuracy: 0.7341 - 937ms/epoch - 5ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.4954 - accuracy: 0.7647 - val_loss: 0.5578 - val_accuracy: 0.7071 - 924ms/epoch - 5ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.4949 - accuracy: 0.7687 - val_loss: 0.5567 - val_accuracy: 0.7206 - 920ms/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.4923 - accuracy: 0.7730 - val_loss: 0.5554 - val_accuracy: 0.7145 - 953ms/epoch - 5ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.5019 - accuracy: 0.7662 - val_loss: 0.5664 - val_accuracy: 0.7243 - 951ms/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.4970 - accuracy: 0.7638 - val_loss: 0.5535 - val_accuracy: 0.7181 - 964ms/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.4884 - accuracy: 0.7678 - val_loss: 0.5499 - val_accuracy: 0.7230 - 938ms/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.4890 - accuracy: 0.7705 - val_loss: 0.5557 - val_accuracy: 0.7157 - 924ms/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.5056 - accuracy: 0.7518 - val_loss: 0.5602 - val_accuracy: 0.7145 - 927ms/epoch - 5ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.4917 - accuracy: 0.7693 - val_loss: 0.5555 - val_accuracy: 0.7169 - 930ms/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.4992 - accuracy: 0.7546 - val_loss: 0.5653 - val_accuracy: 0.7059 - 964ms/epoch - 5ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.4922 - accuracy: 0.7662 - val_loss: 0.5685 - val_accuracy: 0.7267 - 924ms/epoch - 5ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.4996 - accuracy: 0.7561 - val_loss: 0.5553 - val_accuracy: 0.7120 - 913ms/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.4837 - accuracy: 0.7672 - val_loss: 0.5608 - val_accuracy: 0.7059 - 894ms/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.4986 - accuracy: 0.7601 - val_loss: 0.5610 - val_accuracy: 0.7157 - 902ms/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.4909 - accuracy: 0.7665 - val_loss: 0.5561 - val_accuracy: 0.7279 - 937ms/epoch - 5ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.4903 - accuracy: 0.7555 - val_loss: 0.5549 - val_accuracy: 0.7169 - 942ms/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.5074 - accuracy: 0.7552 - val_loss: 0.5637 - val_accuracy: 0.7181 - 939ms/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.5004 - accuracy: 0.7583 - val_loss: 0.5653 - val_accuracy: 0.7169 - 928ms/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.4978 - accuracy: 0.7543 - val_loss: 0.5492 - val_accuracy: 0.7218 - 939ms/epoch - 5ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.4886 - accuracy: 0.7534 - val_loss: 0.5620 - val_accuracy: 0.7230 - 940ms/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.5006 - accuracy: 0.7567 - val_loss: 0.5580 - val_accuracy: 0.7206 - 922ms/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.5018 - accuracy: 0.7619 - val_loss: 0.5664 - val_accuracy: 0.7071 - 951ms/epoch - 5ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.5072 - accuracy: 0.7595 - val_loss: 0.5604 - val_accuracy: 0.7243 - 966ms/epoch - 5ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.4925 - accuracy: 0.7598 - val_loss: 0.5600 - val_accuracy: 0.7132 - 930ms/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.4946 - accuracy: 0.7616 - val_loss: 0.5657 - val_accuracy: 0.7206 - 951ms/epoch - 5ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.4993 - accuracy: 0.7531 - val_loss: 0.5682 - val_accuracy: 0.7194 - 937ms/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.4921 - accuracy: 0.7546 - val_loss: 0.5516 - val_accuracy: 0.7267 - 933ms/epoch - 5ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.4965 - accuracy: 0.7629 - val_loss: 0.5550 - val_accuracy: 0.7255 - 948ms/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.4919 - accuracy: 0.7589 - val_loss: 0.5542 - val_accuracy: 0.7218 - 938ms/epoch - 5ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.5003 - accuracy: 0.7546 - val_loss: 0.5564 - val_accuracy: 0.7206 - 920ms/epoch - 5ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.5005 - accuracy: 0.7623 - val_loss: 0.5558 - val_accuracy: 0.7145 - 954ms/epoch - 5ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    2    3 ... 4077 4078 4079]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   1    9   13   25   26   33   34   37   41   55   60   66   73   74\n",
      "   77   81   82   89   92   93   94   96  104  112  126  129  131  140\n",
      "  147  149  156  164  165  166  167  173  182  199  211  222  223  229\n",
      "  234  237  240  243  245  248  250  252  261  264  277  283  285  291\n",
      "  296  300  301  307  312  317  318  321  322  323  325  336  341  344\n",
      "  352  353  356  373  376  378  379  382  385  386  390  397  400  415\n",
      "  422  426  432  433  436  437  439  443  448  456  462  473  478  479\n",
      "  485  488  495  498  499  508  516  518  520  529  530  534  538  541\n",
      "  547  549  561  562  565  567  570  576  582  583  599  605  618  620\n",
      "  631  641  648  651  653  655  663  671  686  692  699  704  709  714\n",
      "  720  725  739  745  750  755  760  762  767  768  775  778  781  798\n",
      "  803  804  807  810  821  830  831  834  837  838  839  843  844  846\n",
      "  848  849  857  866  867  870  877  888  889  892  893  897  898  906\n",
      "  910  914  917  923  926  928  932  938  943  953  958  963  974  982\n",
      "  992  993  994 1000 1001 1003 1009 1014 1015 1020 1028 1039 1042 1044\n",
      " 1047 1063 1064 1072 1077 1079 1084 1088 1093 1094 1095 1102 1114 1128\n",
      " 1133 1135 1138 1150 1153 1154 1155 1160 1162 1163 1164 1165 1172 1188\n",
      " 1192 1193 1195 1205 1206 1212 1217 1226 1241 1252 1253 1258 1263 1266\n",
      " 1282 1291 1295 1304 1307 1308 1311 1319 1320 1326 1327 1336 1337 1350\n",
      " 1351 1359 1367 1373 1375 1382 1388 1399 1402 1403 1405 1406 1408 1413\n",
      " 1417 1419 1421 1423 1426 1448 1451 1463 1464 1465 1470 1487 1490 1494\n",
      " 1498 1508 1514 1517 1524 1527 1529 1530 1534 1550 1552 1559 1569 1589\n",
      " 1592 1597 1600 1606 1608 1609 1613 1614 1615 1616 1623 1625 1626 1640\n",
      " 1644 1649 1657 1658 1663 1665 1681 1682 1691 1695 1704 1707 1708 1715\n",
      " 1716 1722 1723 1725 1726 1727 1731 1734 1736 1739 1757 1767 1769 1770\n",
      " 1781 1787 1792 1805 1808 1815 1835 1841 1844 1845 1850 1851 1857 1864\n",
      " 1875 1883 1885 1887 1888 1891 1902 1903 1904 1907 1910 1911 1912 1919\n",
      " 1922 1923 1924 1926 1934 1935 1936 1939 1951 1952 1963 1972 1973 1980\n",
      " 1987 1989 1990 1992 2003 2004 2011 2017 2019 2022 2024 2025 2033 2036\n",
      " 2037 2038 2047 2051 2056 2057 2064 2071 2074 2089 2091 2095 2099 2100\n",
      " 2105 2108 2113 2119 2121 2124 2129 2133 2137 2138 2140 2146 2154 2158\n",
      " 2164 2167 2184 2189 2193 2196 2206 2216 2221 2222 2223 2230 2239 2242\n",
      " 2251 2254 2262 2280 2285 2304 2306 2308 2311 2328 2331 2332 2333 2334\n",
      " 2337 2340 2344 2346 2354 2366 2371 2373 2380 2391 2392 2397 2406 2418\n",
      " 2420 2421 2430 2437 2450 2454 2455 2464 2465 2479 2481 2484 2488 2492\n",
      " 2497 2499 2502 2504 2510 2514 2525 2526 2536 2544 2555 2562 2563 2565\n",
      " 2571 2572 2574 2581 2587 2589 2598 2604 2612 2613 2621 2625 2642 2645\n",
      " 2650 2653 2655 2664 2670 2672 2677 2680 2681 2683 2688 2690 2696 2707\n",
      " 2709 2711 2715 2722 2724 2726 2727 2729 2731 2732 2738 2739 2740 2749\n",
      " 2760 2762 2765 2769 2773 2775 2776 2780 2784 2785 2788 2792 2793 2794\n",
      " 2809 2811 2812 2818 2825 2828 2839 2842 2843 2846 2847 2849 2850 2852\n",
      " 2855 2857 2858 2861 2868 2872 2881 2882 2883 2890 2894 2897 2918 2928\n",
      " 2931 2942 2946 2952 2953 2959 2980 2986 2994 2999 3000 3004 3007 3010\n",
      " 3011 3013 3014 3021 3030 3032 3038 3045 3054 3059 3068 3074 3078 3079\n",
      " 3080 3085 3096 3098 3099 3103 3107 3108 3114 3120 3123 3130 3137 3142\n",
      " 3144 3149 3167 3170 3174 3181 3183 3186 3193 3195 3202 3208 3210 3211\n",
      " 3214 3215 3218 3220 3221 3227 3228 3232 3233 3240 3248 3254 3264 3267\n",
      " 3274 3281 3284 3295 3298 3299 3316 3317 3319 3333 3349 3354 3355 3373\n",
      " 3377 3378 3380 3389 3393 3414 3415 3417 3418 3420 3423 3425 3431 3433\n",
      " 3448 3450 3457 3458 3478 3481 3485 3486 3488 3489 3496 3509 3510 3521\n",
      " 3522 3530 3535 3539 3551 3553 3562 3563 3571 3574 3576 3581 3599 3608\n",
      " 3615 3620 3627 3628 3636 3643 3656 3665 3669 3673 3674 3675 3682 3683\n",
      " 3688 3691 3694 3703 3704 3705 3706 3709 3713 3739 3740 3741 3743 3746\n",
      " 3748 3749 3752 3757 3769 3774 3778 3784 3796 3803 3804 3807 3810 3811\n",
      " 3812 3814 3817 3818 3819 3820 3827 3828 3835 3848 3849 3852 3854 3859\n",
      " 3865 3868 3871 3873 3876 3877 3882 3883 3888 3892 3893 3896 3901 3905\n",
      " 3910 3911 3920 3924 3927 3931 3933 3940 3941 3943 3949 3951 3954 3962\n",
      " 3963 3965 3973 3984 3989 3995 4002 4006 4009 4021 4026 4027 4031 4046\n",
      " 4052 4062 4065 4072]\n",
      "Number of samples for test set: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:06:25.401857: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_358/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6935 - accuracy: 0.5107 - val_loss: 0.6908 - val_accuracy: 0.5294 - 3s/epoch - 13ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6845 - accuracy: 0.5545 - val_loss: 0.6766 - val_accuracy: 0.5858 - 941ms/epoch - 5ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6610 - accuracy: 0.6060 - val_loss: 0.6501 - val_accuracy: 0.6556 - 939ms/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6447 - accuracy: 0.6376 - val_loss: 0.6404 - val_accuracy: 0.6691 - 935ms/epoch - 5ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6341 - accuracy: 0.6504 - val_loss: 0.6415 - val_accuracy: 0.6556 - 932ms/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6296 - accuracy: 0.6529 - val_loss: 0.6255 - val_accuracy: 0.6801 - 913ms/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6268 - accuracy: 0.6513 - val_loss: 0.6344 - val_accuracy: 0.6630 - 916ms/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6265 - accuracy: 0.6627 - val_loss: 0.6289 - val_accuracy: 0.6630 - 916ms/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6182 - accuracy: 0.6654 - val_loss: 0.6252 - val_accuracy: 0.6826 - 938ms/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.6176 - accuracy: 0.6728 - val_loss: 0.6272 - val_accuracy: 0.6850 - 932ms/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6140 - accuracy: 0.6795 - val_loss: 0.6236 - val_accuracy: 0.6642 - 950ms/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.6031 - accuracy: 0.6780 - val_loss: 0.6171 - val_accuracy: 0.6728 - 943ms/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.6012 - accuracy: 0.6838 - val_loss: 0.6207 - val_accuracy: 0.6691 - 928ms/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.5980 - accuracy: 0.6936 - val_loss: 0.6199 - val_accuracy: 0.6618 - 928ms/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.5952 - accuracy: 0.6924 - val_loss: 0.6183 - val_accuracy: 0.6789 - 959ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.5948 - accuracy: 0.6881 - val_loss: 0.6213 - val_accuracy: 0.6691 - 971ms/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.5895 - accuracy: 0.7037 - val_loss: 0.6114 - val_accuracy: 0.6765 - 919ms/epoch - 5ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.5868 - accuracy: 0.7099 - val_loss: 0.6141 - val_accuracy: 0.6728 - 919ms/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.5886 - accuracy: 0.6930 - val_loss: 0.6178 - val_accuracy: 0.6654 - 899ms/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.5896 - accuracy: 0.6896 - val_loss: 0.6139 - val_accuracy: 0.6826 - 927ms/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.5816 - accuracy: 0.7077 - val_loss: 0.6132 - val_accuracy: 0.6814 - 918ms/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.5830 - accuracy: 0.7047 - val_loss: 0.6156 - val_accuracy: 0.6789 - 929ms/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.5853 - accuracy: 0.7083 - val_loss: 0.6147 - val_accuracy: 0.6801 - 947ms/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.5814 - accuracy: 0.7083 - val_loss: 0.6127 - val_accuracy: 0.6924 - 919ms/epoch - 5ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.5810 - accuracy: 0.7096 - val_loss: 0.6134 - val_accuracy: 0.6900 - 920ms/epoch - 5ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.5708 - accuracy: 0.7184 - val_loss: 0.6121 - val_accuracy: 0.6789 - 950ms/epoch - 5ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.5704 - accuracy: 0.7083 - val_loss: 0.6123 - val_accuracy: 0.6912 - 939ms/epoch - 5ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.5757 - accuracy: 0.7080 - val_loss: 0.6153 - val_accuracy: 0.6936 - 918ms/epoch - 5ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.5628 - accuracy: 0.7233 - val_loss: 0.6160 - val_accuracy: 0.6728 - 948ms/epoch - 5ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.5669 - accuracy: 0.7224 - val_loss: 0.6069 - val_accuracy: 0.6850 - 921ms/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.5672 - accuracy: 0.7172 - val_loss: 0.6082 - val_accuracy: 0.6752 - 938ms/epoch - 5ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.5671 - accuracy: 0.7163 - val_loss: 0.6039 - val_accuracy: 0.6912 - 950ms/epoch - 5ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.5693 - accuracy: 0.7111 - val_loss: 0.6055 - val_accuracy: 0.6826 - 957ms/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.5639 - accuracy: 0.7230 - val_loss: 0.6016 - val_accuracy: 0.6887 - 925ms/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.5577 - accuracy: 0.7203 - val_loss: 0.6058 - val_accuracy: 0.6949 - 955ms/epoch - 5ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.5510 - accuracy: 0.7292 - val_loss: 0.6074 - val_accuracy: 0.6838 - 928ms/epoch - 5ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.5657 - accuracy: 0.7135 - val_loss: 0.6136 - val_accuracy: 0.6728 - 927ms/epoch - 5ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.5574 - accuracy: 0.7178 - val_loss: 0.5986 - val_accuracy: 0.6765 - 949ms/epoch - 5ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.5575 - accuracy: 0.7188 - val_loss: 0.6149 - val_accuracy: 0.6900 - 941ms/epoch - 5ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.5540 - accuracy: 0.7252 - val_loss: 0.6035 - val_accuracy: 0.6863 - 914ms/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.5607 - accuracy: 0.7233 - val_loss: 0.6078 - val_accuracy: 0.6740 - 928ms/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.5509 - accuracy: 0.7264 - val_loss: 0.5984 - val_accuracy: 0.6887 - 913ms/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.5602 - accuracy: 0.7328 - val_loss: 0.5993 - val_accuracy: 0.6936 - 936ms/epoch - 5ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.5520 - accuracy: 0.7359 - val_loss: 0.6028 - val_accuracy: 0.6826 - 933ms/epoch - 5ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.5416 - accuracy: 0.7368 - val_loss: 0.6023 - val_accuracy: 0.6801 - 940ms/epoch - 5ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.5524 - accuracy: 0.7255 - val_loss: 0.6011 - val_accuracy: 0.6826 - 888ms/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.5490 - accuracy: 0.7258 - val_loss: 0.6034 - val_accuracy: 0.6900 - 882ms/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.5429 - accuracy: 0.7264 - val_loss: 0.5985 - val_accuracy: 0.6900 - 908ms/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.5442 - accuracy: 0.7267 - val_loss: 0.5939 - val_accuracy: 0.6985 - 911ms/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.5525 - accuracy: 0.7295 - val_loss: 0.6022 - val_accuracy: 0.6912 - 922ms/epoch - 5ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.5491 - accuracy: 0.7279 - val_loss: 0.5935 - val_accuracy: 0.6850 - 925ms/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.5393 - accuracy: 0.7362 - val_loss: 0.5948 - val_accuracy: 0.7022 - 917ms/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.5446 - accuracy: 0.7335 - val_loss: 0.5906 - val_accuracy: 0.6875 - 942ms/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.5437 - accuracy: 0.7310 - val_loss: 0.5946 - val_accuracy: 0.6949 - 928ms/epoch - 5ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.5397 - accuracy: 0.7362 - val_loss: 0.5974 - val_accuracy: 0.7132 - 905ms/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.5401 - accuracy: 0.7341 - val_loss: 0.6033 - val_accuracy: 0.7047 - 924ms/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.5350 - accuracy: 0.7497 - val_loss: 0.5962 - val_accuracy: 0.6875 - 938ms/epoch - 5ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.5453 - accuracy: 0.7350 - val_loss: 0.5950 - val_accuracy: 0.6863 - 924ms/epoch - 5ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.5403 - accuracy: 0.7387 - val_loss: 0.5962 - val_accuracy: 0.6973 - 920ms/epoch - 5ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.5389 - accuracy: 0.7417 - val_loss: 0.5898 - val_accuracy: 0.6949 - 913ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.5397 - accuracy: 0.7359 - val_loss: 0.5889 - val_accuracy: 0.7034 - 885ms/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.5387 - accuracy: 0.7344 - val_loss: 0.5901 - val_accuracy: 0.7071 - 923ms/epoch - 5ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.5395 - accuracy: 0.7381 - val_loss: 0.5891 - val_accuracy: 0.6887 - 906ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.5364 - accuracy: 0.7393 - val_loss: 0.5926 - val_accuracy: 0.6961 - 907ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.5394 - accuracy: 0.7365 - val_loss: 0.5865 - val_accuracy: 0.6887 - 965ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.5351 - accuracy: 0.7472 - val_loss: 0.5897 - val_accuracy: 0.7010 - 943ms/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.5296 - accuracy: 0.7451 - val_loss: 0.5899 - val_accuracy: 0.6949 - 893ms/epoch - 4ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.5365 - accuracy: 0.7322 - val_loss: 0.5889 - val_accuracy: 0.7071 - 917ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.5359 - accuracy: 0.7420 - val_loss: 0.5847 - val_accuracy: 0.6985 - 938ms/epoch - 5ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.5349 - accuracy: 0.7396 - val_loss: 0.5833 - val_accuracy: 0.6998 - 946ms/epoch - 5ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.5298 - accuracy: 0.7436 - val_loss: 0.5846 - val_accuracy: 0.6973 - 963ms/epoch - 5ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.5326 - accuracy: 0.7442 - val_loss: 0.5845 - val_accuracy: 0.6985 - 989ms/epoch - 5ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.5323 - accuracy: 0.7387 - val_loss: 0.5909 - val_accuracy: 0.6924 - 927ms/epoch - 5ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.5391 - accuracy: 0.7319 - val_loss: 0.5863 - val_accuracy: 0.6961 - 939ms/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.5295 - accuracy: 0.7433 - val_loss: 0.5818 - val_accuracy: 0.7059 - 867ms/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.5309 - accuracy: 0.7381 - val_loss: 0.5729 - val_accuracy: 0.7132 - 919ms/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.5318 - accuracy: 0.7377 - val_loss: 0.5855 - val_accuracy: 0.7034 - 938ms/epoch - 5ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.5318 - accuracy: 0.7396 - val_loss: 0.5893 - val_accuracy: 0.7059 - 955ms/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.5338 - accuracy: 0.7463 - val_loss: 0.5880 - val_accuracy: 0.6924 - 933ms/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.5499 - accuracy: 0.7390 - val_loss: 0.5850 - val_accuracy: 0.6985 - 970ms/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.5350 - accuracy: 0.7405 - val_loss: 0.5818 - val_accuracy: 0.7230 - 933ms/epoch - 5ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.5292 - accuracy: 0.7426 - val_loss: 0.5823 - val_accuracy: 0.7034 - 948ms/epoch - 5ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.5331 - accuracy: 0.7448 - val_loss: 0.5802 - val_accuracy: 0.7132 - 932ms/epoch - 5ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.5299 - accuracy: 0.7399 - val_loss: 0.5882 - val_accuracy: 0.7010 - 917ms/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.5274 - accuracy: 0.7466 - val_loss: 0.5864 - val_accuracy: 0.6961 - 931ms/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.5279 - accuracy: 0.7457 - val_loss: 0.5855 - val_accuracy: 0.6998 - 919ms/epoch - 5ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.5295 - accuracy: 0.7371 - val_loss: 0.5842 - val_accuracy: 0.7083 - 953ms/epoch - 5ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.5280 - accuracy: 0.7411 - val_loss: 0.5805 - val_accuracy: 0.7071 - 945ms/epoch - 5ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.5286 - accuracy: 0.7402 - val_loss: 0.5785 - val_accuracy: 0.6998 - 935ms/epoch - 5ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.5256 - accuracy: 0.7521 - val_loss: 0.5875 - val_accuracy: 0.6936 - 943ms/epoch - 5ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.5268 - accuracy: 0.7485 - val_loss: 0.5887 - val_accuracy: 0.7022 - 928ms/epoch - 5ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.5233 - accuracy: 0.7503 - val_loss: 0.5776 - val_accuracy: 0.6998 - 907ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.5223 - accuracy: 0.7463 - val_loss: 0.5883 - val_accuracy: 0.6998 - 913ms/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.5261 - accuracy: 0.7454 - val_loss: 0.5931 - val_accuracy: 0.7047 - 924ms/epoch - 5ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.5298 - accuracy: 0.7460 - val_loss: 0.5791 - val_accuracy: 0.6985 - 935ms/epoch - 5ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.5160 - accuracy: 0.7469 - val_loss: 0.5843 - val_accuracy: 0.7010 - 922ms/epoch - 5ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.5283 - accuracy: 0.7448 - val_loss: 0.5896 - val_accuracy: 0.7132 - 923ms/epoch - 5ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.5233 - accuracy: 0.7463 - val_loss: 0.5836 - val_accuracy: 0.6924 - 921ms/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.5224 - accuracy: 0.7500 - val_loss: 0.5830 - val_accuracy: 0.7059 - 917ms/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.5270 - accuracy: 0.7472 - val_loss: 0.5799 - val_accuracy: 0.7169 - 878ms/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.5218 - accuracy: 0.7460 - val_loss: 0.5833 - val_accuracy: 0.7022 - 912ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.5276 - accuracy: 0.7460 - val_loss: 0.5876 - val_accuracy: 0.7157 - 936ms/epoch - 5ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.5206 - accuracy: 0.7436 - val_loss: 0.5898 - val_accuracy: 0.7071 - 896ms/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.5235 - accuracy: 0.7577 - val_loss: 0.5750 - val_accuracy: 0.7047 - 939ms/epoch - 5ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.5215 - accuracy: 0.7423 - val_loss: 0.5845 - val_accuracy: 0.7034 - 913ms/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.5234 - accuracy: 0.7503 - val_loss: 0.5763 - val_accuracy: 0.7157 - 941ms/epoch - 5ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.5198 - accuracy: 0.7472 - val_loss: 0.5758 - val_accuracy: 0.7169 - 943ms/epoch - 5ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.5171 - accuracy: 0.7574 - val_loss: 0.5806 - val_accuracy: 0.7181 - 944ms/epoch - 5ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.5178 - accuracy: 0.7555 - val_loss: 0.5794 - val_accuracy: 0.7132 - 946ms/epoch - 5ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.5174 - accuracy: 0.7488 - val_loss: 0.5867 - val_accuracy: 0.7047 - 921ms/epoch - 5ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.5177 - accuracy: 0.7500 - val_loss: 0.5807 - val_accuracy: 0.7083 - 926ms/epoch - 5ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.5097 - accuracy: 0.7512 - val_loss: 0.5687 - val_accuracy: 0.7218 - 911ms/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.5189 - accuracy: 0.7546 - val_loss: 0.5774 - val_accuracy: 0.7096 - 932ms/epoch - 5ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.5224 - accuracy: 0.7512 - val_loss: 0.5836 - val_accuracy: 0.7047 - 930ms/epoch - 5ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.5178 - accuracy: 0.7561 - val_loss: 0.5742 - val_accuracy: 0.6961 - 916ms/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.5093 - accuracy: 0.7475 - val_loss: 0.5811 - val_accuracy: 0.7096 - 934ms/epoch - 5ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.5276 - accuracy: 0.7426 - val_loss: 0.5699 - val_accuracy: 0.7169 - 929ms/epoch - 5ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.5304 - accuracy: 0.7439 - val_loss: 0.5751 - val_accuracy: 0.7010 - 933ms/epoch - 5ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.5143 - accuracy: 0.7549 - val_loss: 0.5727 - val_accuracy: 0.7120 - 927ms/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.5122 - accuracy: 0.7525 - val_loss: 0.5794 - val_accuracy: 0.7157 - 904ms/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.5208 - accuracy: 0.7475 - val_loss: 0.5861 - val_accuracy: 0.6924 - 913ms/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.5109 - accuracy: 0.7537 - val_loss: 0.5756 - val_accuracy: 0.7047 - 921ms/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.5165 - accuracy: 0.7558 - val_loss: 0.5865 - val_accuracy: 0.7047 - 921ms/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.5248 - accuracy: 0.7436 - val_loss: 0.5893 - val_accuracy: 0.7157 - 888ms/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.5099 - accuracy: 0.7503 - val_loss: 0.5831 - val_accuracy: 0.7230 - 906ms/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.5103 - accuracy: 0.7564 - val_loss: 0.5789 - val_accuracy: 0.7169 - 923ms/epoch - 5ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.5208 - accuracy: 0.7433 - val_loss: 0.5806 - val_accuracy: 0.6998 - 938ms/epoch - 5ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.5180 - accuracy: 0.7485 - val_loss: 0.5764 - val_accuracy: 0.7206 - 935ms/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.5131 - accuracy: 0.7460 - val_loss: 0.5740 - val_accuracy: 0.7206 - 937ms/epoch - 5ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.5166 - accuracy: 0.7531 - val_loss: 0.5681 - val_accuracy: 0.7157 - 950ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.5043 - accuracy: 0.7546 - val_loss: 0.5677 - val_accuracy: 0.7096 - 927ms/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.5100 - accuracy: 0.7558 - val_loss: 0.5701 - val_accuracy: 0.7267 - 948ms/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.5226 - accuracy: 0.7457 - val_loss: 0.5751 - val_accuracy: 0.7120 - 899ms/epoch - 4ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.5147 - accuracy: 0.7515 - val_loss: 0.5745 - val_accuracy: 0.7279 - 919ms/epoch - 5ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.5131 - accuracy: 0.7595 - val_loss: 0.5743 - val_accuracy: 0.7120 - 932ms/epoch - 5ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.5104 - accuracy: 0.7506 - val_loss: 0.5753 - val_accuracy: 0.7206 - 938ms/epoch - 5ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.5100 - accuracy: 0.7531 - val_loss: 0.5708 - val_accuracy: 0.7120 - 929ms/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.5082 - accuracy: 0.7546 - val_loss: 0.5734 - val_accuracy: 0.7194 - 937ms/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.5254 - accuracy: 0.7436 - val_loss: 0.5657 - val_accuracy: 0.7059 - 921ms/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.5082 - accuracy: 0.7564 - val_loss: 0.5704 - val_accuracy: 0.7071 - 925ms/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.5155 - accuracy: 0.7543 - val_loss: 0.5775 - val_accuracy: 0.7083 - 917ms/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.5024 - accuracy: 0.7607 - val_loss: 0.5739 - val_accuracy: 0.7108 - 950ms/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.5171 - accuracy: 0.7543 - val_loss: 0.5764 - val_accuracy: 0.7194 - 896ms/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.5120 - accuracy: 0.7525 - val_loss: 0.5797 - val_accuracy: 0.7083 - 925ms/epoch - 5ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.5025 - accuracy: 0.7647 - val_loss: 0.5818 - val_accuracy: 0.7059 - 932ms/epoch - 5ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.5013 - accuracy: 0.7518 - val_loss: 0.5660 - val_accuracy: 0.7218 - 922ms/epoch - 5ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.5148 - accuracy: 0.7531 - val_loss: 0.5751 - val_accuracy: 0.7083 - 923ms/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.5171 - accuracy: 0.7623 - val_loss: 0.5786 - val_accuracy: 0.7169 - 933ms/epoch - 5ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.5053 - accuracy: 0.7604 - val_loss: 0.5669 - val_accuracy: 0.7096 - 929ms/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.4958 - accuracy: 0.7675 - val_loss: 0.5745 - val_accuracy: 0.7022 - 951ms/epoch - 5ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.5111 - accuracy: 0.7534 - val_loss: 0.5756 - val_accuracy: 0.7157 - 908ms/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.5011 - accuracy: 0.7641 - val_loss: 0.5714 - val_accuracy: 0.7120 - 918ms/epoch - 5ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.5120 - accuracy: 0.7488 - val_loss: 0.5652 - val_accuracy: 0.7083 - 914ms/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.5064 - accuracy: 0.7525 - val_loss: 0.5682 - val_accuracy: 0.7206 - 875ms/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.5022 - accuracy: 0.7561 - val_loss: 0.5730 - val_accuracy: 0.7132 - 914ms/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.5124 - accuracy: 0.7405 - val_loss: 0.5836 - val_accuracy: 0.7132 - 923ms/epoch - 5ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.5192 - accuracy: 0.7491 - val_loss: 0.5746 - val_accuracy: 0.7059 - 943ms/epoch - 5ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.5053 - accuracy: 0.7583 - val_loss: 0.5761 - val_accuracy: 0.7132 - 905ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.5038 - accuracy: 0.7632 - val_loss: 0.5805 - val_accuracy: 0.7157 - 952ms/epoch - 5ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.5032 - accuracy: 0.7601 - val_loss: 0.5709 - val_accuracy: 0.7194 - 938ms/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.5010 - accuracy: 0.7623 - val_loss: 0.5772 - val_accuracy: 0.7071 - 932ms/epoch - 5ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.5031 - accuracy: 0.7607 - val_loss: 0.5661 - val_accuracy: 0.7181 - 947ms/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.5068 - accuracy: 0.7577 - val_loss: 0.5642 - val_accuracy: 0.7206 - 931ms/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.5069 - accuracy: 0.7543 - val_loss: 0.5677 - val_accuracy: 0.7279 - 925ms/epoch - 5ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.5036 - accuracy: 0.7570 - val_loss: 0.5693 - val_accuracy: 0.7120 - 920ms/epoch - 5ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.5082 - accuracy: 0.7482 - val_loss: 0.5772 - val_accuracy: 0.7145 - 912ms/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.4986 - accuracy: 0.7699 - val_loss: 0.5845 - val_accuracy: 0.7096 - 911ms/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.5110 - accuracy: 0.7518 - val_loss: 0.5759 - val_accuracy: 0.7132 - 915ms/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.5043 - accuracy: 0.7629 - val_loss: 0.5859 - val_accuracy: 0.6998 - 926ms/epoch - 5ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.5055 - accuracy: 0.7506 - val_loss: 0.5790 - val_accuracy: 0.7096 - 896ms/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.5002 - accuracy: 0.7546 - val_loss: 0.5758 - val_accuracy: 0.6998 - 924ms/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.5046 - accuracy: 0.7601 - val_loss: 0.5789 - val_accuracy: 0.7218 - 933ms/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.5039 - accuracy: 0.7488 - val_loss: 0.5711 - val_accuracy: 0.7230 - 926ms/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.4985 - accuracy: 0.7696 - val_loss: 0.5823 - val_accuracy: 0.7096 - 934ms/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.5043 - accuracy: 0.7567 - val_loss: 0.5795 - val_accuracy: 0.7120 - 937ms/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.4995 - accuracy: 0.7718 - val_loss: 0.5791 - val_accuracy: 0.7181 - 856ms/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.4967 - accuracy: 0.7570 - val_loss: 0.5628 - val_accuracy: 0.7169 - 899ms/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.5021 - accuracy: 0.7638 - val_loss: 0.5687 - val_accuracy: 0.7169 - 918ms/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.5093 - accuracy: 0.7580 - val_loss: 0.5650 - val_accuracy: 0.7157 - 929ms/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.4943 - accuracy: 0.7595 - val_loss: 0.5784 - val_accuracy: 0.7194 - 887ms/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.5034 - accuracy: 0.7589 - val_loss: 0.5689 - val_accuracy: 0.7206 - 898ms/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.5102 - accuracy: 0.7512 - val_loss: 0.5718 - val_accuracy: 0.7157 - 937ms/epoch - 5ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.5082 - accuracy: 0.7601 - val_loss: 0.5724 - val_accuracy: 0.7071 - 921ms/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.4998 - accuracy: 0.7616 - val_loss: 0.5617 - val_accuracy: 0.7145 - 940ms/epoch - 5ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.4922 - accuracy: 0.7604 - val_loss: 0.5692 - val_accuracy: 0.7230 - 941ms/epoch - 5ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.5045 - accuracy: 0.7616 - val_loss: 0.5689 - val_accuracy: 0.7206 - 936ms/epoch - 5ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.5003 - accuracy: 0.7574 - val_loss: 0.5825 - val_accuracy: 0.7071 - 963ms/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.4997 - accuracy: 0.7543 - val_loss: 0.5703 - val_accuracy: 0.7071 - 946ms/epoch - 5ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.5044 - accuracy: 0.7641 - val_loss: 0.5662 - val_accuracy: 0.7083 - 946ms/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.4962 - accuracy: 0.7604 - val_loss: 0.5709 - val_accuracy: 0.7255 - 947ms/epoch - 5ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.5079 - accuracy: 0.7543 - val_loss: 0.5715 - val_accuracy: 0.7243 - 951ms/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.5038 - accuracy: 0.7567 - val_loss: 0.5698 - val_accuracy: 0.7255 - 910ms/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.4970 - accuracy: 0.7583 - val_loss: 0.5778 - val_accuracy: 0.7279 - 942ms/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.5058 - accuracy: 0.7518 - val_loss: 0.5762 - val_accuracy: 0.7059 - 917ms/epoch - 4ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.5008 - accuracy: 0.7623 - val_loss: 0.5766 - val_accuracy: 0.7157 - 946ms/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.4947 - accuracy: 0.7714 - val_loss: 0.5784 - val_accuracy: 0.7059 - 909ms/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.4992 - accuracy: 0.7607 - val_loss: 0.5605 - val_accuracy: 0.7341 - 874ms/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.5079 - accuracy: 0.7589 - val_loss: 0.5711 - val_accuracy: 0.7034 - 888ms/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.4957 - accuracy: 0.7613 - val_loss: 0.5662 - val_accuracy: 0.7132 - 940ms/epoch - 5ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.5047 - accuracy: 0.7623 - val_loss: 0.5686 - val_accuracy: 0.7243 - 919ms/epoch - 5ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.5045 - accuracy: 0.7549 - val_loss: 0.5742 - val_accuracy: 0.7132 - 928ms/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.5089 - accuracy: 0.7515 - val_loss: 0.5766 - val_accuracy: 0.7034 - 928ms/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.4998 - accuracy: 0.7629 - val_loss: 0.5685 - val_accuracy: 0.7194 - 902ms/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.4919 - accuracy: 0.7702 - val_loss: 0.5701 - val_accuracy: 0.7206 - 882ms/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.4921 - accuracy: 0.7567 - val_loss: 0.5809 - val_accuracy: 0.6936 - 902ms/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.5062 - accuracy: 0.7518 - val_loss: 0.5710 - val_accuracy: 0.7108 - 916ms/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.4985 - accuracy: 0.7577 - val_loss: 0.5744 - val_accuracy: 0.7120 - 889ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.5002 - accuracy: 0.7632 - val_loss: 0.5757 - val_accuracy: 0.7206 - 891ms/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.5028 - accuracy: 0.7675 - val_loss: 0.5830 - val_accuracy: 0.7218 - 945ms/epoch - 5ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.4935 - accuracy: 0.7619 - val_loss: 0.5724 - val_accuracy: 0.7206 - 915ms/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.4885 - accuracy: 0.7702 - val_loss: 0.5811 - val_accuracy: 0.7071 - 923ms/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.4959 - accuracy: 0.7647 - val_loss: 0.5797 - val_accuracy: 0.7206 - 918ms/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.5026 - accuracy: 0.7644 - val_loss: 0.5795 - val_accuracy: 0.7108 - 910ms/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.4961 - accuracy: 0.7650 - val_loss: 0.5722 - val_accuracy: 0.7218 - 931ms/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.4940 - accuracy: 0.7696 - val_loss: 0.5727 - val_accuracy: 0.7157 - 907ms/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.4915 - accuracy: 0.7690 - val_loss: 0.5687 - val_accuracy: 0.7194 - 912ms/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.4978 - accuracy: 0.7543 - val_loss: 0.5662 - val_accuracy: 0.7145 - 941ms/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.4906 - accuracy: 0.7693 - val_loss: 0.5788 - val_accuracy: 0.7120 - 922ms/epoch - 5ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.5027 - accuracy: 0.7500 - val_loss: 0.5788 - val_accuracy: 0.7132 - 942ms/epoch - 5ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.4910 - accuracy: 0.7629 - val_loss: 0.5631 - val_accuracy: 0.7304 - 948ms/epoch - 5ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.5010 - accuracy: 0.7601 - val_loss: 0.5644 - val_accuracy: 0.7169 - 954ms/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.4922 - accuracy: 0.7598 - val_loss: 0.5740 - val_accuracy: 0.7341 - 956ms/epoch - 5ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.5045 - accuracy: 0.7577 - val_loss: 0.5643 - val_accuracy: 0.7365 - 944ms/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.5003 - accuracy: 0.7604 - val_loss: 0.5776 - val_accuracy: 0.7194 - 915ms/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.5066 - accuracy: 0.7619 - val_loss: 0.5748 - val_accuracy: 0.7059 - 937ms/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.4942 - accuracy: 0.7656 - val_loss: 0.5728 - val_accuracy: 0.7108 - 932ms/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.4937 - accuracy: 0.7589 - val_loss: 0.5669 - val_accuracy: 0.7206 - 905ms/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.4899 - accuracy: 0.7592 - val_loss: 0.5689 - val_accuracy: 0.7341 - 920ms/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.4922 - accuracy: 0.7757 - val_loss: 0.5665 - val_accuracy: 0.7341 - 910ms/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.4937 - accuracy: 0.7607 - val_loss: 0.5813 - val_accuracy: 0.7108 - 899ms/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.4946 - accuracy: 0.7644 - val_loss: 0.5741 - val_accuracy: 0.7047 - 905ms/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.4988 - accuracy: 0.7678 - val_loss: 0.5783 - val_accuracy: 0.7083 - 916ms/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.5027 - accuracy: 0.7555 - val_loss: 0.5716 - val_accuracy: 0.7194 - 926ms/epoch - 5ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.4988 - accuracy: 0.7629 - val_loss: 0.5715 - val_accuracy: 0.7218 - 944ms/epoch - 5ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.4868 - accuracy: 0.7675 - val_loss: 0.5703 - val_accuracy: 0.7096 - 930ms/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.5060 - accuracy: 0.7678 - val_loss: 0.5700 - val_accuracy: 0.7157 - 969ms/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.4902 - accuracy: 0.7662 - val_loss: 0.5636 - val_accuracy: 0.7181 - 922ms/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.4957 - accuracy: 0.7681 - val_loss: 0.5691 - val_accuracy: 0.7243 - 893ms/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.4936 - accuracy: 0.7610 - val_loss: 0.5685 - val_accuracy: 0.7120 - 932ms/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.4927 - accuracy: 0.7708 - val_loss: 0.5668 - val_accuracy: 0.7206 - 924ms/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.4937 - accuracy: 0.7647 - val_loss: 0.5700 - val_accuracy: 0.7157 - 892ms/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.4967 - accuracy: 0.7629 - val_loss: 0.5688 - val_accuracy: 0.7206 - 908ms/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.4843 - accuracy: 0.7779 - val_loss: 0.5694 - val_accuracy: 0.7230 - 956ms/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.5076 - accuracy: 0.7549 - val_loss: 0.5717 - val_accuracy: 0.7267 - 924ms/epoch - 5ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.4933 - accuracy: 0.7650 - val_loss: 0.5776 - val_accuracy: 0.7132 - 920ms/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.4993 - accuracy: 0.7521 - val_loss: 0.5708 - val_accuracy: 0.6998 - 911ms/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.5006 - accuracy: 0.7629 - val_loss: 0.5741 - val_accuracy: 0.7169 - 888ms/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.4957 - accuracy: 0.7699 - val_loss: 0.5713 - val_accuracy: 0.7169 - 942ms/epoch - 5ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.5023 - accuracy: 0.7616 - val_loss: 0.5713 - val_accuracy: 0.7083 - 959ms/epoch - 5ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.4925 - accuracy: 0.7678 - val_loss: 0.5691 - val_accuracy: 0.7120 - 928ms/epoch - 5ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 4077 4078 4079]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   3    6   20   22   31   45   47   51   52   61   62   63   70   78\n",
      "   79   84   90   97  100  101  105  108  113  114  120  122  130  134\n",
      "  135  138  145  148  150  151  152  170  176  178  180  183  185  186\n",
      "  189  194  196  198  205  206  207  218  225  227  230  231  239  247\n",
      "  249  255  256  260  263  268  274  280  281  290  298  306  308  313\n",
      "  320  326  329  334  337  338  345  349  357  359  363  366  380  411\n",
      "  412  414  417  421  427  429  431  435  438  442  444  446  454  460\n",
      "  463  468  471  481  491  493  501  502  503  506  509  515  532  536\n",
      "  539  563  569  573  585  587  588  589  594  608  625  626  627  628\n",
      "  638  640  643  650  652  654  656  661  667  674  678  680  682  688\n",
      "  689  691  696  700  711  716  722  723  728  729  735  737  744  749\n",
      "  751  753  771  773  776  779  782  783  788  800  806  813  815  822\n",
      "  823  828  841  845  852  855  863  865  872  873  880  881  884  887\n",
      "  894  895  900  902  903  908  919  931  933  936  951  954  959  961\n",
      "  962  970  972  980  981  985  986  987  989  995 1011 1022 1026 1029\n",
      " 1030 1031 1033 1035 1036 1037 1038 1041 1046 1050 1067 1073 1083 1085\n",
      " 1086 1096 1098 1101 1107 1115 1117 1119 1124 1131 1132 1140 1141 1159\n",
      " 1168 1169 1171 1173 1174 1176 1180 1183 1184 1190 1191 1197 1199 1203\n",
      " 1218 1222 1224 1232 1234 1236 1238 1239 1243 1246 1254 1255 1262 1265\n",
      " 1272 1278 1283 1284 1288 1292 1301 1303 1324 1325 1332 1335 1340 1344\n",
      " 1352 1353 1357 1363 1364 1366 1370 1379 1395 1400 1401 1409 1410 1414\n",
      " 1424 1428 1430 1441 1442 1443 1444 1446 1453 1456 1458 1461 1466 1471\n",
      " 1473 1481 1486 1500 1506 1509 1512 1516 1519 1521 1533 1535 1540 1567\n",
      " 1573 1578 1588 1593 1595 1596 1599 1605 1610 1617 1618 1624 1637 1645\n",
      " 1650 1651 1653 1659 1666 1675 1677 1680 1685 1686 1689 1692 1697 1710\n",
      " 1719 1729 1733 1740 1745 1748 1749 1751 1755 1759 1768 1773 1783 1795\n",
      " 1796 1798 1799 1800 1806 1807 1809 1813 1816 1820 1823 1824 1827 1831\n",
      " 1834 1837 1847 1855 1858 1861 1862 1868 1871 1876 1878 1879 1881 1889\n",
      " 1890 1896 1898 1901 1921 1925 1927 1928 1929 1933 1940 1947 1956 1959\n",
      " 1960 1967 1970 1971 1975 1976 1977 1998 2000 2001 2002 2008 2009 2012\n",
      " 2021 2027 2028 2029 2031 2032 2040 2045 2048 2052 2053 2055 2059 2062\n",
      " 2066 2070 2076 2086 2087 2103 2104 2109 2112 2114 2118 2128 2130 2135\n",
      " 2136 2148 2150 2156 2160 2163 2171 2172 2177 2181 2182 2183 2186 2187\n",
      " 2197 2199 2205 2207 2211 2212 2214 2219 2225 2232 2235 2238 2241 2243\n",
      " 2245 2246 2250 2252 2256 2257 2263 2265 2268 2271 2281 2282 2287 2291\n",
      " 2292 2303 2309 2356 2358 2361 2365 2369 2379 2394 2395 2399 2400 2410\n",
      " 2425 2426 2434 2435 2442 2446 2449 2452 2458 2463 2472 2476 2480 2489\n",
      " 2493 2494 2495 2496 2498 2505 2506 2507 2515 2516 2517 2524 2529 2532\n",
      " 2540 2542 2546 2547 2550 2554 2569 2570 2576 2577 2579 2602 2607 2610\n",
      " 2615 2618 2624 2626 2627 2628 2629 2630 2639 2643 2646 2648 2651 2656\n",
      " 2659 2687 2702 2705 2706 2713 2717 2719 2734 2735 2737 2745 2758 2761\n",
      " 2782 2787 2795 2796 2799 2806 2815 2823 2824 2832 2835 2848 2853 2854\n",
      " 2862 2864 2867 2875 2877 2879 2880 2893 2895 2899 2900 2906 2913 2919\n",
      " 2921 2927 2930 2941 2943 2944 2954 2957 2965 2968 2971 2975 2977 2982\n",
      " 2985 2992 3009 3012 3015 3023 3027 3035 3036 3043 3044 3048 3052 3053\n",
      " 3063 3069 3070 3076 3082 3084 3089 3094 3102 3105 3109 3111 3127 3128\n",
      " 3129 3141 3150 3151 3154 3157 3164 3166 3169 3175 3176 3191 3194 3206\n",
      " 3219 3224 3230 3235 3237 3238 3245 3249 3250 3251 3252 3256 3259 3268\n",
      " 3271 3272 3276 3280 3283 3292 3301 3311 3314 3318 3321 3322 3323 3335\n",
      " 3337 3338 3341 3356 3357 3359 3362 3376 3379 3385 3390 3400 3401 3404\n",
      " 3409 3412 3426 3427 3428 3429 3432 3439 3445 3451 3462 3464 3469 3471\n",
      " 3476 3484 3504 3520 3528 3533 3537 3538 3547 3552 3561 3568 3572 3582\n",
      " 3594 3600 3607 3622 3623 3624 3625 3639 3645 3646 3651 3672 3677 3681\n",
      " 3696 3707 3712 3715 3716 3717 3719 3724 3730 3735 3737 3738 3756 3761\n",
      " 3764 3765 3766 3772 3775 3783 3789 3790 3791 3797 3800 3802 3806 3815\n",
      " 3821 3824 3826 3837 3839 3846 3853 3856 3860 3861 3864 3869 3889 3897\n",
      " 3899 3902 3903 3907 3917 3921 3925 3937 3938 3942 3953 3956 3969 3972\n",
      " 3977 3980 3990 3998 4003 4005 4007 4012 4016 4023 4030 4039 4043 4050\n",
      " 4058 4061 4064 4069]\n",
      "Number of samples for test set: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:10:20.417640: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_359/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6929 - accuracy: 0.5132 - val_loss: 0.6913 - val_accuracy: 0.5049 - 3s/epoch - 13ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6840 - accuracy: 0.5668 - val_loss: 0.6703 - val_accuracy: 0.6066 - 942ms/epoch - 5ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6635 - accuracy: 0.6020 - val_loss: 0.6541 - val_accuracy: 0.6176 - 957ms/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6570 - accuracy: 0.6204 - val_loss: 0.6491 - val_accuracy: 0.6409 - 912ms/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6448 - accuracy: 0.6373 - val_loss: 0.6463 - val_accuracy: 0.6287 - 922ms/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6399 - accuracy: 0.6480 - val_loss: 0.6365 - val_accuracy: 0.6532 - 933ms/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6276 - accuracy: 0.6529 - val_loss: 0.6224 - val_accuracy: 0.6679 - 937ms/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6186 - accuracy: 0.6664 - val_loss: 0.6154 - val_accuracy: 0.6875 - 943ms/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6169 - accuracy: 0.6670 - val_loss: 0.6104 - val_accuracy: 0.7022 - 923ms/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.6119 - accuracy: 0.6801 - val_loss: 0.6097 - val_accuracy: 0.6838 - 907ms/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6090 - accuracy: 0.6780 - val_loss: 0.6041 - val_accuracy: 0.6961 - 941ms/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.6068 - accuracy: 0.6823 - val_loss: 0.6004 - val_accuracy: 0.7145 - 919ms/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.6040 - accuracy: 0.6936 - val_loss: 0.6015 - val_accuracy: 0.6936 - 936ms/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.6003 - accuracy: 0.6952 - val_loss: 0.5951 - val_accuracy: 0.6900 - 927ms/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.5967 - accuracy: 0.6942 - val_loss: 0.5986 - val_accuracy: 0.6887 - 944ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.5999 - accuracy: 0.6906 - val_loss: 0.5887 - val_accuracy: 0.7145 - 942ms/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.5907 - accuracy: 0.6991 - val_loss: 0.5928 - val_accuracy: 0.7157 - 950ms/epoch - 5ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.5890 - accuracy: 0.6945 - val_loss: 0.5904 - val_accuracy: 0.7108 - 936ms/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.5883 - accuracy: 0.7025 - val_loss: 0.5959 - val_accuracy: 0.6900 - 922ms/epoch - 5ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.5858 - accuracy: 0.7074 - val_loss: 0.5853 - val_accuracy: 0.7120 - 968ms/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.5899 - accuracy: 0.7016 - val_loss: 0.5836 - val_accuracy: 0.7047 - 947ms/epoch - 5ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.5814 - accuracy: 0.7056 - val_loss: 0.5792 - val_accuracy: 0.7120 - 921ms/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.5760 - accuracy: 0.7062 - val_loss: 0.5897 - val_accuracy: 0.7132 - 919ms/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.5802 - accuracy: 0.7019 - val_loss: 0.5857 - val_accuracy: 0.7353 - 926ms/epoch - 5ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.5740 - accuracy: 0.7138 - val_loss: 0.5826 - val_accuracy: 0.7022 - 912ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.5745 - accuracy: 0.7068 - val_loss: 0.5788 - val_accuracy: 0.7096 - 930ms/epoch - 5ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.5733 - accuracy: 0.7102 - val_loss: 0.5789 - val_accuracy: 0.7169 - 900ms/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.5687 - accuracy: 0.7114 - val_loss: 0.5715 - val_accuracy: 0.7181 - 953ms/epoch - 5ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.5739 - accuracy: 0.7059 - val_loss: 0.5719 - val_accuracy: 0.7292 - 953ms/epoch - 5ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.5728 - accuracy: 0.7175 - val_loss: 0.5740 - val_accuracy: 0.7255 - 929ms/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.5632 - accuracy: 0.7194 - val_loss: 0.5758 - val_accuracy: 0.7267 - 929ms/epoch - 5ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.5652 - accuracy: 0.7154 - val_loss: 0.5776 - val_accuracy: 0.7096 - 940ms/epoch - 5ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.5666 - accuracy: 0.7191 - val_loss: 0.5734 - val_accuracy: 0.7243 - 918ms/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.5632 - accuracy: 0.7188 - val_loss: 0.5729 - val_accuracy: 0.7169 - 943ms/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.5610 - accuracy: 0.7246 - val_loss: 0.5734 - val_accuracy: 0.7132 - 955ms/epoch - 5ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.5628 - accuracy: 0.7157 - val_loss: 0.5615 - val_accuracy: 0.7451 - 979ms/epoch - 5ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.5579 - accuracy: 0.7298 - val_loss: 0.5669 - val_accuracy: 0.7316 - 931ms/epoch - 5ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.5613 - accuracy: 0.7215 - val_loss: 0.5687 - val_accuracy: 0.7194 - 946ms/epoch - 5ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.5542 - accuracy: 0.7243 - val_loss: 0.5642 - val_accuracy: 0.7365 - 963ms/epoch - 5ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.5664 - accuracy: 0.7154 - val_loss: 0.5688 - val_accuracy: 0.7377 - 965ms/epoch - 5ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.5614 - accuracy: 0.7227 - val_loss: 0.5723 - val_accuracy: 0.7145 - 969ms/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.5554 - accuracy: 0.7200 - val_loss: 0.5661 - val_accuracy: 0.7230 - 953ms/epoch - 5ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.5543 - accuracy: 0.7230 - val_loss: 0.5623 - val_accuracy: 0.7194 - 944ms/epoch - 5ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.5571 - accuracy: 0.7255 - val_loss: 0.5682 - val_accuracy: 0.7145 - 937ms/epoch - 5ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.5471 - accuracy: 0.7304 - val_loss: 0.5654 - val_accuracy: 0.7316 - 954ms/epoch - 5ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.5615 - accuracy: 0.7255 - val_loss: 0.5635 - val_accuracy: 0.7365 - 949ms/epoch - 5ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.5579 - accuracy: 0.7209 - val_loss: 0.5677 - val_accuracy: 0.7218 - 919ms/epoch - 5ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.5488 - accuracy: 0.7252 - val_loss: 0.5657 - val_accuracy: 0.7145 - 931ms/epoch - 5ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.5517 - accuracy: 0.7264 - val_loss: 0.5663 - val_accuracy: 0.7206 - 963ms/epoch - 5ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.5535 - accuracy: 0.7267 - val_loss: 0.5643 - val_accuracy: 0.7230 - 953ms/epoch - 5ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.5466 - accuracy: 0.7295 - val_loss: 0.5606 - val_accuracy: 0.7279 - 939ms/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.5542 - accuracy: 0.7237 - val_loss: 0.5634 - val_accuracy: 0.7255 - 942ms/epoch - 5ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.5451 - accuracy: 0.7350 - val_loss: 0.5640 - val_accuracy: 0.7341 - 963ms/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.5566 - accuracy: 0.7224 - val_loss: 0.5666 - val_accuracy: 0.7132 - 955ms/epoch - 5ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.5469 - accuracy: 0.7381 - val_loss: 0.5640 - val_accuracy: 0.6973 - 948ms/epoch - 5ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.5434 - accuracy: 0.7310 - val_loss: 0.5670 - val_accuracy: 0.7047 - 918ms/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.5461 - accuracy: 0.7307 - val_loss: 0.5567 - val_accuracy: 0.7304 - 915ms/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.5505 - accuracy: 0.7249 - val_loss: 0.5568 - val_accuracy: 0.7206 - 949ms/epoch - 5ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.5484 - accuracy: 0.7310 - val_loss: 0.5594 - val_accuracy: 0.7279 - 953ms/epoch - 5ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.5377 - accuracy: 0.7368 - val_loss: 0.5571 - val_accuracy: 0.7328 - 940ms/epoch - 5ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.5426 - accuracy: 0.7261 - val_loss: 0.5616 - val_accuracy: 0.7181 - 923ms/epoch - 5ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.5431 - accuracy: 0.7298 - val_loss: 0.5605 - val_accuracy: 0.7206 - 946ms/epoch - 5ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.5350 - accuracy: 0.7472 - val_loss: 0.5596 - val_accuracy: 0.7218 - 932ms/epoch - 5ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.5406 - accuracy: 0.7387 - val_loss: 0.5609 - val_accuracy: 0.7292 - 934ms/epoch - 5ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.5418 - accuracy: 0.7237 - val_loss: 0.5609 - val_accuracy: 0.7194 - 940ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.5489 - accuracy: 0.7209 - val_loss: 0.5581 - val_accuracy: 0.7206 - 952ms/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.5477 - accuracy: 0.7237 - val_loss: 0.5609 - val_accuracy: 0.7255 - 947ms/epoch - 5ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.5412 - accuracy: 0.7295 - val_loss: 0.5570 - val_accuracy: 0.7304 - 948ms/epoch - 5ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.5388 - accuracy: 0.7399 - val_loss: 0.5637 - val_accuracy: 0.7096 - 955ms/epoch - 5ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.5420 - accuracy: 0.7347 - val_loss: 0.5620 - val_accuracy: 0.7157 - 936ms/epoch - 5ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.5440 - accuracy: 0.7436 - val_loss: 0.5591 - val_accuracy: 0.7120 - 938ms/epoch - 5ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.5293 - accuracy: 0.7445 - val_loss: 0.5526 - val_accuracy: 0.7218 - 925ms/epoch - 5ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.5352 - accuracy: 0.7377 - val_loss: 0.5534 - val_accuracy: 0.7267 - 935ms/epoch - 5ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.5447 - accuracy: 0.7328 - val_loss: 0.5512 - val_accuracy: 0.7377 - 943ms/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.5312 - accuracy: 0.7408 - val_loss: 0.5531 - val_accuracy: 0.7267 - 943ms/epoch - 5ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.5365 - accuracy: 0.7365 - val_loss: 0.5591 - val_accuracy: 0.7132 - 935ms/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.5338 - accuracy: 0.7442 - val_loss: 0.5552 - val_accuracy: 0.7181 - 940ms/epoch - 5ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.5359 - accuracy: 0.7408 - val_loss: 0.5491 - val_accuracy: 0.7390 - 954ms/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.5367 - accuracy: 0.7264 - val_loss: 0.5505 - val_accuracy: 0.7304 - 941ms/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.5329 - accuracy: 0.7377 - val_loss: 0.5508 - val_accuracy: 0.7255 - 922ms/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.5347 - accuracy: 0.7399 - val_loss: 0.5548 - val_accuracy: 0.7292 - 917ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.5319 - accuracy: 0.7341 - val_loss: 0.5594 - val_accuracy: 0.7157 - 923ms/epoch - 5ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.5345 - accuracy: 0.7304 - val_loss: 0.5595 - val_accuracy: 0.7169 - 932ms/epoch - 5ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.5342 - accuracy: 0.7463 - val_loss: 0.5589 - val_accuracy: 0.7353 - 949ms/epoch - 5ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.5359 - accuracy: 0.7426 - val_loss: 0.5687 - val_accuracy: 0.7169 - 957ms/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.5320 - accuracy: 0.7353 - val_loss: 0.5618 - val_accuracy: 0.7145 - 931ms/epoch - 5ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.5233 - accuracy: 0.7426 - val_loss: 0.5693 - val_accuracy: 0.7194 - 947ms/epoch - 5ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.5320 - accuracy: 0.7350 - val_loss: 0.5504 - val_accuracy: 0.7353 - 950ms/epoch - 5ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.5327 - accuracy: 0.7448 - val_loss: 0.5527 - val_accuracy: 0.7316 - 930ms/epoch - 5ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.5296 - accuracy: 0.7423 - val_loss: 0.5475 - val_accuracy: 0.7353 - 915ms/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.5225 - accuracy: 0.7479 - val_loss: 0.5587 - val_accuracy: 0.7194 - 918ms/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.5268 - accuracy: 0.7381 - val_loss: 0.5574 - val_accuracy: 0.7255 - 937ms/epoch - 5ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.5276 - accuracy: 0.7451 - val_loss: 0.5536 - val_accuracy: 0.7316 - 948ms/epoch - 5ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.5237 - accuracy: 0.7512 - val_loss: 0.5619 - val_accuracy: 0.7145 - 891ms/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.5298 - accuracy: 0.7381 - val_loss: 0.5572 - val_accuracy: 0.7230 - 907ms/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.5264 - accuracy: 0.7433 - val_loss: 0.5552 - val_accuracy: 0.7304 - 945ms/epoch - 5ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.5219 - accuracy: 0.7485 - val_loss: 0.5490 - val_accuracy: 0.7377 - 936ms/epoch - 5ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.5230 - accuracy: 0.7454 - val_loss: 0.5480 - val_accuracy: 0.7402 - 955ms/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.5218 - accuracy: 0.7521 - val_loss: 0.5463 - val_accuracy: 0.7304 - 922ms/epoch - 5ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.5296 - accuracy: 0.7442 - val_loss: 0.5538 - val_accuracy: 0.7169 - 929ms/epoch - 5ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.5257 - accuracy: 0.7411 - val_loss: 0.5589 - val_accuracy: 0.7255 - 959ms/epoch - 5ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.5371 - accuracy: 0.7420 - val_loss: 0.5585 - val_accuracy: 0.7083 - 917ms/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.5247 - accuracy: 0.7417 - val_loss: 0.5544 - val_accuracy: 0.7353 - 932ms/epoch - 5ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.5240 - accuracy: 0.7475 - val_loss: 0.5528 - val_accuracy: 0.7206 - 916ms/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.5315 - accuracy: 0.7402 - val_loss: 0.5513 - val_accuracy: 0.7206 - 934ms/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.5277 - accuracy: 0.7420 - val_loss: 0.5530 - val_accuracy: 0.7194 - 951ms/epoch - 5ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.5274 - accuracy: 0.7439 - val_loss: 0.5576 - val_accuracy: 0.7181 - 926ms/epoch - 5ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.5179 - accuracy: 0.7531 - val_loss: 0.5545 - val_accuracy: 0.7194 - 938ms/epoch - 5ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.5213 - accuracy: 0.7475 - val_loss: 0.5587 - val_accuracy: 0.7132 - 928ms/epoch - 5ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.5146 - accuracy: 0.7466 - val_loss: 0.5484 - val_accuracy: 0.7316 - 922ms/epoch - 5ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.5208 - accuracy: 0.7485 - val_loss: 0.5522 - val_accuracy: 0.7267 - 934ms/epoch - 5ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.5253 - accuracy: 0.7491 - val_loss: 0.5533 - val_accuracy: 0.7145 - 937ms/epoch - 5ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.5219 - accuracy: 0.7399 - val_loss: 0.5561 - val_accuracy: 0.7169 - 932ms/epoch - 5ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.5207 - accuracy: 0.7574 - val_loss: 0.5552 - val_accuracy: 0.7157 - 931ms/epoch - 5ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.5187 - accuracy: 0.7491 - val_loss: 0.5456 - val_accuracy: 0.7218 - 935ms/epoch - 5ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.5214 - accuracy: 0.7497 - val_loss: 0.5470 - val_accuracy: 0.7292 - 951ms/epoch - 5ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.5210 - accuracy: 0.7454 - val_loss: 0.5495 - val_accuracy: 0.7218 - 936ms/epoch - 5ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.5259 - accuracy: 0.7445 - val_loss: 0.5476 - val_accuracy: 0.7292 - 946ms/epoch - 5ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.5212 - accuracy: 0.7466 - val_loss: 0.5578 - val_accuracy: 0.7169 - 931ms/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.5152 - accuracy: 0.7500 - val_loss: 0.5509 - val_accuracy: 0.7230 - 945ms/epoch - 5ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.5171 - accuracy: 0.7503 - val_loss: 0.5456 - val_accuracy: 0.7279 - 925ms/epoch - 5ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.5166 - accuracy: 0.7506 - val_loss: 0.5465 - val_accuracy: 0.7279 - 961ms/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.5108 - accuracy: 0.7558 - val_loss: 0.5577 - val_accuracy: 0.7145 - 933ms/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.5241 - accuracy: 0.7396 - val_loss: 0.5508 - val_accuracy: 0.7157 - 928ms/epoch - 5ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.5271 - accuracy: 0.7371 - val_loss: 0.5524 - val_accuracy: 0.7218 - 948ms/epoch - 5ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.5171 - accuracy: 0.7454 - val_loss: 0.5645 - val_accuracy: 0.7230 - 969ms/epoch - 5ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.5247 - accuracy: 0.7460 - val_loss: 0.5514 - val_accuracy: 0.7304 - 966ms/epoch - 5ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.5193 - accuracy: 0.7390 - val_loss: 0.5483 - val_accuracy: 0.7120 - 938ms/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.5177 - accuracy: 0.7463 - val_loss: 0.5518 - val_accuracy: 0.7157 - 945ms/epoch - 5ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.5202 - accuracy: 0.7423 - val_loss: 0.5504 - val_accuracy: 0.7255 - 926ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.5086 - accuracy: 0.7641 - val_loss: 0.5574 - val_accuracy: 0.7292 - 933ms/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.5101 - accuracy: 0.7521 - val_loss: 0.5574 - val_accuracy: 0.7132 - 958ms/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.5135 - accuracy: 0.7500 - val_loss: 0.5491 - val_accuracy: 0.7377 - 923ms/epoch - 5ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.5173 - accuracy: 0.7430 - val_loss: 0.5534 - val_accuracy: 0.7218 - 937ms/epoch - 5ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.5231 - accuracy: 0.7448 - val_loss: 0.5535 - val_accuracy: 0.7304 - 953ms/epoch - 5ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.5111 - accuracy: 0.7567 - val_loss: 0.5597 - val_accuracy: 0.7353 - 938ms/epoch - 5ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.5151 - accuracy: 0.7616 - val_loss: 0.5503 - val_accuracy: 0.7267 - 933ms/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.5101 - accuracy: 0.7577 - val_loss: 0.5446 - val_accuracy: 0.7316 - 948ms/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.5164 - accuracy: 0.7549 - val_loss: 0.5483 - val_accuracy: 0.7402 - 960ms/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.5024 - accuracy: 0.7644 - val_loss: 0.5507 - val_accuracy: 0.7365 - 973ms/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.5095 - accuracy: 0.7595 - val_loss: 0.5544 - val_accuracy: 0.7181 - 944ms/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.5064 - accuracy: 0.7583 - val_loss: 0.5555 - val_accuracy: 0.7267 - 945ms/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.5203 - accuracy: 0.7457 - val_loss: 0.5568 - val_accuracy: 0.7243 - 955ms/epoch - 5ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.5131 - accuracy: 0.7586 - val_loss: 0.5626 - val_accuracy: 0.7022 - 930ms/epoch - 5ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.5025 - accuracy: 0.7665 - val_loss: 0.5493 - val_accuracy: 0.7230 - 943ms/epoch - 5ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.5179 - accuracy: 0.7586 - val_loss: 0.5518 - val_accuracy: 0.7267 - 936ms/epoch - 5ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.5131 - accuracy: 0.7592 - val_loss: 0.5538 - val_accuracy: 0.7083 - 938ms/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.5172 - accuracy: 0.7479 - val_loss: 0.5545 - val_accuracy: 0.7341 - 935ms/epoch - 5ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.5132 - accuracy: 0.7549 - val_loss: 0.5506 - val_accuracy: 0.7353 - 947ms/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.5006 - accuracy: 0.7619 - val_loss: 0.5577 - val_accuracy: 0.7181 - 946ms/epoch - 5ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.5142 - accuracy: 0.7500 - val_loss: 0.5535 - val_accuracy: 0.7243 - 944ms/epoch - 5ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.5110 - accuracy: 0.7580 - val_loss: 0.5552 - val_accuracy: 0.7267 - 970ms/epoch - 5ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.5086 - accuracy: 0.7589 - val_loss: 0.5493 - val_accuracy: 0.7181 - 910ms/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.5093 - accuracy: 0.7601 - val_loss: 0.5491 - val_accuracy: 0.7157 - 952ms/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.5092 - accuracy: 0.7589 - val_loss: 0.5469 - val_accuracy: 0.7328 - 953ms/epoch - 5ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.5083 - accuracy: 0.7601 - val_loss: 0.5486 - val_accuracy: 0.7267 - 931ms/epoch - 5ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.5001 - accuracy: 0.7699 - val_loss: 0.5539 - val_accuracy: 0.7157 - 953ms/epoch - 5ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.5115 - accuracy: 0.7616 - val_loss: 0.5552 - val_accuracy: 0.7169 - 935ms/epoch - 5ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.5136 - accuracy: 0.7485 - val_loss: 0.5470 - val_accuracy: 0.7279 - 957ms/epoch - 5ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.4961 - accuracy: 0.7567 - val_loss: 0.5493 - val_accuracy: 0.7341 - 979ms/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.5013 - accuracy: 0.7540 - val_loss: 0.5502 - val_accuracy: 0.7304 - 966ms/epoch - 5ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.5124 - accuracy: 0.7567 - val_loss: 0.5500 - val_accuracy: 0.7304 - 957ms/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.5068 - accuracy: 0.7518 - val_loss: 0.5501 - val_accuracy: 0.7194 - 943ms/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.5151 - accuracy: 0.7445 - val_loss: 0.5540 - val_accuracy: 0.7157 - 938ms/epoch - 5ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.5040 - accuracy: 0.7531 - val_loss: 0.5622 - val_accuracy: 0.7059 - 907ms/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.5110 - accuracy: 0.7549 - val_loss: 0.5452 - val_accuracy: 0.7341 - 957ms/epoch - 5ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.5051 - accuracy: 0.7647 - val_loss: 0.5447 - val_accuracy: 0.7463 - 957ms/epoch - 5ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.5155 - accuracy: 0.7491 - val_loss: 0.5459 - val_accuracy: 0.7377 - 954ms/epoch - 5ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.5057 - accuracy: 0.7580 - val_loss: 0.5524 - val_accuracy: 0.7279 - 938ms/epoch - 5ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.5048 - accuracy: 0.7589 - val_loss: 0.5615 - val_accuracy: 0.7120 - 944ms/epoch - 5ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.4985 - accuracy: 0.7647 - val_loss: 0.5617 - val_accuracy: 0.7132 - 949ms/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.4983 - accuracy: 0.7552 - val_loss: 0.5515 - val_accuracy: 0.7181 - 950ms/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.5180 - accuracy: 0.7485 - val_loss: 0.5551 - val_accuracy: 0.7255 - 945ms/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.5115 - accuracy: 0.7534 - val_loss: 0.5544 - val_accuracy: 0.7304 - 950ms/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.4952 - accuracy: 0.7641 - val_loss: 0.5490 - val_accuracy: 0.7316 - 930ms/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.5047 - accuracy: 0.7662 - val_loss: 0.5508 - val_accuracy: 0.7365 - 952ms/epoch - 5ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.5147 - accuracy: 0.7561 - val_loss: 0.5477 - val_accuracy: 0.7316 - 950ms/epoch - 5ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.5091 - accuracy: 0.7598 - val_loss: 0.5510 - val_accuracy: 0.7292 - 946ms/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.4994 - accuracy: 0.7601 - val_loss: 0.5500 - val_accuracy: 0.7230 - 953ms/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.4993 - accuracy: 0.7687 - val_loss: 0.5562 - val_accuracy: 0.7255 - 971ms/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.5001 - accuracy: 0.7647 - val_loss: 0.5506 - val_accuracy: 0.7341 - 926ms/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.4994 - accuracy: 0.7708 - val_loss: 0.5515 - val_accuracy: 0.7243 - 945ms/epoch - 5ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.4999 - accuracy: 0.7607 - val_loss: 0.5423 - val_accuracy: 0.7426 - 935ms/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.5019 - accuracy: 0.7604 - val_loss: 0.5457 - val_accuracy: 0.7255 - 938ms/epoch - 5ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.5023 - accuracy: 0.7543 - val_loss: 0.5427 - val_accuracy: 0.7255 - 930ms/epoch - 5ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.4902 - accuracy: 0.7623 - val_loss: 0.5489 - val_accuracy: 0.7243 - 913ms/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.4988 - accuracy: 0.7595 - val_loss: 0.5527 - val_accuracy: 0.7181 - 943ms/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.5154 - accuracy: 0.7558 - val_loss: 0.5600 - val_accuracy: 0.7145 - 958ms/epoch - 5ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.5105 - accuracy: 0.7552 - val_loss: 0.5496 - val_accuracy: 0.7402 - 926ms/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.5093 - accuracy: 0.7586 - val_loss: 0.5522 - val_accuracy: 0.7292 - 903ms/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.5040 - accuracy: 0.7623 - val_loss: 0.5531 - val_accuracy: 0.7108 - 965ms/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.4996 - accuracy: 0.7604 - val_loss: 0.5603 - val_accuracy: 0.7083 - 959ms/epoch - 5ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.5138 - accuracy: 0.7515 - val_loss: 0.5511 - val_accuracy: 0.7157 - 929ms/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.5033 - accuracy: 0.7678 - val_loss: 0.5495 - val_accuracy: 0.7304 - 950ms/epoch - 5ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.4944 - accuracy: 0.7672 - val_loss: 0.5528 - val_accuracy: 0.7279 - 927ms/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.5165 - accuracy: 0.7549 - val_loss: 0.5492 - val_accuracy: 0.7218 - 944ms/epoch - 5ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.5021 - accuracy: 0.7598 - val_loss: 0.5460 - val_accuracy: 0.7341 - 943ms/epoch - 5ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.5121 - accuracy: 0.7564 - val_loss: 0.5483 - val_accuracy: 0.7341 - 933ms/epoch - 5ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.4979 - accuracy: 0.7540 - val_loss: 0.5505 - val_accuracy: 0.7267 - 932ms/epoch - 5ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.5108 - accuracy: 0.7506 - val_loss: 0.5454 - val_accuracy: 0.7243 - 939ms/epoch - 5ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.5002 - accuracy: 0.7574 - val_loss: 0.5574 - val_accuracy: 0.7206 - 947ms/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.5117 - accuracy: 0.7567 - val_loss: 0.5465 - val_accuracy: 0.7218 - 953ms/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.5019 - accuracy: 0.7601 - val_loss: 0.5555 - val_accuracy: 0.7120 - 945ms/epoch - 5ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.5008 - accuracy: 0.7601 - val_loss: 0.5545 - val_accuracy: 0.7096 - 927ms/epoch - 5ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.4921 - accuracy: 0.7656 - val_loss: 0.5468 - val_accuracy: 0.7243 - 928ms/epoch - 5ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.4978 - accuracy: 0.7586 - val_loss: 0.5486 - val_accuracy: 0.7292 - 946ms/epoch - 5ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.5105 - accuracy: 0.7613 - val_loss: 0.5493 - val_accuracy: 0.7316 - 943ms/epoch - 5ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.4998 - accuracy: 0.7641 - val_loss: 0.5562 - val_accuracy: 0.7145 - 962ms/epoch - 5ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.5102 - accuracy: 0.7567 - val_loss: 0.5569 - val_accuracy: 0.7218 - 963ms/epoch - 5ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.5026 - accuracy: 0.7580 - val_loss: 0.5449 - val_accuracy: 0.7377 - 958ms/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.5005 - accuracy: 0.7684 - val_loss: 0.5462 - val_accuracy: 0.7255 - 959ms/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.4939 - accuracy: 0.7607 - val_loss: 0.5489 - val_accuracy: 0.7328 - 963ms/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.4973 - accuracy: 0.7604 - val_loss: 0.5547 - val_accuracy: 0.7230 - 937ms/epoch - 5ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.5011 - accuracy: 0.7601 - val_loss: 0.5548 - val_accuracy: 0.7218 - 945ms/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.5023 - accuracy: 0.7574 - val_loss: 0.5637 - val_accuracy: 0.7132 - 967ms/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.5020 - accuracy: 0.7623 - val_loss: 0.5520 - val_accuracy: 0.7328 - 949ms/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.4947 - accuracy: 0.7543 - val_loss: 0.5538 - val_accuracy: 0.7230 - 955ms/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.4961 - accuracy: 0.7672 - val_loss: 0.5474 - val_accuracy: 0.7316 - 933ms/epoch - 5ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.4955 - accuracy: 0.7687 - val_loss: 0.5487 - val_accuracy: 0.7279 - 957ms/epoch - 5ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.5061 - accuracy: 0.7607 - val_loss: 0.5434 - val_accuracy: 0.7292 - 958ms/epoch - 5ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.4944 - accuracy: 0.7684 - val_loss: 0.5517 - val_accuracy: 0.7292 - 930ms/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.5055 - accuracy: 0.7577 - val_loss: 0.5521 - val_accuracy: 0.7267 - 954ms/epoch - 5ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.4967 - accuracy: 0.7610 - val_loss: 0.5451 - val_accuracy: 0.7255 - 941ms/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.5013 - accuracy: 0.7567 - val_loss: 0.5585 - val_accuracy: 0.7157 - 951ms/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.5086 - accuracy: 0.7641 - val_loss: 0.5506 - val_accuracy: 0.7328 - 937ms/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.4908 - accuracy: 0.7684 - val_loss: 0.5531 - val_accuracy: 0.7194 - 928ms/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.4969 - accuracy: 0.7626 - val_loss: 0.5414 - val_accuracy: 0.7439 - 940ms/epoch - 5ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.4889 - accuracy: 0.7574 - val_loss: 0.5533 - val_accuracy: 0.7255 - 948ms/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.4936 - accuracy: 0.7635 - val_loss: 0.5525 - val_accuracy: 0.7230 - 960ms/epoch - 5ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.4924 - accuracy: 0.7644 - val_loss: 0.5572 - val_accuracy: 0.7206 - 964ms/epoch - 5ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.5114 - accuracy: 0.7463 - val_loss: 0.5515 - val_accuracy: 0.7243 - 940ms/epoch - 5ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.4982 - accuracy: 0.7638 - val_loss: 0.5517 - val_accuracy: 0.7206 - 949ms/epoch - 5ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.4922 - accuracy: 0.7721 - val_loss: 0.5559 - val_accuracy: 0.7194 - 938ms/epoch - 5ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.4979 - accuracy: 0.7561 - val_loss: 0.5522 - val_accuracy: 0.7255 - 938ms/epoch - 5ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.4996 - accuracy: 0.7595 - val_loss: 0.5422 - val_accuracy: 0.7218 - 924ms/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.4962 - accuracy: 0.7653 - val_loss: 0.5508 - val_accuracy: 0.7218 - 931ms/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.5005 - accuracy: 0.7598 - val_loss: 0.5490 - val_accuracy: 0.7255 - 915ms/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.4972 - accuracy: 0.7702 - val_loss: 0.5391 - val_accuracy: 0.7377 - 908ms/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.5077 - accuracy: 0.7552 - val_loss: 0.5447 - val_accuracy: 0.7145 - 935ms/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.4962 - accuracy: 0.7555 - val_loss: 0.5400 - val_accuracy: 0.7304 - 947ms/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.4908 - accuracy: 0.7570 - val_loss: 0.5433 - val_accuracy: 0.7255 - 955ms/epoch - 5ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.4962 - accuracy: 0.7638 - val_loss: 0.5516 - val_accuracy: 0.7230 - 931ms/epoch - 5ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.4936 - accuracy: 0.7632 - val_loss: 0.5492 - val_accuracy: 0.7145 - 937ms/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.4968 - accuracy: 0.7616 - val_loss: 0.5480 - val_accuracy: 0.7218 - 947ms/epoch - 5ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.4908 - accuracy: 0.7690 - val_loss: 0.5654 - val_accuracy: 0.7059 - 944ms/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.4999 - accuracy: 0.7552 - val_loss: 0.5434 - val_accuracy: 0.7365 - 951ms/epoch - 5ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.4933 - accuracy: 0.7647 - val_loss: 0.5617 - val_accuracy: 0.7181 - 951ms/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.4911 - accuracy: 0.7650 - val_loss: 0.5577 - val_accuracy: 0.7218 - 962ms/epoch - 5ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.4909 - accuracy: 0.7687 - val_loss: 0.5445 - val_accuracy: 0.7255 - 1s/epoch - 5ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.4998 - accuracy: 0.7604 - val_loss: 0.5522 - val_accuracy: 0.7230 - 954ms/epoch - 5ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   1    2    3 ... 4076 4077 4078]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   0    5    7    8   11   15   17   24   27   30   48   49   50   53\n",
      "   56   57   59   64   67   69   80   83   95   98  106  107  111  115\n",
      "  121  132  141  143  144  154  158  161  163  168  175  177  179  181\n",
      "  191  192  197  202  203  208  214  220  226  228  233  235  236  238\n",
      "  241  246  251  253  257  262  288  289  299  302  314  327  330  331\n",
      "  339  343  348  354  355  361  364  372  377  381  388  389  402  408\n",
      "  409  424  434  440  445  447  449  461  464  470  472  474  476  477\n",
      "  483  486  489  496  510  514  517  519  524  526  531  543  544  545\n",
      "  559  560  572  577  578  580  586  591  593  600  603  604  609  610\n",
      "  612  613  614  619  629  630  634  636  639  644  645  670  673  681\n",
      "  683  687  690  702  733  741  747  752  757  758  761  763  764  765\n",
      "  772  777  780  785  790  792  793  796  799  805  814  820  825  827\n",
      "  829  833  840  850  858  869  878  883  886  896  905  907  918  922\n",
      "  929  935  940  941  952  955  967  973  975  990  998  999 1004 1010\n",
      " 1024 1025 1027 1032 1034 1045 1048 1052 1053 1055 1056 1060 1062 1080\n",
      " 1099 1105 1106 1109 1110 1118 1122 1123 1129 1136 1137 1142 1144 1146\n",
      " 1148 1157 1167 1175 1178 1179 1185 1207 1208 1229 1230 1231 1244 1245\n",
      " 1249 1250 1251 1269 1277 1281 1285 1286 1287 1289 1305 1306 1309 1310\n",
      " 1315 1318 1322 1329 1330 1334 1338 1341 1349 1356 1358 1361 1368 1372\n",
      " 1374 1387 1394 1398 1415 1420 1425 1427 1431 1433 1437 1440 1452 1455\n",
      " 1459 1475 1477 1478 1480 1482 1488 1503 1507 1510 1511 1513 1515 1522\n",
      " 1525 1531 1537 1538 1539 1546 1551 1554 1563 1568 1572 1575 1576 1579\n",
      " 1580 1582 1583 1590 1591 1611 1619 1620 1621 1622 1630 1632 1642 1646\n",
      " 1654 1667 1669 1672 1674 1676 1687 1688 1694 1698 1699 1700 1712 1717\n",
      " 1742 1744 1747 1754 1756 1758 1765 1766 1772 1775 1776 1780 1784 1785\n",
      " 1789 1797 1814 1817 1821 1825 1832 1848 1852 1867 1874 1877 1892 1893\n",
      " 1894 1895 1900 1905 1906 1913 1914 1915 1920 1930 1931 1942 1944 1945\n",
      " 1949 1953 1958 1961 1964 1965 1966 1981 1986 1993 1997 1999 2007 2026\n",
      " 2049 2050 2080 2081 2082 2083 2088 2096 2106 2122 2126 2134 2139 2153\n",
      " 2159 2162 2165 2168 2169 2170 2173 2191 2198 2202 2208 2209 2215 2218\n",
      " 2233 2234 2240 2253 2255 2258 2260 2267 2269 2273 2274 2277 2284 2288\n",
      " 2293 2296 2298 2307 2310 2315 2316 2317 2319 2322 2329 2335 2342 2343\n",
      " 2345 2347 2351 2352 2353 2355 2374 2377 2382 2387 2389 2390 2393 2401\n",
      " 2402 2403 2407 2409 2413 2415 2416 2432 2433 2441 2445 2447 2461 2462\n",
      " 2467 2468 2471 2483 2485 2521 2523 2527 2530 2537 2539 2541 2543 2545\n",
      " 2549 2558 2559 2561 2575 2578 2586 2591 2594 2597 2601 2605 2608 2611\n",
      " 2616 2631 2632 2634 2636 2640 2644 2654 2660 2663 2668 2669 2676 2682\n",
      " 2684 2686 2694 2695 2699 2704 2708 2718 2720 2741 2742 2744 2748 2751\n",
      " 2752 2753 2754 2755 2766 2767 2770 2774 2778 2779 2783 2789 2790 2791\n",
      " 2797 2800 2801 2805 2807 2808 2810 2813 2817 2821 2822 2826 2829 2830\n",
      " 2831 2840 2841 2844 2865 2866 2870 2871 2884 2892 2901 2903 2904 2916\n",
      " 2924 2925 2929 2933 2934 2935 2936 2940 2945 2947 2948 2956 2962 2966\n",
      " 2967 2969 2970 2972 2973 2974 2979 2981 2983 2984 2988 2997 3001 3003\n",
      " 3008 3017 3020 3022 3024 3028 3050 3051 3060 3065 3066 3067 3092 3093\n",
      " 3106 3113 3122 3126 3134 3135 3136 3139 3145 3152 3153 3155 3156 3159\n",
      " 3161 3162 3168 3171 3179 3187 3201 3205 3209 3217 3223 3225 3231 3234\n",
      " 3239 3246 3247 3260 3261 3262 3265 3269 3270 3278 3279 3286 3289 3293\n",
      " 3297 3300 3303 3309 3310 3315 3325 3328 3329 3330 3331 3336 3342 3351\n",
      " 3352 3363 3367 3370 3372 3374 3375 3381 3387 3388 3392 3394 3397 3399\n",
      " 3402 3405 3408 3413 3424 3430 3437 3442 3456 3459 3460 3463 3467 3474\n",
      " 3483 3487 3491 3494 3500 3506 3514 3515 3519 3527 3532 3540 3541 3543\n",
      " 3555 3559 3566 3569 3578 3584 3585 3591 3592 3602 3606 3611 3612 3616\n",
      " 3617 3621 3626 3634 3637 3638 3642 3659 3664 3684 3687 3695 3701 3702\n",
      " 3710 3720 3722 3723 3725 3728 3731 3732 3747 3754 3755 3758 3770 3771\n",
      " 3773 3779 3785 3788 3792 3793 3794 3801 3805 3825 3830 3834 3836 3838\n",
      " 3840 3851 3866 3870 3872 3879 3886 3908 3912 3914 3916 3923 3928 3930\n",
      " 3935 3936 3945 3966 3967 3974 3976 3979 3981 3986 3992 3993 3996 4000\n",
      " 4013 4019 4028 4029 4033 4038 4045 4047 4048 4055 4056 4057 4067 4068\n",
      " 4071 4073 4074 4079]\n",
      "Number of samples for test set: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:14:19.334994: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_360/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6909 - accuracy: 0.5300 - val_loss: 0.6888 - val_accuracy: 0.5368 - 3s/epoch - 13ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6725 - accuracy: 0.5827 - val_loss: 0.6645 - val_accuracy: 0.6189 - 947ms/epoch - 5ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6586 - accuracy: 0.6143 - val_loss: 0.6486 - val_accuracy: 0.6483 - 959ms/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6431 - accuracy: 0.6486 - val_loss: 0.6346 - val_accuracy: 0.6593 - 969ms/epoch - 5ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6301 - accuracy: 0.6541 - val_loss: 0.6308 - val_accuracy: 0.6581 - 925ms/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6277 - accuracy: 0.6630 - val_loss: 0.6275 - val_accuracy: 0.6618 - 957ms/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6189 - accuracy: 0.6670 - val_loss: 0.6229 - val_accuracy: 0.6667 - 961ms/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6178 - accuracy: 0.6719 - val_loss: 0.6258 - val_accuracy: 0.6801 - 974ms/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6099 - accuracy: 0.6826 - val_loss: 0.6222 - val_accuracy: 0.6826 - 948ms/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.6078 - accuracy: 0.6694 - val_loss: 0.6202 - val_accuracy: 0.6961 - 948ms/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6018 - accuracy: 0.6869 - val_loss: 0.6217 - val_accuracy: 0.6924 - 938ms/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.6025 - accuracy: 0.6780 - val_loss: 0.6183 - val_accuracy: 0.6936 - 941ms/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.5998 - accuracy: 0.6915 - val_loss: 0.6170 - val_accuracy: 0.6826 - 922ms/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.5986 - accuracy: 0.6844 - val_loss: 0.6207 - val_accuracy: 0.6900 - 948ms/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.5961 - accuracy: 0.6826 - val_loss: 0.6136 - val_accuracy: 0.7047 - 934ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.5956 - accuracy: 0.6970 - val_loss: 0.6171 - val_accuracy: 0.6777 - 948ms/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.5940 - accuracy: 0.6942 - val_loss: 0.6244 - val_accuracy: 0.6581 - 940ms/epoch - 5ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.5872 - accuracy: 0.6988 - val_loss: 0.6114 - val_accuracy: 0.7010 - 935ms/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.5911 - accuracy: 0.6903 - val_loss: 0.6104 - val_accuracy: 0.6801 - 901ms/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.5854 - accuracy: 0.6976 - val_loss: 0.6128 - val_accuracy: 0.6826 - 923ms/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.5883 - accuracy: 0.6998 - val_loss: 0.6049 - val_accuracy: 0.6973 - 971ms/epoch - 5ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.5872 - accuracy: 0.6936 - val_loss: 0.6110 - val_accuracy: 0.7034 - 958ms/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.5807 - accuracy: 0.7056 - val_loss: 0.6112 - val_accuracy: 0.6826 - 959ms/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.5801 - accuracy: 0.7047 - val_loss: 0.6148 - val_accuracy: 0.6936 - 932ms/epoch - 5ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.5733 - accuracy: 0.7093 - val_loss: 0.6081 - val_accuracy: 0.6863 - 961ms/epoch - 5ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.5722 - accuracy: 0.7083 - val_loss: 0.6059 - val_accuracy: 0.6863 - 936ms/epoch - 5ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.5687 - accuracy: 0.7163 - val_loss: 0.6009 - val_accuracy: 0.7145 - 947ms/epoch - 5ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.5777 - accuracy: 0.7086 - val_loss: 0.6057 - val_accuracy: 0.7047 - 962ms/epoch - 5ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.5669 - accuracy: 0.7172 - val_loss: 0.5979 - val_accuracy: 0.6936 - 925ms/epoch - 5ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.5719 - accuracy: 0.7093 - val_loss: 0.5924 - val_accuracy: 0.7169 - 899ms/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.5649 - accuracy: 0.7178 - val_loss: 0.5995 - val_accuracy: 0.7034 - 905ms/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.5659 - accuracy: 0.7178 - val_loss: 0.5928 - val_accuracy: 0.7071 - 957ms/epoch - 5ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.5589 - accuracy: 0.7249 - val_loss: 0.5959 - val_accuracy: 0.7071 - 966ms/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.5632 - accuracy: 0.7135 - val_loss: 0.5923 - val_accuracy: 0.7230 - 938ms/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.5592 - accuracy: 0.7191 - val_loss: 0.5953 - val_accuracy: 0.7169 - 948ms/epoch - 5ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.5652 - accuracy: 0.7178 - val_loss: 0.5946 - val_accuracy: 0.7022 - 956ms/epoch - 5ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.5587 - accuracy: 0.7148 - val_loss: 0.5965 - val_accuracy: 0.7034 - 941ms/epoch - 5ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.5585 - accuracy: 0.7240 - val_loss: 0.5984 - val_accuracy: 0.6949 - 941ms/epoch - 5ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.5625 - accuracy: 0.7142 - val_loss: 0.5990 - val_accuracy: 0.7120 - 947ms/epoch - 5ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.5547 - accuracy: 0.7203 - val_loss: 0.5824 - val_accuracy: 0.7255 - 923ms/epoch - 5ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.5626 - accuracy: 0.7206 - val_loss: 0.5830 - val_accuracy: 0.7230 - 967ms/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.5590 - accuracy: 0.7243 - val_loss: 0.5890 - val_accuracy: 0.7218 - 961ms/epoch - 5ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.5507 - accuracy: 0.7246 - val_loss: 0.5952 - val_accuracy: 0.7169 - 949ms/epoch - 5ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.5617 - accuracy: 0.7126 - val_loss: 0.5930 - val_accuracy: 0.7083 - 939ms/epoch - 5ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.5523 - accuracy: 0.7237 - val_loss: 0.5972 - val_accuracy: 0.7071 - 907ms/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.5504 - accuracy: 0.7227 - val_loss: 0.5890 - val_accuracy: 0.7218 - 945ms/epoch - 5ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.5560 - accuracy: 0.7252 - val_loss: 0.5887 - val_accuracy: 0.7169 - 943ms/epoch - 5ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.5585 - accuracy: 0.7163 - val_loss: 0.5879 - val_accuracy: 0.7010 - 949ms/epoch - 5ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.5569 - accuracy: 0.7194 - val_loss: 0.5958 - val_accuracy: 0.7096 - 953ms/epoch - 5ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.5556 - accuracy: 0.7166 - val_loss: 0.5864 - val_accuracy: 0.7255 - 928ms/epoch - 5ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.5473 - accuracy: 0.7258 - val_loss: 0.5905 - val_accuracy: 0.7218 - 934ms/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.5450 - accuracy: 0.7307 - val_loss: 0.5978 - val_accuracy: 0.6961 - 935ms/epoch - 5ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.5457 - accuracy: 0.7258 - val_loss: 0.5798 - val_accuracy: 0.7206 - 944ms/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.5390 - accuracy: 0.7335 - val_loss: 0.5774 - val_accuracy: 0.7169 - 959ms/epoch - 5ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.5450 - accuracy: 0.7286 - val_loss: 0.5923 - val_accuracy: 0.7083 - 964ms/epoch - 5ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.5471 - accuracy: 0.7282 - val_loss: 0.5858 - val_accuracy: 0.7096 - 925ms/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.5373 - accuracy: 0.7371 - val_loss: 0.5889 - val_accuracy: 0.7157 - 960ms/epoch - 5ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.5506 - accuracy: 0.7221 - val_loss: 0.5900 - val_accuracy: 0.7059 - 912ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.5372 - accuracy: 0.7331 - val_loss: 0.5868 - val_accuracy: 0.7047 - 906ms/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.5448 - accuracy: 0.7270 - val_loss: 0.5842 - val_accuracy: 0.7279 - 915ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.5401 - accuracy: 0.7359 - val_loss: 0.5808 - val_accuracy: 0.7120 - 936ms/epoch - 5ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.5441 - accuracy: 0.7289 - val_loss: 0.5759 - val_accuracy: 0.7353 - 942ms/epoch - 5ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.5432 - accuracy: 0.7399 - val_loss: 0.5805 - val_accuracy: 0.7279 - 942ms/epoch - 5ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.5465 - accuracy: 0.7194 - val_loss: 0.5822 - val_accuracy: 0.7169 - 958ms/epoch - 5ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.5408 - accuracy: 0.7353 - val_loss: 0.5799 - val_accuracy: 0.7169 - 949ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.5373 - accuracy: 0.7439 - val_loss: 0.5738 - val_accuracy: 0.7316 - 950ms/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.5452 - accuracy: 0.7279 - val_loss: 0.5789 - val_accuracy: 0.7292 - 934ms/epoch - 5ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.5342 - accuracy: 0.7430 - val_loss: 0.5818 - val_accuracy: 0.7108 - 914ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.5306 - accuracy: 0.7399 - val_loss: 0.5754 - val_accuracy: 0.7255 - 955ms/epoch - 5ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.5367 - accuracy: 0.7399 - val_loss: 0.5860 - val_accuracy: 0.7132 - 944ms/epoch - 5ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.5413 - accuracy: 0.7347 - val_loss: 0.5850 - val_accuracy: 0.7083 - 944ms/epoch - 5ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.5385 - accuracy: 0.7316 - val_loss: 0.5813 - val_accuracy: 0.7279 - 937ms/epoch - 5ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.5347 - accuracy: 0.7387 - val_loss: 0.5822 - val_accuracy: 0.7169 - 937ms/epoch - 5ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.5302 - accuracy: 0.7377 - val_loss: 0.5828 - val_accuracy: 0.7071 - 928ms/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.5318 - accuracy: 0.7405 - val_loss: 0.5895 - val_accuracy: 0.7181 - 966ms/epoch - 5ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.5339 - accuracy: 0.7338 - val_loss: 0.5764 - val_accuracy: 0.7194 - 968ms/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.5274 - accuracy: 0.7414 - val_loss: 0.5811 - val_accuracy: 0.7096 - 977ms/epoch - 5ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.5278 - accuracy: 0.7439 - val_loss: 0.5776 - val_accuracy: 0.7181 - 929ms/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.5287 - accuracy: 0.7371 - val_loss: 0.5797 - val_accuracy: 0.7181 - 952ms/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.5207 - accuracy: 0.7460 - val_loss: 0.5860 - val_accuracy: 0.7181 - 952ms/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.5350 - accuracy: 0.7347 - val_loss: 0.5794 - val_accuracy: 0.7218 - 958ms/epoch - 5ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.5240 - accuracy: 0.7442 - val_loss: 0.5925 - val_accuracy: 0.7181 - 954ms/epoch - 5ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.5242 - accuracy: 0.7359 - val_loss: 0.5788 - val_accuracy: 0.7169 - 945ms/epoch - 5ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.5365 - accuracy: 0.7335 - val_loss: 0.5882 - val_accuracy: 0.7181 - 936ms/epoch - 5ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.5328 - accuracy: 0.7387 - val_loss: 0.5725 - val_accuracy: 0.7328 - 928ms/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.5194 - accuracy: 0.7619 - val_loss: 0.5813 - val_accuracy: 0.7218 - 919ms/epoch - 5ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.5337 - accuracy: 0.7387 - val_loss: 0.5764 - val_accuracy: 0.7218 - 905ms/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.5343 - accuracy: 0.7359 - val_loss: 0.5747 - val_accuracy: 0.7096 - 894ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.5235 - accuracy: 0.7500 - val_loss: 0.5853 - val_accuracy: 0.7108 - 921ms/epoch - 5ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.5275 - accuracy: 0.7356 - val_loss: 0.5807 - val_accuracy: 0.7181 - 965ms/epoch - 5ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.5263 - accuracy: 0.7479 - val_loss: 0.5832 - val_accuracy: 0.7108 - 965ms/epoch - 5ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.5277 - accuracy: 0.7396 - val_loss: 0.5826 - val_accuracy: 0.7169 - 952ms/epoch - 5ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.5255 - accuracy: 0.7393 - val_loss: 0.5789 - val_accuracy: 0.7059 - 920ms/epoch - 5ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.5312 - accuracy: 0.7362 - val_loss: 0.5721 - val_accuracy: 0.7292 - 935ms/epoch - 5ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.5253 - accuracy: 0.7390 - val_loss: 0.5733 - val_accuracy: 0.7255 - 938ms/epoch - 5ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.5305 - accuracy: 0.7365 - val_loss: 0.5801 - val_accuracy: 0.7243 - 934ms/epoch - 5ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.5193 - accuracy: 0.7509 - val_loss: 0.5943 - val_accuracy: 0.6949 - 933ms/epoch - 5ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.5295 - accuracy: 0.7310 - val_loss: 0.5800 - val_accuracy: 0.7194 - 957ms/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.5279 - accuracy: 0.7368 - val_loss: 0.5839 - val_accuracy: 0.7206 - 935ms/epoch - 5ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.5299 - accuracy: 0.7436 - val_loss: 0.5715 - val_accuracy: 0.7145 - 946ms/epoch - 5ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.5185 - accuracy: 0.7479 - val_loss: 0.5735 - val_accuracy: 0.7292 - 949ms/epoch - 5ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.5335 - accuracy: 0.7325 - val_loss: 0.5854 - val_accuracy: 0.7010 - 942ms/epoch - 5ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.5263 - accuracy: 0.7338 - val_loss: 0.5820 - val_accuracy: 0.7132 - 944ms/epoch - 5ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.5337 - accuracy: 0.7387 - val_loss: 0.5889 - val_accuracy: 0.7120 - 953ms/epoch - 5ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.5272 - accuracy: 0.7387 - val_loss: 0.5765 - val_accuracy: 0.7181 - 965ms/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.5268 - accuracy: 0.7479 - val_loss: 0.5821 - val_accuracy: 0.7181 - 975ms/epoch - 5ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.5225 - accuracy: 0.7451 - val_loss: 0.5783 - val_accuracy: 0.7206 - 979ms/epoch - 5ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.5210 - accuracy: 0.7396 - val_loss: 0.5746 - val_accuracy: 0.7132 - 968ms/epoch - 5ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.5338 - accuracy: 0.7359 - val_loss: 0.5814 - val_accuracy: 0.7108 - 954ms/epoch - 5ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.5161 - accuracy: 0.7402 - val_loss: 0.5843 - val_accuracy: 0.7145 - 951ms/epoch - 5ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.5181 - accuracy: 0.7509 - val_loss: 0.5813 - val_accuracy: 0.7157 - 931ms/epoch - 5ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.5310 - accuracy: 0.7384 - val_loss: 0.5771 - val_accuracy: 0.7120 - 968ms/epoch - 5ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.5131 - accuracy: 0.7482 - val_loss: 0.5823 - val_accuracy: 0.7157 - 960ms/epoch - 5ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.5279 - accuracy: 0.7384 - val_loss: 0.5680 - val_accuracy: 0.7181 - 936ms/epoch - 5ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.5143 - accuracy: 0.7488 - val_loss: 0.5753 - val_accuracy: 0.7108 - 960ms/epoch - 5ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.5247 - accuracy: 0.7457 - val_loss: 0.5715 - val_accuracy: 0.7194 - 932ms/epoch - 5ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.5225 - accuracy: 0.7482 - val_loss: 0.5701 - val_accuracy: 0.7230 - 938ms/epoch - 5ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.5158 - accuracy: 0.7433 - val_loss: 0.5879 - val_accuracy: 0.7096 - 956ms/epoch - 5ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.5204 - accuracy: 0.7469 - val_loss: 0.5809 - val_accuracy: 0.7230 - 952ms/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.5198 - accuracy: 0.7402 - val_loss: 0.5771 - val_accuracy: 0.7230 - 953ms/epoch - 5ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.5299 - accuracy: 0.7377 - val_loss: 0.5699 - val_accuracy: 0.7145 - 918ms/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.5202 - accuracy: 0.7368 - val_loss: 0.5903 - val_accuracy: 0.6949 - 960ms/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.5214 - accuracy: 0.7423 - val_loss: 0.5832 - val_accuracy: 0.7181 - 958ms/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.5115 - accuracy: 0.7580 - val_loss: 0.5871 - val_accuracy: 0.7059 - 926ms/epoch - 5ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.5268 - accuracy: 0.7433 - val_loss: 0.5887 - val_accuracy: 0.7047 - 925ms/epoch - 5ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.5240 - accuracy: 0.7390 - val_loss: 0.5745 - val_accuracy: 0.7047 - 921ms/epoch - 5ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.5178 - accuracy: 0.7497 - val_loss: 0.5847 - val_accuracy: 0.7022 - 938ms/epoch - 5ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.5194 - accuracy: 0.7396 - val_loss: 0.5736 - val_accuracy: 0.7194 - 920ms/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.5172 - accuracy: 0.7472 - val_loss: 0.5773 - val_accuracy: 0.7096 - 916ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.5190 - accuracy: 0.7488 - val_loss: 0.5679 - val_accuracy: 0.7194 - 938ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.5185 - accuracy: 0.7417 - val_loss: 0.5818 - val_accuracy: 0.7132 - 923ms/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.5150 - accuracy: 0.7515 - val_loss: 0.5707 - val_accuracy: 0.7169 - 945ms/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.5192 - accuracy: 0.7445 - val_loss: 0.5827 - val_accuracy: 0.7071 - 945ms/epoch - 5ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.5102 - accuracy: 0.7506 - val_loss: 0.5654 - val_accuracy: 0.7377 - 971ms/epoch - 5ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.5146 - accuracy: 0.7494 - val_loss: 0.5748 - val_accuracy: 0.7047 - 935ms/epoch - 5ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.5218 - accuracy: 0.7442 - val_loss: 0.5789 - val_accuracy: 0.7157 - 930ms/epoch - 5ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.5168 - accuracy: 0.7518 - val_loss: 0.5793 - val_accuracy: 0.7255 - 941ms/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.5143 - accuracy: 0.7521 - val_loss: 0.5742 - val_accuracy: 0.7071 - 937ms/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.5188 - accuracy: 0.7497 - val_loss: 0.5801 - val_accuracy: 0.7194 - 935ms/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.5161 - accuracy: 0.7540 - val_loss: 0.5805 - val_accuracy: 0.6998 - 936ms/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.5156 - accuracy: 0.7433 - val_loss: 0.5821 - val_accuracy: 0.7120 - 961ms/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.5103 - accuracy: 0.7491 - val_loss: 0.5738 - val_accuracy: 0.7181 - 938ms/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.5101 - accuracy: 0.7454 - val_loss: 0.5708 - val_accuracy: 0.7218 - 962ms/epoch - 5ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.5081 - accuracy: 0.7515 - val_loss: 0.5809 - val_accuracy: 0.7071 - 958ms/epoch - 5ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.5141 - accuracy: 0.7500 - val_loss: 0.5715 - val_accuracy: 0.7230 - 927ms/epoch - 5ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.5161 - accuracy: 0.7482 - val_loss: 0.5835 - val_accuracy: 0.7120 - 896ms/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.5217 - accuracy: 0.7387 - val_loss: 0.5720 - val_accuracy: 0.7243 - 953ms/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.5125 - accuracy: 0.7472 - val_loss: 0.5866 - val_accuracy: 0.6985 - 950ms/epoch - 5ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.5165 - accuracy: 0.7475 - val_loss: 0.5731 - val_accuracy: 0.7230 - 956ms/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.5118 - accuracy: 0.7439 - val_loss: 0.5782 - val_accuracy: 0.7206 - 946ms/epoch - 5ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.5215 - accuracy: 0.7442 - val_loss: 0.5860 - val_accuracy: 0.7267 - 956ms/epoch - 5ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.5148 - accuracy: 0.7525 - val_loss: 0.5835 - val_accuracy: 0.7083 - 972ms/epoch - 5ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.5080 - accuracy: 0.7515 - val_loss: 0.5740 - val_accuracy: 0.7120 - 943ms/epoch - 5ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.5087 - accuracy: 0.7512 - val_loss: 0.5919 - val_accuracy: 0.7071 - 987ms/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.5183 - accuracy: 0.7460 - val_loss: 0.5793 - val_accuracy: 0.7218 - 922ms/epoch - 5ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.5221 - accuracy: 0.7463 - val_loss: 0.5790 - val_accuracy: 0.7071 - 941ms/epoch - 5ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.5052 - accuracy: 0.7546 - val_loss: 0.5748 - val_accuracy: 0.7255 - 903ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.5001 - accuracy: 0.7586 - val_loss: 0.5792 - val_accuracy: 0.7145 - 956ms/epoch - 5ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.5011 - accuracy: 0.7525 - val_loss: 0.5735 - val_accuracy: 0.7181 - 966ms/epoch - 5ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.5113 - accuracy: 0.7482 - val_loss: 0.5722 - val_accuracy: 0.7096 - 980ms/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.5227 - accuracy: 0.7509 - val_loss: 0.5783 - val_accuracy: 0.7181 - 957ms/epoch - 5ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.5106 - accuracy: 0.7607 - val_loss: 0.5761 - val_accuracy: 0.7010 - 966ms/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.5187 - accuracy: 0.7491 - val_loss: 0.5831 - val_accuracy: 0.7169 - 949ms/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.5114 - accuracy: 0.7482 - val_loss: 0.5846 - val_accuracy: 0.6985 - 965ms/epoch - 5ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.5139 - accuracy: 0.7475 - val_loss: 0.5757 - val_accuracy: 0.7157 - 936ms/epoch - 5ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.5120 - accuracy: 0.7528 - val_loss: 0.5824 - val_accuracy: 0.7181 - 910ms/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.5085 - accuracy: 0.7546 - val_loss: 0.5818 - val_accuracy: 0.7047 - 923ms/epoch - 5ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.5138 - accuracy: 0.7515 - val_loss: 0.5848 - val_accuracy: 0.6985 - 940ms/epoch - 5ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.5284 - accuracy: 0.7426 - val_loss: 0.5840 - val_accuracy: 0.7071 - 912ms/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.5125 - accuracy: 0.7503 - val_loss: 0.5805 - val_accuracy: 0.7108 - 940ms/epoch - 5ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.5158 - accuracy: 0.7488 - val_loss: 0.5834 - val_accuracy: 0.7022 - 924ms/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.5197 - accuracy: 0.7365 - val_loss: 0.5736 - val_accuracy: 0.7120 - 969ms/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.5116 - accuracy: 0.7580 - val_loss: 0.5864 - val_accuracy: 0.7022 - 970ms/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.5222 - accuracy: 0.7482 - val_loss: 0.5784 - val_accuracy: 0.7083 - 933ms/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.5088 - accuracy: 0.7469 - val_loss: 0.5823 - val_accuracy: 0.7108 - 945ms/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.5172 - accuracy: 0.7488 - val_loss: 0.5805 - val_accuracy: 0.7132 - 956ms/epoch - 5ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.5172 - accuracy: 0.7512 - val_loss: 0.5806 - val_accuracy: 0.7108 - 964ms/epoch - 5ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.5111 - accuracy: 0.7537 - val_loss: 0.5887 - val_accuracy: 0.7034 - 972ms/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.5047 - accuracy: 0.7589 - val_loss: 0.5814 - val_accuracy: 0.7230 - 945ms/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.5021 - accuracy: 0.7494 - val_loss: 0.5820 - val_accuracy: 0.7071 - 925ms/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.5122 - accuracy: 0.7564 - val_loss: 0.5803 - val_accuracy: 0.7145 - 963ms/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.5120 - accuracy: 0.7574 - val_loss: 0.5914 - val_accuracy: 0.6900 - 928ms/epoch - 5ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.5048 - accuracy: 0.7589 - val_loss: 0.5851 - val_accuracy: 0.6949 - 949ms/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.5036 - accuracy: 0.7558 - val_loss: 0.5810 - val_accuracy: 0.7145 - 959ms/epoch - 5ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.5120 - accuracy: 0.7417 - val_loss: 0.5779 - val_accuracy: 0.7145 - 929ms/epoch - 5ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.5061 - accuracy: 0.7537 - val_loss: 0.5724 - val_accuracy: 0.7206 - 942ms/epoch - 5ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.5115 - accuracy: 0.7500 - val_loss: 0.5775 - val_accuracy: 0.6985 - 922ms/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.5102 - accuracy: 0.7515 - val_loss: 0.5810 - val_accuracy: 0.7010 - 936ms/epoch - 5ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.5072 - accuracy: 0.7586 - val_loss: 0.5706 - val_accuracy: 0.7047 - 932ms/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.5219 - accuracy: 0.7457 - val_loss: 0.5700 - val_accuracy: 0.7120 - 928ms/epoch - 5ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.5027 - accuracy: 0.7583 - val_loss: 0.5668 - val_accuracy: 0.7194 - 937ms/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.4981 - accuracy: 0.7662 - val_loss: 0.5832 - val_accuracy: 0.7047 - 933ms/epoch - 5ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.5044 - accuracy: 0.7659 - val_loss: 0.5909 - val_accuracy: 0.7010 - 944ms/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.5038 - accuracy: 0.7613 - val_loss: 0.5684 - val_accuracy: 0.7463 - 979ms/epoch - 5ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.5039 - accuracy: 0.7629 - val_loss: 0.5765 - val_accuracy: 0.7096 - 953ms/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.5162 - accuracy: 0.7534 - val_loss: 0.5862 - val_accuracy: 0.7022 - 966ms/epoch - 5ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.5088 - accuracy: 0.7549 - val_loss: 0.5813 - val_accuracy: 0.7120 - 988ms/epoch - 5ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.5077 - accuracy: 0.7515 - val_loss: 0.5751 - val_accuracy: 0.7132 - 968ms/epoch - 5ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.5152 - accuracy: 0.7457 - val_loss: 0.5806 - val_accuracy: 0.7243 - 929ms/epoch - 5ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.5233 - accuracy: 0.7500 - val_loss: 0.5770 - val_accuracy: 0.7157 - 967ms/epoch - 5ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.5118 - accuracy: 0.7512 - val_loss: 0.5699 - val_accuracy: 0.7181 - 933ms/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.5044 - accuracy: 0.7644 - val_loss: 0.5914 - val_accuracy: 0.6973 - 978ms/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.5122 - accuracy: 0.7564 - val_loss: 0.5781 - val_accuracy: 0.7096 - 981ms/epoch - 5ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.5085 - accuracy: 0.7506 - val_loss: 0.5723 - val_accuracy: 0.7218 - 961ms/epoch - 5ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.4977 - accuracy: 0.7601 - val_loss: 0.5731 - val_accuracy: 0.7034 - 966ms/epoch - 5ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.5058 - accuracy: 0.7574 - val_loss: 0.5886 - val_accuracy: 0.7108 - 966ms/epoch - 5ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.4997 - accuracy: 0.7607 - val_loss: 0.5815 - val_accuracy: 0.7206 - 975ms/epoch - 5ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.5059 - accuracy: 0.7650 - val_loss: 0.5858 - val_accuracy: 0.7108 - 924ms/epoch - 5ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.5106 - accuracy: 0.7506 - val_loss: 0.5803 - val_accuracy: 0.7059 - 965ms/epoch - 5ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.5054 - accuracy: 0.7580 - val_loss: 0.5830 - val_accuracy: 0.6961 - 947ms/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.5061 - accuracy: 0.7534 - val_loss: 0.5930 - val_accuracy: 0.6838 - 948ms/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.4970 - accuracy: 0.7641 - val_loss: 0.5808 - val_accuracy: 0.7108 - 944ms/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.4994 - accuracy: 0.7586 - val_loss: 0.5815 - val_accuracy: 0.7108 - 944ms/epoch - 5ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.5030 - accuracy: 0.7659 - val_loss: 0.5868 - val_accuracy: 0.7022 - 965ms/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.5120 - accuracy: 0.7463 - val_loss: 0.5802 - val_accuracy: 0.7083 - 938ms/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.5025 - accuracy: 0.7503 - val_loss: 0.5746 - val_accuracy: 0.7194 - 927ms/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.5015 - accuracy: 0.7619 - val_loss: 0.5736 - val_accuracy: 0.7047 - 949ms/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.4946 - accuracy: 0.7528 - val_loss: 0.5779 - val_accuracy: 0.7071 - 938ms/epoch - 5ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.5004 - accuracy: 0.7537 - val_loss: 0.5874 - val_accuracy: 0.6998 - 963ms/epoch - 5ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.5061 - accuracy: 0.7494 - val_loss: 0.5683 - val_accuracy: 0.7145 - 941ms/epoch - 5ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.5079 - accuracy: 0.7567 - val_loss: 0.5859 - val_accuracy: 0.6985 - 953ms/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.5086 - accuracy: 0.7518 - val_loss: 0.5688 - val_accuracy: 0.7218 - 981ms/epoch - 5ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.4909 - accuracy: 0.7693 - val_loss: 0.5724 - val_accuracy: 0.7181 - 951ms/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.5075 - accuracy: 0.7534 - val_loss: 0.5829 - val_accuracy: 0.7022 - 946ms/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.5100 - accuracy: 0.7564 - val_loss: 0.5859 - val_accuracy: 0.7108 - 992ms/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.5053 - accuracy: 0.7601 - val_loss: 0.5712 - val_accuracy: 0.7096 - 948ms/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.4945 - accuracy: 0.7543 - val_loss: 0.5786 - val_accuracy: 0.7047 - 932ms/epoch - 5ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.5048 - accuracy: 0.7641 - val_loss: 0.5721 - val_accuracy: 0.7108 - 944ms/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.4967 - accuracy: 0.7549 - val_loss: 0.5769 - val_accuracy: 0.7145 - 981ms/epoch - 5ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.5085 - accuracy: 0.7540 - val_loss: 0.5835 - val_accuracy: 0.6924 - 938ms/epoch - 5ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.4967 - accuracy: 0.7598 - val_loss: 0.5807 - val_accuracy: 0.7096 - 947ms/epoch - 5ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.4973 - accuracy: 0.7616 - val_loss: 0.5861 - val_accuracy: 0.7169 - 940ms/epoch - 5ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.5077 - accuracy: 0.7436 - val_loss: 0.5795 - val_accuracy: 0.6985 - 931ms/epoch - 5ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.4947 - accuracy: 0.7629 - val_loss: 0.5906 - val_accuracy: 0.6924 - 938ms/epoch - 5ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.5052 - accuracy: 0.7546 - val_loss: 0.5824 - val_accuracy: 0.6936 - 954ms/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.4948 - accuracy: 0.7598 - val_loss: 0.5783 - val_accuracy: 0.7169 - 952ms/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.4997 - accuracy: 0.7574 - val_loss: 0.5731 - val_accuracy: 0.7059 - 935ms/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.5044 - accuracy: 0.7616 - val_loss: 0.5870 - val_accuracy: 0.6985 - 929ms/epoch - 5ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.5063 - accuracy: 0.7558 - val_loss: 0.5854 - val_accuracy: 0.7010 - 980ms/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.5036 - accuracy: 0.7570 - val_loss: 0.5787 - val_accuracy: 0.7083 - 976ms/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.4929 - accuracy: 0.7669 - val_loss: 0.5899 - val_accuracy: 0.6961 - 962ms/epoch - 5ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.5062 - accuracy: 0.7561 - val_loss: 0.5870 - val_accuracy: 0.7071 - 913ms/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.5172 - accuracy: 0.7485 - val_loss: 0.5815 - val_accuracy: 0.7145 - 918ms/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.5078 - accuracy: 0.7525 - val_loss: 0.5717 - val_accuracy: 0.7132 - 968ms/epoch - 5ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.5126 - accuracy: 0.7479 - val_loss: 0.5782 - val_accuracy: 0.7083 - 942ms/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.5052 - accuracy: 0.7626 - val_loss: 0.5848 - val_accuracy: 0.7145 - 972ms/epoch - 5ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.5111 - accuracy: 0.7525 - val_loss: 0.5731 - val_accuracy: 0.7243 - 968ms/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.5018 - accuracy: 0.7521 - val_loss: 0.5805 - val_accuracy: 0.7096 - 942ms/epoch - 5ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.5016 - accuracy: 0.7589 - val_loss: 0.5767 - val_accuracy: 0.7096 - 928ms/epoch - 5ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.4958 - accuracy: 0.7546 - val_loss: 0.5827 - val_accuracy: 0.7096 - 909ms/epoch - 4ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "128/128 [==============================] - 0s 2ms/step\n",
      "N_CLASSES: 3\n",
      "New shape for X: (4860, 31, 251, 1)\n",
      "New shape for y: (4860,)\n",
      "Train index for this split: [   0    3    4 ... 4857 4858 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   1    2   14   18   19   21   23   28   32   35   38   42   50   58\n",
      "   60   65   71   72   74   76   86   87  103  106  115  129  137  142\n",
      "  148  149  155  156  164  166  169  172  176  181  182  186  187  188\n",
      "  189  200  209  213  215  216  219  221  224  242  254  258  259  262\n",
      "  267  270  275  278  282  288  292  293  297  303  304  311  319  324\n",
      "  328  333  342  346  347  351  353  355  360  362  363  365  371  375\n",
      "  384  387  395  397  407  419  420  424  430  451  455  457  461  465\n",
      "  467  469  475  480  481  484  487  488  490  500  504  509  512  522\n",
      "  527  533  542  553  557  558  563  564  568  571  574  576  581  582\n",
      "  590  592  595  602  603  606  607  609  610  615  622  623  629  637\n",
      "  642  645  658  659  662  673  676  679  695  703  705  712  713  715\n",
      "  717  719  721  732  745  748  754  760  769  786  797  808  809  812\n",
      "  824  833  835  851  864  868  872  879  889  890  896  909  911  912\n",
      "  915  916  920  921  924  934  949  950  957  960  968  969  978  979\n",
      "  983  984  986  990 1005 1007 1014 1016 1017 1021 1023 1027 1037 1040\n",
      " 1041 1051 1058 1061 1062 1068 1071 1076 1077 1081 1084 1087 1092 1098\n",
      " 1104 1120 1121 1122 1125 1126 1139 1143 1147 1151 1158 1165 1179 1196\n",
      " 1199 1210 1211 1213 1216 1220 1233 1242 1243 1247 1257 1267 1269 1271\n",
      " 1276 1278 1286 1287 1289 1294 1297 1299 1308 1315 1316 1323 1331 1333\n",
      " 1337 1342 1343 1345 1354 1360 1369 1375 1377 1380 1381 1384 1385 1386\n",
      " 1389 1393 1398 1412 1416 1431 1451 1454 1467 1469 1474 1478 1484 1491\n",
      " 1493 1497 1499 1502 1503 1504 1505 1520 1522 1529 1536 1543 1545 1555\n",
      " 1556 1557 1561 1562 1564 1565 1569 1570 1577 1580 1584 1585 1596 1601\n",
      " 1602 1612 1631 1634 1635 1638 1639 1641 1660 1662 1668 1672 1678 1679\n",
      " 1684 1701 1702 1703 1705 1719 1723 1726 1731 1734 1739 1741 1746 1758\n",
      " 1763 1770 1774 1788 1790 1791 1794 1802 1804 1811 1814 1818 1821 1824\n",
      " 1826 1833 1840 1842 1846 1848 1857 1860 1863 1866 1872 1873 1878 1882\n",
      " 1887 1892 1897 1903 1909 1911 1917 1922 1926 1938 1941 1946 1952 1954\n",
      " 1969 1978 1995 1996 2003 2009 2020 2026 2030 2033 2037 2046 2058 2069\n",
      " 2071 2073 2089 2090 2092 2098 2111 2113 2117 2120 2125 2127 2135 2139\n",
      " 2143 2145 2155 2157 2164 2178 2192 2193 2194 2195 2215 2216 2217 2219\n",
      " 2221 2228 2229 2249 2276 2278 2279 2297 2300 2301 2308 2314 2318 2322\n",
      " 2323 2328 2330 2332 2334 2339 2342 2349 2351 2360 2363 2364 2368 2381\n",
      " 2384 2386 2388 2406 2417 2424 2428 2437 2439 2448 2454 2455 2458 2459\n",
      " 2463 2465 2477 2480 2486 2490 2496 2497 2500 2504 2506 2510 2512 2513\n",
      " 2520 2522 2528 2535 2543 2548 2550 2553 2557 2572 2575 2579 2589 2592\n",
      " 2604 2606 2614 2617 2619 2623 2625 2628 2658 2659 2664 2668 2672 2673\n",
      " 2678 2681 2685 2697 2709 2712 2715 2716 2722 2724 2725 2734 2741 2746\n",
      " 2750 2756 2760 2763 2766 2767 2769 2771 2772 2773 2778 2783 2796 2798\n",
      " 2823 2828 2833 2834 2839 2842 2849 2850 2855 2856 2858 2860 2863 2869\n",
      " 2873 2874 2890 2891 2895 2898 2901 2914 2917 2919 2920 2929 2939 2950\n",
      " 2964 2965 2970 2989 2990 2994 2995 2999 3000 3009 3012 3014 3015 3020\n",
      " 3029 3034 3036 3037 3039 3041 3042 3046 3048 3057 3058 3070 3090 3092\n",
      " 3094 3095 3099 3102 3107 3117 3118 3124 3131 3139 3142 3144 3145 3157\n",
      " 3166 3175 3182 3184 3193 3196 3197 3199 3201 3202 3203 3204 3205 3206\n",
      " 3210 3211 3212 3214 3216 3220 3224 3233 3236 3237 3240 3241 3242 3256\n",
      " 3257 3258 3263 3270 3271 3277 3284 3285 3299 3301 3305 3307 3318 3322\n",
      " 3323 3324 3326 3333 3343 3344 3347 3356 3362 3364 3369 3374 3384 3385\n",
      " 3388 3391 3392 3395 3398 3401 3403 3407 3413 3414 3417 3421 3428 3438\n",
      " 3445 3449 3458 3460 3465 3466 3479 3483 3487 3488 3494 3497 3498 3502\n",
      " 3503 3505 3506 3511 3522 3535 3538 3540 3542 3546 3548 3557 3564 3565\n",
      " 3566 3568 3572 3579 3581 3590 3599 3601 3603 3624 3626 3632 3638 3640\n",
      " 3644 3645 3648 3651 3668 3671 3674 3681 3685 3693 3697 3700 3705 3707\n",
      " 3709 3723 3725 3729 3740 3741 3750 3756 3759 3770 3773 3775 3780 3781\n",
      " 3789 3791 3805 3808 3809 3812 3815 3820 3823 3825 3853 3859 3867 3881\n",
      " 3882 3885 3886 3888 3893 3898 3900 3902 3913 3920 3925 3929 3936 3938\n",
      " 3942 3952 3959 3968 3973 3976 3977 3992 4002 4004 4014 4015 4017 4019\n",
      " 4020 4025 4040 4041 4045 4059 4062 4077 4082 4084 4086 4088 4094 4097\n",
      " 4098 4099 4100 4102 4109 4117 4122 4124 4125 4129 4131 4134 4135 4140\n",
      " 4144 4158 4161 4163 4170 4171 4178 4189 4198 4208 4210 4218 4220 4226\n",
      " 4229 4232 4234 4235 4237 4244 4251 4258 4262 4265 4269 4276 4278 4282\n",
      " 4283 4287 4291 4299 4300 4301 4303 4308 4309 4312 4319 4321 4343 4344\n",
      " 4346 4347 4348 4350 4359 4364 4367 4368 4370 4376 4377 4378 4380 4382\n",
      " 4383 4386 4388 4397 4401 4405 4409 4412 4414 4417 4419 4436 4447 4450\n",
      " 4452 4454 4456 4467 4474 4478 4479 4482 4485 4490 4491 4495 4504 4513\n",
      " 4514 4515 4521 4534 4537 4550 4554 4558 4559 4560 4567 4572 4583 4597\n",
      " 4598 4601 4605 4606 4609 4611 4612 4621 4623 4631 4635 4643 4650 4663\n",
      " 4671 4673 4686 4687 4709 4715 4722 4738 4744 4747 4751 4753 4762 4765\n",
      " 4767 4774 4778 4779 4783 4793 4797 4798 4805 4809 4814 4829 4835 4839\n",
      " 4841 4844 4848 4849 4854 4856]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:18:22.357398: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_361/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.1031 - accuracy: 0.3380 - val_loss: 1.0975 - val_accuracy: 0.3519 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0967 - accuracy: 0.3603 - val_loss: 1.0951 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0791 - accuracy: 0.4064 - val_loss: 1.0781 - val_accuracy: 0.3714 - 1s/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0667 - accuracy: 0.4228 - val_loss: 1.0600 - val_accuracy: 0.4177 - 1s/epoch - 5ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0477 - accuracy: 0.4308 - val_loss: 1.0535 - val_accuracy: 0.4444 - 1s/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0451 - accuracy: 0.4280 - val_loss: 1.0506 - val_accuracy: 0.4136 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0325 - accuracy: 0.4514 - val_loss: 1.0431 - val_accuracy: 0.4527 - 1s/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0303 - accuracy: 0.4586 - val_loss: 1.0414 - val_accuracy: 0.4383 - 1s/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0234 - accuracy: 0.4547 - val_loss: 1.0478 - val_accuracy: 0.4084 - 1s/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0262 - accuracy: 0.4491 - val_loss: 1.0460 - val_accuracy: 0.4033 - 1s/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0207 - accuracy: 0.4542 - val_loss: 1.0442 - val_accuracy: 0.4300 - 1s/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0202 - accuracy: 0.4609 - val_loss: 1.0375 - val_accuracy: 0.4393 - 1s/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0177 - accuracy: 0.4717 - val_loss: 1.0407 - val_accuracy: 0.4558 - 1s/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0133 - accuracy: 0.4681 - val_loss: 1.0447 - val_accuracy: 0.4239 - 1s/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0099 - accuracy: 0.4671 - val_loss: 1.0374 - val_accuracy: 0.4444 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0066 - accuracy: 0.4704 - val_loss: 1.0363 - val_accuracy: 0.4434 - 1s/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 0.9990 - accuracy: 0.4733 - val_loss: 1.0410 - val_accuracy: 0.4393 - 1s/epoch - 5ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0009 - accuracy: 0.4838 - val_loss: 1.0360 - val_accuracy: 0.4331 - 1s/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0030 - accuracy: 0.4761 - val_loss: 1.0390 - val_accuracy: 0.4455 - 1s/epoch - 5ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0016 - accuracy: 0.4738 - val_loss: 1.0372 - val_accuracy: 0.4465 - 1s/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 1.0012 - accuracy: 0.4740 - val_loss: 1.0243 - val_accuracy: 0.4516 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 1.0001 - accuracy: 0.4699 - val_loss: 1.0297 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 0.9928 - accuracy: 0.4856 - val_loss: 1.0353 - val_accuracy: 0.4403 - 1s/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9912 - accuracy: 0.4920 - val_loss: 1.0337 - val_accuracy: 0.4475 - 1s/epoch - 5ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9903 - accuracy: 0.4779 - val_loss: 1.0282 - val_accuracy: 0.4547 - 1s/epoch - 5ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 0.9899 - accuracy: 0.4835 - val_loss: 1.0229 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9947 - accuracy: 0.4907 - val_loss: 1.0233 - val_accuracy: 0.4537 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9920 - accuracy: 0.4810 - val_loss: 1.0296 - val_accuracy: 0.4455 - 1s/epoch - 5ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9864 - accuracy: 0.4833 - val_loss: 1.0258 - val_accuracy: 0.4424 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9822 - accuracy: 0.4846 - val_loss: 1.0247 - val_accuracy: 0.4568 - 1s/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9826 - accuracy: 0.4877 - val_loss: 1.0223 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9854 - accuracy: 0.4859 - val_loss: 1.0218 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9817 - accuracy: 0.4841 - val_loss: 1.0235 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9889 - accuracy: 0.4797 - val_loss: 1.0250 - val_accuracy: 0.4486 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9800 - accuracy: 0.4933 - val_loss: 1.0262 - val_accuracy: 0.4630 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9804 - accuracy: 0.4900 - val_loss: 1.0256 - val_accuracy: 0.4537 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9781 - accuracy: 0.4941 - val_loss: 1.0213 - val_accuracy: 0.4640 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9751 - accuracy: 0.4884 - val_loss: 1.0151 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9782 - accuracy: 0.4941 - val_loss: 1.0170 - val_accuracy: 0.4681 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9740 - accuracy: 0.4871 - val_loss: 1.0191 - val_accuracy: 0.4599 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9820 - accuracy: 0.4969 - val_loss: 1.0204 - val_accuracy: 0.4558 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9728 - accuracy: 0.4877 - val_loss: 1.0274 - val_accuracy: 0.4558 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9734 - accuracy: 0.5039 - val_loss: 1.0220 - val_accuracy: 0.4547 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9671 - accuracy: 0.4923 - val_loss: 1.0162 - val_accuracy: 0.4712 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9657 - accuracy: 0.5082 - val_loss: 1.0192 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9635 - accuracy: 0.5057 - val_loss: 1.0119 - val_accuracy: 0.4712 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9693 - accuracy: 0.4851 - val_loss: 1.0254 - val_accuracy: 0.4383 - 1s/epoch - 5ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9681 - accuracy: 0.4964 - val_loss: 1.0206 - val_accuracy: 0.4403 - 1s/epoch - 5ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9636 - accuracy: 0.4997 - val_loss: 1.0070 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9614 - accuracy: 0.5064 - val_loss: 1.0121 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9642 - accuracy: 0.4982 - val_loss: 1.0123 - val_accuracy: 0.4558 - 1s/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9649 - accuracy: 0.5064 - val_loss: 1.0155 - val_accuracy: 0.4558 - 1s/epoch - 5ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9594 - accuracy: 0.5015 - val_loss: 1.0087 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9666 - accuracy: 0.4887 - val_loss: 1.0134 - val_accuracy: 0.4578 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9592 - accuracy: 0.5049 - val_loss: 1.0125 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9663 - accuracy: 0.4982 - val_loss: 1.0173 - val_accuracy: 0.4537 - 1s/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9555 - accuracy: 0.5136 - val_loss: 1.0053 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9566 - accuracy: 0.5085 - val_loss: 1.0070 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9562 - accuracy: 0.5221 - val_loss: 1.0167 - val_accuracy: 0.4588 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9566 - accuracy: 0.5170 - val_loss: 1.0134 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9610 - accuracy: 0.5113 - val_loss: 1.0194 - val_accuracy: 0.4424 - 1s/epoch - 5ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9591 - accuracy: 0.5075 - val_loss: 1.0196 - val_accuracy: 0.4578 - 1s/epoch - 5ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9612 - accuracy: 0.5031 - val_loss: 1.0134 - val_accuracy: 0.4588 - 1s/epoch - 5ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9555 - accuracy: 0.5095 - val_loss: 1.0085 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9545 - accuracy: 0.5041 - val_loss: 1.0084 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9567 - accuracy: 0.5075 - val_loss: 1.0246 - val_accuracy: 0.4506 - 1s/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9473 - accuracy: 0.5185 - val_loss: 1.0095 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9585 - accuracy: 0.5000 - val_loss: 1.0003 - val_accuracy: 0.4763 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9506 - accuracy: 0.5123 - val_loss: 1.0077 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9551 - accuracy: 0.5131 - val_loss: 1.0120 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9445 - accuracy: 0.5221 - val_loss: 1.0174 - val_accuracy: 0.4568 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9539 - accuracy: 0.5201 - val_loss: 1.0036 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9583 - accuracy: 0.5013 - val_loss: 1.0042 - val_accuracy: 0.4743 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9445 - accuracy: 0.5229 - val_loss: 1.0122 - val_accuracy: 0.4619 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9529 - accuracy: 0.5044 - val_loss: 1.0166 - val_accuracy: 0.4547 - 1s/epoch - 5ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9600 - accuracy: 0.5023 - val_loss: 1.0155 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9463 - accuracy: 0.5198 - val_loss: 1.0103 - val_accuracy: 0.4671 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9502 - accuracy: 0.5051 - val_loss: 1.0073 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9465 - accuracy: 0.5211 - val_loss: 1.0144 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9538 - accuracy: 0.5113 - val_loss: 1.0057 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9433 - accuracy: 0.5177 - val_loss: 1.0127 - val_accuracy: 0.4455 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9383 - accuracy: 0.5267 - val_loss: 0.9970 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9463 - accuracy: 0.5165 - val_loss: 1.0049 - val_accuracy: 0.4630 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9461 - accuracy: 0.5082 - val_loss: 0.9998 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9436 - accuracy: 0.5152 - val_loss: 1.0020 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9382 - accuracy: 0.5123 - val_loss: 0.9992 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9367 - accuracy: 0.5257 - val_loss: 1.0074 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9580 - accuracy: 0.5198 - val_loss: 1.0040 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9433 - accuracy: 0.5159 - val_loss: 1.0055 - val_accuracy: 0.4660 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9444 - accuracy: 0.5157 - val_loss: 1.0032 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9413 - accuracy: 0.5183 - val_loss: 1.0026 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9393 - accuracy: 0.5180 - val_loss: 1.0093 - val_accuracy: 0.4681 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9414 - accuracy: 0.5175 - val_loss: 1.0072 - val_accuracy: 0.4599 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9429 - accuracy: 0.5108 - val_loss: 1.0065 - val_accuracy: 0.4733 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9463 - accuracy: 0.5190 - val_loss: 1.0001 - val_accuracy: 0.4650 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9372 - accuracy: 0.5201 - val_loss: 1.0146 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9360 - accuracy: 0.5283 - val_loss: 0.9948 - val_accuracy: 0.4763 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9406 - accuracy: 0.5188 - val_loss: 0.9946 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9435 - accuracy: 0.5177 - val_loss: 1.0056 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9481 - accuracy: 0.5090 - val_loss: 1.0136 - val_accuracy: 0.4558 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9407 - accuracy: 0.5224 - val_loss: 1.0031 - val_accuracy: 0.4691 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9348 - accuracy: 0.5167 - val_loss: 0.9961 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9371 - accuracy: 0.5177 - val_loss: 1.0156 - val_accuracy: 0.4516 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9411 - accuracy: 0.5221 - val_loss: 1.0064 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9470 - accuracy: 0.5265 - val_loss: 1.0011 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9410 - accuracy: 0.5123 - val_loss: 1.0131 - val_accuracy: 0.4671 - 1s/epoch - 5ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.9432 - accuracy: 0.5211 - val_loss: 1.0022 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9353 - accuracy: 0.5229 - val_loss: 1.0092 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.9315 - accuracy: 0.5309 - val_loss: 1.0121 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9463 - accuracy: 0.5183 - val_loss: 1.0086 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9342 - accuracy: 0.5185 - val_loss: 1.0235 - val_accuracy: 0.4496 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9357 - accuracy: 0.5322 - val_loss: 1.0096 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9345 - accuracy: 0.5342 - val_loss: 1.0183 - val_accuracy: 0.4424 - 1s/epoch - 5ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9323 - accuracy: 0.5280 - val_loss: 1.0038 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9382 - accuracy: 0.5165 - val_loss: 1.0127 - val_accuracy: 0.4640 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9329 - accuracy: 0.5350 - val_loss: 1.0045 - val_accuracy: 0.4599 - 1s/epoch - 5ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9429 - accuracy: 0.5116 - val_loss: 1.0058 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9352 - accuracy: 0.5347 - val_loss: 1.0007 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9375 - accuracy: 0.5147 - val_loss: 0.9988 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9417 - accuracy: 0.5159 - val_loss: 1.0027 - val_accuracy: 0.4671 - 1s/epoch - 5ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9317 - accuracy: 0.5237 - val_loss: 1.0010 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9379 - accuracy: 0.5195 - val_loss: 1.0002 - val_accuracy: 0.4763 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9292 - accuracy: 0.5301 - val_loss: 1.0100 - val_accuracy: 0.4599 - 1s/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9405 - accuracy: 0.5183 - val_loss: 1.0055 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.9368 - accuracy: 0.5255 - val_loss: 1.0070 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.9418 - accuracy: 0.5239 - val_loss: 1.0181 - val_accuracy: 0.4691 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9297 - accuracy: 0.5360 - val_loss: 1.0015 - val_accuracy: 0.4712 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.9358 - accuracy: 0.5298 - val_loss: 0.9999 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.9294 - accuracy: 0.5231 - val_loss: 1.0190 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9350 - accuracy: 0.5249 - val_loss: 1.0047 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.9269 - accuracy: 0.5352 - val_loss: 1.0118 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5324 - val_loss: 1.0063 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9328 - accuracy: 0.5311 - val_loss: 0.9988 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.9352 - accuracy: 0.5239 - val_loss: 1.0065 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.9271 - accuracy: 0.5347 - val_loss: 1.0128 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.9317 - accuracy: 0.5244 - val_loss: 1.0104 - val_accuracy: 0.4568 - 1s/epoch - 5ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9335 - accuracy: 0.5208 - val_loss: 1.0154 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.9406 - accuracy: 0.5226 - val_loss: 1.0043 - val_accuracy: 0.4887 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.9229 - accuracy: 0.5327 - val_loss: 1.0041 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.9415 - accuracy: 0.5334 - val_loss: 1.0073 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9279 - accuracy: 0.5208 - val_loss: 0.9969 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9284 - accuracy: 0.5206 - val_loss: 1.0107 - val_accuracy: 0.4619 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9343 - accuracy: 0.5206 - val_loss: 1.0037 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.9298 - accuracy: 0.5383 - val_loss: 1.0073 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5355 - val_loss: 0.9988 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9349 - accuracy: 0.5221 - val_loss: 1.0078 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.9267 - accuracy: 0.5373 - val_loss: 1.0231 - val_accuracy: 0.4444 - 1s/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.9352 - accuracy: 0.5303 - val_loss: 1.0092 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.9302 - accuracy: 0.5298 - val_loss: 1.0066 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.9325 - accuracy: 0.5203 - val_loss: 1.0149 - val_accuracy: 0.4516 - 1s/epoch - 5ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.9312 - accuracy: 0.5162 - val_loss: 1.0106 - val_accuracy: 0.4743 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.9309 - accuracy: 0.5340 - val_loss: 1.0117 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.9293 - accuracy: 0.5221 - val_loss: 1.0213 - val_accuracy: 0.4558 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.9241 - accuracy: 0.5378 - val_loss: 1.0209 - val_accuracy: 0.4424 - 1s/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.9258 - accuracy: 0.5324 - val_loss: 0.9974 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.9257 - accuracy: 0.5358 - val_loss: 1.0024 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9273 - accuracy: 0.5365 - val_loss: 0.9948 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.9277 - accuracy: 0.5229 - val_loss: 1.0048 - val_accuracy: 0.4805 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.9282 - accuracy: 0.5237 - val_loss: 1.0012 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.9314 - accuracy: 0.5386 - val_loss: 1.0045 - val_accuracy: 0.4712 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9177 - accuracy: 0.5337 - val_loss: 0.9973 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.9200 - accuracy: 0.5401 - val_loss: 1.0012 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.9266 - accuracy: 0.5342 - val_loss: 1.0017 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.9318 - accuracy: 0.5224 - val_loss: 1.0061 - val_accuracy: 0.4691 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9246 - accuracy: 0.5363 - val_loss: 1.0139 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.9278 - accuracy: 0.5301 - val_loss: 1.0047 - val_accuracy: 0.4650 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.9241 - accuracy: 0.5306 - val_loss: 1.0149 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.9227 - accuracy: 0.5301 - val_loss: 1.0132 - val_accuracy: 0.4660 - 1s/epoch - 5ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.9224 - accuracy: 0.5316 - val_loss: 1.0035 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.9221 - accuracy: 0.5234 - val_loss: 1.0037 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.9202 - accuracy: 0.5373 - val_loss: 1.0042 - val_accuracy: 0.4660 - 1s/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.9175 - accuracy: 0.5414 - val_loss: 1.0217 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.9332 - accuracy: 0.5260 - val_loss: 1.0180 - val_accuracy: 0.4486 - 1s/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.9290 - accuracy: 0.5340 - val_loss: 0.9947 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9237 - accuracy: 0.5355 - val_loss: 1.0044 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.9275 - accuracy: 0.5288 - val_loss: 1.0076 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.9250 - accuracy: 0.5360 - val_loss: 0.9986 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.9180 - accuracy: 0.5399 - val_loss: 0.9999 - val_accuracy: 0.4856 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5270 - val_loss: 1.0057 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.9230 - accuracy: 0.5316 - val_loss: 1.0129 - val_accuracy: 0.4599 - 1s/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.9269 - accuracy: 0.5342 - val_loss: 1.0028 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.9255 - accuracy: 0.5322 - val_loss: 0.9992 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.9283 - accuracy: 0.5306 - val_loss: 1.0125 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.9303 - accuracy: 0.5363 - val_loss: 1.0121 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.9278 - accuracy: 0.5340 - val_loss: 1.0004 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.9226 - accuracy: 0.5337 - val_loss: 1.0060 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.9297 - accuracy: 0.5265 - val_loss: 1.0073 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.9200 - accuracy: 0.5422 - val_loss: 1.0130 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.9250 - accuracy: 0.5265 - val_loss: 1.0077 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.9173 - accuracy: 0.5391 - val_loss: 1.0174 - val_accuracy: 0.4671 - 1s/epoch - 5ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.9184 - accuracy: 0.5334 - val_loss: 1.0136 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9266 - accuracy: 0.5363 - val_loss: 1.0063 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.9355 - accuracy: 0.5291 - val_loss: 1.0166 - val_accuracy: 0.4619 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.9266 - accuracy: 0.5306 - val_loss: 1.0072 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.9117 - accuracy: 0.5427 - val_loss: 1.0180 - val_accuracy: 0.4372 - 1s/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.9224 - accuracy: 0.5340 - val_loss: 1.0104 - val_accuracy: 0.4609 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.9325 - accuracy: 0.5301 - val_loss: 1.0048 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.9199 - accuracy: 0.5340 - val_loss: 1.0076 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.9220 - accuracy: 0.5355 - val_loss: 1.0027 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.9149 - accuracy: 0.5417 - val_loss: 1.0014 - val_accuracy: 0.4660 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.9165 - accuracy: 0.5381 - val_loss: 1.0011 - val_accuracy: 0.4897 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.9173 - accuracy: 0.5448 - val_loss: 1.0021 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.9105 - accuracy: 0.5424 - val_loss: 1.0028 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.9216 - accuracy: 0.5252 - val_loss: 1.0068 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.9190 - accuracy: 0.5319 - val_loss: 1.0005 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.9151 - accuracy: 0.5404 - val_loss: 0.9951 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.9260 - accuracy: 0.5368 - val_loss: 1.0004 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5309 - val_loss: 1.0057 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.9237 - accuracy: 0.5342 - val_loss: 0.9987 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5340 - val_loss: 1.0071 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.9246 - accuracy: 0.5394 - val_loss: 1.0119 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9306 - accuracy: 0.5208 - val_loss: 1.0048 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9284 - accuracy: 0.5219 - val_loss: 0.9993 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.9235 - accuracy: 0.5309 - val_loss: 0.9943 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.9201 - accuracy: 0.5329 - val_loss: 0.9997 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.9253 - accuracy: 0.5376 - val_loss: 0.9980 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.9175 - accuracy: 0.5445 - val_loss: 1.0105 - val_accuracy: 0.4599 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.9283 - accuracy: 0.5280 - val_loss: 1.0119 - val_accuracy: 0.4516 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.9162 - accuracy: 0.5432 - val_loss: 1.0010 - val_accuracy: 0.4640 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.9184 - accuracy: 0.5370 - val_loss: 1.0130 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.9193 - accuracy: 0.5368 - val_loss: 0.9993 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.9337 - accuracy: 0.5368 - val_loss: 1.0130 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5370 - val_loss: 0.9970 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.9257 - accuracy: 0.5265 - val_loss: 0.9987 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.9236 - accuracy: 0.5399 - val_loss: 1.0062 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.9259 - accuracy: 0.5352 - val_loss: 1.0037 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.9309 - accuracy: 0.5283 - val_loss: 1.0011 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.9214 - accuracy: 0.5311 - val_loss: 1.0147 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.9130 - accuracy: 0.5471 - val_loss: 1.0320 - val_accuracy: 0.4527 - 1s/epoch - 5ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.9142 - accuracy: 0.5394 - val_loss: 0.9960 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.9210 - accuracy: 0.5280 - val_loss: 1.0043 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.9259 - accuracy: 0.5376 - val_loss: 0.9880 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.9170 - accuracy: 0.5499 - val_loss: 1.0095 - val_accuracy: 0.4640 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.9248 - accuracy: 0.5414 - val_loss: 0.9917 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.9190 - accuracy: 0.5388 - val_loss: 0.9942 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.9183 - accuracy: 0.5378 - val_loss: 0.9864 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.9192 - accuracy: 0.5319 - val_loss: 0.9921 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9169 - accuracy: 0.5396 - val_loss: 1.0143 - val_accuracy: 0.4578 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.9209 - accuracy: 0.5368 - val_loss: 1.0048 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.9223 - accuracy: 0.5373 - val_loss: 0.9941 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9151 - accuracy: 0.5401 - val_loss: 0.9971 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.9156 - accuracy: 0.5360 - val_loss: 1.0041 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.9047 - accuracy: 0.5414 - val_loss: 1.0017 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.9166 - accuracy: 0.5404 - val_loss: 0.9938 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.9224 - accuracy: 0.5368 - val_loss: 0.9969 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.9246 - accuracy: 0.5298 - val_loss: 0.9956 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9163 - accuracy: 0.5512 - val_loss: 0.9993 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.9063 - accuracy: 0.5360 - val_loss: 1.0209 - val_accuracy: 0.4609 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.9259 - accuracy: 0.5288 - val_loss: 1.0029 - val_accuracy: 0.4516 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9215 - accuracy: 0.5363 - val_loss: 0.9981 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   1    2    3 ... 4856 4857 4858]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   0   10   12   13   16   29   36   39   40   43   46   66   73   75\n",
      "   85   88   91   99  100  102  105  110  111  117  123  124  127  128\n",
      "  132  133  136  153  157  159  160  174  177  190  192  193  195  204\n",
      "  208  210  212  214  217  232  244  266  269  286  296  309  316  326\n",
      "  332  335  344  368  369  370  373  383  391  392  394  398  399  401\n",
      "  403  404  405  406  410  416  423  441  444  452  453  459  476  492\n",
      "  494  497  511  513  514  518  521  525  531  534  535  537  546  547\n",
      "  551  554  556  565  575  579  596  597  600  601  616  635  636  646\n",
      "  657  663  664  665  669  672  684  685  687  693  694  698  701  714\n",
      "  730  731  733  738  740  742  743  746  749  752  756  759  766  768\n",
      "  770  774  787  789  790  795  801  802  804  816  817  818  822  825\n",
      "  830  832  842  847  853  854  856  857  859  861  862  874  876  882\n",
      "  893  910  913  925  927  945  946  958  965  966  971  972  975  976\n",
      "  977  991  998 1002 1013 1018 1043 1049 1056 1057 1065 1066 1069 1070\n",
      " 1078 1082 1089 1090 1097 1100 1111 1112 1116 1127 1128 1130 1133 1134\n",
      " 1145 1152 1156 1159 1162 1167 1170 1175 1177 1181 1182 1186 1187 1189\n",
      " 1192 1198 1201 1204 1205 1207 1212 1214 1219 1221 1225 1227 1230 1235\n",
      " 1240 1244 1249 1256 1258 1259 1261 1268 1270 1275 1279 1290 1293 1296\n",
      " 1300 1312 1314 1317 1321 1328 1347 1362 1365 1371 1373 1376 1378 1383\n",
      " 1390 1391 1392 1395 1397 1401 1404 1407 1411 1422 1432 1434 1447 1450\n",
      " 1452 1459 1460 1462 1476 1479 1483 1486 1489 1495 1523 1526 1527 1528\n",
      " 1534 1544 1547 1548 1553 1558 1568 1571 1579 1586 1587 1594 1599 1604\n",
      " 1607 1609 1621 1627 1628 1636 1642 1648 1652 1655 1656 1661 1670 1671\n",
      " 1673 1683 1689 1690 1700 1706 1708 1712 1713 1721 1725 1728 1730 1735\n",
      " 1737 1742 1743 1755 1760 1762 1771 1777 1778 1782 1785 1786 1805 1812\n",
      " 1815 1816 1820 1829 1830 1832 1837 1843 1849 1850 1851 1856 1859 1862\n",
      " 1869 1874 1880 1884 1895 1899 1910 1918 1921 1930 1932 1937 1943 1944\n",
      " 1949 1950 1957 1968 1970 1974 1976 1984 1986 1991 2005 2006 2007 2010\n",
      " 2013 2014 2015 2017 2018 2034 2036 2039 2041 2042 2052 2054 2060 2064\n",
      " 2077 2083 2084 2095 2097 2110 2116 2123 2129 2131 2132 2140 2142 2147\n",
      " 2151 2156 2158 2167 2174 2175 2176 2179 2180 2184 2190 2201 2203 2206\n",
      " 2210 2227 2235 2237 2239 2244 2247 2248 2259 2264 2272 2275 2281 2283\n",
      " 2285 2294 2311 2313 2319 2321 2325 2327 2329 2336 2345 2359 2361 2362\n",
      " 2367 2377 2382 2383 2391 2395 2397 2404 2407 2408 2412 2418 2420 2429\n",
      " 2430 2438 2441 2451 2461 2474 2478 2479 2484 2488 2494 2499 2511 2518\n",
      " 2519 2525 2531 2538 2541 2555 2563 2571 2580 2583 2585 2588 2594 2596\n",
      " 2597 2598 2599 2600 2603 2605 2608 2612 2616 2620 2631 2633 2634 2635\n",
      " 2636 2651 2652 2653 2654 2662 2667 2670 2680 2684 2690 2691 2701 2704\n",
      " 2706 2714 2718 2723 2726 2727 2730 2732 2749 2754 2758 2759 2764 2765\n",
      " 2776 2788 2794 2801 2802 2805 2814 2818 2832 2845 2854 2857 2864 2866\n",
      " 2868 2877 2878 2880 2883 2885 2889 2894 2896 2897 2899 2900 2903 2905\n",
      " 2909 2911 2918 2927 2931 2944 2945 2946 2952 2954 2958 2961 2967 2968\n",
      " 2973 2977 2982 2985 2992 2996 3003 3011 3016 3017 3026 3033 3040 3043\n",
      " 3044 3052 3054 3055 3072 3075 3079 3081 3084 3085 3086 3087 3097 3104\n",
      " 3120 3121 3127 3137 3138 3140 3149 3158 3160 3165 3167 3177 3179 3191\n",
      " 3194 3200 3213 3215 3251 3252 3255 3261 3273 3280 3282 3289 3304 3306\n",
      " 3312 3316 3320 3331 3334 3335 3337 3340 3350 3353 3354 3358 3359 3360\n",
      " 3365 3367 3376 3377 3381 3386 3387 3389 3399 3404 3409 3411 3416 3423\n",
      " 3425 3426 3432 3433 3440 3446 3453 3459 3461 3462 3463 3472 3478 3481\n",
      " 3482 3484 3490 3491 3493 3507 3509 3523 3526 3528 3533 3534 3537 3539\n",
      " 3547 3552 3554 3558 3570 3576 3578 3583 3584 3585 3598 3600 3605 3606\n",
      " 3608 3610 3612 3613 3614 3616 3620 3621 3627 3633 3635 3661 3662 3663\n",
      " 3679 3682 3684 3690 3699 3704 3706 3708 3711 3714 3716 3719 3720 3728\n",
      " 3730 3735 3737 3739 3744 3746 3751 3753 3754 3758 3760 3761 3777 3782\n",
      " 3786 3790 3795 3800 3803 3804 3813 3818 3824 3828 3833 3835 3837 3840\n",
      " 3844 3845 3849 3850 3858 3861 3865 3868 3869 3876 3877 3879 3891 3905\n",
      " 3909 3923 3930 3941 3951 3960 3961 3965 3967 3972 3978 3982 3985 3987\n",
      " 3989 3993 3994 3995 4001 4006 4018 4023 4027 4030 4033 4034 4036 4037\n",
      " 4043 4049 4054 4055 4067 4068 4078 4092 4105 4112 4115 4116 4120 4130\n",
      " 4132 4137 4138 4145 4157 4166 4167 4180 4184 4185 4187 4190 4195 4205\n",
      " 4206 4215 4222 4224 4240 4249 4255 4256 4259 4261 4263 4267 4268 4275\n",
      " 4284 4286 4289 4290 4294 4296 4297 4311 4313 4315 4322 4335 4341 4354\n",
      " 4362 4363 4365 4371 4394 4406 4408 4416 4418 4420 4433 4434 4444 4448\n",
      " 4449 4458 4466 4472 4475 4487 4488 4489 4492 4497 4498 4500 4508 4509\n",
      " 4510 4516 4518 4528 4530 4533 4540 4544 4546 4547 4548 4561 4576 4577\n",
      " 4578 4579 4585 4591 4593 4596 4600 4607 4613 4615 4616 4617 4620 4622\n",
      " 4626 4633 4659 4664 4674 4675 4683 4688 4689 4694 4700 4704 4707 4711\n",
      " 4721 4724 4727 4729 4733 4734 4737 4741 4748 4750 4752 4754 4757 4758\n",
      " 4763 4768 4772 4782 4788 4789 4794 4795 4800 4802 4803 4807 4818 4821\n",
      " 4826 4827 4830 4845 4850 4859]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:23:00.801514: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_362/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.1022 - accuracy: 0.3302 - val_loss: 1.0940 - val_accuracy: 0.3745 - 3s/epoch - 12ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0929 - accuracy: 0.3727 - val_loss: 1.0818 - val_accuracy: 0.3961 - 1s/epoch - 5ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0758 - accuracy: 0.3925 - val_loss: 1.0669 - val_accuracy: 0.4270 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0660 - accuracy: 0.4200 - val_loss: 1.0515 - val_accuracy: 0.4444 - 1s/epoch - 5ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0478 - accuracy: 0.4416 - val_loss: 1.0436 - val_accuracy: 0.4455 - 1s/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0392 - accuracy: 0.4450 - val_loss: 1.0351 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0355 - accuracy: 0.4442 - val_loss: 1.0324 - val_accuracy: 0.4516 - 1s/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0299 - accuracy: 0.4421 - val_loss: 1.0300 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0324 - accuracy: 0.4511 - val_loss: 1.0354 - val_accuracy: 0.4486 - 1s/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0266 - accuracy: 0.4617 - val_loss: 1.0252 - val_accuracy: 0.4588 - 1s/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0266 - accuracy: 0.4504 - val_loss: 1.0296 - val_accuracy: 0.4434 - 1s/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0216 - accuracy: 0.4609 - val_loss: 1.0235 - val_accuracy: 0.4516 - 1s/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0151 - accuracy: 0.4676 - val_loss: 1.0173 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0200 - accuracy: 0.4588 - val_loss: 1.0211 - val_accuracy: 0.4465 - 1s/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0168 - accuracy: 0.4627 - val_loss: 1.0186 - val_accuracy: 0.4496 - 1s/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0131 - accuracy: 0.4604 - val_loss: 1.0154 - val_accuracy: 0.4352 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 1.0135 - accuracy: 0.4648 - val_loss: 1.0217 - val_accuracy: 0.4218 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0116 - accuracy: 0.4601 - val_loss: 1.0157 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0040 - accuracy: 0.4841 - val_loss: 1.0157 - val_accuracy: 0.4691 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0033 - accuracy: 0.4751 - val_loss: 1.0066 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 1.0007 - accuracy: 0.4846 - val_loss: 1.0084 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 1.0074 - accuracy: 0.4712 - val_loss: 1.0070 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 0.9952 - accuracy: 0.4758 - val_loss: 1.0063 - val_accuracy: 0.4527 - 1s/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9974 - accuracy: 0.4774 - val_loss: 1.0076 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9950 - accuracy: 0.4895 - val_loss: 1.0052 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 0.9925 - accuracy: 0.4938 - val_loss: 1.0027 - val_accuracy: 0.4660 - 1s/epoch - 5ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9957 - accuracy: 0.4846 - val_loss: 1.0061 - val_accuracy: 0.4609 - 1s/epoch - 5ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9864 - accuracy: 0.4910 - val_loss: 1.0018 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9945 - accuracy: 0.4877 - val_loss: 0.9952 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9865 - accuracy: 0.4825 - val_loss: 0.9972 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9822 - accuracy: 0.4946 - val_loss: 0.9956 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9904 - accuracy: 0.4815 - val_loss: 1.0037 - val_accuracy: 0.4630 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9861 - accuracy: 0.4918 - val_loss: 1.0047 - val_accuracy: 0.4588 - 1s/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9839 - accuracy: 0.4956 - val_loss: 1.0030 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9795 - accuracy: 0.4959 - val_loss: 0.9967 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9759 - accuracy: 0.4902 - val_loss: 0.9968 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9776 - accuracy: 0.4964 - val_loss: 0.9923 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9811 - accuracy: 0.4895 - val_loss: 0.9953 - val_accuracy: 0.4856 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9722 - accuracy: 0.4913 - val_loss: 0.9989 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9751 - accuracy: 0.4961 - val_loss: 0.9913 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9671 - accuracy: 0.5003 - val_loss: 0.9928 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9681 - accuracy: 0.5057 - val_loss: 0.9997 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9720 - accuracy: 0.4900 - val_loss: 0.9992 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9675 - accuracy: 0.4964 - val_loss: 0.9856 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9702 - accuracy: 0.4956 - val_loss: 0.9873 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9699 - accuracy: 0.4933 - val_loss: 0.9875 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9663 - accuracy: 0.4882 - val_loss: 0.9874 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9727 - accuracy: 0.4859 - val_loss: 0.9895 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9641 - accuracy: 0.4866 - val_loss: 0.9904 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9646 - accuracy: 0.4907 - val_loss: 0.9847 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9646 - accuracy: 0.4995 - val_loss: 0.9820 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9655 - accuracy: 0.4936 - val_loss: 0.9875 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9601 - accuracy: 0.5033 - val_loss: 0.9876 - val_accuracy: 0.4609 - 1s/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9548 - accuracy: 0.5123 - val_loss: 0.9776 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9670 - accuracy: 0.4877 - val_loss: 0.9894 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9621 - accuracy: 0.5000 - val_loss: 0.9835 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9645 - accuracy: 0.4902 - val_loss: 0.9853 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9634 - accuracy: 0.5049 - val_loss: 0.9763 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9653 - accuracy: 0.4931 - val_loss: 0.9831 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9538 - accuracy: 0.5087 - val_loss: 0.9840 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9542 - accuracy: 0.4979 - val_loss: 0.9845 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9478 - accuracy: 0.5044 - val_loss: 0.9887 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9591 - accuracy: 0.4964 - val_loss: 0.9886 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9561 - accuracy: 0.4967 - val_loss: 0.9970 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9502 - accuracy: 0.5144 - val_loss: 0.9932 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9604 - accuracy: 0.4985 - val_loss: 0.9872 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9558 - accuracy: 0.4995 - val_loss: 0.9855 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9484 - accuracy: 0.5023 - val_loss: 0.9852 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9468 - accuracy: 0.5147 - val_loss: 0.9794 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9564 - accuracy: 0.5018 - val_loss: 0.9892 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9479 - accuracy: 0.5087 - val_loss: 0.9933 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9514 - accuracy: 0.5033 - val_loss: 0.9854 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9524 - accuracy: 0.5013 - val_loss: 0.9834 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9509 - accuracy: 0.5008 - val_loss: 0.9891 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9544 - accuracy: 0.5116 - val_loss: 0.9849 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9512 - accuracy: 0.5054 - val_loss: 0.9791 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9488 - accuracy: 0.5059 - val_loss: 0.9810 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9494 - accuracy: 0.5121 - val_loss: 0.9880 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9412 - accuracy: 0.5162 - val_loss: 0.9900 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9434 - accuracy: 0.5213 - val_loss: 0.9762 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9427 - accuracy: 0.4974 - val_loss: 0.9789 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9455 - accuracy: 0.5013 - val_loss: 0.9819 - val_accuracy: 0.4609 - 1s/epoch - 5ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9444 - accuracy: 0.5139 - val_loss: 0.9802 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9400 - accuracy: 0.5075 - val_loss: 0.9877 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9468 - accuracy: 0.4974 - val_loss: 0.9807 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9488 - accuracy: 0.5103 - val_loss: 0.9760 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9413 - accuracy: 0.5185 - val_loss: 0.9888 - val_accuracy: 0.4733 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9397 - accuracy: 0.4902 - val_loss: 0.9918 - val_accuracy: 0.4619 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9499 - accuracy: 0.5090 - val_loss: 0.9805 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9500 - accuracy: 0.5113 - val_loss: 0.9727 - val_accuracy: 0.4969 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9450 - accuracy: 0.5147 - val_loss: 0.9944 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9456 - accuracy: 0.5131 - val_loss: 0.9796 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9375 - accuracy: 0.5159 - val_loss: 0.9761 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9448 - accuracy: 0.5059 - val_loss: 0.9885 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9487 - accuracy: 0.5008 - val_loss: 0.9830 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9356 - accuracy: 0.5224 - val_loss: 0.9874 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9463 - accuracy: 0.5077 - val_loss: 0.9803 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9412 - accuracy: 0.5069 - val_loss: 0.9754 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9511 - accuracy: 0.5018 - val_loss: 0.9745 - val_accuracy: 0.4928 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9409 - accuracy: 0.5111 - val_loss: 0.9763 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9382 - accuracy: 0.5103 - val_loss: 0.9889 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9465 - accuracy: 0.5093 - val_loss: 0.9903 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9443 - accuracy: 0.5026 - val_loss: 0.9747 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9492 - accuracy: 0.5044 - val_loss: 0.9763 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9497 - accuracy: 0.5118 - val_loss: 0.9735 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9366 - accuracy: 0.5087 - val_loss: 0.9744 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.9397 - accuracy: 0.5123 - val_loss: 0.9635 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9412 - accuracy: 0.5023 - val_loss: 0.9792 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.9352 - accuracy: 0.5149 - val_loss: 0.9747 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9381 - accuracy: 0.5129 - val_loss: 0.9756 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9451 - accuracy: 0.5129 - val_loss: 0.9858 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9392 - accuracy: 0.5090 - val_loss: 0.9665 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9333 - accuracy: 0.5159 - val_loss: 0.9770 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9360 - accuracy: 0.5069 - val_loss: 0.9741 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9423 - accuracy: 0.5095 - val_loss: 0.9811 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9334 - accuracy: 0.5162 - val_loss: 0.9783 - val_accuracy: 0.5021 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9366 - accuracy: 0.5095 - val_loss: 0.9780 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9422 - accuracy: 0.5080 - val_loss: 0.9775 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9332 - accuracy: 0.5188 - val_loss: 0.9808 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9312 - accuracy: 0.5116 - val_loss: 0.9665 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9396 - accuracy: 0.4905 - val_loss: 0.9731 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9285 - accuracy: 0.5147 - val_loss: 0.9723 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9372 - accuracy: 0.5152 - val_loss: 0.9773 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9296 - accuracy: 0.5095 - val_loss: 0.9704 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.9374 - accuracy: 0.5147 - val_loss: 0.9766 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.9329 - accuracy: 0.5365 - val_loss: 0.9821 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9356 - accuracy: 0.5121 - val_loss: 0.9733 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.9363 - accuracy: 0.5057 - val_loss: 0.9730 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.9290 - accuracy: 0.5216 - val_loss: 0.9765 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9313 - accuracy: 0.5087 - val_loss: 0.9802 - val_accuracy: 0.4887 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.9315 - accuracy: 0.5177 - val_loss: 0.9750 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.9310 - accuracy: 0.5098 - val_loss: 0.9718 - val_accuracy: 0.5134 - 1s/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9263 - accuracy: 0.5118 - val_loss: 0.9724 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.9367 - accuracy: 0.5141 - val_loss: 0.9681 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.9379 - accuracy: 0.5059 - val_loss: 0.9674 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.9340 - accuracy: 0.5057 - val_loss: 0.9734 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9331 - accuracy: 0.5188 - val_loss: 0.9650 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.9326 - accuracy: 0.5195 - val_loss: 0.9781 - val_accuracy: 0.4671 - 1s/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.9265 - accuracy: 0.5242 - val_loss: 0.9765 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.9341 - accuracy: 0.5010 - val_loss: 0.9667 - val_accuracy: 0.4959 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9318 - accuracy: 0.5072 - val_loss: 0.9754 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9311 - accuracy: 0.5252 - val_loss: 0.9775 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9302 - accuracy: 0.5252 - val_loss: 0.9747 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.9219 - accuracy: 0.5172 - val_loss: 0.9814 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.9356 - accuracy: 0.5134 - val_loss: 0.9796 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9351 - accuracy: 0.5015 - val_loss: 0.9714 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.9261 - accuracy: 0.5177 - val_loss: 0.9771 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.9275 - accuracy: 0.5170 - val_loss: 0.9953 - val_accuracy: 0.4578 - 1s/epoch - 5ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.9257 - accuracy: 0.5188 - val_loss: 0.9812 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.9279 - accuracy: 0.5159 - val_loss: 0.9846 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.9218 - accuracy: 0.5208 - val_loss: 0.9725 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.9334 - accuracy: 0.5172 - val_loss: 0.9779 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5159 - val_loss: 0.9754 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.9263 - accuracy: 0.5152 - val_loss: 0.9884 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.9394 - accuracy: 0.5193 - val_loss: 0.9824 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.9324 - accuracy: 0.5221 - val_loss: 0.9716 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9276 - accuracy: 0.5116 - val_loss: 0.9833 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5185 - val_loss: 0.9747 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.9230 - accuracy: 0.5139 - val_loss: 0.9853 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.9353 - accuracy: 0.5121 - val_loss: 0.9774 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9282 - accuracy: 0.5064 - val_loss: 0.9852 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.9295 - accuracy: 0.5131 - val_loss: 0.9768 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.9322 - accuracy: 0.5129 - val_loss: 0.9762 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.9339 - accuracy: 0.5190 - val_loss: 0.9829 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9217 - accuracy: 0.5211 - val_loss: 0.9759 - val_accuracy: 0.4846 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.9258 - accuracy: 0.5229 - val_loss: 0.9864 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.9248 - accuracy: 0.5283 - val_loss: 0.9760 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.9295 - accuracy: 0.5185 - val_loss: 0.9832 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.9252 - accuracy: 0.5249 - val_loss: 0.9725 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.9214 - accuracy: 0.5262 - val_loss: 0.9793 - val_accuracy: 0.4733 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.9294 - accuracy: 0.5226 - val_loss: 0.9761 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.9306 - accuracy: 0.5049 - val_loss: 0.9697 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.9315 - accuracy: 0.5270 - val_loss: 0.9931 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.9227 - accuracy: 0.5144 - val_loss: 0.9672 - val_accuracy: 0.4949 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9229 - accuracy: 0.5100 - val_loss: 0.9732 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.9253 - accuracy: 0.5273 - val_loss: 0.9709 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.9214 - accuracy: 0.5219 - val_loss: 0.9891 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.9144 - accuracy: 0.5211 - val_loss: 0.9706 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.9298 - accuracy: 0.5185 - val_loss: 0.9736 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.9330 - accuracy: 0.5123 - val_loss: 0.9889 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.9317 - accuracy: 0.5152 - val_loss: 0.9739 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.9190 - accuracy: 0.5267 - val_loss: 0.9657 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.9168 - accuracy: 0.5152 - val_loss: 0.9734 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.9233 - accuracy: 0.5267 - val_loss: 0.9882 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.9256 - accuracy: 0.5175 - val_loss: 0.9689 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.9214 - accuracy: 0.5242 - val_loss: 0.9781 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.9166 - accuracy: 0.5247 - val_loss: 0.9925 - val_accuracy: 0.4959 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.9207 - accuracy: 0.5201 - val_loss: 0.9785 - val_accuracy: 0.4918 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.9282 - accuracy: 0.5206 - val_loss: 0.9858 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.9209 - accuracy: 0.5139 - val_loss: 0.9763 - val_accuracy: 0.5093 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.9195 - accuracy: 0.5231 - val_loss: 0.9680 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9271 - accuracy: 0.5195 - val_loss: 0.9699 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.9240 - accuracy: 0.5147 - val_loss: 0.9777 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.9201 - accuracy: 0.5288 - val_loss: 0.9707 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.9185 - accuracy: 0.5129 - val_loss: 0.9870 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.9197 - accuracy: 0.5198 - val_loss: 1.0050 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.9229 - accuracy: 0.5216 - val_loss: 0.9778 - val_accuracy: 0.5093 - 1s/epoch - 5ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.9319 - accuracy: 0.5057 - val_loss: 0.9991 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.9182 - accuracy: 0.5095 - val_loss: 0.9638 - val_accuracy: 0.5144 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.9248 - accuracy: 0.5260 - val_loss: 0.9642 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.9279 - accuracy: 0.5126 - val_loss: 0.9744 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.9218 - accuracy: 0.5283 - val_loss: 0.9703 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.9120 - accuracy: 0.5342 - val_loss: 0.9753 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.9253 - accuracy: 0.5111 - val_loss: 0.9627 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.9174 - accuracy: 0.5175 - val_loss: 0.9616 - val_accuracy: 0.5082 - 1s/epoch - 5ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.9255 - accuracy: 0.5242 - val_loss: 0.9657 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.9238 - accuracy: 0.5216 - val_loss: 0.9643 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.9193 - accuracy: 0.5275 - val_loss: 0.9606 - val_accuracy: 0.5082 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.9204 - accuracy: 0.5093 - val_loss: 0.9643 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.9223 - accuracy: 0.5108 - val_loss: 0.9704 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.9214 - accuracy: 0.5185 - val_loss: 0.9580 - val_accuracy: 0.5123 - 1s/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9300 - accuracy: 0.5105 - val_loss: 0.9746 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9198 - accuracy: 0.5159 - val_loss: 0.9710 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.9269 - accuracy: 0.5152 - val_loss: 0.9801 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.9185 - accuracy: 0.5265 - val_loss: 0.9800 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.9234 - accuracy: 0.5229 - val_loss: 0.9755 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.9228 - accuracy: 0.5180 - val_loss: 0.9723 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.9233 - accuracy: 0.5136 - val_loss: 0.9677 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.9168 - accuracy: 0.5154 - val_loss: 0.9689 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.9137 - accuracy: 0.5234 - val_loss: 0.9724 - val_accuracy: 0.4671 - 1s/epoch - 5ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.9206 - accuracy: 0.5226 - val_loss: 0.9682 - val_accuracy: 0.4733 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.9283 - accuracy: 0.5185 - val_loss: 0.9660 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.9203 - accuracy: 0.5296 - val_loss: 0.9660 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.9213 - accuracy: 0.5211 - val_loss: 0.9833 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.9267 - accuracy: 0.5118 - val_loss: 0.9730 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.9195 - accuracy: 0.5226 - val_loss: 0.9564 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.9188 - accuracy: 0.5175 - val_loss: 0.9609 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.9194 - accuracy: 0.5252 - val_loss: 0.9804 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.9273 - accuracy: 0.5075 - val_loss: 0.9562 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.9215 - accuracy: 0.5118 - val_loss: 0.9777 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.9216 - accuracy: 0.5134 - val_loss: 0.9779 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.9234 - accuracy: 0.5198 - val_loss: 0.9767 - val_accuracy: 0.5021 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.9210 - accuracy: 0.5242 - val_loss: 0.9754 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.9137 - accuracy: 0.5255 - val_loss: 0.9673 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.9203 - accuracy: 0.5190 - val_loss: 0.9745 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.9270 - accuracy: 0.5159 - val_loss: 0.9745 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.9153 - accuracy: 0.5213 - val_loss: 0.9693 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9164 - accuracy: 0.5322 - val_loss: 0.9683 - val_accuracy: 0.5010 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.9183 - accuracy: 0.5203 - val_loss: 0.9767 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5206 - val_loss: 0.9724 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9251 - accuracy: 0.5075 - val_loss: 0.9625 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.9204 - accuracy: 0.5208 - val_loss: 0.9805 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.9138 - accuracy: 0.5170 - val_loss: 0.9663 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.9233 - accuracy: 0.5288 - val_loss: 0.9801 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.9178 - accuracy: 0.5309 - val_loss: 0.9752 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.9122 - accuracy: 0.5172 - val_loss: 0.9618 - val_accuracy: 0.5113 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9129 - accuracy: 0.5381 - val_loss: 0.9676 - val_accuracy: 0.5082 - 1s/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.9212 - accuracy: 0.5149 - val_loss: 0.9701 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.9188 - accuracy: 0.5285 - val_loss: 0.9777 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9186 - accuracy: 0.5141 - val_loss: 0.9712 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 4856 4857 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   4    7    9   11   26   34   37   41   44   53   54   68   77   80\n",
      "   82   94  104  109  112  116  118  119  125  139  146  147  158  161\n",
      "  162  165  171  173  175  184  201  220  228  236  237  243  250  260\n",
      "  261  265  271  272  273  276  277  279  280  283  284  287  294  295\n",
      "  298  300  302  305  307  310  312  314  315  320  321  329  340  350\n",
      "  352  358  366  367  374  378  379  388  393  396  413  418  425  428\n",
      "  439  443  450  456  458  466  468  473  477  479  482  505  507  508\n",
      "  517  523  528  538  540  548  550  552  555  561  566  570  572  573\n",
      "  584  598  599  605  611  614  617  618  621  624  632  633  647  648\n",
      "  649  653  654  655  660  666  668  670  675  677  680  683  697  706\n",
      "  707  708  709  710  718  720  724  726  727  729  734  736  750  755\n",
      "  767  784  791  794  796  803  807  811  819  826  836  839  843  848\n",
      "  860  866  871  875  883  885  891  897  899  901  903  904  914  917\n",
      "  923  930  932  936  937  938  939  942  944  947  948  956  963  964\n",
      "  974  988  994  996  997 1000 1001 1006 1008 1012 1015 1019 1036 1052\n",
      " 1054 1059 1072 1073 1074 1075 1088 1091 1093 1103 1108 1113 1149 1153\n",
      " 1161 1166 1172 1183 1185 1193 1194 1195 1200 1202 1206 1209 1215 1223\n",
      " 1228 1231 1237 1241 1248 1253 1260 1264 1266 1273 1274 1280 1282 1298\n",
      " 1302 1307 1311 1313 1327 1329 1339 1346 1348 1349 1351 1355 1358 1359\n",
      " 1361 1363 1366 1387 1396 1402 1405 1406 1408 1417 1418 1423 1429 1435\n",
      " 1436 1438 1439 1445 1449 1455 1457 1463 1468 1470 1472 1485 1487 1490\n",
      " 1492 1496 1500 1501 1508 1517 1518 1521 1524 1532 1538 1541 1542 1549\n",
      " 1550 1559 1560 1566 1574 1575 1576 1581 1591 1592 1597 1598 1600 1603\n",
      " 1606 1613 1625 1626 1629 1630 1633 1640 1643 1647 1654 1658 1664 1676\n",
      " 1688 1693 1696 1698 1707 1709 1711 1714 1715 1716 1718 1720 1724 1727\n",
      " 1732 1736 1738 1750 1752 1753 1759 1761 1764 1767 1773 1779 1793 1801\n",
      " 1803 1808 1810 1819 1822 1825 1828 1831 1835 1836 1838 1839 1845 1853\n",
      " 1854 1864 1865 1870 1871 1886 1891 1893 1908 1912 1916 1928 1935 1948\n",
      " 1951 1955 1959 1961 1962 1963 1972 1979 1982 1983 1985 1988 1994 2004\n",
      " 2011 2016 2019 2022 2023 2035 2043 2044 2059 2061 2063 2065 2067 2068\n",
      " 2072 2074 2075 2078 2079 2085 2093 2094 2099 2101 2102 2103 2105 2107\n",
      " 2108 2115 2133 2137 2138 2141 2144 2149 2152 2159 2166 2170 2185 2188\n",
      " 2199 2200 2204 2213 2220 2222 2224 2226 2230 2234 2242 2261 2262 2265\n",
      " 2266 2270 2289 2290 2295 2302 2305 2306 2320 2326 2331 2337 2338 2341\n",
      " 2346 2348 2350 2357 2375 2376 2393 2396 2398 2405 2411 2414 2419 2421\n",
      " 2422 2427 2436 2443 2444 2450 2457 2460 2466 2469 2470 2472 2475 2481\n",
      " 2482 2487 2489 2491 2492 2503 2508 2509 2521 2524 2536 2544 2551 2556\n",
      " 2562 2565 2566 2567 2568 2574 2587 2595 2607 2609 2621 2626 2629 2630\n",
      " 2632 2637 2638 2641 2645 2650 2657 2666 2671 2674 2677 2683 2688 2692\n",
      " 2695 2698 2699 2700 2731 2733 2736 2743 2747 2752 2757 2761 2774 2780\n",
      " 2784 2785 2786 2792 2795 2803 2806 2809 2812 2813 2816 2819 2820 2829\n",
      " 2831 2836 2838 2843 2859 2861 2862 2867 2879 2887 2902 2915 2922 2923\n",
      " 2924 2925 2926 2934 2938 2941 2942 2963 2966 2980 2986 2987 2997 3007\n",
      " 3018 3019 3021 3025 3027 3030 3049 3053 3056 3060 3063 3069 3073 3080\n",
      " 3083 3096 3098 3105 3109 3114 3116 3123 3125 3126 3129 3132 3133 3141\n",
      " 3147 3161 3172 3174 3186 3188 3189 3190 3218 3219 3225 3226 3229 3230\n",
      " 3232 3235 3244 3248 3250 3253 3267 3268 3274 3283 3287 3294 3302 3303\n",
      " 3317 3319 3321 3327 3329 3332 3338 3346 3361 3363 3373 3379 3390 3393\n",
      " 3400 3418 3419 3422 3427 3431 3434 3439 3443 3448 3450 3451 3454 3455\n",
      " 3457 3475 3485 3495 3500 3510 3512 3516 3518 3519 3521 3525 3536 3544\n",
      " 3553 3560 3573 3575 3577 3580 3586 3591 3602 3604 3607 3609 3615 3617\n",
      " 3619 3628 3629 3630 3636 3646 3649 3653 3654 3655 3660 3665 3666 3667\n",
      " 3669 3670 3672 3675 3677 3683 3688 3692 3694 3710 3712 3713 3718 3724\n",
      " 3727 3731 3733 3736 3742 3743 3757 3762 3763 3766 3778 3787 3802 3806\n",
      " 3807 3814 3816 3819 3822 3826 3830 3836 3838 3843 3851 3852 3854 3856\n",
      " 3872 3878 3884 3887 3889 3890 3901 3914 3915 3921 3927 3931 3933 3935\n",
      " 3939 3940 3943 3944 3946 3950 3956 3958 3963 3964 3969 3971 3980 3983\n",
      " 3984 3988 3990 3991 3998 4024 4028 4031 4038 4039 4042 4044 4046 4048\n",
      " 4051 4056 4057 4060 4063 4065 4070 4071 4072 4075 4087 4090 4104 4106\n",
      " 4111 4114 4118 4126 4128 4133 4141 4147 4151 4153 4154 4159 4162 4164\n",
      " 4169 4173 4174 4175 4179 4188 4191 4192 4193 4197 4203 4209 4214 4219\n",
      " 4223 4225 4230 4233 4242 4246 4247 4260 4274 4279 4295 4323 4325 4333\n",
      " 4336 4337 4352 4353 4361 4374 4381 4391 4393 4399 4400 4403 4407 4422\n",
      " 4423 4429 4431 4432 4435 4438 4460 4463 4464 4470 4480 4494 4506 4507\n",
      " 4519 4522 4523 4524 4527 4539 4542 4545 4549 4555 4556 4564 4565 4566\n",
      " 4571 4582 4588 4589 4602 4604 4619 4624 4629 4634 4637 4639 4640 4648\n",
      " 4656 4658 4669 4672 4678 4679 4685 4691 4693 4695 4698 4703 4705 4710\n",
      " 4712 4713 4717 4718 4720 4723 4726 4728 4730 4739 4740 4755 4761 4769\n",
      " 4773 4776 4781 4784 4785 4796 4799 4806 4808 4815 4816 4820 4822 4831\n",
      " 4832 4834 4843 4846 4851 4858]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:27:42.863830: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_363/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.1011 - accuracy: 0.3421 - val_loss: 1.0946 - val_accuracy: 0.3447 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0918 - accuracy: 0.3732 - val_loss: 1.0875 - val_accuracy: 0.3673 - 1s/epoch - 5ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0766 - accuracy: 0.4110 - val_loss: 1.0686 - val_accuracy: 0.4074 - 1s/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0626 - accuracy: 0.4244 - val_loss: 1.0583 - val_accuracy: 0.4177 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0481 - accuracy: 0.4360 - val_loss: 1.0552 - val_accuracy: 0.4290 - 1s/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0500 - accuracy: 0.4357 - val_loss: 1.0476 - val_accuracy: 0.4486 - 1s/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0401 - accuracy: 0.4558 - val_loss: 1.0473 - val_accuracy: 0.4527 - 1s/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0409 - accuracy: 0.4527 - val_loss: 1.0523 - val_accuracy: 0.4259 - 1s/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0406 - accuracy: 0.4480 - val_loss: 1.0433 - val_accuracy: 0.4599 - 1s/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0284 - accuracy: 0.4637 - val_loss: 1.0559 - val_accuracy: 0.4259 - 1s/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0285 - accuracy: 0.4424 - val_loss: 1.0426 - val_accuracy: 0.4568 - 1s/epoch - 5ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0231 - accuracy: 0.4676 - val_loss: 1.0445 - val_accuracy: 0.4506 - 1s/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0172 - accuracy: 0.4671 - val_loss: 1.0394 - val_accuracy: 0.4671 - 1s/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0208 - accuracy: 0.4722 - val_loss: 1.0399 - val_accuracy: 0.4475 - 1s/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0146 - accuracy: 0.4702 - val_loss: 1.0436 - val_accuracy: 0.4414 - 1s/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0140 - accuracy: 0.4902 - val_loss: 1.0365 - val_accuracy: 0.4537 - 1s/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4779 - val_loss: 1.0384 - val_accuracy: 0.4424 - 1s/epoch - 5ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0131 - accuracy: 0.4637 - val_loss: 1.0401 - val_accuracy: 0.4403 - 1s/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0068 - accuracy: 0.4851 - val_loss: 1.0311 - val_accuracy: 0.4660 - 1s/epoch - 5ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0112 - accuracy: 0.4694 - val_loss: 1.0272 - val_accuracy: 0.4486 - 1s/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 1.0076 - accuracy: 0.4807 - val_loss: 1.0302 - val_accuracy: 0.4527 - 1s/epoch - 5ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 1.0018 - accuracy: 0.4794 - val_loss: 1.0237 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 1.0015 - accuracy: 0.4802 - val_loss: 1.0256 - val_accuracy: 0.4660 - 1s/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9989 - accuracy: 0.4918 - val_loss: 1.0235 - val_accuracy: 0.4558 - 1s/epoch - 5ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9964 - accuracy: 0.4877 - val_loss: 1.0256 - val_accuracy: 0.4578 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 0.9933 - accuracy: 0.4856 - val_loss: 1.0243 - val_accuracy: 0.4630 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9938 - accuracy: 0.4838 - val_loss: 1.0275 - val_accuracy: 0.4547 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9871 - accuracy: 0.4964 - val_loss: 1.0137 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9835 - accuracy: 0.4964 - val_loss: 1.0208 - val_accuracy: 0.4660 - 1s/epoch - 5ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9865 - accuracy: 0.4941 - val_loss: 1.0160 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9881 - accuracy: 0.4959 - val_loss: 1.0223 - val_accuracy: 0.4558 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9835 - accuracy: 0.4941 - val_loss: 1.0103 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9909 - accuracy: 0.4866 - val_loss: 1.0176 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9833 - accuracy: 0.4972 - val_loss: 1.0132 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9797 - accuracy: 0.5015 - val_loss: 1.0061 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9749 - accuracy: 0.5044 - val_loss: 1.0078 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9775 - accuracy: 0.4925 - val_loss: 0.9977 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9772 - accuracy: 0.5049 - val_loss: 1.0119 - val_accuracy: 0.4599 - 1s/epoch - 5ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9749 - accuracy: 0.5152 - val_loss: 1.0066 - val_accuracy: 0.4496 - 1s/epoch - 5ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9728 - accuracy: 0.5067 - val_loss: 1.0007 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9776 - accuracy: 0.5093 - val_loss: 1.0091 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9766 - accuracy: 0.5005 - val_loss: 1.0065 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9769 - accuracy: 0.5039 - val_loss: 1.0189 - val_accuracy: 0.4547 - 1s/epoch - 5ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9747 - accuracy: 0.4915 - val_loss: 1.0127 - val_accuracy: 0.4599 - 1s/epoch - 5ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9703 - accuracy: 0.5126 - val_loss: 0.9989 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9710 - accuracy: 0.4977 - val_loss: 0.9992 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9711 - accuracy: 0.5069 - val_loss: 1.0094 - val_accuracy: 0.4588 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9631 - accuracy: 0.5126 - val_loss: 0.9992 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9610 - accuracy: 0.5159 - val_loss: 0.9989 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9521 - accuracy: 0.5098 - val_loss: 0.9953 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9686 - accuracy: 0.5093 - val_loss: 1.0016 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9601 - accuracy: 0.5170 - val_loss: 1.0009 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9549 - accuracy: 0.5183 - val_loss: 1.0022 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9598 - accuracy: 0.5082 - val_loss: 1.0064 - val_accuracy: 0.4671 - 1s/epoch - 5ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9618 - accuracy: 0.5100 - val_loss: 1.0056 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9502 - accuracy: 0.5234 - val_loss: 1.0062 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9606 - accuracy: 0.5100 - val_loss: 1.0042 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9536 - accuracy: 0.5136 - val_loss: 1.0003 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9474 - accuracy: 0.5280 - val_loss: 1.0086 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9563 - accuracy: 0.5108 - val_loss: 0.9985 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9617 - accuracy: 0.5177 - val_loss: 0.9929 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9532 - accuracy: 0.5288 - val_loss: 0.9983 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9506 - accuracy: 0.5229 - val_loss: 1.0091 - val_accuracy: 0.4527 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9527 - accuracy: 0.5188 - val_loss: 0.9933 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9507 - accuracy: 0.5244 - val_loss: 1.0012 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9532 - accuracy: 0.5247 - val_loss: 0.9954 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9527 - accuracy: 0.5296 - val_loss: 0.9968 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9518 - accuracy: 0.5211 - val_loss: 1.0022 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9542 - accuracy: 0.5188 - val_loss: 0.9965 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9472 - accuracy: 0.5322 - val_loss: 1.0177 - val_accuracy: 0.4259 - 1s/epoch - 5ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9565 - accuracy: 0.5131 - val_loss: 1.0056 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9470 - accuracy: 0.5229 - val_loss: 0.9961 - val_accuracy: 0.5093 - 1s/epoch - 5ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9542 - accuracy: 0.5183 - val_loss: 1.0066 - val_accuracy: 0.4681 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9526 - accuracy: 0.5098 - val_loss: 1.0061 - val_accuracy: 0.4588 - 1s/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9480 - accuracy: 0.5193 - val_loss: 1.0049 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9520 - accuracy: 0.5252 - val_loss: 1.0012 - val_accuracy: 0.4733 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9425 - accuracy: 0.5270 - val_loss: 0.9996 - val_accuracy: 0.4763 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9508 - accuracy: 0.5213 - val_loss: 0.9953 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9506 - accuracy: 0.5216 - val_loss: 1.0030 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9501 - accuracy: 0.5229 - val_loss: 1.0060 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9551 - accuracy: 0.5118 - val_loss: 1.0086 - val_accuracy: 0.4578 - 1s/epoch - 5ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9437 - accuracy: 0.5234 - val_loss: 1.0031 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9456 - accuracy: 0.5172 - val_loss: 1.0000 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9403 - accuracy: 0.5291 - val_loss: 0.9931 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9416 - accuracy: 0.5134 - val_loss: 0.9938 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9463 - accuracy: 0.5262 - val_loss: 1.0027 - val_accuracy: 0.4671 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9452 - accuracy: 0.5273 - val_loss: 1.0013 - val_accuracy: 0.4547 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9449 - accuracy: 0.5170 - val_loss: 0.9954 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9455 - accuracy: 0.5278 - val_loss: 1.0064 - val_accuracy: 0.4609 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9457 - accuracy: 0.5350 - val_loss: 0.9975 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9412 - accuracy: 0.5381 - val_loss: 0.9933 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9299 - accuracy: 0.5396 - val_loss: 1.0041 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9390 - accuracy: 0.5221 - val_loss: 0.9933 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9427 - accuracy: 0.5255 - val_loss: 1.0037 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9323 - accuracy: 0.5324 - val_loss: 0.9938 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9354 - accuracy: 0.5316 - val_loss: 1.0009 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9417 - accuracy: 0.5231 - val_loss: 0.9894 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9446 - accuracy: 0.5255 - val_loss: 0.9961 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9399 - accuracy: 0.5319 - val_loss: 1.0054 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9448 - accuracy: 0.5188 - val_loss: 1.0095 - val_accuracy: 0.4434 - 1s/epoch - 5ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9327 - accuracy: 0.5216 - val_loss: 0.9897 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9401 - accuracy: 0.5273 - val_loss: 0.9935 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9413 - accuracy: 0.5188 - val_loss: 1.0058 - val_accuracy: 0.4588 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9358 - accuracy: 0.5280 - val_loss: 0.9917 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9400 - accuracy: 0.5239 - val_loss: 0.9871 - val_accuracy: 0.5082 - 1s/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9414 - accuracy: 0.5314 - val_loss: 1.0009 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.9499 - accuracy: 0.5216 - val_loss: 0.9988 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9371 - accuracy: 0.5296 - val_loss: 0.9985 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.9407 - accuracy: 0.5244 - val_loss: 0.9947 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9297 - accuracy: 0.5399 - val_loss: 0.9997 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9279 - accuracy: 0.5332 - val_loss: 0.9980 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9321 - accuracy: 0.5298 - val_loss: 0.9906 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9347 - accuracy: 0.5350 - val_loss: 0.9962 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9376 - accuracy: 0.5296 - val_loss: 0.9926 - val_accuracy: 0.4969 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9328 - accuracy: 0.5332 - val_loss: 1.0034 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9357 - accuracy: 0.5267 - val_loss: 0.9994 - val_accuracy: 0.4660 - 1s/epoch - 5ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9293 - accuracy: 0.5370 - val_loss: 0.9860 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9446 - accuracy: 0.5280 - val_loss: 0.9945 - val_accuracy: 0.4558 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9358 - accuracy: 0.5244 - val_loss: 0.9968 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9367 - accuracy: 0.5412 - val_loss: 1.0170 - val_accuracy: 0.4321 - 1s/epoch - 5ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9326 - accuracy: 0.5316 - val_loss: 1.0004 - val_accuracy: 0.4578 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9293 - accuracy: 0.5401 - val_loss: 0.9939 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9324 - accuracy: 0.5396 - val_loss: 0.9862 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9358 - accuracy: 0.5216 - val_loss: 0.9952 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.9217 - accuracy: 0.5360 - val_loss: 0.9954 - val_accuracy: 0.4805 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.9312 - accuracy: 0.5329 - val_loss: 0.9935 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9299 - accuracy: 0.5368 - val_loss: 0.9936 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.9302 - accuracy: 0.5301 - val_loss: 1.0033 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.9312 - accuracy: 0.5242 - val_loss: 1.0005 - val_accuracy: 0.4743 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9341 - accuracy: 0.5211 - val_loss: 0.9909 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.9314 - accuracy: 0.5319 - val_loss: 0.9918 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.9288 - accuracy: 0.5412 - val_loss: 0.9979 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9297 - accuracy: 0.5314 - val_loss: 1.0023 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.9313 - accuracy: 0.5324 - val_loss: 0.9949 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.9217 - accuracy: 0.5450 - val_loss: 0.9997 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.9339 - accuracy: 0.5242 - val_loss: 1.0004 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9242 - accuracy: 0.5391 - val_loss: 0.9945 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.9339 - accuracy: 0.5237 - val_loss: 0.9917 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.9379 - accuracy: 0.5226 - val_loss: 0.9920 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.9296 - accuracy: 0.5329 - val_loss: 0.9958 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9336 - accuracy: 0.5260 - val_loss: 0.9929 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9313 - accuracy: 0.5396 - val_loss: 0.9971 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9327 - accuracy: 0.5381 - val_loss: 0.9918 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.9251 - accuracy: 0.5412 - val_loss: 1.0010 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.9370 - accuracy: 0.5358 - val_loss: 0.9890 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9266 - accuracy: 0.5329 - val_loss: 1.0048 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.9248 - accuracy: 0.5450 - val_loss: 0.9964 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.9347 - accuracy: 0.5301 - val_loss: 0.9929 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.9168 - accuracy: 0.5455 - val_loss: 0.9957 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.9261 - accuracy: 0.5412 - val_loss: 1.0074 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.9242 - accuracy: 0.5404 - val_loss: 0.9946 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.9333 - accuracy: 0.5355 - val_loss: 1.0035 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.9270 - accuracy: 0.5514 - val_loss: 1.0171 - val_accuracy: 0.4506 - 1s/epoch - 5ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.9238 - accuracy: 0.5388 - val_loss: 1.0063 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.9311 - accuracy: 0.5386 - val_loss: 0.9944 - val_accuracy: 0.4897 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.9235 - accuracy: 0.5412 - val_loss: 1.0026 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9237 - accuracy: 0.5463 - val_loss: 0.9929 - val_accuracy: 0.5021 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.9315 - accuracy: 0.5363 - val_loss: 0.9923 - val_accuracy: 0.5123 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.9227 - accuracy: 0.5486 - val_loss: 0.9968 - val_accuracy: 0.4763 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.9243 - accuracy: 0.5430 - val_loss: 0.9968 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9256 - accuracy: 0.5437 - val_loss: 0.9968 - val_accuracy: 0.4990 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.9267 - accuracy: 0.5466 - val_loss: 0.9953 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.9276 - accuracy: 0.5311 - val_loss: 0.9936 - val_accuracy: 0.4547 - 1s/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.9278 - accuracy: 0.5347 - val_loss: 0.9993 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.5468 - val_loss: 0.9955 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.9207 - accuracy: 0.5373 - val_loss: 0.9923 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.9199 - accuracy: 0.5396 - val_loss: 0.9964 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.9224 - accuracy: 0.5301 - val_loss: 0.9933 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.9185 - accuracy: 0.5406 - val_loss: 1.0026 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.9129 - accuracy: 0.5412 - val_loss: 0.9965 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.9313 - accuracy: 0.5391 - val_loss: 0.9903 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.9200 - accuracy: 0.5363 - val_loss: 0.9986 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.5288 - val_loss: 1.0122 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.5378 - val_loss: 0.9921 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9115 - accuracy: 0.5386 - val_loss: 1.0005 - val_accuracy: 0.4671 - 1s/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.9213 - accuracy: 0.5406 - val_loss: 0.9941 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.9230 - accuracy: 0.5381 - val_loss: 0.9938 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.9243 - accuracy: 0.5437 - val_loss: 0.9917 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.9334 - accuracy: 0.5414 - val_loss: 0.9946 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.9178 - accuracy: 0.5463 - val_loss: 0.9961 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.9263 - accuracy: 0.5409 - val_loss: 0.9961 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.9234 - accuracy: 0.5442 - val_loss: 0.9927 - val_accuracy: 0.4609 - 1s/epoch - 5ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.9221 - accuracy: 0.5394 - val_loss: 1.0090 - val_accuracy: 0.4434 - 1s/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.9262 - accuracy: 0.5440 - val_loss: 0.9913 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.9282 - accuracy: 0.5471 - val_loss: 0.9901 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.9200 - accuracy: 0.5458 - val_loss: 0.9944 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.9233 - accuracy: 0.5376 - val_loss: 0.9945 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.9180 - accuracy: 0.5365 - val_loss: 0.9873 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.9190 - accuracy: 0.5419 - val_loss: 0.9912 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.9186 - accuracy: 0.5509 - val_loss: 0.9854 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.9328 - accuracy: 0.5427 - val_loss: 0.9944 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5535 - val_loss: 0.9819 - val_accuracy: 0.5082 - 1s/epoch - 5ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.9328 - accuracy: 0.5288 - val_loss: 0.9916 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.9221 - accuracy: 0.5424 - val_loss: 0.9844 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.9194 - accuracy: 0.5522 - val_loss: 0.9965 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.9241 - accuracy: 0.5460 - val_loss: 0.9826 - val_accuracy: 0.5134 - 1s/epoch - 5ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.9198 - accuracy: 0.5406 - val_loss: 0.9986 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.9237 - accuracy: 0.5476 - val_loss: 0.9912 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.9240 - accuracy: 0.5365 - val_loss: 1.0032 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.9227 - accuracy: 0.5394 - val_loss: 0.9899 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.9222 - accuracy: 0.5520 - val_loss: 0.9902 - val_accuracy: 0.5093 - 1s/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.9188 - accuracy: 0.5432 - val_loss: 0.9845 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.9264 - accuracy: 0.5340 - val_loss: 0.9824 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.9190 - accuracy: 0.5406 - val_loss: 0.9877 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.9160 - accuracy: 0.5538 - val_loss: 0.9893 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.9223 - accuracy: 0.5430 - val_loss: 0.9963 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.9167 - accuracy: 0.5437 - val_loss: 0.9912 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.9160 - accuracy: 0.5478 - val_loss: 0.9878 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.9232 - accuracy: 0.5399 - val_loss: 0.9992 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.9189 - accuracy: 0.5427 - val_loss: 0.9943 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.9308 - accuracy: 0.5427 - val_loss: 0.9959 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9179 - accuracy: 0.5365 - val_loss: 0.9903 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9229 - accuracy: 0.5532 - val_loss: 0.9986 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.9127 - accuracy: 0.5404 - val_loss: 1.0011 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.9176 - accuracy: 0.5502 - val_loss: 1.0013 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.9183 - accuracy: 0.5337 - val_loss: 0.9889 - val_accuracy: 0.5134 - 1s/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.9005 - accuracy: 0.5558 - val_loss: 1.0042 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.9025 - accuracy: 0.5478 - val_loss: 1.0037 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.9054 - accuracy: 0.5553 - val_loss: 0.9929 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.5460 - val_loss: 0.9923 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.9212 - accuracy: 0.5478 - val_loss: 0.9958 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.9088 - accuracy: 0.5494 - val_loss: 0.9862 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.9165 - accuracy: 0.5486 - val_loss: 1.0013 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.9131 - accuracy: 0.5535 - val_loss: 0.9969 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.9209 - accuracy: 0.5463 - val_loss: 0.9876 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.9068 - accuracy: 0.5489 - val_loss: 0.9818 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.9278 - accuracy: 0.5314 - val_loss: 1.0094 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.9219 - accuracy: 0.5311 - val_loss: 1.0003 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.9248 - accuracy: 0.5394 - val_loss: 0.9981 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.9206 - accuracy: 0.5489 - val_loss: 0.9907 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.9219 - accuracy: 0.5448 - val_loss: 0.9886 - val_accuracy: 0.4959 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.9145 - accuracy: 0.5507 - val_loss: 0.9922 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.9128 - accuracy: 0.5440 - val_loss: 0.9807 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.9139 - accuracy: 0.5478 - val_loss: 0.9855 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.9091 - accuracy: 0.5484 - val_loss: 0.9940 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.9094 - accuracy: 0.5612 - val_loss: 0.9882 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.9114 - accuracy: 0.5489 - val_loss: 0.9876 - val_accuracy: 0.5051 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9167 - accuracy: 0.5445 - val_loss: 0.9906 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.9208 - accuracy: 0.5404 - val_loss: 0.9876 - val_accuracy: 0.5185 - 1s/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.9164 - accuracy: 0.5545 - val_loss: 1.0043 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9102 - accuracy: 0.5535 - val_loss: 0.9843 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.9119 - accuracy: 0.5522 - val_loss: 1.0096 - val_accuracy: 0.4609 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.9127 - accuracy: 0.5520 - val_loss: 0.9845 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.9161 - accuracy: 0.5530 - val_loss: 1.0114 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.9242 - accuracy: 0.5324 - val_loss: 0.9863 - val_accuracy: 0.5113 - 1s/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.9198 - accuracy: 0.5440 - val_loss: 1.0036 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9221 - accuracy: 0.5391 - val_loss: 0.9972 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.9184 - accuracy: 0.5522 - val_loss: 1.0061 - val_accuracy: 0.4599 - 1s/epoch - 5ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.9140 - accuracy: 0.5525 - val_loss: 0.9983 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9128 - accuracy: 0.5440 - val_loss: 0.9877 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 4857 4858 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   3   22   25   27   31   33   45   52   55   56   61   62   63   70\n",
      "   79   81   89   90   92   93   96   98  108  113  114  120  122  126\n",
      "  130  131  134  135  140  145  150  151  154  167  198  199  205  207\n",
      "  211  218  222  223  225  227  229  230  231  234  240  245  246  248\n",
      "  249  252  256  264  268  274  285  291  301  308  313  317  318  322\n",
      "  323  325  336  337  341  345  356  359  361  376  382  385  386  390\n",
      "  400  409  415  422  426  427  432  433  436  437  438  442  446  448\n",
      "  449  454  460  462  471  478  485  491  493  495  498  499  506  516\n",
      "  520  529  530  532  539  541  544  549  562  567  583  585  587  594\n",
      "  620  627  631  640  641  650  651  656  661  671  674  686  688  689\n",
      "  692  696  699  700  704  725  728  739  751  762  773  775  778  781\n",
      "  798  799  810  821  823  827  831  834  837  838  841  844  845  846\n",
      "  849  850  855  858  863  867  870  873  877  880  884  886  887  888\n",
      "  892  894  898  900  905  906  907  926  928  931  933  943  953  962\n",
      "  970  982  987  989  992  993  995 1003 1009 1011 1020 1022 1028 1030\n",
      " 1031 1039 1042 1044 1047 1050 1063 1064 1067 1079 1094 1095 1096 1102\n",
      " 1107 1114 1117 1119 1131 1132 1135 1138 1141 1150 1154 1155 1160 1163\n",
      " 1164 1173 1176 1184 1188 1191 1197 1203 1217 1222 1226 1232 1234 1239\n",
      " 1252 1254 1262 1263 1272 1277 1285 1291 1295 1301 1303 1304 1319 1320\n",
      " 1322 1324 1326 1332 1335 1336 1340 1344 1350 1357 1364 1367 1368 1379\n",
      " 1382 1388 1399 1403 1410 1413 1419 1421 1426 1428 1430 1442 1443 1448\n",
      " 1453 1458 1464 1465 1466 1482 1494 1498 1512 1514 1515 1516 1519 1530\n",
      " 1533 1535 1540 1552 1563 1589 1595 1608 1614 1615 1616 1617 1618 1622\n",
      " 1623 1632 1637 1644 1649 1657 1659 1663 1665 1666 1669 1680 1681 1682\n",
      " 1685 1691 1695 1697 1704 1710 1722 1729 1733 1747 1748 1749 1757 1769\n",
      " 1781 1784 1787 1792 1796 1798 1800 1807 1813 1841 1844 1861 1875 1879\n",
      " 1883 1885 1888 1889 1890 1902 1904 1907 1919 1923 1924 1934 1936 1939\n",
      " 1940 1942 1947 1958 1960 1967 1973 1975 1977 1980 1981 1987 1989 1990\n",
      " 1992 1999 2008 2021 2024 2025 2028 2029 2031 2038 2040 2047 2051 2056\n",
      " 2057 2066 2082 2086 2088 2091 2100 2104 2112 2119 2121 2124 2130 2146\n",
      " 2148 2154 2161 2172 2177 2182 2189 2196 2197 2205 2208 2211 2212 2223\n",
      " 2231 2232 2236 2240 2241 2245 2246 2250 2251 2252 2254 2256 2257 2267\n",
      " 2268 2271 2280 2286 2299 2303 2304 2312 2315 2324 2333 2340 2344 2354\n",
      " 2356 2358 2365 2366 2370 2371 2372 2373 2378 2380 2385 2392 2394 2399\n",
      " 2423 2425 2431 2433 2440 2446 2449 2452 2453 2456 2462 2464 2467 2468\n",
      " 2473 2501 2502 2507 2514 2517 2523 2526 2529 2532 2533 2534 2537 2546\n",
      " 2552 2560 2564 2570 2573 2578 2581 2582 2584 2590 2593 2602 2613 2622\n",
      " 2624 2642 2646 2647 2649 2655 2661 2665 2675 2679 2689 2693 2694 2696\n",
      " 2703 2707 2710 2711 2719 2721 2728 2729 2737 2738 2739 2740 2742 2751\n",
      " 2755 2768 2775 2777 2781 2789 2793 2804 2808 2811 2817 2825 2827 2835\n",
      " 2837 2844 2846 2847 2851 2852 2870 2872 2876 2881 2884 2886 2888 2907\n",
      " 2908 2910 2912 2921 2928 2932 2937 2949 2951 2953 2957 2959 2960 2976\n",
      " 2978 2979 2991 3002 3004 3006 3010 3013 3028 3031 3032 3035 3045 3047\n",
      " 3050 3061 3062 3068 3074 3077 3078 3088 3089 3100 3101 3103 3106 3108\n",
      " 3110 3111 3112 3115 3119 3130 3143 3150 3151 3159 3164 3173 3176 3180\n",
      " 3195 3207 3208 3217 3221 3228 3238 3243 3245 3249 3254 3266 3281 3288\n",
      " 3290 3292 3295 3296 3297 3298 3313 3314 3325 3339 3341 3345 3349 3355\n",
      " 3357 3366 3368 3370 3371 3372 3380 3382 3396 3406 3410 3415 3424 3435\n",
      " 3436 3437 3442 3447 3452 3464 3468 3469 3470 3473 3477 3486 3489 3492\n",
      " 3499 3501 3504 3508 3514 3515 3530 3531 3543 3549 3550 3551 3556 3559\n",
      " 3561 3562 3563 3567 3571 3574 3582 3587 3588 3589 3593 3595 3611 3618\n",
      " 3622 3623 3631 3637 3639 3641 3650 3657 3658 3659 3664 3673 3676 3678\n",
      " 3680 3691 3696 3715 3717 3721 3722 3732 3747 3764 3765 3768 3769 3771\n",
      " 3772 3774 3776 3779 3783 3792 3793 3796 3801 3810 3821 3827 3831 3832\n",
      " 3839 3848 3855 3857 3860 3862 3864 3866 3871 3874 3875 3883 3892 3894\n",
      " 3895 3896 3897 3899 3904 3907 3910 3912 3917 3919 3922 3928 3932 3934\n",
      " 3937 3947 3948 3953 3954 3962 3966 3975 3979 3981 3996 3997 3999 4000\n",
      " 4003 4008 4009 4010 4011 4012 4016 4021 4022 4026 4035 4052 4053 4058\n",
      " 4061 4066 4076 4079 4080 4081 4083 4091 4093 4095 4108 4110 4119 4121\n",
      " 4136 4142 4143 4148 4150 4155 4156 4160 4165 4168 4177 4181 4182 4183\n",
      " 4186 4199 4200 4212 4213 4216 4217 4221 4227 4236 4238 4239 4245 4248\n",
      " 4252 4253 4264 4266 4270 4272 4280 4302 4305 4307 4314 4318 4320 4326\n",
      " 4328 4329 4330 4334 4340 4345 4351 4355 4357 4366 4369 4372 4373 4375\n",
      " 4387 4402 4404 4411 4413 4415 4421 4424 4425 4426 4427 4428 4446 4453\n",
      " 4455 4461 4462 4465 4471 4476 4477 4483 4486 4501 4502 4512 4517 4520\n",
      " 4525 4526 4529 4532 4535 4538 4541 4543 4551 4552 4562 4574 4575 4581\n",
      " 4586 4590 4592 4594 4603 4625 4628 4630 4632 4642 4645 4649 4653 4655\n",
      " 4657 4660 4661 4662 4665 4680 4690 4692 4696 4697 4716 4719 4725 4731\n",
      " 4732 4735 4742 4745 4749 4756 4770 4780 4790 4791 4801 4819 4823 4828\n",
      " 4836 4838 4840 4842 4852 4853]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:32:23.961911: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_364/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.1010 - accuracy: 0.3457 - val_loss: 1.0958 - val_accuracy: 0.3529 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0946 - accuracy: 0.3580 - val_loss: 1.0818 - val_accuracy: 0.3807 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0694 - accuracy: 0.4223 - val_loss: 1.0610 - val_accuracy: 0.4249 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0566 - accuracy: 0.4120 - val_loss: 1.0475 - val_accuracy: 0.4208 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0465 - accuracy: 0.4398 - val_loss: 1.0455 - val_accuracy: 0.4588 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0504 - accuracy: 0.4282 - val_loss: 1.0392 - val_accuracy: 0.4424 - 1s/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0406 - accuracy: 0.4475 - val_loss: 1.0406 - val_accuracy: 0.4136 - 1s/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0342 - accuracy: 0.4516 - val_loss: 1.0346 - val_accuracy: 0.4403 - 1s/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0284 - accuracy: 0.4581 - val_loss: 1.0276 - val_accuracy: 0.4496 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0321 - accuracy: 0.4434 - val_loss: 1.0219 - val_accuracy: 0.4516 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0297 - accuracy: 0.4493 - val_loss: 1.0266 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0251 - accuracy: 0.4504 - val_loss: 1.0256 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0164 - accuracy: 0.4668 - val_loss: 1.0260 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0235 - accuracy: 0.4527 - val_loss: 1.0255 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0188 - accuracy: 0.4619 - val_loss: 1.0171 - val_accuracy: 0.4640 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0141 - accuracy: 0.4588 - val_loss: 1.0175 - val_accuracy: 0.4650 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 1.0145 - accuracy: 0.4697 - val_loss: 1.0198 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0088 - accuracy: 0.4766 - val_loss: 1.0173 - val_accuracy: 0.4609 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0017 - accuracy: 0.4763 - val_loss: 1.0098 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0010 - accuracy: 0.4758 - val_loss: 1.0133 - val_accuracy: 0.4537 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 0.9985 - accuracy: 0.4830 - val_loss: 1.0117 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 1.0025 - accuracy: 0.4828 - val_loss: 1.0153 - val_accuracy: 0.4681 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 1.0014 - accuracy: 0.4805 - val_loss: 1.0126 - val_accuracy: 0.4846 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9990 - accuracy: 0.4830 - val_loss: 1.0064 - val_accuracy: 0.4743 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9992 - accuracy: 0.4843 - val_loss: 1.0100 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 0.9933 - accuracy: 0.4838 - val_loss: 1.0010 - val_accuracy: 0.4949 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9986 - accuracy: 0.4910 - val_loss: 1.0050 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9909 - accuracy: 0.4869 - val_loss: 0.9977 - val_accuracy: 0.4887 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9944 - accuracy: 0.4807 - val_loss: 1.0082 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9907 - accuracy: 0.4902 - val_loss: 1.0014 - val_accuracy: 0.4753 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9871 - accuracy: 0.4905 - val_loss: 0.9935 - val_accuracy: 0.4990 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9864 - accuracy: 0.4936 - val_loss: 1.0060 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9922 - accuracy: 0.4884 - val_loss: 1.0017 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9827 - accuracy: 0.4990 - val_loss: 0.9980 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9876 - accuracy: 0.4956 - val_loss: 1.0083 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9820 - accuracy: 0.4959 - val_loss: 1.0027 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9857 - accuracy: 0.4910 - val_loss: 0.9939 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9768 - accuracy: 0.5021 - val_loss: 1.0011 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9792 - accuracy: 0.5026 - val_loss: 0.9944 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9798 - accuracy: 0.4985 - val_loss: 0.9894 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9728 - accuracy: 0.5049 - val_loss: 0.9933 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9741 - accuracy: 0.5090 - val_loss: 0.9974 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9794 - accuracy: 0.4846 - val_loss: 0.9860 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9772 - accuracy: 0.4941 - val_loss: 0.9865 - val_accuracy: 0.5267 - 1s/epoch - 5ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9742 - accuracy: 0.4954 - val_loss: 0.9893 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9772 - accuracy: 0.5026 - val_loss: 0.9840 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9743 - accuracy: 0.5023 - val_loss: 0.9853 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9638 - accuracy: 0.5144 - val_loss: 0.9896 - val_accuracy: 0.5010 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9697 - accuracy: 0.5157 - val_loss: 1.0031 - val_accuracy: 0.4568 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9687 - accuracy: 0.5118 - val_loss: 0.9990 - val_accuracy: 0.4763 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9720 - accuracy: 0.5159 - val_loss: 0.9940 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9629 - accuracy: 0.5095 - val_loss: 0.9901 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9693 - accuracy: 0.5111 - val_loss: 0.9800 - val_accuracy: 0.4990 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9555 - accuracy: 0.5188 - val_loss: 0.9933 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9623 - accuracy: 0.5136 - val_loss: 0.9866 - val_accuracy: 0.4928 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9718 - accuracy: 0.5093 - val_loss: 0.9855 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9658 - accuracy: 0.5008 - val_loss: 0.9994 - val_accuracy: 0.4671 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9650 - accuracy: 0.5090 - val_loss: 0.9812 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9653 - accuracy: 0.5113 - val_loss: 0.9821 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9610 - accuracy: 0.5069 - val_loss: 0.9875 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9555 - accuracy: 0.5105 - val_loss: 1.0059 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9638 - accuracy: 0.5093 - val_loss: 0.9897 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9615 - accuracy: 0.5203 - val_loss: 0.9816 - val_accuracy: 0.5072 - 1s/epoch - 5ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9580 - accuracy: 0.5100 - val_loss: 0.9838 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9536 - accuracy: 0.5149 - val_loss: 0.9888 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9616 - accuracy: 0.5062 - val_loss: 0.9850 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9609 - accuracy: 0.5044 - val_loss: 0.9864 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9511 - accuracy: 0.5195 - val_loss: 0.9905 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9540 - accuracy: 0.5190 - val_loss: 0.9985 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9486 - accuracy: 0.5201 - val_loss: 0.9760 - val_accuracy: 0.5093 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9560 - accuracy: 0.5103 - val_loss: 0.9863 - val_accuracy: 0.4969 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9571 - accuracy: 0.5103 - val_loss: 0.9817 - val_accuracy: 0.4887 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9549 - accuracy: 0.5013 - val_loss: 0.9689 - val_accuracy: 0.4949 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9498 - accuracy: 0.5267 - val_loss: 0.9963 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9457 - accuracy: 0.5229 - val_loss: 0.9779 - val_accuracy: 0.4969 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9520 - accuracy: 0.5226 - val_loss: 0.9842 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9550 - accuracy: 0.5237 - val_loss: 0.9732 - val_accuracy: 0.4990 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9515 - accuracy: 0.5157 - val_loss: 0.9787 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9440 - accuracy: 0.5185 - val_loss: 0.9856 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9508 - accuracy: 0.5172 - val_loss: 0.9875 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9491 - accuracy: 0.5193 - val_loss: 0.9856 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9451 - accuracy: 0.5190 - val_loss: 0.9814 - val_accuracy: 0.4897 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9473 - accuracy: 0.5231 - val_loss: 0.9828 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9499 - accuracy: 0.5141 - val_loss: 0.9819 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9519 - accuracy: 0.5224 - val_loss: 0.9698 - val_accuracy: 0.5144 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9453 - accuracy: 0.5183 - val_loss: 0.9773 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9465 - accuracy: 0.5219 - val_loss: 0.9838 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9492 - accuracy: 0.5170 - val_loss: 0.9783 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9477 - accuracy: 0.5152 - val_loss: 0.9990 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9477 - accuracy: 0.5172 - val_loss: 0.9710 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9447 - accuracy: 0.5301 - val_loss: 0.9820 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9464 - accuracy: 0.5075 - val_loss: 0.9805 - val_accuracy: 0.4918 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9508 - accuracy: 0.5111 - val_loss: 0.9967 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9335 - accuracy: 0.5363 - val_loss: 0.9986 - val_accuracy: 0.4712 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9441 - accuracy: 0.5208 - val_loss: 0.9752 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9446 - accuracy: 0.5159 - val_loss: 0.9705 - val_accuracy: 0.5226 - 1s/epoch - 5ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9430 - accuracy: 0.5149 - val_loss: 0.9825 - val_accuracy: 0.5206 - 1s/epoch - 5ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9418 - accuracy: 0.5244 - val_loss: 0.9793 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9502 - accuracy: 0.5244 - val_loss: 0.9857 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9411 - accuracy: 0.5324 - val_loss: 0.9822 - val_accuracy: 0.4969 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9479 - accuracy: 0.5183 - val_loss: 0.9686 - val_accuracy: 0.5113 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9427 - accuracy: 0.5319 - val_loss: 0.9821 - val_accuracy: 0.5072 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9390 - accuracy: 0.5219 - val_loss: 0.9783 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9461 - accuracy: 0.5177 - val_loss: 0.9816 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9361 - accuracy: 0.5175 - val_loss: 0.9773 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9312 - accuracy: 0.5273 - val_loss: 0.9938 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.9410 - accuracy: 0.5190 - val_loss: 0.9722 - val_accuracy: 0.4990 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9512 - accuracy: 0.5231 - val_loss: 0.9777 - val_accuracy: 0.5103 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.9379 - accuracy: 0.5239 - val_loss: 0.9865 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9466 - accuracy: 0.5267 - val_loss: 0.9687 - val_accuracy: 0.5093 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9415 - accuracy: 0.5267 - val_loss: 0.9689 - val_accuracy: 0.5144 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9431 - accuracy: 0.5190 - val_loss: 0.9780 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9333 - accuracy: 0.5370 - val_loss: 0.9887 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9345 - accuracy: 0.5226 - val_loss: 0.9919 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9383 - accuracy: 0.5224 - val_loss: 0.9722 - val_accuracy: 0.5123 - 1s/epoch - 5ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9420 - accuracy: 0.5090 - val_loss: 0.9829 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9463 - accuracy: 0.5180 - val_loss: 0.9919 - val_accuracy: 0.4897 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9292 - accuracy: 0.5319 - val_loss: 0.9906 - val_accuracy: 0.4887 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9399 - accuracy: 0.5190 - val_loss: 0.9867 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9458 - accuracy: 0.5283 - val_loss: 0.9758 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9424 - accuracy: 0.5237 - val_loss: 0.9812 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9444 - accuracy: 0.5211 - val_loss: 0.9835 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9413 - accuracy: 0.5329 - val_loss: 0.9839 - val_accuracy: 0.4990 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9386 - accuracy: 0.5311 - val_loss: 0.9883 - val_accuracy: 0.5041 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.9435 - accuracy: 0.5159 - val_loss: 0.9927 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.9415 - accuracy: 0.5226 - val_loss: 0.9845 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9384 - accuracy: 0.5285 - val_loss: 0.9747 - val_accuracy: 0.5093 - 1s/epoch - 5ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.9502 - accuracy: 0.5123 - val_loss: 0.9785 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.9424 - accuracy: 0.5231 - val_loss: 0.9874 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9312 - accuracy: 0.5288 - val_loss: 0.9784 - val_accuracy: 0.5021 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.9412 - accuracy: 0.5352 - val_loss: 0.9866 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.9326 - accuracy: 0.5288 - val_loss: 0.9915 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9335 - accuracy: 0.5337 - val_loss: 0.9757 - val_accuracy: 0.5175 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.9326 - accuracy: 0.5445 - val_loss: 0.9889 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.9347 - accuracy: 0.5363 - val_loss: 0.9904 - val_accuracy: 0.5175 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.9374 - accuracy: 0.5242 - val_loss: 0.9875 - val_accuracy: 0.5175 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9349 - accuracy: 0.5275 - val_loss: 0.9800 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.9338 - accuracy: 0.5314 - val_loss: 0.9777 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.9338 - accuracy: 0.5342 - val_loss: 0.9814 - val_accuracy: 0.5072 - 1s/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.9284 - accuracy: 0.5432 - val_loss: 0.9842 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9304 - accuracy: 0.5226 - val_loss: 0.9779 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9323 - accuracy: 0.5340 - val_loss: 0.9875 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9302 - accuracy: 0.5283 - val_loss: 0.9885 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.9321 - accuracy: 0.5319 - val_loss: 0.9841 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.9413 - accuracy: 0.5388 - val_loss: 0.9867 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9317 - accuracy: 0.5311 - val_loss: 0.9757 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.9269 - accuracy: 0.5417 - val_loss: 0.9935 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.9280 - accuracy: 0.5221 - val_loss: 0.9868 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.9284 - accuracy: 0.5350 - val_loss: 0.9788 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.9316 - accuracy: 0.5391 - val_loss: 0.9748 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.9412 - accuracy: 0.5306 - val_loss: 0.9817 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.9304 - accuracy: 0.5319 - val_loss: 0.9940 - val_accuracy: 0.4609 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.9215 - accuracy: 0.5388 - val_loss: 0.9773 - val_accuracy: 0.4887 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.9307 - accuracy: 0.5342 - val_loss: 0.9777 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.9176 - accuracy: 0.5440 - val_loss: 0.9707 - val_accuracy: 0.5165 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.9338 - accuracy: 0.5265 - val_loss: 0.9795 - val_accuracy: 0.5041 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9319 - accuracy: 0.5231 - val_loss: 0.9794 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.9253 - accuracy: 0.5314 - val_loss: 0.9703 - val_accuracy: 0.5185 - 1s/epoch - 5ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.9370 - accuracy: 0.5340 - val_loss: 0.9860 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.9247 - accuracy: 0.5329 - val_loss: 0.9791 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9243 - accuracy: 0.5455 - val_loss: 1.0060 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.9295 - accuracy: 0.5327 - val_loss: 0.9726 - val_accuracy: 0.5144 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.9175 - accuracy: 0.5435 - val_loss: 0.9840 - val_accuracy: 0.5093 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.9321 - accuracy: 0.5283 - val_loss: 1.0100 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9311 - accuracy: 0.5466 - val_loss: 0.9737 - val_accuracy: 0.5123 - 1s/epoch - 5ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.9206 - accuracy: 0.5445 - val_loss: 0.9866 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.9360 - accuracy: 0.5347 - val_loss: 0.9685 - val_accuracy: 0.5216 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.9302 - accuracy: 0.5198 - val_loss: 0.9837 - val_accuracy: 0.5021 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.9311 - accuracy: 0.5283 - val_loss: 0.9754 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.9198 - accuracy: 0.5332 - val_loss: 0.9796 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.9260 - accuracy: 0.5388 - val_loss: 0.9762 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.9338 - accuracy: 0.5332 - val_loss: 0.9777 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.9277 - accuracy: 0.5358 - val_loss: 0.9833 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.9331 - accuracy: 0.5442 - val_loss: 0.9856 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9266 - accuracy: 0.5342 - val_loss: 1.0083 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.9199 - accuracy: 0.5394 - val_loss: 0.9990 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5494 - val_loss: 0.9842 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.9230 - accuracy: 0.5409 - val_loss: 0.9906 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.9281 - accuracy: 0.5322 - val_loss: 0.9858 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.9227 - accuracy: 0.5478 - val_loss: 0.9785 - val_accuracy: 0.4969 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.9341 - accuracy: 0.5298 - val_loss: 0.9836 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.9308 - accuracy: 0.5340 - val_loss: 0.9817 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.5427 - val_loss: 0.9757 - val_accuracy: 0.5041 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.9214 - accuracy: 0.5440 - val_loss: 0.9808 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.9308 - accuracy: 0.5309 - val_loss: 0.9838 - val_accuracy: 0.5113 - 1s/epoch - 5ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.9279 - accuracy: 0.5306 - val_loss: 0.9891 - val_accuracy: 0.5113 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.9234 - accuracy: 0.5399 - val_loss: 0.9749 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.9243 - accuracy: 0.5412 - val_loss: 0.9779 - val_accuracy: 0.5072 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.9276 - accuracy: 0.5414 - val_loss: 0.9696 - val_accuracy: 0.5113 - 1s/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.9340 - accuracy: 0.5260 - val_loss: 0.9680 - val_accuracy: 0.5010 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.9218 - accuracy: 0.5247 - val_loss: 0.9718 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9255 - accuracy: 0.5412 - val_loss: 0.9803 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.9316 - accuracy: 0.5417 - val_loss: 0.9698 - val_accuracy: 0.5113 - 1s/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.9202 - accuracy: 0.5412 - val_loss: 0.9845 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.9215 - accuracy: 0.5414 - val_loss: 0.9830 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.9201 - accuracy: 0.5376 - val_loss: 0.9717 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.9310 - accuracy: 0.5237 - val_loss: 0.9901 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.9305 - accuracy: 0.5288 - val_loss: 0.9862 - val_accuracy: 0.4969 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.9253 - accuracy: 0.5350 - val_loss: 0.9809 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.9198 - accuracy: 0.5350 - val_loss: 1.0026 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.9234 - accuracy: 0.5486 - val_loss: 0.9820 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.9258 - accuracy: 0.5309 - val_loss: 0.9717 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.9334 - accuracy: 0.5224 - val_loss: 0.9895 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.9275 - accuracy: 0.5314 - val_loss: 0.9677 - val_accuracy: 0.5051 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.9179 - accuracy: 0.5468 - val_loss: 0.9706 - val_accuracy: 0.5165 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.5327 - val_loss: 0.9884 - val_accuracy: 0.4897 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.9334 - accuracy: 0.5340 - val_loss: 0.9800 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.9244 - accuracy: 0.5293 - val_loss: 0.9834 - val_accuracy: 0.4949 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.9189 - accuracy: 0.5391 - val_loss: 0.9898 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.9164 - accuracy: 0.5388 - val_loss: 0.9892 - val_accuracy: 0.5144 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.9162 - accuracy: 0.5435 - val_loss: 0.9742 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9316 - accuracy: 0.5265 - val_loss: 0.9895 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9232 - accuracy: 0.5386 - val_loss: 0.9912 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.9137 - accuracy: 0.5401 - val_loss: 0.9755 - val_accuracy: 0.5134 - 1s/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.9257 - accuracy: 0.5383 - val_loss: 0.9913 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.9231 - accuracy: 0.5340 - val_loss: 0.9800 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5345 - val_loss: 0.9847 - val_accuracy: 0.5134 - 1s/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.9256 - accuracy: 0.5381 - val_loss: 0.9832 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.9157 - accuracy: 0.5391 - val_loss: 0.9766 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.9182 - accuracy: 0.5378 - val_loss: 0.9957 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.9239 - accuracy: 0.5427 - val_loss: 0.9829 - val_accuracy: 0.5072 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.9259 - accuracy: 0.5352 - val_loss: 0.9697 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.9270 - accuracy: 0.5417 - val_loss: 0.9720 - val_accuracy: 0.5093 - 1s/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.9267 - accuracy: 0.5322 - val_loss: 0.9747 - val_accuracy: 0.5216 - 1s/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.9228 - accuracy: 0.5383 - val_loss: 0.9862 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.9250 - accuracy: 0.5396 - val_loss: 0.9870 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.9233 - accuracy: 0.5296 - val_loss: 0.9840 - val_accuracy: 0.5072 - 1s/epoch - 5ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.9167 - accuracy: 0.5381 - val_loss: 0.9832 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.9216 - accuracy: 0.5394 - val_loss: 1.0076 - val_accuracy: 0.4856 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.9228 - accuracy: 0.5427 - val_loss: 0.9915 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.9203 - accuracy: 0.5468 - val_loss: 0.9806 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.9293 - accuracy: 0.5373 - val_loss: 0.9921 - val_accuracy: 0.4897 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.9255 - accuracy: 0.5486 - val_loss: 0.9782 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.9062 - accuracy: 0.5540 - val_loss: 0.9789 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.9203 - accuracy: 0.5427 - val_loss: 0.9817 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.9070 - accuracy: 0.5597 - val_loss: 0.9697 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.9193 - accuracy: 0.5491 - val_loss: 0.9843 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9210 - accuracy: 0.5473 - val_loss: 0.9984 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.9147 - accuracy: 0.5440 - val_loss: 0.9855 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.9191 - accuracy: 0.5247 - val_loss: 0.9809 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9208 - accuracy: 0.5376 - val_loss: 0.9837 - val_accuracy: 0.5082 - 1s/epoch - 5ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.9142 - accuracy: 0.5440 - val_loss: 1.0044 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.9283 - accuracy: 0.5293 - val_loss: 0.9832 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.9222 - accuracy: 0.5388 - val_loss: 0.9646 - val_accuracy: 0.5041 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.9144 - accuracy: 0.5422 - val_loss: 0.9772 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.9161 - accuracy: 0.5527 - val_loss: 0.9841 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9205 - accuracy: 0.5412 - val_loss: 0.9723 - val_accuracy: 0.5021 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.9178 - accuracy: 0.5430 - val_loss: 0.9648 - val_accuracy: 0.4979 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.5365 - val_loss: 0.9654 - val_accuracy: 0.5103 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9158 - accuracy: 0.5327 - val_loss: 0.9719 - val_accuracy: 0.5072 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 4856 4858 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   5    6    8   15   17   20   24   30   47   48   49   51   57   59\n",
      "   64   67   69   78   83   84   95   97  101  107  121  138  141  143\n",
      "  144  152  163  168  170  178  179  180  183  185  191  194  196  197\n",
      "  202  203  206  226  233  235  238  239  241  247  251  253  255  257\n",
      "  263  281  289  290  299  306  327  330  331  334  338  339  343  348\n",
      "  349  354  357  364  372  377  380  381  389  402  408  411  412  414\n",
      "  417  421  429  431  434  435  440  445  447  463  464  470  472  474\n",
      "  483  486  489  496  501  502  503  510  515  519  524  526  536  543\n",
      "  545  559  560  569  577  578  580  586  588  589  591  593  604  608\n",
      "  612  613  619  625  626  628  630  634  638  639  643  644  652  667\n",
      "  678  681  682  690  691  702  711  716  722  723  735  737  741  744\n",
      "  747  753  757  758  761  763  764  765  771  772  776  777  779  780\n",
      "  782  783  785  788  792  793  800  805  806  813  814  815  820  828\n",
      "  829  840  852  865  869  878  881  895  902  908  918  919  922  929\n",
      "  935  940  941  951  952  954  955  959  961  967  973  980  981  985\n",
      "  999 1004 1010 1024 1025 1026 1029 1032 1033 1034 1035 1038 1045 1046\n",
      " 1048 1053 1055 1060 1080 1083 1085 1086 1099 1101 1105 1106 1109 1110\n",
      " 1115 1118 1123 1124 1129 1136 1137 1140 1142 1144 1146 1148 1157 1168\n",
      " 1169 1171 1174 1178 1180 1190 1208 1218 1224 1229 1236 1238 1245 1246\n",
      " 1250 1251 1255 1265 1281 1283 1284 1288 1292 1305 1306 1309 1310 1318\n",
      " 1325 1330 1334 1338 1341 1352 1353 1356 1370 1372 1374 1394 1400 1409\n",
      " 1414 1415 1420 1424 1425 1427 1433 1437 1440 1441 1444 1446 1456 1461\n",
      " 1471 1473 1475 1477 1480 1481 1488 1506 1507 1509 1510 1511 1513 1525\n",
      " 1531 1537 1539 1546 1551 1554 1567 1572 1573 1578 1582 1583 1588 1590\n",
      " 1593 1605 1610 1611 1619 1620 1624 1645 1646 1650 1651 1653 1667 1674\n",
      " 1675 1677 1686 1687 1692 1694 1699 1717 1740 1744 1745 1751 1754 1756\n",
      " 1765 1766 1768 1772 1775 1776 1780 1783 1789 1795 1797 1799 1806 1809\n",
      " 1817 1823 1827 1834 1847 1852 1855 1858 1867 1868 1876 1877 1881 1894\n",
      " 1896 1898 1900 1901 1905 1906 1913 1914 1915 1920 1925 1927 1929 1931\n",
      " 1933 1945 1953 1956 1964 1965 1966 1971 1993 1997 1998 2000 2001 2002\n",
      " 2012 2027 2032 2045 2048 2049 2050 2053 2055 2062 2070 2076 2080 2081\n",
      " 2087 2096 2106 2109 2114 2118 2122 2126 2128 2134 2136 2150 2153 2160\n",
      " 2162 2163 2165 2168 2169 2171 2173 2181 2183 2186 2187 2191 2198 2202\n",
      " 2207 2209 2214 2218 2225 2233 2238 2243 2253 2255 2258 2260 2263 2269\n",
      " 2273 2274 2277 2282 2284 2287 2288 2291 2292 2293 2296 2298 2307 2309\n",
      " 2310 2316 2317 2335 2343 2347 2352 2353 2355 2369 2374 2379 2387 2389\n",
      " 2390 2400 2401 2402 2403 2409 2410 2413 2415 2416 2426 2432 2434 2435\n",
      " 2442 2445 2447 2471 2476 2483 2485 2493 2495 2498 2505 2515 2516 2527\n",
      " 2530 2539 2540 2542 2545 2547 2549 2554 2558 2559 2561 2569 2576 2577\n",
      " 2586 2591 2601 2610 2611 2615 2618 2627 2639 2640 2643 2644 2648 2656\n",
      " 2660 2663 2669 2676 2682 2686 2687 2702 2705 2708 2713 2717 2720 2735\n",
      " 2744 2745 2748 2753 2762 2770 2779 2782 2787 2790 2791 2797 2799 2800\n",
      " 2807 2810 2815 2821 2822 2824 2826 2830 2840 2841 2848 2853 2865 2871\n",
      " 2875 2882 2892 2893 2904 2906 2913 2916 2930 2933 2935 2936 2940 2943\n",
      " 2947 2948 2955 2956 2962 2969 2971 2972 2974 2975 2981 2983 2984 2988\n",
      " 2993 2998 3001 3005 3008 3022 3023 3024 3038 3051 3059 3064 3065 3066\n",
      " 3067 3071 3076 3082 3091 3093 3113 3122 3128 3134 3135 3136 3146 3148\n",
      " 3152 3153 3154 3155 3156 3162 3163 3168 3169 3170 3171 3178 3181 3183\n",
      " 3185 3187 3192 3198 3209 3222 3223 3227 3231 3234 3239 3246 3247 3259\n",
      " 3260 3262 3264 3265 3269 3272 3275 3276 3278 3279 3286 3291 3293 3300\n",
      " 3308 3309 3310 3311 3315 3328 3330 3336 3342 3348 3351 3352 3375 3378\n",
      " 3383 3394 3397 3402 3405 3408 3412 3420 3429 3430 3441 3444 3456 3467\n",
      " 3471 3474 3476 3480 3496 3513 3517 3520 3524 3527 3529 3532 3541 3545\n",
      " 3555 3569 3592 3594 3596 3597 3625 3634 3642 3643 3647 3652 3656 3686\n",
      " 3687 3689 3695 3698 3701 3702 3703 3726 3734 3738 3745 3748 3749 3752\n",
      " 3755 3767 3784 3785 3788 3794 3797 3798 3799 3811 3817 3829 3834 3841\n",
      " 3842 3846 3847 3863 3870 3873 3880 3903 3906 3908 3911 3916 3918 3924\n",
      " 3926 3945 3949 3955 3957 3970 3974 3986 4005 4007 4013 4029 4032 4047\n",
      " 4050 4064 4069 4073 4074 4085 4089 4096 4101 4103 4107 4113 4123 4127\n",
      " 4139 4146 4149 4152 4172 4176 4194 4196 4201 4202 4204 4207 4211 4228\n",
      " 4231 4241 4243 4250 4254 4257 4271 4273 4277 4281 4285 4288 4292 4293\n",
      " 4298 4304 4306 4310 4316 4317 4324 4327 4331 4332 4338 4339 4342 4349\n",
      " 4356 4358 4360 4379 4384 4385 4389 4390 4392 4395 4396 4398 4410 4430\n",
      " 4437 4439 4440 4441 4442 4443 4445 4451 4457 4459 4468 4469 4473 4481\n",
      " 4484 4493 4496 4499 4503 4505 4511 4531 4536 4553 4557 4563 4568 4569\n",
      " 4570 4573 4580 4584 4587 4595 4599 4608 4610 4614 4618 4627 4636 4638\n",
      " 4641 4644 4646 4647 4651 4652 4654 4666 4667 4668 4670 4676 4677 4681\n",
      " 4682 4684 4699 4701 4702 4706 4708 4714 4736 4743 4746 4759 4760 4764\n",
      " 4766 4771 4775 4777 4786 4787 4792 4804 4810 4811 4812 4813 4817 4824\n",
      " 4825 4833 4837 4847 4855 4857]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 09:37:00.262674: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_365/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.0997 - accuracy: 0.3488 - val_loss: 1.0979 - val_accuracy: 0.3323 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0904 - accuracy: 0.3804 - val_loss: 1.0897 - val_accuracy: 0.3591 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0724 - accuracy: 0.4141 - val_loss: 1.0633 - val_accuracy: 0.4342 - 1s/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0607 - accuracy: 0.4267 - val_loss: 1.0576 - val_accuracy: 0.4300 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0537 - accuracy: 0.4342 - val_loss: 1.0462 - val_accuracy: 0.4568 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0459 - accuracy: 0.4393 - val_loss: 1.0484 - val_accuracy: 0.4547 - 1s/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0370 - accuracy: 0.4468 - val_loss: 1.0375 - val_accuracy: 0.4455 - 1s/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0358 - accuracy: 0.4540 - val_loss: 1.0335 - val_accuracy: 0.4630 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0339 - accuracy: 0.4527 - val_loss: 1.0328 - val_accuracy: 0.4516 - 1s/epoch - 5ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0271 - accuracy: 0.4552 - val_loss: 1.0271 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0338 - accuracy: 0.4542 - val_loss: 1.0353 - val_accuracy: 0.4547 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0241 - accuracy: 0.4617 - val_loss: 1.0273 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0170 - accuracy: 0.4586 - val_loss: 1.0212 - val_accuracy: 0.4465 - 1s/epoch - 5ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0206 - accuracy: 0.4681 - val_loss: 1.0233 - val_accuracy: 0.4588 - 1s/epoch - 5ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0165 - accuracy: 0.4678 - val_loss: 1.0195 - val_accuracy: 0.4599 - 1s/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0094 - accuracy: 0.4792 - val_loss: 1.0201 - val_accuracy: 0.4321 - 1s/epoch - 5ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 1.0097 - accuracy: 0.4871 - val_loss: 1.0118 - val_accuracy: 0.4588 - 1s/epoch - 5ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0036 - accuracy: 0.4763 - val_loss: 1.0122 - val_accuracy: 0.4846 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0096 - accuracy: 0.4722 - val_loss: 1.0111 - val_accuracy: 0.4630 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0031 - accuracy: 0.4776 - val_loss: 1.0068 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 1.0048 - accuracy: 0.4805 - val_loss: 1.0074 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 0.9943 - accuracy: 0.4895 - val_loss: 1.0084 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 1.0024 - accuracy: 0.4918 - val_loss: 1.0035 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9978 - accuracy: 0.4910 - val_loss: 1.0089 - val_accuracy: 0.4660 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9887 - accuracy: 0.4928 - val_loss: 1.0035 - val_accuracy: 0.4733 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 1.0009 - accuracy: 0.4815 - val_loss: 1.0081 - val_accuracy: 0.4671 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9927 - accuracy: 0.4859 - val_loss: 1.0069 - val_accuracy: 0.4671 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9905 - accuracy: 0.4959 - val_loss: 1.0059 - val_accuracy: 0.4691 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9899 - accuracy: 0.4951 - val_loss: 0.9972 - val_accuracy: 0.4743 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9940 - accuracy: 0.4954 - val_loss: 0.9963 - val_accuracy: 0.4805 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9904 - accuracy: 0.4928 - val_loss: 0.9998 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9774 - accuracy: 0.4910 - val_loss: 0.9976 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9920 - accuracy: 0.4871 - val_loss: 0.9971 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9852 - accuracy: 0.4941 - val_loss: 0.9976 - val_accuracy: 0.4609 - 1s/epoch - 5ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9813 - accuracy: 0.4943 - val_loss: 0.9908 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9901 - accuracy: 0.4928 - val_loss: 0.9911 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9885 - accuracy: 0.4967 - val_loss: 0.9981 - val_accuracy: 0.4722 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9882 - accuracy: 0.5054 - val_loss: 0.9916 - val_accuracy: 0.4568 - 1s/epoch - 5ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9798 - accuracy: 0.5013 - val_loss: 0.9938 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9774 - accuracy: 0.5090 - val_loss: 0.9954 - val_accuracy: 0.4805 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9719 - accuracy: 0.5064 - val_loss: 0.9904 - val_accuracy: 0.4733 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9777 - accuracy: 0.4969 - val_loss: 0.9899 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9672 - accuracy: 0.5039 - val_loss: 0.9994 - val_accuracy: 0.4691 - 1s/epoch - 5ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9789 - accuracy: 0.4992 - val_loss: 0.9914 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9768 - accuracy: 0.5170 - val_loss: 0.9915 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9785 - accuracy: 0.4961 - val_loss: 0.9967 - val_accuracy: 0.4619 - 1s/epoch - 5ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9778 - accuracy: 0.5008 - val_loss: 0.9996 - val_accuracy: 0.4640 - 1s/epoch - 5ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9803 - accuracy: 0.4915 - val_loss: 0.9845 - val_accuracy: 0.4805 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9709 - accuracy: 0.5149 - val_loss: 0.9891 - val_accuracy: 0.4578 - 1s/epoch - 5ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9746 - accuracy: 0.5018 - val_loss: 0.9894 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9760 - accuracy: 0.5077 - val_loss: 0.9886 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9705 - accuracy: 0.5075 - val_loss: 0.9887 - val_accuracy: 0.4743 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9664 - accuracy: 0.5157 - val_loss: 0.9892 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9653 - accuracy: 0.5010 - val_loss: 0.9934 - val_accuracy: 0.4743 - 1s/epoch - 5ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9693 - accuracy: 0.5165 - val_loss: 0.9825 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9700 - accuracy: 0.5149 - val_loss: 0.9820 - val_accuracy: 0.4702 - 1s/epoch - 5ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9654 - accuracy: 0.5105 - val_loss: 0.9839 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9629 - accuracy: 0.5213 - val_loss: 0.9900 - val_accuracy: 0.4506 - 1s/epoch - 5ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9626 - accuracy: 0.5198 - val_loss: 0.9851 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9653 - accuracy: 0.5157 - val_loss: 0.9882 - val_accuracy: 0.4609 - 1s/epoch - 5ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9611 - accuracy: 0.5157 - val_loss: 0.9793 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9599 - accuracy: 0.5103 - val_loss: 0.9846 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9670 - accuracy: 0.5129 - val_loss: 0.9830 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9647 - accuracy: 0.5154 - val_loss: 0.9862 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9585 - accuracy: 0.5108 - val_loss: 0.9899 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9573 - accuracy: 0.5165 - val_loss: 0.9880 - val_accuracy: 0.4547 - 1s/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9644 - accuracy: 0.5054 - val_loss: 0.9922 - val_accuracy: 0.4475 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9585 - accuracy: 0.5095 - val_loss: 0.9894 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9598 - accuracy: 0.5267 - val_loss: 0.9840 - val_accuracy: 0.4733 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9673 - accuracy: 0.5111 - val_loss: 0.9940 - val_accuracy: 0.4527 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9653 - accuracy: 0.5134 - val_loss: 0.9822 - val_accuracy: 0.4733 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9661 - accuracy: 0.5134 - val_loss: 0.9906 - val_accuracy: 0.4599 - 1s/epoch - 5ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9569 - accuracy: 0.5139 - val_loss: 0.9786 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9641 - accuracy: 0.5185 - val_loss: 0.9787 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9624 - accuracy: 0.5129 - val_loss: 0.9783 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9608 - accuracy: 0.5260 - val_loss: 0.9819 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9572 - accuracy: 0.5170 - val_loss: 0.9905 - val_accuracy: 0.4527 - 1s/epoch - 5ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9573 - accuracy: 0.5172 - val_loss: 0.9891 - val_accuracy: 0.4486 - 1s/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9511 - accuracy: 0.5183 - val_loss: 0.9706 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9618 - accuracy: 0.5075 - val_loss: 0.9754 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9579 - accuracy: 0.5195 - val_loss: 0.9759 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9522 - accuracy: 0.5185 - val_loss: 0.9747 - val_accuracy: 0.4918 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9619 - accuracy: 0.5064 - val_loss: 0.9750 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9469 - accuracy: 0.5303 - val_loss: 0.9803 - val_accuracy: 0.4733 - 1s/epoch - 5ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9530 - accuracy: 0.5262 - val_loss: 0.9748 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9533 - accuracy: 0.5149 - val_loss: 0.9776 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9618 - accuracy: 0.5221 - val_loss: 0.9843 - val_accuracy: 0.4681 - 1s/epoch - 5ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9503 - accuracy: 0.5247 - val_loss: 0.9788 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9564 - accuracy: 0.5257 - val_loss: 0.9743 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9570 - accuracy: 0.5108 - val_loss: 0.9874 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9538 - accuracy: 0.5247 - val_loss: 0.9763 - val_accuracy: 0.4928 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9487 - accuracy: 0.5278 - val_loss: 0.9817 - val_accuracy: 0.4794 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9427 - accuracy: 0.5319 - val_loss: 0.9728 - val_accuracy: 0.4949 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9547 - accuracy: 0.5316 - val_loss: 0.9628 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9504 - accuracy: 0.5309 - val_loss: 0.9788 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9427 - accuracy: 0.5319 - val_loss: 0.9735 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9566 - accuracy: 0.5322 - val_loss: 0.9743 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9479 - accuracy: 0.5226 - val_loss: 0.9725 - val_accuracy: 0.4815 - 1s/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9501 - accuracy: 0.5216 - val_loss: 0.9703 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9503 - accuracy: 0.5231 - val_loss: 0.9761 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9502 - accuracy: 0.5244 - val_loss: 0.9763 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9446 - accuracy: 0.5373 - val_loss: 0.9740 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9448 - accuracy: 0.5342 - val_loss: 0.9744 - val_accuracy: 0.4630 - 1s/epoch - 5ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9468 - accuracy: 0.5337 - val_loss: 0.9745 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9591 - accuracy: 0.5249 - val_loss: 0.9633 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9479 - accuracy: 0.5319 - val_loss: 0.9632 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.9457 - accuracy: 0.5303 - val_loss: 0.9751 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9438 - accuracy: 0.5316 - val_loss: 0.9748 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.9399 - accuracy: 0.5257 - val_loss: 0.9784 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9405 - accuracy: 0.5242 - val_loss: 0.9741 - val_accuracy: 0.4959 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9373 - accuracy: 0.5293 - val_loss: 0.9681 - val_accuracy: 0.4918 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9412 - accuracy: 0.5386 - val_loss: 0.9775 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9440 - accuracy: 0.5365 - val_loss: 0.9670 - val_accuracy: 0.4784 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9441 - accuracy: 0.5275 - val_loss: 0.9689 - val_accuracy: 0.5082 - 1s/epoch - 5ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9435 - accuracy: 0.5252 - val_loss: 0.9673 - val_accuracy: 0.4702 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9461 - accuracy: 0.5337 - val_loss: 0.9890 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9384 - accuracy: 0.5432 - val_loss: 0.9631 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9473 - accuracy: 0.5224 - val_loss: 0.9632 - val_accuracy: 0.4784 - 1s/epoch - 5ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9394 - accuracy: 0.5337 - val_loss: 0.9778 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9456 - accuracy: 0.5283 - val_loss: 0.9760 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9478 - accuracy: 0.5345 - val_loss: 0.9703 - val_accuracy: 0.4835 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9464 - accuracy: 0.5316 - val_loss: 0.9645 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9364 - accuracy: 0.5283 - val_loss: 0.9683 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9420 - accuracy: 0.5213 - val_loss: 0.9808 - val_accuracy: 0.4712 - 1s/epoch - 5ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.9424 - accuracy: 0.5316 - val_loss: 0.9688 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.9435 - accuracy: 0.5322 - val_loss: 0.9653 - val_accuracy: 0.4918 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9379 - accuracy: 0.5334 - val_loss: 0.9635 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.9376 - accuracy: 0.5285 - val_loss: 0.9688 - val_accuracy: 0.4918 - 1s/epoch - 5ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.9347 - accuracy: 0.5496 - val_loss: 0.9698 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9467 - accuracy: 0.5340 - val_loss: 0.9798 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.9427 - accuracy: 0.5309 - val_loss: 0.9714 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.9344 - accuracy: 0.5388 - val_loss: 0.9644 - val_accuracy: 0.4825 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9430 - accuracy: 0.5224 - val_loss: 0.9733 - val_accuracy: 0.4712 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.9353 - accuracy: 0.5301 - val_loss: 0.9668 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.9404 - accuracy: 0.5383 - val_loss: 0.9829 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.9429 - accuracy: 0.5370 - val_loss: 0.9671 - val_accuracy: 0.4743 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9450 - accuracy: 0.5280 - val_loss: 0.9748 - val_accuracy: 0.4763 - 1s/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.9458 - accuracy: 0.5322 - val_loss: 0.9792 - val_accuracy: 0.4444 - 1s/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.9459 - accuracy: 0.5291 - val_loss: 0.9696 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.9407 - accuracy: 0.5303 - val_loss: 0.9674 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9341 - accuracy: 0.5285 - val_loss: 0.9671 - val_accuracy: 0.5021 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9428 - accuracy: 0.5334 - val_loss: 0.9715 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9421 - accuracy: 0.5244 - val_loss: 0.9717 - val_accuracy: 0.4805 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.9379 - accuracy: 0.5257 - val_loss: 0.9635 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.9328 - accuracy: 0.5363 - val_loss: 0.9660 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9393 - accuracy: 0.5291 - val_loss: 0.9670 - val_accuracy: 0.4805 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.9267 - accuracy: 0.5417 - val_loss: 0.9641 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.9381 - accuracy: 0.5334 - val_loss: 0.9687 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.9413 - accuracy: 0.5406 - val_loss: 0.9698 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.9387 - accuracy: 0.5417 - val_loss: 0.9722 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.9263 - accuracy: 0.5504 - val_loss: 0.9681 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.9280 - accuracy: 0.5381 - val_loss: 0.9728 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.9414 - accuracy: 0.5211 - val_loss: 0.9605 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.9446 - accuracy: 0.5237 - val_loss: 0.9603 - val_accuracy: 0.5082 - 1s/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.9303 - accuracy: 0.5437 - val_loss: 0.9778 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.9341 - accuracy: 0.5365 - val_loss: 0.9732 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9388 - accuracy: 0.5347 - val_loss: 0.9702 - val_accuracy: 0.4753 - 1s/epoch - 5ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.9297 - accuracy: 0.5358 - val_loss: 0.9682 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.9458 - accuracy: 0.5358 - val_loss: 0.9704 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.9380 - accuracy: 0.5316 - val_loss: 0.9701 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9291 - accuracy: 0.5437 - val_loss: 0.9674 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.9425 - accuracy: 0.5340 - val_loss: 0.9586 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.9414 - accuracy: 0.5298 - val_loss: 0.9669 - val_accuracy: 0.4969 - 1s/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.9389 - accuracy: 0.5378 - val_loss: 0.9580 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9357 - accuracy: 0.5311 - val_loss: 0.9691 - val_accuracy: 0.4846 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.9342 - accuracy: 0.5424 - val_loss: 0.9711 - val_accuracy: 0.4846 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.9343 - accuracy: 0.5327 - val_loss: 0.9591 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.9366 - accuracy: 0.5340 - val_loss: 0.9637 - val_accuracy: 0.4805 - 1s/epoch - 5ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.9426 - accuracy: 0.5352 - val_loss: 0.9755 - val_accuracy: 0.4774 - 1s/epoch - 5ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.9409 - accuracy: 0.5234 - val_loss: 0.9555 - val_accuracy: 0.5010 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.9235 - accuracy: 0.5471 - val_loss: 0.9633 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.9286 - accuracy: 0.5337 - val_loss: 0.9676 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.9306 - accuracy: 0.5525 - val_loss: 0.9665 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.9251 - accuracy: 0.5409 - val_loss: 0.9620 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9358 - accuracy: 0.5334 - val_loss: 0.9615 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.9296 - accuracy: 0.5463 - val_loss: 0.9509 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.9275 - accuracy: 0.5427 - val_loss: 0.9609 - val_accuracy: 0.5123 - 1s/epoch - 5ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.9413 - accuracy: 0.5345 - val_loss: 0.9537 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.9295 - accuracy: 0.5430 - val_loss: 0.9728 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.9352 - accuracy: 0.5455 - val_loss: 0.9688 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.9192 - accuracy: 0.5463 - val_loss: 0.9565 - val_accuracy: 0.5134 - 1s/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.9292 - accuracy: 0.5406 - val_loss: 0.9661 - val_accuracy: 0.5072 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.9254 - accuracy: 0.5499 - val_loss: 0.9602 - val_accuracy: 0.5082 - 1s/epoch - 5ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.9196 - accuracy: 0.5484 - val_loss: 0.9593 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.9249 - accuracy: 0.5453 - val_loss: 0.9591 - val_accuracy: 0.4949 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.9381 - accuracy: 0.5391 - val_loss: 0.9618 - val_accuracy: 0.4969 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5535 - val_loss: 0.9543 - val_accuracy: 0.5113 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.9222 - accuracy: 0.5448 - val_loss: 0.9620 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.9326 - accuracy: 0.5368 - val_loss: 0.9578 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.5484 - val_loss: 0.9624 - val_accuracy: 0.4897 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.9339 - accuracy: 0.5432 - val_loss: 0.9702 - val_accuracy: 0.4938 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9261 - accuracy: 0.5450 - val_loss: 0.9783 - val_accuracy: 0.4774 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5352 - val_loss: 0.9589 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.9377 - accuracy: 0.5347 - val_loss: 0.9626 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.9391 - accuracy: 0.5419 - val_loss: 0.9697 - val_accuracy: 0.5093 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.9181 - accuracy: 0.5471 - val_loss: 0.9746 - val_accuracy: 0.4835 - 1s/epoch - 5ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.9311 - accuracy: 0.5458 - val_loss: 0.9667 - val_accuracy: 0.4959 - 1s/epoch - 5ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.9255 - accuracy: 0.5448 - val_loss: 0.9600 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.9322 - accuracy: 0.5463 - val_loss: 0.9587 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.9234 - accuracy: 0.5445 - val_loss: 0.9558 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.9187 - accuracy: 0.5440 - val_loss: 0.9587 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.9249 - accuracy: 0.5509 - val_loss: 0.9606 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5507 - val_loss: 0.9547 - val_accuracy: 0.5123 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.9315 - accuracy: 0.5471 - val_loss: 0.9671 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.9327 - accuracy: 0.5365 - val_loss: 0.9584 - val_accuracy: 0.5134 - 1s/epoch - 5ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.9147 - accuracy: 0.5563 - val_loss: 0.9737 - val_accuracy: 0.4856 - 1s/epoch - 5ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.9269 - accuracy: 0.5468 - val_loss: 0.9560 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.9300 - accuracy: 0.5363 - val_loss: 0.9543 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.9284 - accuracy: 0.5427 - val_loss: 0.9586 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.9227 - accuracy: 0.5481 - val_loss: 0.9628 - val_accuracy: 0.5000 - 1s/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.9304 - accuracy: 0.5365 - val_loss: 0.9720 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9285 - accuracy: 0.5450 - val_loss: 0.9672 - val_accuracy: 0.4887 - 1s/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9278 - accuracy: 0.5517 - val_loss: 0.9591 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.9297 - accuracy: 0.5471 - val_loss: 0.9706 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.9234 - accuracy: 0.5460 - val_loss: 0.9615 - val_accuracy: 0.4928 - 1s/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.9278 - accuracy: 0.5522 - val_loss: 0.9641 - val_accuracy: 0.4856 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.9336 - accuracy: 0.5430 - val_loss: 0.9596 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.9236 - accuracy: 0.5494 - val_loss: 0.9627 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.9237 - accuracy: 0.5502 - val_loss: 0.9561 - val_accuracy: 0.5051 - 1s/epoch - 5ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.9348 - accuracy: 0.5406 - val_loss: 0.9559 - val_accuracy: 0.4938 - 1s/epoch - 5ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.9263 - accuracy: 0.5386 - val_loss: 0.9622 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5496 - val_loss: 0.9584 - val_accuracy: 0.5144 - 1s/epoch - 5ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.9259 - accuracy: 0.5540 - val_loss: 0.9540 - val_accuracy: 0.5113 - 1s/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.9205 - accuracy: 0.5417 - val_loss: 0.9608 - val_accuracy: 0.4897 - 1s/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.9274 - accuracy: 0.5494 - val_loss: 0.9607 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.9231 - accuracy: 0.5481 - val_loss: 0.9672 - val_accuracy: 0.4949 - 1s/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.9277 - accuracy: 0.5455 - val_loss: 0.9684 - val_accuracy: 0.4877 - 1s/epoch - 5ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.9231 - accuracy: 0.5566 - val_loss: 0.9576 - val_accuracy: 0.5010 - 1s/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.9307 - accuracy: 0.5435 - val_loss: 0.9644 - val_accuracy: 0.5041 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.9305 - accuracy: 0.5358 - val_loss: 0.9574 - val_accuracy: 0.5113 - 1s/epoch - 5ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.9245 - accuracy: 0.5548 - val_loss: 0.9523 - val_accuracy: 0.5113 - 1s/epoch - 5ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.9320 - accuracy: 0.5514 - val_loss: 0.9617 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.9217 - accuracy: 0.5427 - val_loss: 0.9574 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.9278 - accuracy: 0.5424 - val_loss: 0.9543 - val_accuracy: 0.5082 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.9269 - accuracy: 0.5412 - val_loss: 0.9616 - val_accuracy: 0.5123 - 1s/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.9193 - accuracy: 0.5571 - val_loss: 0.9609 - val_accuracy: 0.4825 - 1s/epoch - 5ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.9213 - accuracy: 0.5412 - val_loss: 0.9495 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9197 - accuracy: 0.5535 - val_loss: 0.9549 - val_accuracy: 0.5123 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.9197 - accuracy: 0.5458 - val_loss: 0.9685 - val_accuracy: 0.4866 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.9329 - accuracy: 0.5471 - val_loss: 0.9647 - val_accuracy: 0.4949 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9200 - accuracy: 0.5540 - val_loss: 0.9549 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.9236 - accuracy: 0.5463 - val_loss: 0.9629 - val_accuracy: 0.5031 - 1s/epoch - 5ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.9301 - accuracy: 0.5427 - val_loss: 0.9531 - val_accuracy: 0.5062 - 1s/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.9203 - accuracy: 0.5558 - val_loss: 0.9627 - val_accuracy: 0.4990 - 1s/epoch - 5ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.9261 - accuracy: 0.5543 - val_loss: 0.9700 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.9323 - accuracy: 0.5417 - val_loss: 0.9550 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9232 - accuracy: 0.5514 - val_loss: 0.9612 - val_accuracy: 0.5113 - 1s/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.9236 - accuracy: 0.5432 - val_loss: 0.9618 - val_accuracy: 0.4846 - 1s/epoch - 5ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.9278 - accuracy: 0.5399 - val_loss: 0.9683 - val_accuracy: 0.5041 - 1s/epoch - 5ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9188 - accuracy: 0.5558 - val_loss: 0.9627 - val_accuracy: 0.5010 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "152/152 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PER SUB \n",
    "# SUBJECTS=[1,2,3,4,5,6,7,8,9,11,12,13,14,16,17]\n",
    "# for temp_sub in SUBJECTS:\n",
    "CLASSES= [2,3]\n",
    "#questa va applicata a for loop di subject che deve essere il più esterno \n",
    "sub=\"{:02d}\".format(temp_sub)\n",
    "for n_classes in CLASSES:\n",
    "    #Define loss function\n",
    "    loss_fn= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    LABELS= list(range(0,n_classes))\n",
    "    numero_classi=n_classes\n",
    "\n",
    "    dir0= os.path.join(\"FINAL_motor_imagery_classification/10_sec_windows/raw/\"+str(n_classes)+\"class/output/\", \"all\")\n",
    "    os.mkdir(dir0)\n",
    "    dir_input=(\"FINAL_motor_imagery_classification/10_sec_windows/raw/\"+str(n_classes)+\"class/input\")\n",
    "\n",
    "    evaluation=[]\n",
    "    iteration=[]\n",
    "    confusion_matrix_x_test=[]\n",
    "    confusion_matrix_y_test= []\n",
    "    validation_acc=[]\n",
    "    PERFORMANCE=[]\n",
    "\n",
    "#         print(\"SUBJECT: \"+ str(sub))\n",
    "    print(\"N_CLASSES: \"+ str(n_classes))\n",
    "\n",
    "#         X=sio.loadmat(dir_input+\"/sub_\"+str(sub)+ \"_X.mat\")[\"array_X\"]\n",
    "#         y= sio.loadmat(dir_input+\"/sub_\"+str(sub)+\"_y.mat\")[\"array_y\"]\n",
    "    X=sio.loadmat(dir_input+\"/all_X.mat\")[\"array_X\"]\n",
    "    y= sio.loadmat(dir_input+\"/all_y.mat\")[\"array_y\"]\n",
    "    X= X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    y=y.flatten()\n",
    "    print(\"New shape for X: \" + str(X.shape))\n",
    "    print(\"New shape for y: \"+str(y.shape))\n",
    "\n",
    "    dir1=os.path.join(dir0, \"comparison\")\n",
    "    dir2=os.path.join(dir0, \"temporal_convolution\")\n",
    "    dir3=os.path.join(dir0, \"spatial_convolution\")\n",
    "    os.mkdir(dir1)\n",
    "    os.mkdir(dir2)\n",
    "    os.mkdir(dir3)\n",
    "\n",
    "    ################################################################################################################################################################################################################################################################################\n",
    "\n",
    "    n_folds = 5\n",
    "    seed = 21\n",
    "    shuffle_test = True\n",
    "    EPOCHS=250\n",
    "\n",
    "    kfold = KFold(n_splits = n_folds, shuffle = shuffle_test, random_state = seed)\n",
    "    count=0\n",
    "    sommatoria=0\n",
    "\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        count=count+1\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        print(\"Train index for this split: \"+ str(train_index)) \n",
    "        print(\"Number of samples for train set: \"+str(train_index.shape[0]))\n",
    "        print(\"Test index for this split: \"+ str(test_index))\n",
    "        print(\"Number of samples for test set: \"+str(test_index.shape[0]))\n",
    "\n",
    "        # Define the model architecture - \n",
    "\n",
    "        model=Sequential()\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "        model.add(Conv2D(8, (1, 64), padding = 'same',\n",
    "                                       input_shape = (N_chan, N_samples_long, 1),\n",
    "                                       use_bias = False, name=\"temporal_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_1\"))\n",
    "        model.add(DepthwiseConv2D((31, 1), use_bias = False, \n",
    "                                       depth_multiplier = 2,\n",
    "                                       depthwise_constraint = max_norm(1.), name=\"spatial_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_2\"))\n",
    "        model.add(Activation('elu', name=\"activation_1\"))\n",
    "        model.add(AveragePooling2D((1, 4), name=\"pooling_layer_1\"))\n",
    "        model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "\n",
    "        model.add(SeparableConv2D(16, (1, 16),\n",
    "                                       use_bias = False, padding = 'same', name=\"separable_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_3\"))\n",
    "        model.add(Activation('elu', name=\"activation_2\"))\n",
    "        model.add(AveragePooling2D((1, 8), name=\"pooling_layer_2\"))\n",
    "        model.add(Dropout(0.5, name=\"drpout_2\")) #QUI DROPOUT E' LASCIATO A 0.5 come in eegnet paper\n",
    "\n",
    "        model.add(Flatten(name = 'flatten'))\n",
    "\n",
    "        model.add(Dense(numero_classi, name = 'dense', \n",
    "                                 kernel_constraint = max_norm(0.25)))\n",
    "        model.add(Activation('softmax', name = 'softmax'))\n",
    "\n",
    "\n",
    "        # Define the optimizer\n",
    "        optimizer= optimizers.Adam(\n",
    "        learning_rate= 1e-3,\n",
    "        weight_decay= 0\n",
    "        )\n",
    "        model.compile(optimizer=optimizer,\n",
    "                       loss=loss_fn,\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "        evaluation.append(model.fit(X_train, y_train, batch_size=16,\n",
    "                  epochs=EPOCHS, \n",
    "                  validation_data=(X_test, y_test), \n",
    "                  verbose=2, workers=1)\n",
    "                     )\n",
    "\n",
    "        # Iteration = fold, i am just saving the model for that fold\n",
    "        iteration.append(model)\n",
    "\n",
    "        confusion_matrix_x_test.append(X_test)\n",
    "        confusion_matrix_y_test.append(y_test)\n",
    "\n",
    "        #Plotting confusion matrix\n",
    "        pred=model.predict(X_test)\n",
    "        y_test_pred= np.argmax(pred, axis=1)\n",
    "\n",
    "        confusion_matrix= metrics.confusion_matrix(y_test, y_test_pred, normalize='true')\n",
    "        plt.figure()\n",
    "        metrics.ConfusionMatrixDisplay(confusion_matrix).plot()\n",
    "        plt.savefig(dir1+\"/confusion_matrix_kfold_\"+str(count))\n",
    "        plt.close()\n",
    "\n",
    "        validation_acc.append(np.sum(y_test==y_test_pred)/y_test.shape[0])\n",
    "\n",
    "        PERFORMANCE.append(classification_report(y_test, y_test_pred, labels=LABELS, output_dict=True))\n",
    "\n",
    "        #Salvo risultati di singolo fold\n",
    "        sio.savemat(dir1+\"/y_pred_test_kfold\"+str(count), {\"array\": y_test_pred})\n",
    "        sio.savemat(dir1+\"/y_test_kfold\"+str(count), {\"array\": y_test})\n",
    "\n",
    "\n",
    "        # PLOTTO FILTRI TEMPORALI E SPAZIALI E LI SALVO\n",
    "        var= (model.get_layer(\"temporal_conv\").weights)\n",
    "        for lallo in range(8):\n",
    "            plt.figure()\n",
    "            plt.title(\"temp_conv_\"+str(lallo))\n",
    "            plt.plot(var[0][0,:,0][:,lallo]) #this way i access the temporal filters, cambiando ultimo zero\n",
    "            plt.savefig(dir2+\"/temp_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo))\n",
    "            temp= (var[0][0,:,0][:,lallo]).numpy()\n",
    "            sio.savemat(dir2+\"/temp_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo), {\"array\": temp})\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "        var_2= (model.get_layer(\"spatial_conv\").weights)\n",
    "        reshaped_var_2=tf.reshape(var_2[0][:,0,:,:],(31,16))\n",
    "        for lallo in range(16):\n",
    "            nump= reshaped_var_2[:,lallo].numpy()\n",
    "            sio.savemat(dir3+\"/spat_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo), {\"array\": nump})\n",
    "\n",
    "    ###################################################################################################################\n",
    "\n",
    "    #plot accuracy and loss function across epochs\n",
    "    epoch_vec=np.linspace(1,EPOCHS,EPOCHS)\n",
    "    min_temp_loss=10\n",
    "    min_temp_acc=10\n",
    "    max_temp_loss=0\n",
    "    max_temp_acc=0\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        if (np.min(evaluation[idx].history['loss'])<min_temp_loss):\n",
    "            min_temp_loss=np.min(evaluation[idx].history['loss'])\n",
    "        if (np.min(evaluation[idx].history['val_loss'])<min_temp_loss):\n",
    "            min_temp_loss=np.min(evaluation[idx].history['val_loss'])\n",
    "        if (np.max(evaluation[idx].history['loss'])>max_temp_loss):\n",
    "            max_temp_loss=np.max(evaluation[idx].history['loss'])\n",
    "        if (np.max(evaluation[idx].history['val_loss'])>max_temp_loss):\n",
    "            max_temp_loss=np.max(evaluation[idx].history['val_loss'])\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        if (np.min(evaluation[idx].history['accuracy'])<min_temp_acc):\n",
    "            min_temp_acc=np.min(evaluation[idx].history['accuracy'])\n",
    "        if (np.min(evaluation[idx].history['val_accuracy'])<min_temp_acc):\n",
    "            min_temp_acc=np.min(evaluation[idx].history['val_accuracy'])\n",
    "        if (np.max(evaluation[idx].history['accuracy'])>max_temp_acc):\n",
    "            max_temp_acc=np.max(evaluation[idx].history['accuracy'])\n",
    "        if (np.max(evaluation[idx].history['val_accuracy'])>max_temp_acc):\n",
    "            max_temp_acc=np.max(evaluation[idx].history['val_accuracy'])\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        loss_vec_train= evaluation[idx].history['loss']\n",
    "        loss_vec_test= evaluation[idx].history['val_loss']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epoch_vec,loss_vec_test,'b-', label= 'test');\n",
    "        plt.plot(epoch_vec,loss_vec_train,'r-', label='train');\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss across epochs for fold: '+str(idx))\n",
    "        plt.ylim([min_temp_loss, max_temp_loss])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(dir1+\"/loss_kfold_\"+str(idx))\n",
    "        plt.close()\n",
    "\n",
    "    #plot accuracy and loss function across epochs\n",
    "    epoch_vec=np.linspace(1,EPOCHS,EPOCHS)\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        loss_vec_train= evaluation[idx].history['accuracy']\n",
    "        loss_vec_test= evaluation[idx].history['val_accuracy']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epoch_vec,loss_vec_test,'b-', label= 'test');\n",
    "        plt.plot(epoch_vec,loss_vec_train,'r-', label='train');\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy across epochs for fold: '+str(idx))\n",
    "        plt.ylim([min_temp_acc, max_temp_acc])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(dir1+\"/accuracy_kfold_\"+str(idx))\n",
    "        plt.close()\n",
    "\n",
    "    #SALVO VARIABILI STATISTICHE E MODELLO IN MODO DA PLOTTARLO\n",
    "\n",
    "#         acc_temp=[]\n",
    "    accuratezza=np.zeros(n_classes*2)\n",
    "#         for idx in range(n_folds):\n",
    "#             acc_temp.append(PERFORMANCE[idx][\"accuracy\"])\n",
    "    accuratezza[0]=(np.mean(validation_acc))\n",
    "    accuratezza[1]=(statistics.pstdev(validation_acc))\n",
    "\n",
    "\n",
    "    precisione=[]\n",
    "    recall=[]\n",
    "    f1_score=[]\n",
    "    support=[]\n",
    "    for classe in range(numero_classi):\n",
    "        precision_temp=[]\n",
    "        recall_temp=[]\n",
    "        f1_score_temp=[]\n",
    "        support_temp=[]\n",
    "        for idx in range(n_folds):\n",
    "            precision_temp.append(PERFORMANCE[idx][str(classe)][\"precision\"])\n",
    "            recall_temp.append(PERFORMANCE[idx][str(classe)][\"recall\"])\n",
    "            f1_score_temp.append(PERFORMANCE[idx][str(classe)][\"f1-score\"])\n",
    "            support_temp.append(PERFORMANCE[idx][str(classe)][\"support\"])\n",
    "\n",
    "        precisione.append(np.mean(precision_temp))\n",
    "        precisione.append(statistics.pstdev(precision_temp))\n",
    "        recall.append(np.mean(recall_temp))\n",
    "        recall.append(statistics.pstdev(recall_temp))\n",
    "        f1_score.append(np.mean(f1_score_temp))\n",
    "        f1_score.append(statistics.pstdev(f1_score_temp))    \n",
    "        support.append(np.mean(support_temp))\n",
    "        support.append(statistics.pstdev(support_temp)) \n",
    "\n",
    "    sommario=[]\n",
    "    sommario=np.vstack((accuratezza,precisione,recall,f1_score,support))\n",
    "    sio.savemat(dir0+\"/sommario.mat\", {\"array\": sommario})\n",
    "\n",
    "    gianfranco=model.predict(X)\n",
    "    gianfranco2=np.argmax(gianfranco, axis=1)\n",
    "    sio.savemat(dir0+\"/predizione_totale.mat\", {\"array\": gianfranco2})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb82b1",
   "metadata": {},
   "source": [
    "# POWERBANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bd594f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 17\n",
      "N_CLASSES: 2\n",
      "New shape for X: (6480, 31, 50, 4)\n",
      "New shape for y: (6480,)\n",
      "Train index for this split: [   1    3    5 ... 6476 6477 6479]\n",
      "Number of samples for train set: 5184\n",
      "Test index for this split: [   0    2    4 ... 6472 6474 6478]\n",
      "Number of samples for test set: 1296\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 23:34:13.247744: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_301/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 - 3s - loss: 0.6852 - accuracy: 0.5471 - val_loss: 0.6909 - val_accuracy: 0.5201 - 3s/epoch - 10ms/step\n",
      "Epoch 2/250\n",
      "324/324 - 1s - loss: 0.6609 - accuracy: 0.5982 - val_loss: 0.6887 - val_accuracy: 0.5332 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "324/324 - 1s - loss: 0.6466 - accuracy: 0.6208 - val_loss: 0.7181 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "324/324 - 1s - loss: 0.6235 - accuracy: 0.6426 - val_loss: 0.7148 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "324/324 - 1s - loss: 0.6207 - accuracy: 0.6481 - val_loss: 0.7532 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "324/324 - 1s - loss: 0.6061 - accuracy: 0.6674 - val_loss: 0.7605 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "324/324 - 1s - loss: 0.6017 - accuracy: 0.6651 - val_loss: 0.7717 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "324/324 - 1s - loss: 0.5978 - accuracy: 0.6775 - val_loss: 0.7418 - val_accuracy: 0.4807 - 1s/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "324/324 - 1s - loss: 0.5903 - accuracy: 0.6784 - val_loss: 0.7455 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "324/324 - 1s - loss: 0.5892 - accuracy: 0.6836 - val_loss: 0.6931 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "324/324 - 1s - loss: 0.5807 - accuracy: 0.6811 - val_loss: 0.7581 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "324/324 - 1s - loss: 0.5815 - accuracy: 0.6777 - val_loss: 0.7519 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "324/324 - 1s - loss: 0.5796 - accuracy: 0.6958 - val_loss: 0.7680 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "324/324 - 1s - loss: 0.5833 - accuracy: 0.6881 - val_loss: 0.7150 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "324/324 - 1s - loss: 0.5745 - accuracy: 0.6939 - val_loss: 0.7250 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "324/324 - 1s - loss: 0.5734 - accuracy: 0.6852 - val_loss: 0.7359 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "324/324 - 1s - loss: 0.5640 - accuracy: 0.7062 - val_loss: 0.8298 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "324/324 - 1s - loss: 0.5659 - accuracy: 0.7052 - val_loss: 0.7559 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "324/324 - 1s - loss: 0.5691 - accuracy: 0.7033 - val_loss: 0.7290 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "324/324 - 1s - loss: 0.5575 - accuracy: 0.7097 - val_loss: 0.7572 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "324/324 - 1s - loss: 0.5662 - accuracy: 0.7018 - val_loss: 0.7183 - val_accuracy: 0.4838 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "324/324 - 1s - loss: 0.5557 - accuracy: 0.7064 - val_loss: 0.7458 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "324/324 - 1s - loss: 0.5658 - accuracy: 0.6946 - val_loss: 0.7793 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "324/324 - 1s - loss: 0.5655 - accuracy: 0.6950 - val_loss: 0.7305 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "324/324 - 1s - loss: 0.5622 - accuracy: 0.6935 - val_loss: 0.7018 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "324/324 - 1s - loss: 0.5597 - accuracy: 0.7010 - val_loss: 0.7584 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "324/324 - 1s - loss: 0.5551 - accuracy: 0.7029 - val_loss: 0.6833 - val_accuracy: 0.5239 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "324/324 - 1s - loss: 0.5492 - accuracy: 0.7076 - val_loss: 0.7170 - val_accuracy: 0.4838 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "324/324 - 1s - loss: 0.5555 - accuracy: 0.7068 - val_loss: 0.7859 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "324/324 - 1s - loss: 0.5505 - accuracy: 0.7105 - val_loss: 0.7300 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "324/324 - 1s - loss: 0.5560 - accuracy: 0.7041 - val_loss: 0.7047 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "324/324 - 1s - loss: 0.5526 - accuracy: 0.7081 - val_loss: 0.7290 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "324/324 - 1s - loss: 0.5539 - accuracy: 0.7047 - val_loss: 0.7122 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "324/324 - 1s - loss: 0.5451 - accuracy: 0.7184 - val_loss: 0.6869 - val_accuracy: 0.5247 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "324/324 - 1s - loss: 0.5501 - accuracy: 0.7078 - val_loss: 0.7130 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "324/324 - 1s - loss: 0.5433 - accuracy: 0.7126 - val_loss: 0.7628 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "324/324 - 1s - loss: 0.5448 - accuracy: 0.7101 - val_loss: 0.7626 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "324/324 - 1s - loss: 0.5416 - accuracy: 0.7159 - val_loss: 0.7288 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "324/324 - 1s - loss: 0.5441 - accuracy: 0.7108 - val_loss: 0.7436 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "324/324 - 1s - loss: 0.5415 - accuracy: 0.7164 - val_loss: 0.8588 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "324/324 - 1s - loss: 0.5367 - accuracy: 0.7209 - val_loss: 0.7898 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "324/324 - 1s - loss: 0.5369 - accuracy: 0.7120 - val_loss: 0.8282 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "324/324 - 1s - loss: 0.5371 - accuracy: 0.7174 - val_loss: 0.7377 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "324/324 - 1s - loss: 0.5364 - accuracy: 0.7176 - val_loss: 0.6966 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "324/324 - 1s - loss: 0.5373 - accuracy: 0.7195 - val_loss: 0.7644 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "324/324 - 1s - loss: 0.5320 - accuracy: 0.7220 - val_loss: 0.8017 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "324/324 - 1s - loss: 0.5382 - accuracy: 0.7103 - val_loss: 0.8335 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "324/324 - 1s - loss: 0.5316 - accuracy: 0.7215 - val_loss: 0.7300 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "324/324 - 1s - loss: 0.5287 - accuracy: 0.7272 - val_loss: 0.7247 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "324/324 - 1s - loss: 0.5317 - accuracy: 0.7203 - val_loss: 0.6860 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "324/324 - 1s - loss: 0.5284 - accuracy: 0.7226 - val_loss: 0.7296 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "324/324 - 1s - loss: 0.5326 - accuracy: 0.7247 - val_loss: 0.6880 - val_accuracy: 0.4931 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "324/324 - 1s - loss: 0.5369 - accuracy: 0.7149 - val_loss: 0.7589 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "324/324 - 1s - loss: 0.5342 - accuracy: 0.7188 - val_loss: 0.8851 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "324/324 - 1s - loss: 0.5294 - accuracy: 0.7247 - val_loss: 0.9213 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "324/324 - 1s - loss: 0.5317 - accuracy: 0.7155 - val_loss: 0.7425 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "324/324 - 1s - loss: 0.5342 - accuracy: 0.7207 - val_loss: 0.7946 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "324/324 - 1s - loss: 0.5289 - accuracy: 0.7272 - val_loss: 0.7275 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "324/324 - 1s - loss: 0.5254 - accuracy: 0.7249 - val_loss: 0.7028 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "324/324 - 1s - loss: 0.5299 - accuracy: 0.7215 - val_loss: 0.7750 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "324/324 - 1s - loss: 0.5296 - accuracy: 0.7242 - val_loss: 0.6894 - val_accuracy: 0.4961 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "324/324 - 1s - loss: 0.5353 - accuracy: 0.7197 - val_loss: 0.7374 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "324/324 - 1s - loss: 0.5431 - accuracy: 0.7137 - val_loss: 0.7215 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "324/324 - 1s - loss: 0.5314 - accuracy: 0.7184 - val_loss: 0.8967 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "324/324 - 1s - loss: 0.5279 - accuracy: 0.7296 - val_loss: 0.8221 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "324/324 - 1s - loss: 0.5321 - accuracy: 0.7199 - val_loss: 0.7046 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "324/324 - 1s - loss: 0.5351 - accuracy: 0.7191 - val_loss: 0.7450 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "324/324 - 1s - loss: 0.5287 - accuracy: 0.7267 - val_loss: 0.7383 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "324/324 - 1s - loss: 0.5273 - accuracy: 0.7236 - val_loss: 0.7606 - val_accuracy: 0.4838 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "324/324 - 1s - loss: 0.5395 - accuracy: 0.7079 - val_loss: 0.6814 - val_accuracy: 0.5370 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "324/324 - 1s - loss: 0.5187 - accuracy: 0.7321 - val_loss: 0.6772 - val_accuracy: 0.6890 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "324/324 - 1s - loss: 0.5269 - accuracy: 0.7303 - val_loss: 0.6767 - val_accuracy: 0.6852 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "324/324 - 1s - loss: 0.5278 - accuracy: 0.7257 - val_loss: 0.6881 - val_accuracy: 0.4969 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "324/324 - 1s - loss: 0.5249 - accuracy: 0.7209 - val_loss: 0.7258 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "324/324 - 1s - loss: 0.5307 - accuracy: 0.7294 - val_loss: 0.6850 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "324/324 - 1s - loss: 0.5177 - accuracy: 0.7311 - val_loss: 0.6905 - val_accuracy: 0.4931 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "324/324 - 1s - loss: 0.5218 - accuracy: 0.7242 - val_loss: 0.6951 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "324/324 - 1s - loss: 0.5259 - accuracy: 0.7263 - val_loss: 0.7276 - val_accuracy: 0.4838 - 1s/epoch - 5ms/step\n",
      "Epoch 79/250\n",
      "324/324 - 1s - loss: 0.5279 - accuracy: 0.7216 - val_loss: 0.6933 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "324/324 - 1s - loss: 0.5358 - accuracy: 0.7126 - val_loss: 0.7155 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "324/324 - 1s - loss: 0.5196 - accuracy: 0.7286 - val_loss: 0.7593 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "324/324 - 1s - loss: 0.5285 - accuracy: 0.7182 - val_loss: 0.8944 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "324/324 - 1s - loss: 0.5176 - accuracy: 0.7301 - val_loss: 0.6961 - val_accuracy: 0.4877 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "324/324 - 1s - loss: 0.5282 - accuracy: 0.7272 - val_loss: 0.7483 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "324/324 - 1s - loss: 0.5213 - accuracy: 0.7245 - val_loss: 0.7353 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "324/324 - 1s - loss: 0.5193 - accuracy: 0.7305 - val_loss: 0.7793 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "324/324 - 1s - loss: 0.5221 - accuracy: 0.7238 - val_loss: 0.8284 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "324/324 - 1s - loss: 0.5100 - accuracy: 0.7294 - val_loss: 0.7527 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "324/324 - 1s - loss: 0.5189 - accuracy: 0.7303 - val_loss: 0.7027 - val_accuracy: 0.4884 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "324/324 - 1s - loss: 0.5212 - accuracy: 0.7216 - val_loss: 0.7320 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "324/324 - 1s - loss: 0.5249 - accuracy: 0.7203 - val_loss: 0.7653 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "324/324 - 1s - loss: 0.5163 - accuracy: 0.7359 - val_loss: 0.8607 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "324/324 - 1s - loss: 0.5173 - accuracy: 0.7367 - val_loss: 0.7937 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "324/324 - 1s - loss: 0.5107 - accuracy: 0.7346 - val_loss: 0.8726 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "324/324 - 1s - loss: 0.5219 - accuracy: 0.7259 - val_loss: 0.7152 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "324/324 - 1s - loss: 0.5190 - accuracy: 0.7323 - val_loss: 0.7229 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "324/324 - 1s - loss: 0.5223 - accuracy: 0.7309 - val_loss: 0.6812 - val_accuracy: 0.5617 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "324/324 - 1s - loss: 0.5145 - accuracy: 0.7297 - val_loss: 0.7622 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "324/324 - 1s - loss: 0.5262 - accuracy: 0.7282 - val_loss: 0.7233 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "324/324 - 1s - loss: 0.5211 - accuracy: 0.7326 - val_loss: 0.8124 - val_accuracy: 0.4838 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "324/324 - 1s - loss: 0.5254 - accuracy: 0.7267 - val_loss: 0.8276 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "324/324 - 1s - loss: 0.5169 - accuracy: 0.7294 - val_loss: 0.8884 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "324/324 - 1s - loss: 0.5177 - accuracy: 0.7251 - val_loss: 0.8534 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "324/324 - 1s - loss: 0.5153 - accuracy: 0.7299 - val_loss: 0.9058 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "324/324 - 1s - loss: 0.5206 - accuracy: 0.7278 - val_loss: 0.7455 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "324/324 - 1s - loss: 0.5200 - accuracy: 0.7240 - val_loss: 0.7856 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "324/324 - 1s - loss: 0.5136 - accuracy: 0.7267 - val_loss: 0.9802 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "324/324 - 1s - loss: 0.5127 - accuracy: 0.7292 - val_loss: 0.8589 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "324/324 - 1s - loss: 0.5150 - accuracy: 0.7272 - val_loss: 0.8935 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "324/324 - 1s - loss: 0.5121 - accuracy: 0.7303 - val_loss: 0.7591 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "324/324 - 1s - loss: 0.5108 - accuracy: 0.7390 - val_loss: 1.0025 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "324/324 - 1s - loss: 0.5131 - accuracy: 0.7257 - val_loss: 0.8755 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "324/324 - 1s - loss: 0.5151 - accuracy: 0.7255 - val_loss: 1.1295 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "324/324 - 1s - loss: 0.5189 - accuracy: 0.7201 - val_loss: 0.9954 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "324/324 - 1s - loss: 0.5171 - accuracy: 0.7267 - val_loss: 0.8284 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "324/324 - 1s - loss: 0.5232 - accuracy: 0.7222 - val_loss: 0.6980 - val_accuracy: 0.4884 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "324/324 - 1s - loss: 0.5192 - accuracy: 0.7213 - val_loss: 0.8030 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "324/324 - 1s - loss: 0.5083 - accuracy: 0.7323 - val_loss: 0.8270 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "324/324 - 1s - loss: 0.5069 - accuracy: 0.7313 - val_loss: 0.8760 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "324/324 - 1s - loss: 0.5110 - accuracy: 0.7340 - val_loss: 0.7884 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "324/324 - 1s - loss: 0.5094 - accuracy: 0.7328 - val_loss: 0.8402 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "324/324 - 1s - loss: 0.5093 - accuracy: 0.7323 - val_loss: 0.7789 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "324/324 - 1s - loss: 0.5104 - accuracy: 0.7371 - val_loss: 0.7536 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "324/324 - 1s - loss: 0.5202 - accuracy: 0.7311 - val_loss: 0.7803 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "324/324 - 1s - loss: 0.5083 - accuracy: 0.7413 - val_loss: 0.9628 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "324/324 - 1s - loss: 0.5079 - accuracy: 0.7404 - val_loss: 1.0255 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "324/324 - 1s - loss: 0.5125 - accuracy: 0.7373 - val_loss: 0.7473 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "324/324 - 1s - loss: 0.5129 - accuracy: 0.7307 - val_loss: 0.9793 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "324/324 - 1s - loss: 0.5107 - accuracy: 0.7330 - val_loss: 0.8481 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "324/324 - 1s - loss: 0.5093 - accuracy: 0.7342 - val_loss: 1.2213 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "324/324 - 1s - loss: 0.5119 - accuracy: 0.7334 - val_loss: 0.6909 - val_accuracy: 0.4892 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "324/324 - 1s - loss: 0.5213 - accuracy: 0.7284 - val_loss: 0.8483 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "324/324 - 1s - loss: 0.5106 - accuracy: 0.7294 - val_loss: 0.7601 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "324/324 - 1s - loss: 0.5134 - accuracy: 0.7274 - val_loss: 0.7769 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "324/324 - 1s - loss: 0.5088 - accuracy: 0.7351 - val_loss: 1.0592 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "324/324 - 1s - loss: 0.5190 - accuracy: 0.7315 - val_loss: 0.8056 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "324/324 - 1s - loss: 0.5094 - accuracy: 0.7309 - val_loss: 1.1294 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "324/324 - 1s - loss: 0.5138 - accuracy: 0.7224 - val_loss: 0.9006 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "324/324 - 1s - loss: 0.5138 - accuracy: 0.7359 - val_loss: 1.1739 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "324/324 - 1s - loss: 0.5125 - accuracy: 0.7218 - val_loss: 0.8405 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "324/324 - 1s - loss: 0.5119 - accuracy: 0.7286 - val_loss: 0.8326 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "324/324 - 1s - loss: 0.5117 - accuracy: 0.7321 - val_loss: 0.8709 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "324/324 - 1s - loss: 0.5059 - accuracy: 0.7317 - val_loss: 0.7029 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "324/324 - 1s - loss: 0.5122 - accuracy: 0.7319 - val_loss: 0.7625 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "324/324 - 1s - loss: 0.5091 - accuracy: 0.7311 - val_loss: 1.0340 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "324/324 - 1s - loss: 0.5181 - accuracy: 0.7303 - val_loss: 0.6947 - val_accuracy: 0.4846 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "324/324 - 1s - loss: 0.5034 - accuracy: 0.7427 - val_loss: 0.8361 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "324/324 - 1s - loss: 0.4999 - accuracy: 0.7377 - val_loss: 0.7871 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "324/324 - 1s - loss: 0.5132 - accuracy: 0.7261 - val_loss: 0.8716 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "324/324 - 1s - loss: 0.5149 - accuracy: 0.7311 - val_loss: 1.1931 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "324/324 - 1s - loss: 0.5129 - accuracy: 0.7274 - val_loss: 1.1990 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "324/324 - 1s - loss: 0.5051 - accuracy: 0.7353 - val_loss: 0.9106 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "324/324 - 1s - loss: 0.5038 - accuracy: 0.7303 - val_loss: 0.8226 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "324/324 - 1s - loss: 0.5106 - accuracy: 0.7267 - val_loss: 0.8626 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "324/324 - 1s - loss: 0.5100 - accuracy: 0.7330 - val_loss: 0.9861 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "324/324 - 1s - loss: 0.5062 - accuracy: 0.7380 - val_loss: 0.7337 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "324/324 - 1s - loss: 0.5057 - accuracy: 0.7359 - val_loss: 0.7347 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "324/324 - 1s - loss: 0.4989 - accuracy: 0.7313 - val_loss: 0.9873 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "324/324 - 1s - loss: 0.5118 - accuracy: 0.7323 - val_loss: 0.8901 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "324/324 - 1s - loss: 0.5103 - accuracy: 0.7311 - val_loss: 0.8171 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "324/324 - 1s - loss: 0.5171 - accuracy: 0.7311 - val_loss: 0.9312 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "324/324 - 1s - loss: 0.5043 - accuracy: 0.7377 - val_loss: 1.0056 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "324/324 - 1s - loss: 0.5078 - accuracy: 0.7371 - val_loss: 1.0806 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "324/324 - 1s - loss: 0.5044 - accuracy: 0.7400 - val_loss: 0.8826 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "324/324 - 1s - loss: 0.5061 - accuracy: 0.7367 - val_loss: 0.7484 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "324/324 - 1s - loss: 0.5031 - accuracy: 0.7415 - val_loss: 0.8442 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "324/324 - 1s - loss: 0.5080 - accuracy: 0.7355 - val_loss: 0.8048 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "324/324 - 1s - loss: 0.5078 - accuracy: 0.7324 - val_loss: 0.6869 - val_accuracy: 0.5826 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "324/324 - 1s - loss: 0.5005 - accuracy: 0.7317 - val_loss: 0.8257 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "324/324 - 1s - loss: 0.5057 - accuracy: 0.7303 - val_loss: 0.8741 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "324/324 - 1s - loss: 0.5127 - accuracy: 0.7326 - val_loss: 0.9156 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "324/324 - 1s - loss: 0.5103 - accuracy: 0.7296 - val_loss: 1.0196 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "324/324 - 1s - loss: 0.5083 - accuracy: 0.7259 - val_loss: 1.1141 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "324/324 - 1s - loss: 0.4936 - accuracy: 0.7434 - val_loss: 1.0100 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "324/324 - 1s - loss: 0.5069 - accuracy: 0.7404 - val_loss: 0.7506 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "324/324 - 1s - loss: 0.5053 - accuracy: 0.7342 - val_loss: 0.7733 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "324/324 - 1s - loss: 0.5054 - accuracy: 0.7336 - val_loss: 0.7541 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "324/324 - 1s - loss: 0.5046 - accuracy: 0.7369 - val_loss: 0.6869 - val_accuracy: 0.4977 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "324/324 - 1s - loss: 0.5050 - accuracy: 0.7400 - val_loss: 0.6941 - val_accuracy: 0.4923 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "324/324 - 1s - loss: 0.5025 - accuracy: 0.7386 - val_loss: 0.7811 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "324/324 - 1s - loss: 0.4973 - accuracy: 0.7446 - val_loss: 0.6878 - val_accuracy: 0.4992 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "324/324 - 1s - loss: 0.4971 - accuracy: 0.7423 - val_loss: 0.8970 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "324/324 - 1s - loss: 0.5090 - accuracy: 0.7388 - val_loss: 0.7277 - val_accuracy: 0.4846 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "324/324 - 1s - loss: 0.5096 - accuracy: 0.7270 - val_loss: 1.1937 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "324/324 - 1s - loss: 0.5154 - accuracy: 0.7269 - val_loss: 1.0052 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "324/324 - 1s - loss: 0.5107 - accuracy: 0.7359 - val_loss: 1.2480 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "324/324 - 1s - loss: 0.5249 - accuracy: 0.7276 - val_loss: 0.6932 - val_accuracy: 0.4853 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "324/324 - 1s - loss: 0.5063 - accuracy: 0.7328 - val_loss: 0.7031 - val_accuracy: 0.4853 - 1s/epoch - 5ms/step\n",
      "Epoch 189/250\n",
      "324/324 - 1s - loss: 0.5113 - accuracy: 0.7307 - val_loss: 0.8349 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "324/324 - 1s - loss: 0.5029 - accuracy: 0.7417 - val_loss: 1.3113 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "324/324 - 1s - loss: 0.5036 - accuracy: 0.7351 - val_loss: 0.6750 - val_accuracy: 0.6968 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "324/324 - 1s - loss: 0.5041 - accuracy: 0.7332 - val_loss: 0.8947 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "324/324 - 1s - loss: 0.4966 - accuracy: 0.7404 - val_loss: 0.9984 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "324/324 - 1s - loss: 0.4996 - accuracy: 0.7380 - val_loss: 0.7154 - val_accuracy: 0.5208 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "324/324 - 1s - loss: 0.5017 - accuracy: 0.7444 - val_loss: 1.3391 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "324/324 - 1s - loss: 0.4989 - accuracy: 0.7371 - val_loss: 0.6851 - val_accuracy: 0.5725 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "324/324 - 1s - loss: 0.5039 - accuracy: 0.7415 - val_loss: 0.8331 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "324/324 - 1s - loss: 0.5029 - accuracy: 0.7355 - val_loss: 0.8171 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "324/324 - 1s - loss: 0.5037 - accuracy: 0.7340 - val_loss: 0.8481 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "324/324 - 1s - loss: 0.5055 - accuracy: 0.7380 - val_loss: 0.7662 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "324/324 - 1s - loss: 0.5028 - accuracy: 0.7419 - val_loss: 0.6915 - val_accuracy: 0.4861 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "324/324 - 1s - loss: 0.5027 - accuracy: 0.7363 - val_loss: 0.6870 - val_accuracy: 0.4961 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "324/324 - 1s - loss: 0.5029 - accuracy: 0.7427 - val_loss: 0.8018 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "324/324 - 1s - loss: 0.5048 - accuracy: 0.7294 - val_loss: 0.6858 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "324/324 - 1s - loss: 0.5038 - accuracy: 0.7334 - val_loss: 0.7791 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "324/324 - 1s - loss: 0.5036 - accuracy: 0.7378 - val_loss: 0.6839 - val_accuracy: 0.5208 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "324/324 - 1s - loss: 0.5036 - accuracy: 0.7417 - val_loss: 0.8983 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "324/324 - 1s - loss: 0.5005 - accuracy: 0.7413 - val_loss: 0.9134 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "324/324 - 1s - loss: 0.4987 - accuracy: 0.7432 - val_loss: 0.8250 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "324/324 - 1s - loss: 0.5110 - accuracy: 0.7367 - val_loss: 0.7990 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "324/324 - 1s - loss: 0.5065 - accuracy: 0.7311 - val_loss: 0.9394 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "324/324 - 1s - loss: 0.5104 - accuracy: 0.7317 - val_loss: 0.8508 - val_accuracy: 0.4838 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "324/324 - 1s - loss: 0.5072 - accuracy: 0.7402 - val_loss: 0.7656 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "324/324 - 1s - loss: 0.4986 - accuracy: 0.7367 - val_loss: 0.7742 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "324/324 - 1s - loss: 0.4973 - accuracy: 0.7425 - val_loss: 0.9218 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "324/324 - 1s - loss: 0.5007 - accuracy: 0.7417 - val_loss: 0.8449 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "324/324 - 1s - loss: 0.4961 - accuracy: 0.7373 - val_loss: 0.7492 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "324/324 - 1s - loss: 0.5092 - accuracy: 0.7388 - val_loss: 0.7052 - val_accuracy: 0.4961 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "324/324 - 1s - loss: 0.5053 - accuracy: 0.7415 - val_loss: 0.6840 - val_accuracy: 0.5417 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "324/324 - 1s - loss: 0.5055 - accuracy: 0.7402 - val_loss: 0.8293 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "324/324 - 1s - loss: 0.5005 - accuracy: 0.7342 - val_loss: 0.6844 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "324/324 - 1s - loss: 0.4953 - accuracy: 0.7469 - val_loss: 1.0116 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "324/324 - 1s - loss: 0.4984 - accuracy: 0.7454 - val_loss: 0.7144 - val_accuracy: 0.4846 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "324/324 - 1s - loss: 0.5007 - accuracy: 0.7432 - val_loss: 0.8391 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "324/324 - 1s - loss: 0.5106 - accuracy: 0.7373 - val_loss: 0.8754 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "324/324 - 1s - loss: 0.5009 - accuracy: 0.7388 - val_loss: 1.2053 - val_accuracy: 0.4799 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "324/324 - 1s - loss: 0.4993 - accuracy: 0.7434 - val_loss: 0.9660 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "324/324 - 1s - loss: 0.5012 - accuracy: 0.7369 - val_loss: 0.8578 - val_accuracy: 0.4838 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "324/324 - 1s - loss: 0.4951 - accuracy: 0.7467 - val_loss: 0.9019 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "324/324 - 1s - loss: 0.4974 - accuracy: 0.7380 - val_loss: 0.9166 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "324/324 - 1s - loss: 0.4969 - accuracy: 0.7446 - val_loss: 1.1187 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "324/324 - 1s - loss: 0.5016 - accuracy: 0.7373 - val_loss: 0.7263 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "324/324 - 1s - loss: 0.4989 - accuracy: 0.7450 - val_loss: 1.1322 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "324/324 - 1s - loss: 0.4978 - accuracy: 0.7467 - val_loss: 0.7638 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "324/324 - 1s - loss: 0.5019 - accuracy: 0.7384 - val_loss: 0.6804 - val_accuracy: 0.5548 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "324/324 - 1s - loss: 0.5099 - accuracy: 0.7361 - val_loss: 0.8065 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "324/324 - 1s - loss: 0.5057 - accuracy: 0.7413 - val_loss: 0.8002 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "324/324 - 1s - loss: 0.5053 - accuracy: 0.7355 - val_loss: 0.7336 - val_accuracy: 0.4830 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "324/324 - 1s - loss: 0.5058 - accuracy: 0.7384 - val_loss: 0.7644 - val_accuracy: 0.5216 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "324/324 - 1s - loss: 0.5060 - accuracy: 0.7411 - val_loss: 0.7257 - val_accuracy: 0.5216 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "324/324 - 1s - loss: 0.4964 - accuracy: 0.7452 - val_loss: 0.6901 - val_accuracy: 0.4884 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "324/324 - 1s - loss: 0.4975 - accuracy: 0.7377 - val_loss: 0.7207 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "324/324 - 1s - loss: 0.5020 - accuracy: 0.7377 - val_loss: 0.7485 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "324/324 - 1s - loss: 0.4989 - accuracy: 0.7398 - val_loss: 0.8777 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "324/324 - 1s - loss: 0.4976 - accuracy: 0.7446 - val_loss: 1.3246 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "324/324 - 1s - loss: 0.5041 - accuracy: 0.7411 - val_loss: 0.8112 - val_accuracy: 0.4823 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "324/324 - 1s - loss: 0.5073 - accuracy: 0.7396 - val_loss: 0.7082 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "324/324 - 1s - loss: 0.4974 - accuracy: 0.7446 - val_loss: 0.9135 - val_accuracy: 0.4807 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "324/324 - 1s - loss: 0.5010 - accuracy: 0.7402 - val_loss: 0.6840 - val_accuracy: 0.5239 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "324/324 - 1s - loss: 0.4965 - accuracy: 0.7402 - val_loss: 0.7900 - val_accuracy: 0.4815 - 1s/epoch - 4ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    2    3 ... 6477 6478 6479]\n",
      "Number of samples for train set: 5184\n",
      "Test index for this split: [   1   11   12 ... 6455 6461 6466]\n",
      "Number of samples for test set: 1296\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 23:40:08.025067: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_302/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 - 3s - loss: 0.6901 - accuracy: 0.5467 - val_loss: 0.6958 - val_accuracy: 0.4730 - 3s/epoch - 9ms/step\n",
      "Epoch 2/250\n",
      "324/324 - 1s - loss: 0.6622 - accuracy: 0.6053 - val_loss: 0.6916 - val_accuracy: 0.5556 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "324/324 - 1s - loss: 0.6361 - accuracy: 0.6387 - val_loss: 0.6970 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "324/324 - 1s - loss: 0.6218 - accuracy: 0.6595 - val_loss: 0.7330 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "324/324 - 1s - loss: 0.6195 - accuracy: 0.6522 - val_loss: 0.8708 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "324/324 - 1s - loss: 0.6118 - accuracy: 0.6617 - val_loss: 0.7894 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "324/324 - 1s - loss: 0.6067 - accuracy: 0.6645 - val_loss: 0.9355 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "324/324 - 1s - loss: 0.6006 - accuracy: 0.6728 - val_loss: 0.7529 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "324/324 - 1s - loss: 0.5923 - accuracy: 0.6757 - val_loss: 0.7659 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "324/324 - 1s - loss: 0.5870 - accuracy: 0.6883 - val_loss: 0.7081 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "324/324 - 1s - loss: 0.5836 - accuracy: 0.6846 - val_loss: 0.7004 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "324/324 - 1s - loss: 0.5823 - accuracy: 0.6885 - val_loss: 0.6935 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "324/324 - 1s - loss: 0.5862 - accuracy: 0.6916 - val_loss: 0.7647 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "324/324 - 1s - loss: 0.5778 - accuracy: 0.6933 - val_loss: 0.7125 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "324/324 - 1s - loss: 0.5761 - accuracy: 0.6960 - val_loss: 0.7148 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "324/324 - 1s - loss: 0.5762 - accuracy: 0.6950 - val_loss: 0.8321 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "324/324 - 1s - loss: 0.5754 - accuracy: 0.6956 - val_loss: 0.7553 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "324/324 - 1s - loss: 0.5711 - accuracy: 0.6979 - val_loss: 0.8030 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "324/324 - 1s - loss: 0.5625 - accuracy: 0.7033 - val_loss: 0.8122 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "324/324 - 1s - loss: 0.5672 - accuracy: 0.7016 - val_loss: 0.7307 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "324/324 - 1s - loss: 0.5654 - accuracy: 0.7000 - val_loss: 0.7830 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "324/324 - 1s - loss: 0.5649 - accuracy: 0.6973 - val_loss: 0.6926 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "324/324 - 1s - loss: 0.5661 - accuracy: 0.6960 - val_loss: 0.7929 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "324/324 - 1s - loss: 0.5613 - accuracy: 0.7070 - val_loss: 0.8142 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "324/324 - 1s - loss: 0.5537 - accuracy: 0.7132 - val_loss: 0.8206 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "324/324 - 1s - loss: 0.5555 - accuracy: 0.7103 - val_loss: 0.7837 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "324/324 - 1s - loss: 0.5546 - accuracy: 0.7031 - val_loss: 0.7561 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "324/324 - 1s - loss: 0.5552 - accuracy: 0.7126 - val_loss: 0.8275 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "324/324 - 1s - loss: 0.5580 - accuracy: 0.7074 - val_loss: 0.7489 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "324/324 - 1s - loss: 0.5556 - accuracy: 0.7093 - val_loss: 0.8096 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "324/324 - 1s - loss: 0.5590 - accuracy: 0.7043 - val_loss: 0.9051 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "324/324 - 1s - loss: 0.5572 - accuracy: 0.7103 - val_loss: 0.7977 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "324/324 - 1s - loss: 0.5509 - accuracy: 0.7135 - val_loss: 0.8618 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "324/324 - 1s - loss: 0.5481 - accuracy: 0.7174 - val_loss: 0.9759 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "324/324 - 1s - loss: 0.5476 - accuracy: 0.7145 - val_loss: 0.9171 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "324/324 - 1s - loss: 0.5533 - accuracy: 0.7149 - val_loss: 0.9078 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "324/324 - 1s - loss: 0.5469 - accuracy: 0.7220 - val_loss: 1.0056 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "324/324 - 1s - loss: 0.5542 - accuracy: 0.7097 - val_loss: 1.0460 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "324/324 - 1s - loss: 0.5458 - accuracy: 0.7141 - val_loss: 1.1818 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "324/324 - 1s - loss: 0.5390 - accuracy: 0.7197 - val_loss: 0.9478 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "324/324 - 1s - loss: 0.5445 - accuracy: 0.7205 - val_loss: 0.9387 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "324/324 - 1s - loss: 0.5387 - accuracy: 0.7220 - val_loss: 0.9250 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "324/324 - 1s - loss: 0.5408 - accuracy: 0.7164 - val_loss: 0.9591 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "324/324 - 1s - loss: 0.5356 - accuracy: 0.7220 - val_loss: 0.8758 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "324/324 - 1s - loss: 0.5354 - accuracy: 0.7243 - val_loss: 0.8770 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "324/324 - 1s - loss: 0.5363 - accuracy: 0.7197 - val_loss: 0.9269 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "324/324 - 1s - loss: 0.5453 - accuracy: 0.7160 - val_loss: 1.0646 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "324/324 - 1s - loss: 0.5419 - accuracy: 0.7230 - val_loss: 0.9874 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "324/324 - 1s - loss: 0.5343 - accuracy: 0.7245 - val_loss: 1.2135 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "324/324 - 1s - loss: 0.5391 - accuracy: 0.7188 - val_loss: 1.2121 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "324/324 - 1s - loss: 0.5356 - accuracy: 0.7292 - val_loss: 0.7607 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "324/324 - 1s - loss: 0.5465 - accuracy: 0.7124 - val_loss: 0.9566 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "324/324 - 1s - loss: 0.5355 - accuracy: 0.7162 - val_loss: 0.9861 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "324/324 - 1s - loss: 0.5374 - accuracy: 0.7172 - val_loss: 1.2056 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "324/324 - 1s - loss: 0.5319 - accuracy: 0.7276 - val_loss: 1.0573 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "324/324 - 1s - loss: 0.5332 - accuracy: 0.7323 - val_loss: 0.9678 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "324/324 - 1s - loss: 0.5342 - accuracy: 0.7236 - val_loss: 0.9980 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "324/324 - 1s - loss: 0.5390 - accuracy: 0.7172 - val_loss: 0.8388 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "324/324 - 1s - loss: 0.5385 - accuracy: 0.7288 - val_loss: 1.1519 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "324/324 - 1s - loss: 0.5364 - accuracy: 0.7255 - val_loss: 1.1693 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "324/324 - 1s - loss: 0.5379 - accuracy: 0.7247 - val_loss: 1.2331 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "324/324 - 1s - loss: 0.5355 - accuracy: 0.7193 - val_loss: 1.2247 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "324/324 - 1s - loss: 0.5337 - accuracy: 0.7265 - val_loss: 1.0034 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "324/324 - 1s - loss: 0.5221 - accuracy: 0.7242 - val_loss: 1.2958 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "324/324 - 1s - loss: 0.5285 - accuracy: 0.7321 - val_loss: 1.5412 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "324/324 - 1s - loss: 0.5337 - accuracy: 0.7220 - val_loss: 1.3589 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "324/324 - 1s - loss: 0.5332 - accuracy: 0.7199 - val_loss: 1.3062 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "324/324 - 1s - loss: 0.5325 - accuracy: 0.7263 - val_loss: 1.1104 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "324/324 - 1s - loss: 0.5300 - accuracy: 0.7278 - val_loss: 1.0885 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "324/324 - 1s - loss: 0.5291 - accuracy: 0.7249 - val_loss: 1.1378 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "324/324 - 1s - loss: 0.5341 - accuracy: 0.7247 - val_loss: 1.1125 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "324/324 - 1s - loss: 0.5251 - accuracy: 0.7309 - val_loss: 1.1039 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "324/324 - 1s - loss: 0.5197 - accuracy: 0.7297 - val_loss: 1.0566 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "324/324 - 1s - loss: 0.5291 - accuracy: 0.7245 - val_loss: 1.2805 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "324/324 - 1s - loss: 0.5232 - accuracy: 0.7351 - val_loss: 1.1643 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "324/324 - 1s - loss: 0.5237 - accuracy: 0.7334 - val_loss: 1.5577 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "324/324 - 1s - loss: 0.5245 - accuracy: 0.7280 - val_loss: 1.6155 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "324/324 - 1s - loss: 0.5305 - accuracy: 0.7270 - val_loss: 1.4428 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "324/324 - 1s - loss: 0.5168 - accuracy: 0.7350 - val_loss: 1.4100 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "324/324 - 1s - loss: 0.5258 - accuracy: 0.7267 - val_loss: 1.3912 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "324/324 - 1s - loss: 0.5229 - accuracy: 0.7257 - val_loss: 1.4049 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "324/324 - 1s - loss: 0.5259 - accuracy: 0.7315 - val_loss: 1.1494 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "324/324 - 1s - loss: 0.5291 - accuracy: 0.7284 - val_loss: 1.0326 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "324/324 - 1s - loss: 0.5273 - accuracy: 0.7259 - val_loss: 1.2777 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "324/324 - 1s - loss: 0.5217 - accuracy: 0.7328 - val_loss: 1.3056 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "324/324 - 1s - loss: 0.5141 - accuracy: 0.7396 - val_loss: 1.5251 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "324/324 - 1s - loss: 0.5221 - accuracy: 0.7336 - val_loss: 1.2368 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "324/324 - 1s - loss: 0.5165 - accuracy: 0.7367 - val_loss: 1.4331 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "324/324 - 1s - loss: 0.5325 - accuracy: 0.7278 - val_loss: 1.0620 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "324/324 - 1s - loss: 0.5220 - accuracy: 0.7351 - val_loss: 1.4303 - val_accuracy: 0.5293 - 1s/epoch - 5ms/step\n",
      "Epoch 91/250\n",
      "324/324 - 1s - loss: 0.5226 - accuracy: 0.7332 - val_loss: 1.0374 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "324/324 - 1s - loss: 0.5187 - accuracy: 0.7384 - val_loss: 0.9512 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "324/324 - 1s - loss: 0.5217 - accuracy: 0.7323 - val_loss: 1.1649 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "324/324 - 1s - loss: 0.5192 - accuracy: 0.7294 - val_loss: 1.3142 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "324/324 - 1s - loss: 0.5157 - accuracy: 0.7326 - val_loss: 1.2664 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "324/324 - 1s - loss: 0.5238 - accuracy: 0.7382 - val_loss: 1.2474 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "324/324 - 1s - loss: 0.5201 - accuracy: 0.7369 - val_loss: 1.3914 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "324/324 - 1s - loss: 0.5217 - accuracy: 0.7355 - val_loss: 1.2157 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "324/324 - 1s - loss: 0.5204 - accuracy: 0.7407 - val_loss: 1.4414 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "324/324 - 1s - loss: 0.5112 - accuracy: 0.7432 - val_loss: 1.0982 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "324/324 - 1s - loss: 0.5201 - accuracy: 0.7315 - val_loss: 1.6036 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "324/324 - 1s - loss: 0.5225 - accuracy: 0.7270 - val_loss: 1.3255 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "324/324 - 1s - loss: 0.5261 - accuracy: 0.7276 - val_loss: 1.3599 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "324/324 - 1s - loss: 0.5175 - accuracy: 0.7390 - val_loss: 1.4337 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "324/324 - 1s - loss: 0.5178 - accuracy: 0.7396 - val_loss: 1.2543 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "324/324 - 1s - loss: 0.5147 - accuracy: 0.7485 - val_loss: 1.2300 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "324/324 - 1s - loss: 0.5182 - accuracy: 0.7280 - val_loss: 1.1606 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "324/324 - 1s - loss: 0.5157 - accuracy: 0.7346 - val_loss: 1.3164 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "324/324 - 1s - loss: 0.5121 - accuracy: 0.7377 - val_loss: 1.4755 - val_accuracy: 0.5293 - 1s/epoch - 5ms/step\n",
      "Epoch 110/250\n",
      "324/324 - 1s - loss: 0.5190 - accuracy: 0.7375 - val_loss: 1.2929 - val_accuracy: 0.5309 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "324/324 - 1s - loss: 0.5141 - accuracy: 0.7350 - val_loss: 1.2093 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "324/324 - 1s - loss: 0.5151 - accuracy: 0.7375 - val_loss: 1.2200 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "324/324 - 1s - loss: 0.5188 - accuracy: 0.7419 - val_loss: 1.2247 - val_accuracy: 0.5301 - 1s/epoch - 5ms/step\n",
      "Epoch 114/250\n",
      "324/324 - 1s - loss: 0.5159 - accuracy: 0.7396 - val_loss: 1.3464 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "324/324 - 1s - loss: 0.5177 - accuracy: 0.7317 - val_loss: 1.2184 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "324/324 - 1s - loss: 0.5103 - accuracy: 0.7465 - val_loss: 1.3354 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "324/324 - 1s - loss: 0.5082 - accuracy: 0.7369 - val_loss: 1.4711 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "324/324 - 1s - loss: 0.5124 - accuracy: 0.7440 - val_loss: 1.2468 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "324/324 - 1s - loss: 0.5196 - accuracy: 0.7390 - val_loss: 1.3830 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "324/324 - 1s - loss: 0.5187 - accuracy: 0.7261 - val_loss: 1.0718 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "324/324 - 1s - loss: 0.5150 - accuracy: 0.7344 - val_loss: 1.1214 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "324/324 - 1s - loss: 0.5135 - accuracy: 0.7413 - val_loss: 1.5046 - val_accuracy: 0.5293 - 1s/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "324/324 - 1s - loss: 0.5072 - accuracy: 0.7471 - val_loss: 1.3200 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "324/324 - 1s - loss: 0.5093 - accuracy: 0.7459 - val_loss: 1.1099 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "324/324 - 1s - loss: 0.5138 - accuracy: 0.7336 - val_loss: 1.1681 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "324/324 - 1s - loss: 0.5258 - accuracy: 0.7286 - val_loss: 1.2166 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "324/324 - 1s - loss: 0.5133 - accuracy: 0.7311 - val_loss: 1.3199 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "324/324 - 1s - loss: 0.5095 - accuracy: 0.7396 - val_loss: 1.1934 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "324/324 - 1s - loss: 0.5217 - accuracy: 0.7357 - val_loss: 1.0923 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "324/324 - 1s - loss: 0.5065 - accuracy: 0.7431 - val_loss: 1.5425 - val_accuracy: 0.5309 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "324/324 - 1s - loss: 0.5104 - accuracy: 0.7452 - val_loss: 1.4219 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "324/324 - 1s - loss: 0.5078 - accuracy: 0.7346 - val_loss: 1.5276 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "324/324 - 1s - loss: 0.5108 - accuracy: 0.7394 - val_loss: 1.5532 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "324/324 - 1s - loss: 0.5091 - accuracy: 0.7382 - val_loss: 1.4128 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "324/324 - 1s - loss: 0.5111 - accuracy: 0.7419 - val_loss: 1.2997 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "324/324 - 1s - loss: 0.5121 - accuracy: 0.7359 - val_loss: 1.3611 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "324/324 - 1s - loss: 0.5198 - accuracy: 0.7330 - val_loss: 1.2525 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "324/324 - 1s - loss: 0.5070 - accuracy: 0.7407 - val_loss: 1.2691 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "324/324 - 1s - loss: 0.5118 - accuracy: 0.7319 - val_loss: 1.3817 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "324/324 - 1s - loss: 0.5168 - accuracy: 0.7353 - val_loss: 1.3179 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "324/324 - 1s - loss: 0.5085 - accuracy: 0.7434 - val_loss: 1.3788 - val_accuracy: 0.5301 - 1s/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "324/324 - 1s - loss: 0.5071 - accuracy: 0.7378 - val_loss: 1.3890 - val_accuracy: 0.5293 - 1s/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "324/324 - 1s - loss: 0.5162 - accuracy: 0.7404 - val_loss: 1.4649 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "324/324 - 1s - loss: 0.5097 - accuracy: 0.7392 - val_loss: 1.5595 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "324/324 - 1s - loss: 0.5076 - accuracy: 0.7461 - val_loss: 1.7420 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "324/324 - 1s - loss: 0.5120 - accuracy: 0.7417 - val_loss: 1.8067 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "324/324 - 1s - loss: 0.5091 - accuracy: 0.7434 - val_loss: 1.6834 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "324/324 - 1s - loss: 0.5070 - accuracy: 0.7434 - val_loss: 1.5901 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "324/324 - 1s - loss: 0.5108 - accuracy: 0.7380 - val_loss: 1.3884 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "324/324 - 1s - loss: 0.5187 - accuracy: 0.7348 - val_loss: 1.5390 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "324/324 - 1s - loss: 0.5069 - accuracy: 0.7388 - val_loss: 1.5299 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "324/324 - 1s - loss: 0.5071 - accuracy: 0.7419 - val_loss: 1.1251 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "324/324 - 1s - loss: 0.5087 - accuracy: 0.7323 - val_loss: 0.9771 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "324/324 - 1s - loss: 0.5083 - accuracy: 0.7398 - val_loss: 1.0430 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "324/324 - 1s - loss: 0.5135 - accuracy: 0.7359 - val_loss: 0.9294 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "324/324 - 1s - loss: 0.5096 - accuracy: 0.7355 - val_loss: 1.1313 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "324/324 - 1s - loss: 0.5110 - accuracy: 0.7363 - val_loss: 1.0010 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "324/324 - 1s - loss: 0.5170 - accuracy: 0.7350 - val_loss: 1.1032 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "324/324 - 1s - loss: 0.5109 - accuracy: 0.7419 - val_loss: 1.2750 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "324/324 - 1s - loss: 0.5050 - accuracy: 0.7425 - val_loss: 1.4547 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "324/324 - 1s - loss: 0.4970 - accuracy: 0.7494 - val_loss: 1.4638 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "324/324 - 1s - loss: 0.4993 - accuracy: 0.7442 - val_loss: 1.7844 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "324/324 - 1s - loss: 0.4988 - accuracy: 0.7454 - val_loss: 1.4624 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "324/324 - 1s - loss: 0.5096 - accuracy: 0.7394 - val_loss: 1.0286 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "324/324 - 1s - loss: 0.5119 - accuracy: 0.7363 - val_loss: 1.3421 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "324/324 - 1s - loss: 0.5193 - accuracy: 0.7369 - val_loss: 1.2156 - val_accuracy: 0.5301 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "324/324 - 1s - loss: 0.5087 - accuracy: 0.7380 - val_loss: 1.3670 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "324/324 - 1s - loss: 0.5061 - accuracy: 0.7421 - val_loss: 0.9181 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "324/324 - 1s - loss: 0.4999 - accuracy: 0.7427 - val_loss: 0.9815 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "324/324 - 1s - loss: 0.4946 - accuracy: 0.7463 - val_loss: 1.2073 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "324/324 - 1s - loss: 0.5081 - accuracy: 0.7398 - val_loss: 0.8308 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "324/324 - 1s - loss: 0.5128 - accuracy: 0.7390 - val_loss: 1.1661 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "324/324 - 1s - loss: 0.5015 - accuracy: 0.7440 - val_loss: 1.4707 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "324/324 - 1s - loss: 0.5124 - accuracy: 0.7375 - val_loss: 1.2932 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "324/324 - 1s - loss: 0.5008 - accuracy: 0.7402 - val_loss: 1.1908 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "324/324 - 1s - loss: 0.5088 - accuracy: 0.7388 - val_loss: 1.2857 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "324/324 - 1s - loss: 0.5066 - accuracy: 0.7413 - val_loss: 1.1575 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "324/324 - 1s - loss: 0.5004 - accuracy: 0.7407 - val_loss: 1.4532 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "324/324 - 1s - loss: 0.5129 - accuracy: 0.7388 - val_loss: 1.3900 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "324/324 - 1s - loss: 0.5035 - accuracy: 0.7425 - val_loss: 1.2255 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "324/324 - 1s - loss: 0.5085 - accuracy: 0.7377 - val_loss: 1.1953 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "324/324 - 1s - loss: 0.5090 - accuracy: 0.7425 - val_loss: 1.1862 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "324/324 - 1s - loss: 0.5109 - accuracy: 0.7330 - val_loss: 1.1765 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "324/324 - 1s - loss: 0.4937 - accuracy: 0.7504 - val_loss: 1.2117 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "324/324 - 1s - loss: 0.5097 - accuracy: 0.7380 - val_loss: 1.0186 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "324/324 - 1s - loss: 0.5074 - accuracy: 0.7384 - val_loss: 1.1263 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "324/324 - 1s - loss: 0.4979 - accuracy: 0.7486 - val_loss: 1.6412 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "324/324 - 1s - loss: 0.5038 - accuracy: 0.7452 - val_loss: 1.4835 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "324/324 - 1s - loss: 0.5111 - accuracy: 0.7452 - val_loss: 1.2360 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "324/324 - 1s - loss: 0.4903 - accuracy: 0.7496 - val_loss: 1.1972 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "324/324 - 1s - loss: 0.4990 - accuracy: 0.7481 - val_loss: 1.1077 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "324/324 - 1s - loss: 0.5087 - accuracy: 0.7326 - val_loss: 0.9859 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "324/324 - 1s - loss: 0.4995 - accuracy: 0.7369 - val_loss: 0.9376 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "324/324 - 1s - loss: 0.5026 - accuracy: 0.7438 - val_loss: 1.2297 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "324/324 - 1s - loss: 0.4993 - accuracy: 0.7436 - val_loss: 0.9894 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "324/324 - 1s - loss: 0.4990 - accuracy: 0.7398 - val_loss: 1.3024 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "324/324 - 1s - loss: 0.5126 - accuracy: 0.7378 - val_loss: 0.8266 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "324/324 - 1s - loss: 0.5060 - accuracy: 0.7357 - val_loss: 0.8204 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "324/324 - 1s - loss: 0.5012 - accuracy: 0.7419 - val_loss: 1.1055 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "324/324 - 1s - loss: 0.5015 - accuracy: 0.7461 - val_loss: 1.0357 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "324/324 - 1s - loss: 0.5097 - accuracy: 0.7421 - val_loss: 1.0067 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "324/324 - 1s - loss: 0.5008 - accuracy: 0.7469 - val_loss: 0.9632 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "324/324 - 1s - loss: 0.5015 - accuracy: 0.7444 - val_loss: 1.0424 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "324/324 - 1s - loss: 0.4982 - accuracy: 0.7425 - val_loss: 0.9575 - val_accuracy: 0.5270 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "324/324 - 1s - loss: 0.5012 - accuracy: 0.7396 - val_loss: 1.1634 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "324/324 - 1s - loss: 0.5073 - accuracy: 0.7438 - val_loss: 0.8773 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "324/324 - 1s - loss: 0.5017 - accuracy: 0.7404 - val_loss: 1.1428 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "324/324 - 1s - loss: 0.4971 - accuracy: 0.7473 - val_loss: 1.0210 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "324/324 - 1s - loss: 0.4964 - accuracy: 0.7425 - val_loss: 1.0316 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "324/324 - 1s - loss: 0.4989 - accuracy: 0.7434 - val_loss: 1.1514 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "324/324 - 1s - loss: 0.4946 - accuracy: 0.7486 - val_loss: 1.2961 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "324/324 - 1s - loss: 0.5050 - accuracy: 0.7452 - val_loss: 0.7738 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "324/324 - 1s - loss: 0.5092 - accuracy: 0.7386 - val_loss: 1.1897 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "324/324 - 1s - loss: 0.5020 - accuracy: 0.7434 - val_loss: 1.2694 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "324/324 - 1s - loss: 0.4911 - accuracy: 0.7469 - val_loss: 1.7007 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "324/324 - 1s - loss: 0.4975 - accuracy: 0.7496 - val_loss: 1.1413 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "324/324 - 1s - loss: 0.5054 - accuracy: 0.7446 - val_loss: 1.2114 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "324/324 - 1s - loss: 0.5034 - accuracy: 0.7440 - val_loss: 0.8416 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "324/324 - 1s - loss: 0.5067 - accuracy: 0.7425 - val_loss: 1.1518 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "324/324 - 1s - loss: 0.5120 - accuracy: 0.7299 - val_loss: 0.9901 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "324/324 - 1s - loss: 0.5042 - accuracy: 0.7400 - val_loss: 1.0359 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "324/324 - 1s - loss: 0.4993 - accuracy: 0.7434 - val_loss: 1.0579 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "324/324 - 1s - loss: 0.4957 - accuracy: 0.7442 - val_loss: 1.1378 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "324/324 - 1s - loss: 0.5009 - accuracy: 0.7450 - val_loss: 1.2064 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "324/324 - 1s - loss: 0.4981 - accuracy: 0.7400 - val_loss: 1.4088 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "324/324 - 1s - loss: 0.4954 - accuracy: 0.7465 - val_loss: 1.2540 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "324/324 - 1s - loss: 0.5008 - accuracy: 0.7500 - val_loss: 1.1361 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "324/324 - 1s - loss: 0.5079 - accuracy: 0.7432 - val_loss: 0.8952 - val_accuracy: 0.5278 - 1s/epoch - 5ms/step\n",
      "Epoch 229/250\n",
      "324/324 - 1s - loss: 0.5022 - accuracy: 0.7394 - val_loss: 1.3215 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "324/324 - 1s - loss: 0.4937 - accuracy: 0.7436 - val_loss: 1.0567 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "324/324 - 1s - loss: 0.5004 - accuracy: 0.7483 - val_loss: 0.8977 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "324/324 - 1s - loss: 0.5035 - accuracy: 0.7386 - val_loss: 0.9726 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "324/324 - 1s - loss: 0.4943 - accuracy: 0.7481 - val_loss: 0.8742 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "324/324 - 1s - loss: 0.5023 - accuracy: 0.7450 - val_loss: 0.9334 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "324/324 - 1s - loss: 0.4977 - accuracy: 0.7459 - val_loss: 1.0788 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "324/324 - 1s - loss: 0.5017 - accuracy: 0.7407 - val_loss: 0.9740 - val_accuracy: 0.5270 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "324/324 - 1s - loss: 0.4950 - accuracy: 0.7486 - val_loss: 1.1635 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "324/324 - 1s - loss: 0.5041 - accuracy: 0.7490 - val_loss: 0.8572 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "324/324 - 1s - loss: 0.5075 - accuracy: 0.7388 - val_loss: 1.2811 - val_accuracy: 0.5278 - 1s/epoch - 5ms/step\n",
      "Epoch 240/250\n",
      "324/324 - 1s - loss: 0.5072 - accuracy: 0.7394 - val_loss: 1.0972 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "324/324 - 1s - loss: 0.4955 - accuracy: 0.7477 - val_loss: 1.2395 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "324/324 - 1s - loss: 0.4924 - accuracy: 0.7465 - val_loss: 1.2612 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "324/324 - 1s - loss: 0.4995 - accuracy: 0.7465 - val_loss: 1.2763 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "324/324 - 1s - loss: 0.5021 - accuracy: 0.7498 - val_loss: 1.3388 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "324/324 - 1s - loss: 0.4981 - accuracy: 0.7479 - val_loss: 0.7597 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "324/324 - 1s - loss: 0.4959 - accuracy: 0.7446 - val_loss: 0.9122 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "324/324 - 1s - loss: 0.5031 - accuracy: 0.7450 - val_loss: 1.0373 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "324/324 - 1s - loss: 0.4940 - accuracy: 0.7500 - val_loss: 1.2816 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "324/324 - 1s - loss: 0.4989 - accuracy: 0.7467 - val_loss: 1.1205 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "324/324 - 1s - loss: 0.4965 - accuracy: 0.7488 - val_loss: 1.3059 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 6476 6478 6479]\n",
      "Number of samples for train set: 5184\n",
      "Test index for this split: [   3    7   10 ... 6473 6475 6477]\n",
      "Number of samples for test set: 1296\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 23:46:06.063299: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_303/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 - 3s - loss: 0.6825 - accuracy: 0.5617 - val_loss: 0.6921 - val_accuracy: 0.4923 - 3s/epoch - 10ms/step\n",
      "Epoch 2/250\n",
      "324/324 - 1s - loss: 0.6606 - accuracy: 0.6049 - val_loss: 0.7092 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "324/324 - 1s - loss: 0.6443 - accuracy: 0.6196 - val_loss: 0.7902 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "324/324 - 1s - loss: 0.6288 - accuracy: 0.6445 - val_loss: 0.9510 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "324/324 - 1s - loss: 0.6199 - accuracy: 0.6518 - val_loss: 0.9600 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "324/324 - 1s - loss: 0.6144 - accuracy: 0.6545 - val_loss: 0.8736 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "324/324 - 1s - loss: 0.6075 - accuracy: 0.6647 - val_loss: 0.7833 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "324/324 - 1s - loss: 0.6023 - accuracy: 0.6734 - val_loss: 0.7607 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "324/324 - 1s - loss: 0.5950 - accuracy: 0.6765 - val_loss: 0.7390 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "324/324 - 1s - loss: 0.5916 - accuracy: 0.6823 - val_loss: 0.7716 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "324/324 - 1s - loss: 0.5909 - accuracy: 0.6796 - val_loss: 0.8904 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "324/324 - 1s - loss: 0.5814 - accuracy: 0.6852 - val_loss: 0.8679 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "324/324 - 1s - loss: 0.5828 - accuracy: 0.6811 - val_loss: 0.8962 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "324/324 - 1s - loss: 0.5824 - accuracy: 0.6900 - val_loss: 0.8913 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "324/324 - 1s - loss: 0.5776 - accuracy: 0.6985 - val_loss: 0.9085 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "324/324 - 1s - loss: 0.5801 - accuracy: 0.6898 - val_loss: 0.9496 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "324/324 - 1s - loss: 0.5760 - accuracy: 0.6914 - val_loss: 0.9219 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "324/324 - 1s - loss: 0.5687 - accuracy: 0.6937 - val_loss: 0.9589 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "324/324 - 1s - loss: 0.5751 - accuracy: 0.6875 - val_loss: 1.0312 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "324/324 - 1s - loss: 0.5750 - accuracy: 0.6869 - val_loss: 0.9926 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "324/324 - 1s - loss: 0.5718 - accuracy: 0.7002 - val_loss: 0.8976 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "324/324 - 1s - loss: 0.5631 - accuracy: 0.7002 - val_loss: 0.9966 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "324/324 - 1s - loss: 0.5668 - accuracy: 0.7047 - val_loss: 1.0107 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "324/324 - 1s - loss: 0.5659 - accuracy: 0.7031 - val_loss: 0.9761 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "324/324 - 1s - loss: 0.5631 - accuracy: 0.6923 - val_loss: 1.0179 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "324/324 - 1s - loss: 0.5604 - accuracy: 0.7058 - val_loss: 0.9902 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "324/324 - 1s - loss: 0.5646 - accuracy: 0.6983 - val_loss: 0.9975 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "324/324 - 1s - loss: 0.5571 - accuracy: 0.7114 - val_loss: 0.9345 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "324/324 - 1s - loss: 0.5625 - accuracy: 0.7008 - val_loss: 1.0756 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "324/324 - 1s - loss: 0.5647 - accuracy: 0.7031 - val_loss: 1.0438 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "324/324 - 1s - loss: 0.5524 - accuracy: 0.7132 - val_loss: 1.0932 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "324/324 - 1s - loss: 0.5527 - accuracy: 0.7122 - val_loss: 0.9903 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "324/324 - 1s - loss: 0.5569 - accuracy: 0.7099 - val_loss: 0.9608 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "324/324 - 1s - loss: 0.5567 - accuracy: 0.7074 - val_loss: 0.9761 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "324/324 - 1s - loss: 0.5529 - accuracy: 0.7184 - val_loss: 0.9436 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "324/324 - 1s - loss: 0.5565 - accuracy: 0.7072 - val_loss: 0.9015 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "324/324 - 1s - loss: 0.5565 - accuracy: 0.7068 - val_loss: 1.0464 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "324/324 - 1s - loss: 0.5554 - accuracy: 0.7120 - val_loss: 1.0556 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "324/324 - 1s - loss: 0.5511 - accuracy: 0.7056 - val_loss: 1.1236 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "324/324 - 1s - loss: 0.5473 - accuracy: 0.7078 - val_loss: 0.9881 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "324/324 - 1s - loss: 0.5483 - accuracy: 0.7083 - val_loss: 0.9907 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "324/324 - 1s - loss: 0.5493 - accuracy: 0.7078 - val_loss: 0.8837 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "324/324 - 1s - loss: 0.5427 - accuracy: 0.7207 - val_loss: 0.8788 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "324/324 - 1s - loss: 0.5482 - accuracy: 0.7097 - val_loss: 0.8995 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "324/324 - 1s - loss: 0.5400 - accuracy: 0.7099 - val_loss: 0.9356 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "324/324 - 1s - loss: 0.5494 - accuracy: 0.7110 - val_loss: 0.9847 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "324/324 - 1s - loss: 0.5437 - accuracy: 0.7151 - val_loss: 1.0556 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "324/324 - 1s - loss: 0.5457 - accuracy: 0.7159 - val_loss: 1.1078 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "324/324 - 1s - loss: 0.5400 - accuracy: 0.7174 - val_loss: 1.0904 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "324/324 - 1s - loss: 0.5474 - accuracy: 0.7128 - val_loss: 0.9629 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "324/324 - 1s - loss: 0.5486 - accuracy: 0.7166 - val_loss: 0.9284 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "324/324 - 1s - loss: 0.5459 - accuracy: 0.7124 - val_loss: 1.0348 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "324/324 - 1s - loss: 0.5438 - accuracy: 0.7114 - val_loss: 1.0135 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "324/324 - 1s - loss: 0.5473 - accuracy: 0.7106 - val_loss: 0.9924 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "324/324 - 1s - loss: 0.5406 - accuracy: 0.7130 - val_loss: 0.9711 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "324/324 - 1s - loss: 0.5322 - accuracy: 0.7288 - val_loss: 0.8723 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "324/324 - 1s - loss: 0.5440 - accuracy: 0.7201 - val_loss: 0.8720 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "324/324 - 1s - loss: 0.5361 - accuracy: 0.7193 - val_loss: 0.8708 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "324/324 - 1s - loss: 0.5354 - accuracy: 0.7188 - val_loss: 0.8791 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "324/324 - 1s - loss: 0.5368 - accuracy: 0.7203 - val_loss: 0.7970 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "324/324 - 1s - loss: 0.5371 - accuracy: 0.7188 - val_loss: 0.8779 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "324/324 - 1s - loss: 0.5325 - accuracy: 0.7257 - val_loss: 0.9027 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "324/324 - 1s - loss: 0.5375 - accuracy: 0.7213 - val_loss: 0.9215 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "324/324 - 1s - loss: 0.5321 - accuracy: 0.7251 - val_loss: 0.9966 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "324/324 - 1s - loss: 0.5458 - accuracy: 0.7139 - val_loss: 1.0569 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "324/324 - 1s - loss: 0.5353 - accuracy: 0.7238 - val_loss: 1.3327 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "324/324 - 1s - loss: 0.5303 - accuracy: 0.7278 - val_loss: 1.0958 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "324/324 - 1s - loss: 0.5336 - accuracy: 0.7220 - val_loss: 0.9835 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "324/324 - 1s - loss: 0.5411 - accuracy: 0.7120 - val_loss: 0.8832 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "324/324 - 1s - loss: 0.5279 - accuracy: 0.7269 - val_loss: 1.0881 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "324/324 - 1s - loss: 0.5342 - accuracy: 0.7274 - val_loss: 1.1637 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "324/324 - 1s - loss: 0.5247 - accuracy: 0.7238 - val_loss: 0.9358 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "324/324 - 1s - loss: 0.5308 - accuracy: 0.7222 - val_loss: 1.0058 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "324/324 - 1s - loss: 0.5395 - accuracy: 0.7170 - val_loss: 0.9549 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "324/324 - 1s - loss: 0.5259 - accuracy: 0.7257 - val_loss: 1.1374 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "324/324 - 1s - loss: 0.5372 - accuracy: 0.7222 - val_loss: 0.8785 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "324/324 - 1s - loss: 0.5318 - accuracy: 0.7203 - val_loss: 1.0897 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "324/324 - 1s - loss: 0.5316 - accuracy: 0.7263 - val_loss: 0.9295 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "324/324 - 1s - loss: 0.5245 - accuracy: 0.7222 - val_loss: 0.8416 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "324/324 - 1s - loss: 0.5289 - accuracy: 0.7207 - val_loss: 1.1315 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "324/324 - 1s - loss: 0.5262 - accuracy: 0.7205 - val_loss: 1.0775 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "324/324 - 1s - loss: 0.5326 - accuracy: 0.7257 - val_loss: 0.9736 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "324/324 - 1s - loss: 0.5307 - accuracy: 0.7261 - val_loss: 1.0821 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "324/324 - 1s - loss: 0.5343 - accuracy: 0.7369 - val_loss: 1.0457 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "324/324 - 1s - loss: 0.5307 - accuracy: 0.7243 - val_loss: 0.9058 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "324/324 - 1s - loss: 0.5214 - accuracy: 0.7369 - val_loss: 0.8288 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "324/324 - 1s - loss: 0.5261 - accuracy: 0.7261 - val_loss: 0.9535 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "324/324 - 1s - loss: 0.5281 - accuracy: 0.7307 - val_loss: 0.9890 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "324/324 - 1s - loss: 0.5216 - accuracy: 0.7286 - val_loss: 1.0740 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "324/324 - 1s - loss: 0.5297 - accuracy: 0.7228 - val_loss: 1.0902 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "324/324 - 1s - loss: 0.5268 - accuracy: 0.7267 - val_loss: 1.2058 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "324/324 - 1s - loss: 0.5328 - accuracy: 0.7228 - val_loss: 1.0716 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "324/324 - 1s - loss: 0.5236 - accuracy: 0.7296 - val_loss: 1.2650 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "324/324 - 1s - loss: 0.5294 - accuracy: 0.7274 - val_loss: 1.1284 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "324/324 - 1s - loss: 0.5296 - accuracy: 0.7251 - val_loss: 1.2428 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "324/324 - 1s - loss: 0.5230 - accuracy: 0.7321 - val_loss: 1.0576 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "324/324 - 1s - loss: 0.5280 - accuracy: 0.7282 - val_loss: 1.0686 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "324/324 - 1s - loss: 0.5195 - accuracy: 0.7319 - val_loss: 1.3363 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "324/324 - 1s - loss: 0.5301 - accuracy: 0.7170 - val_loss: 1.0263 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "324/324 - 1s - loss: 0.5222 - accuracy: 0.7336 - val_loss: 1.0989 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "324/324 - 1s - loss: 0.5230 - accuracy: 0.7355 - val_loss: 1.0281 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "324/324 - 1s - loss: 0.5180 - accuracy: 0.7328 - val_loss: 1.0491 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "324/324 - 1s - loss: 0.5215 - accuracy: 0.7280 - val_loss: 1.2118 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "324/324 - 1s - loss: 0.5188 - accuracy: 0.7363 - val_loss: 0.9987 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "324/324 - 1s - loss: 0.5253 - accuracy: 0.7278 - val_loss: 1.1028 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "324/324 - 1s - loss: 0.5178 - accuracy: 0.7357 - val_loss: 1.0498 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "324/324 - 1s - loss: 0.5204 - accuracy: 0.7359 - val_loss: 1.1194 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "324/324 - 1s - loss: 0.5223 - accuracy: 0.7296 - val_loss: 1.0266 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "324/324 - 1s - loss: 0.5276 - accuracy: 0.7228 - val_loss: 1.0617 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "324/324 - 1s - loss: 0.5220 - accuracy: 0.7324 - val_loss: 0.9908 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "324/324 - 1s - loss: 0.5248 - accuracy: 0.7243 - val_loss: 0.8786 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "324/324 - 1s - loss: 0.5294 - accuracy: 0.7226 - val_loss: 0.8858 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "324/324 - 1s - loss: 0.5445 - accuracy: 0.7089 - val_loss: 0.9992 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "324/324 - 1s - loss: 0.5283 - accuracy: 0.7309 - val_loss: 0.8660 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "324/324 - 1s - loss: 0.5277 - accuracy: 0.7288 - val_loss: 1.0635 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "324/324 - 1s - loss: 0.5199 - accuracy: 0.7305 - val_loss: 0.8682 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "324/324 - 1s - loss: 0.5214 - accuracy: 0.7338 - val_loss: 1.0910 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "324/324 - 1s - loss: 0.5136 - accuracy: 0.7332 - val_loss: 0.9525 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "324/324 - 1s - loss: 0.5229 - accuracy: 0.7251 - val_loss: 0.9585 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "324/324 - 1s - loss: 0.5229 - accuracy: 0.7278 - val_loss: 1.0187 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "324/324 - 1s - loss: 0.5227 - accuracy: 0.7324 - val_loss: 0.8055 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "324/324 - 1s - loss: 0.5168 - accuracy: 0.7390 - val_loss: 0.7924 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "324/324 - 1s - loss: 0.5128 - accuracy: 0.7346 - val_loss: 0.7263 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "324/324 - 1s - loss: 0.5296 - accuracy: 0.7272 - val_loss: 0.9603 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "324/324 - 1s - loss: 0.5177 - accuracy: 0.7367 - val_loss: 0.7945 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "324/324 - 1s - loss: 0.5154 - accuracy: 0.7346 - val_loss: 0.8955 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "324/324 - 1s - loss: 0.5150 - accuracy: 0.7386 - val_loss: 1.0087 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "324/324 - 1s - loss: 0.5221 - accuracy: 0.7292 - val_loss: 0.8478 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "324/324 - 1s - loss: 0.5158 - accuracy: 0.7346 - val_loss: 1.0521 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "324/324 - 1s - loss: 0.5160 - accuracy: 0.7330 - val_loss: 0.8548 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "324/324 - 1s - loss: 0.5164 - accuracy: 0.7288 - val_loss: 1.2018 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "324/324 - 1s - loss: 0.5151 - accuracy: 0.7234 - val_loss: 1.1466 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "324/324 - 1s - loss: 0.5102 - accuracy: 0.7357 - val_loss: 1.2549 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "324/324 - 1s - loss: 0.5220 - accuracy: 0.7367 - val_loss: 1.0774 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "324/324 - 1s - loss: 0.5159 - accuracy: 0.7257 - val_loss: 0.9511 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "324/324 - 1s - loss: 0.5171 - accuracy: 0.7330 - val_loss: 0.9993 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "324/324 - 1s - loss: 0.5235 - accuracy: 0.7269 - val_loss: 0.9917 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "324/324 - 1s - loss: 0.5291 - accuracy: 0.7280 - val_loss: 1.1650 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "324/324 - 1s - loss: 0.5178 - accuracy: 0.7380 - val_loss: 0.8947 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "324/324 - 1s - loss: 0.5150 - accuracy: 0.7373 - val_loss: 0.8679 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "324/324 - 1s - loss: 0.5225 - accuracy: 0.7351 - val_loss: 0.7540 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "324/324 - 1s - loss: 0.5200 - accuracy: 0.7288 - val_loss: 0.9138 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "324/324 - 1s - loss: 0.5117 - accuracy: 0.7386 - val_loss: 1.2916 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "324/324 - 1s - loss: 0.5190 - accuracy: 0.7290 - val_loss: 1.1595 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "324/324 - 1s - loss: 0.5084 - accuracy: 0.7367 - val_loss: 1.1596 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "324/324 - 1s - loss: 0.5093 - accuracy: 0.7431 - val_loss: 1.1514 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "324/324 - 1s - loss: 0.5148 - accuracy: 0.7309 - val_loss: 0.8213 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "324/324 - 1s - loss: 0.5134 - accuracy: 0.7350 - val_loss: 0.9949 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "324/324 - 1s - loss: 0.5072 - accuracy: 0.7392 - val_loss: 0.8445 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "324/324 - 1s - loss: 0.5106 - accuracy: 0.7355 - val_loss: 0.8252 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "324/324 - 1s - loss: 0.5247 - accuracy: 0.7288 - val_loss: 0.9125 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "324/324 - 1s - loss: 0.5143 - accuracy: 0.7390 - val_loss: 0.8483 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "324/324 - 1s - loss: 0.5065 - accuracy: 0.7417 - val_loss: 1.0007 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "324/324 - 1s - loss: 0.5102 - accuracy: 0.7423 - val_loss: 0.9532 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "324/324 - 1s - loss: 0.5156 - accuracy: 0.7363 - val_loss: 0.9970 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "324/324 - 1s - loss: 0.5089 - accuracy: 0.7409 - val_loss: 0.9838 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "324/324 - 1s - loss: 0.5106 - accuracy: 0.7390 - val_loss: 1.1184 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "324/324 - 1s - loss: 0.5159 - accuracy: 0.7321 - val_loss: 1.1608 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "324/324 - 1s - loss: 0.5144 - accuracy: 0.7396 - val_loss: 0.9520 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "324/324 - 1s - loss: 0.5136 - accuracy: 0.7340 - val_loss: 1.0077 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "324/324 - 1s - loss: 0.5167 - accuracy: 0.7350 - val_loss: 1.0701 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "324/324 - 1s - loss: 0.5134 - accuracy: 0.7323 - val_loss: 1.0513 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "324/324 - 1s - loss: 0.5073 - accuracy: 0.7421 - val_loss: 0.9744 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "324/324 - 1s - loss: 0.5048 - accuracy: 0.7450 - val_loss: 1.3215 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "324/324 - 1s - loss: 0.5210 - accuracy: 0.7290 - val_loss: 1.2581 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "324/324 - 1s - loss: 0.5076 - accuracy: 0.7486 - val_loss: 1.1472 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "324/324 - 1s - loss: 0.5149 - accuracy: 0.7350 - val_loss: 0.9380 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "324/324 - 1s - loss: 0.5180 - accuracy: 0.7361 - val_loss: 1.0850 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "324/324 - 1s - loss: 0.5113 - accuracy: 0.7357 - val_loss: 0.9734 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "324/324 - 1s - loss: 0.5165 - accuracy: 0.7348 - val_loss: 1.2562 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "324/324 - 1s - loss: 0.5046 - accuracy: 0.7398 - val_loss: 1.0267 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "324/324 - 1s - loss: 0.5108 - accuracy: 0.7350 - val_loss: 0.9935 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "324/324 - 1s - loss: 0.5097 - accuracy: 0.7363 - val_loss: 0.9929 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "324/324 - 1s - loss: 0.5113 - accuracy: 0.7326 - val_loss: 0.8746 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "324/324 - 1s - loss: 0.5066 - accuracy: 0.7402 - val_loss: 0.8309 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "324/324 - 1s - loss: 0.5155 - accuracy: 0.7359 - val_loss: 0.8204 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "324/324 - 1s - loss: 0.5096 - accuracy: 0.7458 - val_loss: 0.9553 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "324/324 - 1s - loss: 0.4960 - accuracy: 0.7448 - val_loss: 0.8501 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "324/324 - 1s - loss: 0.5070 - accuracy: 0.7357 - val_loss: 1.0037 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "324/324 - 1s - loss: 0.5075 - accuracy: 0.7375 - val_loss: 0.9394 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "324/324 - 1s - loss: 0.5047 - accuracy: 0.7382 - val_loss: 1.0122 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "324/324 - 1s - loss: 0.5076 - accuracy: 0.7342 - val_loss: 1.3234 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "324/324 - 1s - loss: 0.5103 - accuracy: 0.7421 - val_loss: 1.0962 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "324/324 - 1s - loss: 0.5042 - accuracy: 0.7371 - val_loss: 1.2968 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "324/324 - 1s - loss: 0.5045 - accuracy: 0.7444 - val_loss: 0.9884 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "324/324 - 1s - loss: 0.5132 - accuracy: 0.7371 - val_loss: 0.9142 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "324/324 - 1s - loss: 0.5123 - accuracy: 0.7409 - val_loss: 0.9974 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "324/324 - 1s - loss: 0.5145 - accuracy: 0.7369 - val_loss: 0.8938 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "324/324 - 1s - loss: 0.5027 - accuracy: 0.7398 - val_loss: 0.9000 - val_accuracy: 0.4923 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "324/324 - 1s - loss: 0.5066 - accuracy: 0.7413 - val_loss: 1.0025 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "324/324 - 1s - loss: 0.5105 - accuracy: 0.7392 - val_loss: 1.1744 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "324/324 - 1s - loss: 0.5075 - accuracy: 0.7394 - val_loss: 1.3830 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "324/324 - 1s - loss: 0.5062 - accuracy: 0.7467 - val_loss: 1.0118 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "324/324 - 1s - loss: 0.4966 - accuracy: 0.7421 - val_loss: 0.9479 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "324/324 - 1s - loss: 0.5008 - accuracy: 0.7396 - val_loss: 1.0431 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "324/324 - 1s - loss: 0.5085 - accuracy: 0.7367 - val_loss: 1.1072 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "324/324 - 1s - loss: 0.5155 - accuracy: 0.7353 - val_loss: 0.9154 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "324/324 - 1s - loss: 0.5124 - accuracy: 0.7371 - val_loss: 0.9585 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "324/324 - 1s - loss: 0.5117 - accuracy: 0.7324 - val_loss: 0.7843 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "324/324 - 1s - loss: 0.4996 - accuracy: 0.7556 - val_loss: 1.0312 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "324/324 - 1s - loss: 0.5058 - accuracy: 0.7436 - val_loss: 1.0278 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "324/324 - 1s - loss: 0.5129 - accuracy: 0.7307 - val_loss: 0.9271 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "324/324 - 1s - loss: 0.5186 - accuracy: 0.7313 - val_loss: 0.9438 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "324/324 - 1s - loss: 0.5135 - accuracy: 0.7348 - val_loss: 1.0760 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "324/324 - 1s - loss: 0.5065 - accuracy: 0.7377 - val_loss: 1.0606 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "324/324 - 1s - loss: 0.5061 - accuracy: 0.7369 - val_loss: 1.0344 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "324/324 - 1s - loss: 0.5014 - accuracy: 0.7344 - val_loss: 1.3090 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "324/324 - 1s - loss: 0.5033 - accuracy: 0.7429 - val_loss: 1.1828 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "324/324 - 1s - loss: 0.5007 - accuracy: 0.7477 - val_loss: 1.1039 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "324/324 - 1s - loss: 0.5074 - accuracy: 0.7419 - val_loss: 1.1998 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "324/324 - 1s - loss: 0.5097 - accuracy: 0.7336 - val_loss: 1.3822 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "324/324 - 1s - loss: 0.5020 - accuracy: 0.7388 - val_loss: 1.3426 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "324/324 - 1s - loss: 0.4990 - accuracy: 0.7490 - val_loss: 1.4278 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "324/324 - 1s - loss: 0.5116 - accuracy: 0.7386 - val_loss: 1.4850 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "324/324 - 1s - loss: 0.5075 - accuracy: 0.7351 - val_loss: 1.8162 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "324/324 - 1s - loss: 0.5008 - accuracy: 0.7517 - val_loss: 1.6359 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "324/324 - 1s - loss: 0.5044 - accuracy: 0.7425 - val_loss: 1.3660 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "324/324 - 1s - loss: 0.4996 - accuracy: 0.7477 - val_loss: 1.3482 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "324/324 - 1s - loss: 0.5118 - accuracy: 0.7438 - val_loss: 1.3791 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "324/324 - 1s - loss: 0.5048 - accuracy: 0.7371 - val_loss: 1.4473 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "324/324 - 1s - loss: 0.4966 - accuracy: 0.7458 - val_loss: 1.3280 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "324/324 - 1s - loss: 0.5027 - accuracy: 0.7396 - val_loss: 1.1269 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "324/324 - 1s - loss: 0.4985 - accuracy: 0.7432 - val_loss: 1.2562 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "324/324 - 1s - loss: 0.4977 - accuracy: 0.7446 - val_loss: 1.3399 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "324/324 - 1s - loss: 0.4948 - accuracy: 0.7471 - val_loss: 1.1328 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "324/324 - 1s - loss: 0.4951 - accuracy: 0.7517 - val_loss: 1.3116 - val_accuracy: 0.4915 - 1s/epoch - 5ms/step\n",
      "Epoch 227/250\n",
      "324/324 - 1s - loss: 0.5021 - accuracy: 0.7413 - val_loss: 1.0271 - val_accuracy: 0.4923 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "324/324 - 1s - loss: 0.5121 - accuracy: 0.7319 - val_loss: 1.4606 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "324/324 - 1s - loss: 0.5049 - accuracy: 0.7371 - val_loss: 1.4144 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "324/324 - 1s - loss: 0.5046 - accuracy: 0.7375 - val_loss: 1.5444 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "324/324 - 1s - loss: 0.5010 - accuracy: 0.7373 - val_loss: 1.7780 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "324/324 - 1s - loss: 0.5033 - accuracy: 0.7431 - val_loss: 1.6508 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "324/324 - 1s - loss: 0.5047 - accuracy: 0.7363 - val_loss: 1.6201 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "324/324 - 1s - loss: 0.5008 - accuracy: 0.7400 - val_loss: 1.4976 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "324/324 - 1s - loss: 0.5010 - accuracy: 0.7417 - val_loss: 1.1587 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "324/324 - 1s - loss: 0.4976 - accuracy: 0.7444 - val_loss: 1.4872 - val_accuracy: 0.4907 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "324/324 - 1s - loss: 0.5069 - accuracy: 0.7431 - val_loss: 1.5731 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "324/324 - 1s - loss: 0.5068 - accuracy: 0.7355 - val_loss: 1.5286 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "324/324 - 1s - loss: 0.5027 - accuracy: 0.7442 - val_loss: 1.4922 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "324/324 - 1s - loss: 0.5076 - accuracy: 0.7467 - val_loss: 1.2461 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "324/324 - 1s - loss: 0.5028 - accuracy: 0.7429 - val_loss: 1.2714 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "324/324 - 1s - loss: 0.4969 - accuracy: 0.7423 - val_loss: 1.0515 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "324/324 - 1s - loss: 0.5120 - accuracy: 0.7373 - val_loss: 1.1580 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "324/324 - 1s - loss: 0.4990 - accuracy: 0.7454 - val_loss: 1.2712 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "324/324 - 1s - loss: 0.4971 - accuracy: 0.7409 - val_loss: 1.3458 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "324/324 - 1s - loss: 0.4925 - accuracy: 0.7498 - val_loss: 1.8007 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "324/324 - 1s - loss: 0.5012 - accuracy: 0.7425 - val_loss: 1.6522 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "324/324 - 1s - loss: 0.5026 - accuracy: 0.7434 - val_loss: 1.2861 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "324/324 - 1s - loss: 0.5125 - accuracy: 0.7313 - val_loss: 0.9633 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "324/324 - 1s - loss: 0.5053 - accuracy: 0.7392 - val_loss: 0.9567 - val_accuracy: 0.4915 - 1s/epoch - 4ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 6475 6477 6478]\n",
      "Number of samples for train set: 5184\n",
      "Test index for this split: [   9   22   26 ... 6471 6476 6479]\n",
      "Number of samples for test set: 1296\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 23:51:59.224510: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_304/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 - 3s - loss: 0.6824 - accuracy: 0.5646 - val_loss: 0.6897 - val_accuracy: 0.5154 - 3s/epoch - 10ms/step\n",
      "Epoch 2/250\n",
      "324/324 - 1s - loss: 0.6536 - accuracy: 0.6101 - val_loss: 0.7252 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "324/324 - 1s - loss: 0.6354 - accuracy: 0.6370 - val_loss: 0.9102 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "324/324 - 1s - loss: 0.6240 - accuracy: 0.6491 - val_loss: 0.8345 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "324/324 - 1s - loss: 0.6197 - accuracy: 0.6481 - val_loss: 0.8199 - val_accuracy: 0.5123 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "324/324 - 1s - loss: 0.6189 - accuracy: 0.6595 - val_loss: 0.8399 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "324/324 - 1s - loss: 0.5997 - accuracy: 0.6779 - val_loss: 0.7975 - val_accuracy: 0.5139 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "324/324 - 1s - loss: 0.6056 - accuracy: 0.6630 - val_loss: 0.8163 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "324/324 - 1s - loss: 0.6042 - accuracy: 0.6719 - val_loss: 0.8003 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "324/324 - 1s - loss: 0.5973 - accuracy: 0.6738 - val_loss: 0.7814 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "324/324 - 1s - loss: 0.5941 - accuracy: 0.6767 - val_loss: 0.7413 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "324/324 - 1s - loss: 0.5838 - accuracy: 0.6879 - val_loss: 0.7147 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "324/324 - 1s - loss: 0.5891 - accuracy: 0.6850 - val_loss: 0.8011 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "324/324 - 1s - loss: 0.5831 - accuracy: 0.6887 - val_loss: 0.7494 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "324/324 - 1s - loss: 0.5800 - accuracy: 0.6943 - val_loss: 0.7689 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "324/324 - 1s - loss: 0.5821 - accuracy: 0.6910 - val_loss: 0.6944 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "324/324 - 1s - loss: 0.5755 - accuracy: 0.6966 - val_loss: 0.6860 - val_accuracy: 0.5193 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "324/324 - 1s - loss: 0.5734 - accuracy: 0.7062 - val_loss: 0.6818 - val_accuracy: 0.5247 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "324/324 - 1s - loss: 0.5772 - accuracy: 0.6987 - val_loss: 0.6791 - val_accuracy: 0.5386 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "324/324 - 1s - loss: 0.5683 - accuracy: 0.6997 - val_loss: 0.7003 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "324/324 - 1s - loss: 0.5727 - accuracy: 0.6987 - val_loss: 0.7546 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "324/324 - 1s - loss: 0.5712 - accuracy: 0.6989 - val_loss: 0.6792 - val_accuracy: 0.5262 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "324/324 - 1s - loss: 0.5629 - accuracy: 0.7037 - val_loss: 0.6805 - val_accuracy: 0.5378 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "324/324 - 1s - loss: 0.5642 - accuracy: 0.7056 - val_loss: 0.6837 - val_accuracy: 0.5224 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "324/324 - 1s - loss: 0.5674 - accuracy: 0.7081 - val_loss: 0.6899 - val_accuracy: 0.5193 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "324/324 - 1s - loss: 0.5636 - accuracy: 0.7074 - val_loss: 0.6851 - val_accuracy: 0.5216 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "324/324 - 1s - loss: 0.5574 - accuracy: 0.7068 - val_loss: 0.7334 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "324/324 - 1s - loss: 0.5641 - accuracy: 0.7033 - val_loss: 0.7901 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "324/324 - 1s - loss: 0.5620 - accuracy: 0.7062 - val_loss: 0.6876 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "324/324 - 1s - loss: 0.5604 - accuracy: 0.7058 - val_loss: 0.6776 - val_accuracy: 0.7122 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "324/324 - 1s - loss: 0.5575 - accuracy: 0.7155 - val_loss: 0.7058 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "324/324 - 1s - loss: 0.5590 - accuracy: 0.7018 - val_loss: 0.7186 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "324/324 - 1s - loss: 0.5591 - accuracy: 0.7076 - val_loss: 0.7185 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "324/324 - 1s - loss: 0.5555 - accuracy: 0.7074 - val_loss: 0.7479 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "324/324 - 1s - loss: 0.5447 - accuracy: 0.7124 - val_loss: 0.7431 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "324/324 - 1s - loss: 0.5474 - accuracy: 0.7093 - val_loss: 0.7512 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "324/324 - 1s - loss: 0.5525 - accuracy: 0.7105 - val_loss: 0.7211 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "324/324 - 1s - loss: 0.5502 - accuracy: 0.7145 - val_loss: 0.6830 - val_accuracy: 0.5224 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "324/324 - 1s - loss: 0.5504 - accuracy: 0.7120 - val_loss: 0.7134 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "324/324 - 1s - loss: 0.5427 - accuracy: 0.7176 - val_loss: 0.7773 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "324/324 - 1s - loss: 0.5433 - accuracy: 0.7164 - val_loss: 0.7952 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "324/324 - 1s - loss: 0.5466 - accuracy: 0.7141 - val_loss: 0.7445 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "324/324 - 1s - loss: 0.5437 - accuracy: 0.7189 - val_loss: 0.7331 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "324/324 - 1s - loss: 0.5459 - accuracy: 0.7178 - val_loss: 0.6829 - val_accuracy: 0.5224 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "324/324 - 1s - loss: 0.5526 - accuracy: 0.7060 - val_loss: 0.6779 - val_accuracy: 0.5255 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "324/324 - 1s - loss: 0.5444 - accuracy: 0.7174 - val_loss: 0.6868 - val_accuracy: 0.5193 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "324/324 - 1s - loss: 0.5377 - accuracy: 0.7226 - val_loss: 0.6777 - val_accuracy: 0.5270 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "324/324 - 1s - loss: 0.5538 - accuracy: 0.7126 - val_loss: 0.7195 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "324/324 - 1s - loss: 0.5508 - accuracy: 0.7112 - val_loss: 0.7758 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "324/324 - 1s - loss: 0.5411 - accuracy: 0.7251 - val_loss: 0.7691 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "324/324 - 1s - loss: 0.5401 - accuracy: 0.7211 - val_loss: 0.7459 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "324/324 - 1s - loss: 0.5403 - accuracy: 0.7197 - val_loss: 0.8148 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "324/324 - 1s - loss: 0.5440 - accuracy: 0.7213 - val_loss: 0.6766 - val_accuracy: 0.5262 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "324/324 - 1s - loss: 0.5392 - accuracy: 0.7226 - val_loss: 0.7001 - val_accuracy: 0.5201 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "324/324 - 1s - loss: 0.5402 - accuracy: 0.7151 - val_loss: 0.8223 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "324/324 - 1s - loss: 0.5487 - accuracy: 0.7139 - val_loss: 0.7911 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "324/324 - 1s - loss: 0.5370 - accuracy: 0.7269 - val_loss: 0.7138 - val_accuracy: 0.5177 - 1s/epoch - 5ms/step\n",
      "Epoch 58/250\n",
      "324/324 - 1s - loss: 0.5415 - accuracy: 0.7226 - val_loss: 0.6741 - val_accuracy: 0.5679 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "324/324 - 1s - loss: 0.5311 - accuracy: 0.7240 - val_loss: 0.7171 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "324/324 - 1s - loss: 0.5343 - accuracy: 0.7282 - val_loss: 0.7626 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "324/324 - 1s - loss: 0.5349 - accuracy: 0.7245 - val_loss: 0.7714 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "324/324 - 1s - loss: 0.5395 - accuracy: 0.7253 - val_loss: 0.6787 - val_accuracy: 0.5262 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "324/324 - 1s - loss: 0.5320 - accuracy: 0.7245 - val_loss: 0.7194 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "324/324 - 1s - loss: 0.5360 - accuracy: 0.7238 - val_loss: 0.7099 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "324/324 - 1s - loss: 0.5354 - accuracy: 0.7189 - val_loss: 0.6766 - val_accuracy: 0.6566 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "324/324 - 1s - loss: 0.5283 - accuracy: 0.7367 - val_loss: 0.6702 - val_accuracy: 0.6690 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "324/324 - 1s - loss: 0.5340 - accuracy: 0.7249 - val_loss: 0.7069 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "324/324 - 1s - loss: 0.5227 - accuracy: 0.7280 - val_loss: 0.6730 - val_accuracy: 0.6034 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "324/324 - 1s - loss: 0.5340 - accuracy: 0.7245 - val_loss: 0.6872 - val_accuracy: 0.5193 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "324/324 - 1s - loss: 0.5333 - accuracy: 0.7251 - val_loss: 0.7089 - val_accuracy: 0.5193 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "324/324 - 1s - loss: 0.5254 - accuracy: 0.7292 - val_loss: 0.6975 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "324/324 - 1s - loss: 0.5303 - accuracy: 0.7317 - val_loss: 0.6791 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "324/324 - 1s - loss: 0.5327 - accuracy: 0.7207 - val_loss: 0.7078 - val_accuracy: 0.4931 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "324/324 - 1s - loss: 0.5318 - accuracy: 0.7301 - val_loss: 0.7376 - val_accuracy: 0.4923 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "324/324 - 1s - loss: 0.5328 - accuracy: 0.7286 - val_loss: 0.6827 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "324/324 - 1s - loss: 0.5300 - accuracy: 0.7278 - val_loss: 0.6880 - val_accuracy: 0.5216 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "324/324 - 1s - loss: 0.5338 - accuracy: 0.7255 - val_loss: 0.6870 - val_accuracy: 0.5224 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "324/324 - 1s - loss: 0.5263 - accuracy: 0.7305 - val_loss: 0.6917 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "324/324 - 1s - loss: 0.5211 - accuracy: 0.7344 - val_loss: 0.7231 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "324/324 - 1s - loss: 0.5291 - accuracy: 0.7280 - val_loss: 0.6883 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "324/324 - 1s - loss: 0.5228 - accuracy: 0.7282 - val_loss: 0.7231 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "324/324 - 1s - loss: 0.5335 - accuracy: 0.7242 - val_loss: 0.9850 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "324/324 - 1s - loss: 0.5216 - accuracy: 0.7317 - val_loss: 0.8286 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "324/324 - 1s - loss: 0.5211 - accuracy: 0.7361 - val_loss: 0.9866 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "324/324 - 1s - loss: 0.5195 - accuracy: 0.7367 - val_loss: 0.8011 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "324/324 - 1s - loss: 0.5221 - accuracy: 0.7313 - val_loss: 0.7646 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "324/324 - 1s - loss: 0.5235 - accuracy: 0.7288 - val_loss: 0.7429 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "324/324 - 1s - loss: 0.5242 - accuracy: 0.7319 - val_loss: 0.8038 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "324/324 - 1s - loss: 0.5239 - accuracy: 0.7290 - val_loss: 0.7423 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "324/324 - 1s - loss: 0.5153 - accuracy: 0.7363 - val_loss: 0.6973 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "324/324 - 1s - loss: 0.5255 - accuracy: 0.7309 - val_loss: 0.7105 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "324/324 - 1s - loss: 0.5222 - accuracy: 0.7321 - val_loss: 0.6773 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "324/324 - 1s - loss: 0.5263 - accuracy: 0.7288 - val_loss: 0.7307 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "324/324 - 1s - loss: 0.5270 - accuracy: 0.7344 - val_loss: 0.7756 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "324/324 - 1s - loss: 0.5243 - accuracy: 0.7276 - val_loss: 0.8208 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "324/324 - 1s - loss: 0.5175 - accuracy: 0.7396 - val_loss: 0.7250 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "324/324 - 1s - loss: 0.5161 - accuracy: 0.7338 - val_loss: 0.6771 - val_accuracy: 0.5247 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "324/324 - 1s - loss: 0.5202 - accuracy: 0.7357 - val_loss: 0.6873 - val_accuracy: 0.5201 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "324/324 - 1s - loss: 0.5274 - accuracy: 0.7282 - val_loss: 0.7609 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "324/324 - 1s - loss: 0.5113 - accuracy: 0.7413 - val_loss: 0.7106 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "324/324 - 1s - loss: 0.5123 - accuracy: 0.7386 - val_loss: 0.7595 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "324/324 - 1s - loss: 0.5287 - accuracy: 0.7263 - val_loss: 0.7090 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "324/324 - 1s - loss: 0.5141 - accuracy: 0.7309 - val_loss: 0.8706 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "324/324 - 1s - loss: 0.5124 - accuracy: 0.7324 - val_loss: 0.8179 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "324/324 - 1s - loss: 0.5256 - accuracy: 0.7307 - val_loss: 0.7372 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "324/324 - 1s - loss: 0.5180 - accuracy: 0.7338 - val_loss: 0.6712 - val_accuracy: 0.5563 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "324/324 - 1s - loss: 0.5284 - accuracy: 0.7305 - val_loss: 0.7283 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "324/324 - 1s - loss: 0.5231 - accuracy: 0.7326 - val_loss: 0.6766 - val_accuracy: 0.5278 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "324/324 - 1s - loss: 0.5166 - accuracy: 0.7338 - val_loss: 0.7162 - val_accuracy: 0.5224 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "324/324 - 1s - loss: 0.5224 - accuracy: 0.7280 - val_loss: 0.7790 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "324/324 - 1s - loss: 0.5274 - accuracy: 0.7305 - val_loss: 0.7595 - val_accuracy: 0.5154 - 1s/epoch - 5ms/step\n",
      "Epoch 112/250\n",
      "324/324 - 1s - loss: 0.5213 - accuracy: 0.7303 - val_loss: 0.7169 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "324/324 - 1s - loss: 0.5141 - accuracy: 0.7417 - val_loss: 0.7361 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "324/324 - 1s - loss: 0.5249 - accuracy: 0.7334 - val_loss: 0.7111 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "324/324 - 1s - loss: 0.5140 - accuracy: 0.7431 - val_loss: 0.8168 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "324/324 - 1s - loss: 0.5237 - accuracy: 0.7286 - val_loss: 0.8010 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "324/324 - 1s - loss: 0.5098 - accuracy: 0.7404 - val_loss: 0.8855 - val_accuracy: 0.5139 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "324/324 - 1s - loss: 0.5139 - accuracy: 0.7346 - val_loss: 0.8171 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "324/324 - 1s - loss: 0.5207 - accuracy: 0.7324 - val_loss: 0.7772 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "324/324 - 1s - loss: 0.5156 - accuracy: 0.7328 - val_loss: 0.7368 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "324/324 - 1s - loss: 0.5136 - accuracy: 0.7334 - val_loss: 0.8846 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "324/324 - 1s - loss: 0.5217 - accuracy: 0.7351 - val_loss: 0.7162 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "324/324 - 1s - loss: 0.5243 - accuracy: 0.7301 - val_loss: 0.6944 - val_accuracy: 0.5208 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "324/324 - 1s - loss: 0.5182 - accuracy: 0.7280 - val_loss: 0.6824 - val_accuracy: 0.5231 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "324/324 - 1s - loss: 0.5193 - accuracy: 0.7338 - val_loss: 0.6985 - val_accuracy: 0.5193 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "324/324 - 1s - loss: 0.5156 - accuracy: 0.7375 - val_loss: 0.6931 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "324/324 - 1s - loss: 0.5065 - accuracy: 0.7432 - val_loss: 0.7202 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "324/324 - 1s - loss: 0.5155 - accuracy: 0.7384 - val_loss: 0.6755 - val_accuracy: 0.5316 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "324/324 - 1s - loss: 0.5184 - accuracy: 0.7303 - val_loss: 0.7173 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "324/324 - 1s - loss: 0.5192 - accuracy: 0.7330 - val_loss: 0.6750 - val_accuracy: 0.5270 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "324/324 - 1s - loss: 0.5133 - accuracy: 0.7344 - val_loss: 0.6966 - val_accuracy: 0.5216 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "324/324 - 1s - loss: 0.5185 - accuracy: 0.7365 - val_loss: 0.6698 - val_accuracy: 0.5980 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "324/324 - 1s - loss: 0.5106 - accuracy: 0.7423 - val_loss: 0.6887 - val_accuracy: 0.5193 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "324/324 - 1s - loss: 0.5163 - accuracy: 0.7388 - val_loss: 0.6693 - val_accuracy: 0.5710 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "324/324 - 1s - loss: 0.5201 - accuracy: 0.7282 - val_loss: 0.7119 - val_accuracy: 0.5201 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "324/324 - 1s - loss: 0.5144 - accuracy: 0.7369 - val_loss: 0.6761 - val_accuracy: 0.6065 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "324/324 - 1s - loss: 0.5097 - accuracy: 0.7458 - val_loss: 0.6789 - val_accuracy: 0.5054 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "324/324 - 1s - loss: 0.5109 - accuracy: 0.7319 - val_loss: 0.6756 - val_accuracy: 0.5702 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "324/324 - 1s - loss: 0.5157 - accuracy: 0.7276 - val_loss: 0.6905 - val_accuracy: 0.5216 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "324/324 - 1s - loss: 0.5139 - accuracy: 0.7342 - val_loss: 0.7829 - val_accuracy: 0.5154 - 1s/epoch - 5ms/step\n",
      "Epoch 141/250\n",
      "324/324 - 1s - loss: 0.5106 - accuracy: 0.7436 - val_loss: 0.9588 - val_accuracy: 0.5147 - 1s/epoch - 5ms/step\n",
      "Epoch 142/250\n",
      "324/324 - 1s - loss: 0.5103 - accuracy: 0.7452 - val_loss: 0.8130 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "324/324 - 1s - loss: 0.5122 - accuracy: 0.7390 - val_loss: 0.8000 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "324/324 - 1s - loss: 0.5205 - accuracy: 0.7259 - val_loss: 0.6715 - val_accuracy: 0.5347 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "324/324 - 1s - loss: 0.5142 - accuracy: 0.7407 - val_loss: 0.7169 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "324/324 - 1s - loss: 0.5070 - accuracy: 0.7396 - val_loss: 0.7534 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "324/324 - 1s - loss: 0.5142 - accuracy: 0.7382 - val_loss: 0.7494 - val_accuracy: 0.5193 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "324/324 - 1s - loss: 0.5036 - accuracy: 0.7355 - val_loss: 0.7331 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "324/324 - 1s - loss: 0.5105 - accuracy: 0.7382 - val_loss: 0.8158 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "324/324 - 1s - loss: 0.5125 - accuracy: 0.7373 - val_loss: 0.7048 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "324/324 - 1s - loss: 0.5061 - accuracy: 0.7409 - val_loss: 0.6833 - val_accuracy: 0.5224 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "324/324 - 1s - loss: 0.5125 - accuracy: 0.7336 - val_loss: 0.7297 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "324/324 - 1s - loss: 0.5227 - accuracy: 0.7340 - val_loss: 0.6753 - val_accuracy: 0.5316 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "324/324 - 1s - loss: 0.5095 - accuracy: 0.7396 - val_loss: 0.6977 - val_accuracy: 0.5208 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "324/324 - 1s - loss: 0.5083 - accuracy: 0.7444 - val_loss: 0.7472 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "324/324 - 1s - loss: 0.5053 - accuracy: 0.7378 - val_loss: 0.7578 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "324/324 - 1s - loss: 0.5105 - accuracy: 0.7367 - val_loss: 0.7784 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "324/324 - 1s - loss: 0.5173 - accuracy: 0.7409 - val_loss: 0.8223 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "324/324 - 1s - loss: 0.5071 - accuracy: 0.7369 - val_loss: 0.7887 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "324/324 - 1s - loss: 0.5091 - accuracy: 0.7361 - val_loss: 0.8353 - val_accuracy: 0.5154 - 1s/epoch - 5ms/step\n",
      "Epoch 161/250\n",
      "324/324 - 1s - loss: 0.4998 - accuracy: 0.7490 - val_loss: 0.8301 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "324/324 - 1s - loss: 0.5070 - accuracy: 0.7390 - val_loss: 0.8197 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "324/324 - 1s - loss: 0.5036 - accuracy: 0.7465 - val_loss: 0.9392 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "324/324 - 1s - loss: 0.5080 - accuracy: 0.7390 - val_loss: 0.7004 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "324/324 - 1s - loss: 0.5107 - accuracy: 0.7400 - val_loss: 0.7072 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "324/324 - 1s - loss: 0.5142 - accuracy: 0.7340 - val_loss: 0.7458 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "324/324 - 1s - loss: 0.5102 - accuracy: 0.7442 - val_loss: 0.8680 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "324/324 - 1s - loss: 0.5200 - accuracy: 0.7351 - val_loss: 0.7548 - val_accuracy: 0.5154 - 1s/epoch - 5ms/step\n",
      "Epoch 169/250\n",
      "324/324 - 1s - loss: 0.5104 - accuracy: 0.7363 - val_loss: 0.7501 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "324/324 - 1s - loss: 0.5062 - accuracy: 0.7361 - val_loss: 0.7573 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "324/324 - 1s - loss: 0.5052 - accuracy: 0.7398 - val_loss: 0.7063 - val_accuracy: 0.5201 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "324/324 - 1s - loss: 0.5078 - accuracy: 0.7330 - val_loss: 0.8308 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "324/324 - 1s - loss: 0.5102 - accuracy: 0.7367 - val_loss: 1.0205 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "324/324 - 1s - loss: 0.5067 - accuracy: 0.7432 - val_loss: 0.7979 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "324/324 - 1s - loss: 0.5043 - accuracy: 0.7386 - val_loss: 0.7820 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "324/324 - 1s - loss: 0.5017 - accuracy: 0.7359 - val_loss: 0.8905 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "324/324 - 1s - loss: 0.5147 - accuracy: 0.7423 - val_loss: 0.7905 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "324/324 - 1s - loss: 0.5097 - accuracy: 0.7369 - val_loss: 0.7292 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "324/324 - 1s - loss: 0.5047 - accuracy: 0.7434 - val_loss: 1.0256 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "324/324 - 1s - loss: 0.5023 - accuracy: 0.7450 - val_loss: 0.7156 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "324/324 - 1s - loss: 0.5068 - accuracy: 0.7454 - val_loss: 0.7188 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "324/324 - 1s - loss: 0.5050 - accuracy: 0.7465 - val_loss: 0.7213 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "324/324 - 1s - loss: 0.5015 - accuracy: 0.7452 - val_loss: 0.7865 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "324/324 - 1s - loss: 0.5028 - accuracy: 0.7388 - val_loss: 1.1568 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "324/324 - 1s - loss: 0.5106 - accuracy: 0.7392 - val_loss: 0.7614 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "324/324 - 1s - loss: 0.5020 - accuracy: 0.7461 - val_loss: 0.8205 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "324/324 - 1s - loss: 0.5028 - accuracy: 0.7485 - val_loss: 0.7806 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "324/324 - 1s - loss: 0.5116 - accuracy: 0.7384 - val_loss: 0.6887 - val_accuracy: 0.5239 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "324/324 - 1s - loss: 0.5046 - accuracy: 0.7425 - val_loss: 0.7500 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "324/324 - 1s - loss: 0.4995 - accuracy: 0.7432 - val_loss: 0.7033 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "324/324 - 1s - loss: 0.5069 - accuracy: 0.7407 - val_loss: 0.8605 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "324/324 - 1s - loss: 0.5016 - accuracy: 0.7415 - val_loss: 0.7688 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "324/324 - 1s - loss: 0.5096 - accuracy: 0.7461 - val_loss: 1.0661 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "324/324 - 1s - loss: 0.5024 - accuracy: 0.7473 - val_loss: 0.7591 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "324/324 - 1s - loss: 0.4978 - accuracy: 0.7413 - val_loss: 0.7784 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "324/324 - 1s - loss: 0.4992 - accuracy: 0.7450 - val_loss: 0.7475 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "324/324 - 1s - loss: 0.5074 - accuracy: 0.7386 - val_loss: 0.7584 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "324/324 - 1s - loss: 0.5098 - accuracy: 0.7404 - val_loss: 0.7879 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "324/324 - 1s - loss: 0.5067 - accuracy: 0.7386 - val_loss: 0.8294 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "324/324 - 1s - loss: 0.5068 - accuracy: 0.7394 - val_loss: 1.1579 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "324/324 - 1s - loss: 0.5065 - accuracy: 0.7390 - val_loss: 1.1682 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "324/324 - 1s - loss: 0.5047 - accuracy: 0.7458 - val_loss: 0.7819 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "324/324 - 1s - loss: 0.5020 - accuracy: 0.7454 - val_loss: 0.7747 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "324/324 - 1s - loss: 0.4993 - accuracy: 0.7427 - val_loss: 0.9333 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "324/324 - 1s - loss: 0.5030 - accuracy: 0.7425 - val_loss: 0.7401 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "324/324 - 1s - loss: 0.5018 - accuracy: 0.7450 - val_loss: 0.7980 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "324/324 - 1s - loss: 0.4998 - accuracy: 0.7444 - val_loss: 0.7149 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "324/324 - 1s - loss: 0.5090 - accuracy: 0.7436 - val_loss: 0.6797 - val_accuracy: 0.5239 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "324/324 - 1s - loss: 0.5085 - accuracy: 0.7350 - val_loss: 0.9539 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "324/324 - 1s - loss: 0.5048 - accuracy: 0.7388 - val_loss: 0.8564 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "324/324 - 1s - loss: 0.5053 - accuracy: 0.7448 - val_loss: 0.8895 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "324/324 - 1s - loss: 0.5020 - accuracy: 0.7436 - val_loss: 0.7919 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "324/324 - 1s - loss: 0.4976 - accuracy: 0.7475 - val_loss: 0.8635 - val_accuracy: 0.5139 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "324/324 - 1s - loss: 0.5061 - accuracy: 0.7394 - val_loss: 0.7091 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "324/324 - 1s - loss: 0.4984 - accuracy: 0.7413 - val_loss: 0.6973 - val_accuracy: 0.5208 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "324/324 - 1s - loss: 0.5001 - accuracy: 0.7446 - val_loss: 0.7608 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "324/324 - 1s - loss: 0.4978 - accuracy: 0.7531 - val_loss: 0.7010 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "324/324 - 1s - loss: 0.5030 - accuracy: 0.7415 - val_loss: 0.7135 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "324/324 - 1s - loss: 0.5132 - accuracy: 0.7384 - val_loss: 0.7002 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "324/324 - 1s - loss: 0.5005 - accuracy: 0.7446 - val_loss: 0.7424 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "324/324 - 1s - loss: 0.5051 - accuracy: 0.7400 - val_loss: 0.7997 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "324/324 - 1s - loss: 0.5039 - accuracy: 0.7459 - val_loss: 0.7911 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "324/324 - 1s - loss: 0.4977 - accuracy: 0.7500 - val_loss: 0.8993 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "324/324 - 1s - loss: 0.5039 - accuracy: 0.7394 - val_loss: 0.7303 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "324/324 - 1s - loss: 0.5074 - accuracy: 0.7409 - val_loss: 0.7697 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "324/324 - 1s - loss: 0.4946 - accuracy: 0.7587 - val_loss: 0.7426 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "324/324 - 1s - loss: 0.5005 - accuracy: 0.7417 - val_loss: 0.7520 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "324/324 - 1s - loss: 0.5001 - accuracy: 0.7452 - val_loss: 1.0015 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "324/324 - 1s - loss: 0.5061 - accuracy: 0.7417 - val_loss: 1.0440 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "324/324 - 1s - loss: 0.5022 - accuracy: 0.7429 - val_loss: 0.9194 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "324/324 - 1s - loss: 0.4989 - accuracy: 0.7446 - val_loss: 0.9302 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "324/324 - 1s - loss: 0.5026 - accuracy: 0.7465 - val_loss: 0.9317 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "324/324 - 1s - loss: 0.4963 - accuracy: 0.7454 - val_loss: 0.9873 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "324/324 - 1s - loss: 0.5007 - accuracy: 0.7486 - val_loss: 1.0377 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "324/324 - 1s - loss: 0.5011 - accuracy: 0.7450 - val_loss: 1.3312 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "324/324 - 1s - loss: 0.4954 - accuracy: 0.7411 - val_loss: 1.0829 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "324/324 - 1s - loss: 0.5008 - accuracy: 0.7425 - val_loss: 1.1170 - val_accuracy: 0.5147 - 1s/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "324/324 - 1s - loss: 0.5006 - accuracy: 0.7467 - val_loss: 1.0407 - val_accuracy: 0.5139 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "324/324 - 1s - loss: 0.4972 - accuracy: 0.7427 - val_loss: 0.9409 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "324/324 - 1s - loss: 0.4935 - accuracy: 0.7458 - val_loss: 1.0401 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "324/324 - 1s - loss: 0.5049 - accuracy: 0.7373 - val_loss: 1.0885 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "324/324 - 1s - loss: 0.4906 - accuracy: 0.7514 - val_loss: 1.0287 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "324/324 - 1s - loss: 0.5054 - accuracy: 0.7369 - val_loss: 1.0693 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "324/324 - 1s - loss: 0.4938 - accuracy: 0.7492 - val_loss: 1.2466 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "324/324 - 1s - loss: 0.4985 - accuracy: 0.7434 - val_loss: 1.2458 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "324/324 - 1s - loss: 0.4950 - accuracy: 0.7473 - val_loss: 1.3043 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "324/324 - 1s - loss: 0.5002 - accuracy: 0.7415 - val_loss: 1.3362 - val_accuracy: 0.5139 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "324/324 - 1s - loss: 0.4960 - accuracy: 0.7421 - val_loss: 1.2762 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "324/324 - 1s - loss: 0.4927 - accuracy: 0.7488 - val_loss: 0.9590 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "324/324 - 1s - loss: 0.4960 - accuracy: 0.7461 - val_loss: 1.1594 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 6477 6478 6479]\n",
      "Number of samples for train set: 5184\n",
      "Test index for this split: [   5    6    8 ... 6463 6465 6469]\n",
      "Number of samples for test set: 1296\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 23:57:57.147964: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_305/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 - 3s - loss: 0.6820 - accuracy: 0.5648 - val_loss: 0.6900 - val_accuracy: 0.5386 - 3s/epoch - 10ms/step\n",
      "Epoch 2/250\n",
      "324/324 - 1s - loss: 0.6670 - accuracy: 0.5963 - val_loss: 0.6887 - val_accuracy: 0.5100 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "324/324 - 1s - loss: 0.6475 - accuracy: 0.6169 - val_loss: 0.7339 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "324/324 - 1s - loss: 0.6456 - accuracy: 0.6285 - val_loss: 0.8159 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "324/324 - 1s - loss: 0.6278 - accuracy: 0.6404 - val_loss: 0.8370 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "324/324 - 1s - loss: 0.6229 - accuracy: 0.6524 - val_loss: 0.8028 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "324/324 - 1s - loss: 0.6231 - accuracy: 0.6491 - val_loss: 0.8441 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "324/324 - 1s - loss: 0.6099 - accuracy: 0.6690 - val_loss: 0.8723 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "324/324 - 1s - loss: 0.6106 - accuracy: 0.6620 - val_loss: 0.7652 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "324/324 - 1s - loss: 0.6022 - accuracy: 0.6715 - val_loss: 0.7706 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "324/324 - 1s - loss: 0.5980 - accuracy: 0.6802 - val_loss: 0.7978 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "324/324 - 1s - loss: 0.6026 - accuracy: 0.6661 - val_loss: 0.7156 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "324/324 - 1s - loss: 0.5834 - accuracy: 0.6842 - val_loss: 0.7163 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "324/324 - 1s - loss: 0.5905 - accuracy: 0.6732 - val_loss: 0.7369 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "324/324 - 1s - loss: 0.5814 - accuracy: 0.6887 - val_loss: 0.7320 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "324/324 - 1s - loss: 0.5879 - accuracy: 0.6819 - val_loss: 0.7931 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "324/324 - 1s - loss: 0.5851 - accuracy: 0.6869 - val_loss: 0.7273 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "324/324 - 1s - loss: 0.5792 - accuracy: 0.6944 - val_loss: 0.7100 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "324/324 - 1s - loss: 0.5784 - accuracy: 0.6898 - val_loss: 0.7072 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "324/324 - 1s - loss: 0.5830 - accuracy: 0.6889 - val_loss: 0.7243 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "324/324 - 1s - loss: 0.5771 - accuracy: 0.6892 - val_loss: 0.6853 - val_accuracy: 0.5100 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "324/324 - 1s - loss: 0.5715 - accuracy: 0.6979 - val_loss: 0.7347 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "324/324 - 1s - loss: 0.5647 - accuracy: 0.7070 - val_loss: 0.6963 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "324/324 - 1s - loss: 0.5640 - accuracy: 0.7016 - val_loss: 0.7234 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "324/324 - 1s - loss: 0.5711 - accuracy: 0.6958 - val_loss: 0.7030 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "324/324 - 1s - loss: 0.5726 - accuracy: 0.6979 - val_loss: 0.6928 - val_accuracy: 0.5046 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "324/324 - 1s - loss: 0.5647 - accuracy: 0.7027 - val_loss: 0.7579 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "324/324 - 1s - loss: 0.5649 - accuracy: 0.6958 - val_loss: 0.6870 - val_accuracy: 0.7145 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "324/324 - 1s - loss: 0.5567 - accuracy: 0.7029 - val_loss: 0.6889 - val_accuracy: 0.7099 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "324/324 - 1s - loss: 0.5573 - accuracy: 0.7076 - val_loss: 0.6997 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "324/324 - 1s - loss: 0.5648 - accuracy: 0.7031 - val_loss: 0.6996 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "324/324 - 1s - loss: 0.5573 - accuracy: 0.7180 - val_loss: 0.6861 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "324/324 - 1s - loss: 0.5534 - accuracy: 0.7079 - val_loss: 0.6953 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "324/324 - 1s - loss: 0.5604 - accuracy: 0.7118 - val_loss: 0.7821 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "324/324 - 1s - loss: 0.5470 - accuracy: 0.7182 - val_loss: 0.7584 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "324/324 - 1s - loss: 0.5622 - accuracy: 0.7054 - val_loss: 0.6953 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "324/324 - 1s - loss: 0.5558 - accuracy: 0.7022 - val_loss: 0.8016 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "324/324 - 1s - loss: 0.5543 - accuracy: 0.7095 - val_loss: 0.7883 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "324/324 - 1s - loss: 0.5487 - accuracy: 0.7099 - val_loss: 0.7684 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "324/324 - 1s - loss: 0.5537 - accuracy: 0.7114 - val_loss: 0.6961 - val_accuracy: 0.5054 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "324/324 - 1s - loss: 0.5492 - accuracy: 0.7153 - val_loss: 0.6813 - val_accuracy: 0.6042 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "324/324 - 1s - loss: 0.5455 - accuracy: 0.7128 - val_loss: 0.6882 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "324/324 - 1s - loss: 0.5358 - accuracy: 0.7226 - val_loss: 0.6911 - val_accuracy: 0.5069 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "324/324 - 1s - loss: 0.5435 - accuracy: 0.7128 - val_loss: 0.6802 - val_accuracy: 0.5293 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "324/324 - 1s - loss: 0.5400 - accuracy: 0.7215 - val_loss: 0.6886 - val_accuracy: 0.5077 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "324/324 - 1s - loss: 0.5544 - accuracy: 0.7043 - val_loss: 0.7026 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "324/324 - 1s - loss: 0.5473 - accuracy: 0.7145 - val_loss: 0.6808 - val_accuracy: 0.5239 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "324/324 - 1s - loss: 0.5407 - accuracy: 0.7213 - val_loss: 0.6939 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "324/324 - 1s - loss: 0.5470 - accuracy: 0.7160 - val_loss: 0.7125 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "324/324 - 1s - loss: 0.5458 - accuracy: 0.7155 - val_loss: 0.6968 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "324/324 - 1s - loss: 0.5408 - accuracy: 0.7215 - val_loss: 0.6921 - val_accuracy: 0.5069 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "324/324 - 1s - loss: 0.5330 - accuracy: 0.7236 - val_loss: 0.6947 - val_accuracy: 0.5077 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "324/324 - 1s - loss: 0.5379 - accuracy: 0.7162 - val_loss: 0.6928 - val_accuracy: 0.5046 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "324/324 - 1s - loss: 0.5435 - accuracy: 0.7095 - val_loss: 0.6953 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "324/324 - 1s - loss: 0.5460 - accuracy: 0.7172 - val_loss: 0.7013 - val_accuracy: 0.5054 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "324/324 - 1s - loss: 0.5419 - accuracy: 0.7222 - val_loss: 0.7335 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "324/324 - 1s - loss: 0.5418 - accuracy: 0.7209 - val_loss: 0.7157 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "324/324 - 1s - loss: 0.5366 - accuracy: 0.7213 - val_loss: 0.6944 - val_accuracy: 0.5069 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "324/324 - 1s - loss: 0.5415 - accuracy: 0.7199 - val_loss: 0.7372 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "324/324 - 1s - loss: 0.5357 - accuracy: 0.7251 - val_loss: 0.7351 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "324/324 - 1s - loss: 0.5471 - accuracy: 0.7151 - val_loss: 0.7149 - val_accuracy: 0.5000 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "324/324 - 1s - loss: 0.5361 - accuracy: 0.7199 - val_loss: 0.7109 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "324/324 - 1s - loss: 0.5374 - accuracy: 0.7222 - val_loss: 0.7083 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "324/324 - 1s - loss: 0.5349 - accuracy: 0.7255 - val_loss: 0.6914 - val_accuracy: 0.5054 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "324/324 - 1s - loss: 0.5438 - accuracy: 0.7108 - val_loss: 0.7377 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "324/324 - 1s - loss: 0.5324 - accuracy: 0.7191 - val_loss: 0.7671 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "324/324 - 1s - loss: 0.5319 - accuracy: 0.7257 - val_loss: 0.8348 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "324/324 - 1s - loss: 0.5367 - accuracy: 0.7249 - val_loss: 0.7071 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "324/324 - 1s - loss: 0.5367 - accuracy: 0.7149 - val_loss: 0.6790 - val_accuracy: 0.5532 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "324/324 - 1s - loss: 0.5333 - accuracy: 0.7226 - val_loss: 0.6838 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "324/324 - 1s - loss: 0.5286 - accuracy: 0.7184 - val_loss: 0.6842 - val_accuracy: 0.5116 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "324/324 - 1s - loss: 0.5302 - accuracy: 0.7267 - val_loss: 0.7106 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "324/324 - 1s - loss: 0.5227 - accuracy: 0.7280 - val_loss: 0.7532 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "324/324 - 1s - loss: 0.5304 - accuracy: 0.7249 - val_loss: 0.6930 - val_accuracy: 0.5069 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "324/324 - 1s - loss: 0.5398 - accuracy: 0.7141 - val_loss: 0.7173 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "324/324 - 1s - loss: 0.5299 - accuracy: 0.7170 - val_loss: 0.6996 - val_accuracy: 0.6705 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "324/324 - 1s - loss: 0.5257 - accuracy: 0.7299 - val_loss: 0.6962 - val_accuracy: 0.5332 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "324/324 - 1s - loss: 0.5318 - accuracy: 0.7218 - val_loss: 0.6937 - val_accuracy: 0.5054 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "324/324 - 1s - loss: 0.5328 - accuracy: 0.7207 - val_loss: 0.6989 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "324/324 - 1s - loss: 0.5252 - accuracy: 0.7313 - val_loss: 0.7212 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "324/324 - 1s - loss: 0.5381 - accuracy: 0.7137 - val_loss: 0.7229 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "324/324 - 1s - loss: 0.5289 - accuracy: 0.7211 - val_loss: 0.7515 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "324/324 - 1s - loss: 0.5263 - accuracy: 0.7313 - val_loss: 0.7227 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "324/324 - 1s - loss: 0.5269 - accuracy: 0.7267 - val_loss: 0.7362 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "324/324 - 1s - loss: 0.5348 - accuracy: 0.7170 - val_loss: 0.7467 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "324/324 - 1s - loss: 0.5254 - accuracy: 0.7245 - val_loss: 0.8238 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "324/324 - 1s - loss: 0.5276 - accuracy: 0.7242 - val_loss: 0.7406 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "324/324 - 1s - loss: 0.5295 - accuracy: 0.7269 - val_loss: 0.6877 - val_accuracy: 0.5193 - 1s/epoch - 5ms/step\n",
      "Epoch 89/250\n",
      "324/324 - 1s - loss: 0.5216 - accuracy: 0.7332 - val_loss: 0.6953 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "324/324 - 1s - loss: 0.5186 - accuracy: 0.7332 - val_loss: 0.6968 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "324/324 - 1s - loss: 0.5369 - accuracy: 0.7263 - val_loss: 0.7230 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "324/324 - 1s - loss: 0.5240 - accuracy: 0.7294 - val_loss: 0.6923 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "324/324 - 1s - loss: 0.5158 - accuracy: 0.7288 - val_loss: 0.6828 - val_accuracy: 0.5316 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "324/324 - 1s - loss: 0.5237 - accuracy: 0.7226 - val_loss: 0.6908 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "324/324 - 1s - loss: 0.5240 - accuracy: 0.7270 - val_loss: 0.6873 - val_accuracy: 0.5239 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "324/324 - 1s - loss: 0.5275 - accuracy: 0.7259 - val_loss: 0.6817 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "324/324 - 1s - loss: 0.5155 - accuracy: 0.7365 - val_loss: 0.7073 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "324/324 - 1s - loss: 0.5213 - accuracy: 0.7303 - val_loss: 0.7091 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "324/324 - 1s - loss: 0.5224 - accuracy: 0.7286 - val_loss: 0.6824 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "324/324 - 1s - loss: 0.5199 - accuracy: 0.7309 - val_loss: 0.7016 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "324/324 - 1s - loss: 0.5234 - accuracy: 0.7317 - val_loss: 0.7042 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "324/324 - 1s - loss: 0.5154 - accuracy: 0.7330 - val_loss: 0.6942 - val_accuracy: 0.5424 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "324/324 - 1s - loss: 0.5192 - accuracy: 0.7317 - val_loss: 0.6841 - val_accuracy: 0.5177 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "324/324 - 1s - loss: 0.5253 - accuracy: 0.7317 - val_loss: 0.6793 - val_accuracy: 0.5949 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "324/324 - 1s - loss: 0.5223 - accuracy: 0.7267 - val_loss: 0.6854 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "324/324 - 1s - loss: 0.5192 - accuracy: 0.7309 - val_loss: 0.6978 - val_accuracy: 0.5139 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "324/324 - 1s - loss: 0.5234 - accuracy: 0.7245 - val_loss: 0.7071 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "324/324 - 1s - loss: 0.5191 - accuracy: 0.7297 - val_loss: 0.6804 - val_accuracy: 0.5347 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "324/324 - 1s - loss: 0.5203 - accuracy: 0.7326 - val_loss: 0.6963 - val_accuracy: 0.5139 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "324/324 - 1s - loss: 0.5188 - accuracy: 0.7276 - val_loss: 0.7249 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "324/324 - 1s - loss: 0.5155 - accuracy: 0.7311 - val_loss: 0.7609 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "324/324 - 1s - loss: 0.5198 - accuracy: 0.7367 - val_loss: 0.6887 - val_accuracy: 0.6682 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "324/324 - 1s - loss: 0.5315 - accuracy: 0.7213 - val_loss: 0.6837 - val_accuracy: 0.5525 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "324/324 - 1s - loss: 0.5189 - accuracy: 0.7290 - val_loss: 0.7028 - val_accuracy: 0.5139 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "324/324 - 1s - loss: 0.5198 - accuracy: 0.7218 - val_loss: 0.6889 - val_accuracy: 0.5355 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "324/324 - 1s - loss: 0.5183 - accuracy: 0.7338 - val_loss: 0.6856 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "324/324 - 1s - loss: 0.5225 - accuracy: 0.7305 - val_loss: 0.6857 - val_accuracy: 0.5502 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "324/324 - 1s - loss: 0.5164 - accuracy: 0.7336 - val_loss: 0.7078 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "324/324 - 1s - loss: 0.5272 - accuracy: 0.7280 - val_loss: 0.6783 - val_accuracy: 0.6806 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "324/324 - 1s - loss: 0.5166 - accuracy: 0.7259 - val_loss: 0.7101 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "324/324 - 1s - loss: 0.5211 - accuracy: 0.7297 - val_loss: 0.7019 - val_accuracy: 0.5093 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "324/324 - 1s - loss: 0.5243 - accuracy: 0.7346 - val_loss: 0.6952 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "324/324 - 1s - loss: 0.5145 - accuracy: 0.7309 - val_loss: 0.6855 - val_accuracy: 0.5478 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "324/324 - 1s - loss: 0.5139 - accuracy: 0.7324 - val_loss: 0.7118 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "324/324 - 1s - loss: 0.5149 - accuracy: 0.7348 - val_loss: 0.6976 - val_accuracy: 0.6435 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "324/324 - 1s - loss: 0.5118 - accuracy: 0.7348 - val_loss: 0.6852 - val_accuracy: 0.5548 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "324/324 - 1s - loss: 0.5186 - accuracy: 0.7338 - val_loss: 0.7278 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "324/324 - 1s - loss: 0.5128 - accuracy: 0.7357 - val_loss: 0.7227 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "324/324 - 1s - loss: 0.5154 - accuracy: 0.7332 - val_loss: 0.7296 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "324/324 - 1s - loss: 0.5201 - accuracy: 0.7296 - val_loss: 0.7003 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "324/324 - 1s - loss: 0.5117 - accuracy: 0.7326 - val_loss: 0.7155 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "324/324 - 1s - loss: 0.5163 - accuracy: 0.7365 - val_loss: 0.6924 - val_accuracy: 0.5247 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "324/324 - 1s - loss: 0.5195 - accuracy: 0.7324 - val_loss: 0.7028 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "324/324 - 1s - loss: 0.5116 - accuracy: 0.7396 - val_loss: 0.6827 - val_accuracy: 0.7160 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "324/324 - 1s - loss: 0.5208 - accuracy: 0.7301 - val_loss: 0.7780 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "324/324 - 1s - loss: 0.5207 - accuracy: 0.7303 - val_loss: 0.7052 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "324/324 - 1s - loss: 0.5146 - accuracy: 0.7380 - val_loss: 0.7075 - val_accuracy: 0.5046 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "324/324 - 1s - loss: 0.5074 - accuracy: 0.7411 - val_loss: 0.6993 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "324/324 - 1s - loss: 0.5134 - accuracy: 0.7388 - val_loss: 0.7173 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "324/324 - 1s - loss: 0.5136 - accuracy: 0.7319 - val_loss: 0.6876 - val_accuracy: 0.5154 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "324/324 - 1s - loss: 0.5083 - accuracy: 0.7365 - val_loss: 0.6902 - val_accuracy: 0.5116 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "324/324 - 1s - loss: 0.5139 - accuracy: 0.7361 - val_loss: 0.7276 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "324/324 - 1s - loss: 0.5141 - accuracy: 0.7407 - val_loss: 0.6813 - val_accuracy: 0.5957 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "324/324 - 1s - loss: 0.5078 - accuracy: 0.7394 - val_loss: 0.6878 - val_accuracy: 0.5123 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "324/324 - 1s - loss: 0.5177 - accuracy: 0.7301 - val_loss: 0.6803 - val_accuracy: 0.6312 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "324/324 - 1s - loss: 0.5243 - accuracy: 0.7259 - val_loss: 0.7079 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "324/324 - 1s - loss: 0.5169 - accuracy: 0.7346 - val_loss: 0.6768 - val_accuracy: 0.6867 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "324/324 - 1s - loss: 0.5164 - accuracy: 0.7353 - val_loss: 0.6721 - val_accuracy: 0.5849 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "324/324 - 1s - loss: 0.5195 - accuracy: 0.7290 - val_loss: 0.7240 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "324/324 - 1s - loss: 0.5145 - accuracy: 0.7342 - val_loss: 0.6899 - val_accuracy: 0.5108 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "324/324 - 1s - loss: 0.5211 - accuracy: 0.7274 - val_loss: 0.6853 - val_accuracy: 0.5594 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "324/324 - 1s - loss: 0.5185 - accuracy: 0.7326 - val_loss: 0.6933 - val_accuracy: 0.5100 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "324/324 - 1s - loss: 0.5070 - accuracy: 0.7425 - val_loss: 0.6795 - val_accuracy: 0.5556 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "324/324 - 1s - loss: 0.5146 - accuracy: 0.7332 - val_loss: 0.7011 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "324/324 - 1s - loss: 0.5083 - accuracy: 0.7386 - val_loss: 0.6981 - val_accuracy: 0.5046 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "324/324 - 1s - loss: 0.5145 - accuracy: 0.7332 - val_loss: 0.6766 - val_accuracy: 0.6929 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "324/324 - 1s - loss: 0.5092 - accuracy: 0.7436 - val_loss: 0.6796 - val_accuracy: 0.6559 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "324/324 - 1s - loss: 0.5057 - accuracy: 0.7407 - val_loss: 0.6784 - val_accuracy: 0.6497 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "324/324 - 1s - loss: 0.5181 - accuracy: 0.7313 - val_loss: 0.7120 - val_accuracy: 0.5285 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "324/324 - 1s - loss: 0.5086 - accuracy: 0.7380 - val_loss: 0.6880 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "324/324 - 1s - loss: 0.5184 - accuracy: 0.7382 - val_loss: 0.6782 - val_accuracy: 0.5347 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "324/324 - 1s - loss: 0.5078 - accuracy: 0.7365 - val_loss: 0.6969 - val_accuracy: 0.5116 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "324/324 - 1s - loss: 0.5098 - accuracy: 0.7415 - val_loss: 0.6889 - val_accuracy: 0.6674 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "324/324 - 1s - loss: 0.5160 - accuracy: 0.7384 - val_loss: 0.6875 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "324/324 - 1s - loss: 0.5171 - accuracy: 0.7309 - val_loss: 0.6839 - val_accuracy: 0.5123 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "324/324 - 1s - loss: 0.5066 - accuracy: 0.7411 - val_loss: 0.6852 - val_accuracy: 0.6690 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "324/324 - 1s - loss: 0.5005 - accuracy: 0.7373 - val_loss: 0.6849 - val_accuracy: 0.6088 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "324/324 - 1s - loss: 0.5047 - accuracy: 0.7359 - val_loss: 0.6816 - val_accuracy: 0.5309 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "324/324 - 1s - loss: 0.5057 - accuracy: 0.7380 - val_loss: 0.6982 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "324/324 - 1s - loss: 0.5039 - accuracy: 0.7413 - val_loss: 0.6957 - val_accuracy: 0.5309 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "324/324 - 1s - loss: 0.5082 - accuracy: 0.7392 - val_loss: 0.6859 - val_accuracy: 0.5262 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "324/324 - 1s - loss: 0.5057 - accuracy: 0.7440 - val_loss: 0.6793 - val_accuracy: 0.5270 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "324/324 - 1s - loss: 0.5120 - accuracy: 0.7317 - val_loss: 0.7081 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "324/324 - 1s - loss: 0.5107 - accuracy: 0.7377 - val_loss: 0.6785 - val_accuracy: 0.6574 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "324/324 - 1s - loss: 0.5141 - accuracy: 0.7323 - val_loss: 0.6905 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "324/324 - 1s - loss: 0.5218 - accuracy: 0.7305 - val_loss: 0.7080 - val_accuracy: 0.4985 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "324/324 - 1s - loss: 0.5098 - accuracy: 0.7348 - val_loss: 0.7305 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "324/324 - 1s - loss: 0.5099 - accuracy: 0.7313 - val_loss: 0.6754 - val_accuracy: 0.5710 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "324/324 - 1s - loss: 0.5131 - accuracy: 0.7355 - val_loss: 0.7013 - val_accuracy: 0.5046 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "324/324 - 1s - loss: 0.5121 - accuracy: 0.7338 - val_loss: 0.7144 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "324/324 - 1s - loss: 0.5071 - accuracy: 0.7398 - val_loss: 0.7121 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "324/324 - 1s - loss: 0.5085 - accuracy: 0.7365 - val_loss: 0.6940 - val_accuracy: 0.5046 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "324/324 - 1s - loss: 0.5107 - accuracy: 0.7328 - val_loss: 0.7177 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "324/324 - 1s - loss: 0.5056 - accuracy: 0.7378 - val_loss: 0.6787 - val_accuracy: 0.6157 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "324/324 - 1s - loss: 0.5124 - accuracy: 0.7330 - val_loss: 0.6762 - val_accuracy: 0.6790 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "324/324 - 1s - loss: 0.5139 - accuracy: 0.7326 - val_loss: 0.7076 - val_accuracy: 0.5093 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "324/324 - 1s - loss: 0.5129 - accuracy: 0.7292 - val_loss: 0.6917 - val_accuracy: 0.5147 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "324/324 - 1s - loss: 0.5067 - accuracy: 0.7371 - val_loss: 0.7111 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "324/324 - 1s - loss: 0.5132 - accuracy: 0.7344 - val_loss: 0.6891 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "324/324 - 1s - loss: 0.5118 - accuracy: 0.7363 - val_loss: 0.6729 - val_accuracy: 0.5918 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "324/324 - 1s - loss: 0.5054 - accuracy: 0.7348 - val_loss: 0.7296 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "324/324 - 1s - loss: 0.5027 - accuracy: 0.7434 - val_loss: 0.6970 - val_accuracy: 0.5062 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "324/324 - 1s - loss: 0.5117 - accuracy: 0.7348 - val_loss: 0.7110 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "324/324 - 1s - loss: 0.5106 - accuracy: 0.7432 - val_loss: 0.8611 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "324/324 - 1s - loss: 0.5080 - accuracy: 0.7423 - val_loss: 0.7548 - val_accuracy: 0.4992 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "324/324 - 1s - loss: 0.5069 - accuracy: 0.7400 - val_loss: 0.6814 - val_accuracy: 0.6898 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "324/324 - 1s - loss: 0.5013 - accuracy: 0.7367 - val_loss: 0.7319 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "324/324 - 1s - loss: 0.5070 - accuracy: 0.7355 - val_loss: 0.6835 - val_accuracy: 0.5532 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "324/324 - 1s - loss: 0.5143 - accuracy: 0.7299 - val_loss: 0.7788 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "324/324 - 1s - loss: 0.5041 - accuracy: 0.7425 - val_loss: 0.7314 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "324/324 - 1s - loss: 0.4973 - accuracy: 0.7400 - val_loss: 0.6936 - val_accuracy: 0.5123 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "324/324 - 1s - loss: 0.5030 - accuracy: 0.7421 - val_loss: 0.7044 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "324/324 - 1s - loss: 0.5045 - accuracy: 0.7386 - val_loss: 0.6864 - val_accuracy: 0.5123 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "324/324 - 1s - loss: 0.5025 - accuracy: 0.7423 - val_loss: 0.7309 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "324/324 - 1s - loss: 0.5117 - accuracy: 0.7332 - val_loss: 0.7049 - val_accuracy: 0.5185 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "324/324 - 1s - loss: 0.5087 - accuracy: 0.7357 - val_loss: 0.6907 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "324/324 - 1s - loss: 0.5145 - accuracy: 0.7340 - val_loss: 0.7033 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "324/324 - 1s - loss: 0.5114 - accuracy: 0.7355 - val_loss: 0.7053 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "324/324 - 1s - loss: 0.5128 - accuracy: 0.7365 - val_loss: 0.7172 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "324/324 - 1s - loss: 0.5141 - accuracy: 0.7363 - val_loss: 0.7498 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "324/324 - 1s - loss: 0.5104 - accuracy: 0.7380 - val_loss: 0.6926 - val_accuracy: 0.5363 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "324/324 - 1s - loss: 0.5111 - accuracy: 0.7369 - val_loss: 0.7069 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "324/324 - 1s - loss: 0.5084 - accuracy: 0.7429 - val_loss: 0.7343 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "324/324 - 1s - loss: 0.5096 - accuracy: 0.7342 - val_loss: 0.7084 - val_accuracy: 0.5548 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "324/324 - 1s - loss: 0.5017 - accuracy: 0.7450 - val_loss: 0.7335 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "324/324 - 1s - loss: 0.5009 - accuracy: 0.7361 - val_loss: 0.7451 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "324/324 - 1s - loss: 0.4991 - accuracy: 0.7463 - val_loss: 0.6827 - val_accuracy: 0.6728 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "324/324 - 1s - loss: 0.5086 - accuracy: 0.7317 - val_loss: 0.6984 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "324/324 - 1s - loss: 0.5114 - accuracy: 0.7205 - val_loss: 0.6940 - val_accuracy: 0.5170 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "324/324 - 1s - loss: 0.5086 - accuracy: 0.7344 - val_loss: 0.6951 - val_accuracy: 0.5131 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "324/324 - 1s - loss: 0.5030 - accuracy: 0.7427 - val_loss: 0.7088 - val_accuracy: 0.5046 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "324/324 - 1s - loss: 0.5062 - accuracy: 0.7363 - val_loss: 0.7112 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "324/324 - 1s - loss: 0.5074 - accuracy: 0.7377 - val_loss: 0.6772 - val_accuracy: 0.5710 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "324/324 - 1s - loss: 0.5101 - accuracy: 0.7288 - val_loss: 0.6927 - val_accuracy: 0.5532 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "324/324 - 1s - loss: 0.5038 - accuracy: 0.7382 - val_loss: 0.7190 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "324/324 - 1s - loss: 0.4945 - accuracy: 0.7510 - val_loss: 0.7574 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "324/324 - 1s - loss: 0.5002 - accuracy: 0.7438 - val_loss: 0.8234 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "324/324 - 1s - loss: 0.5100 - accuracy: 0.7404 - val_loss: 0.7459 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "324/324 - 1s - loss: 0.5015 - accuracy: 0.7342 - val_loss: 0.7210 - val_accuracy: 0.5039 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "324/324 - 1s - loss: 0.5021 - accuracy: 0.7378 - val_loss: 0.7205 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "324/324 - 1s - loss: 0.5009 - accuracy: 0.7411 - val_loss: 0.7787 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "324/324 - 1s - loss: 0.5096 - accuracy: 0.7353 - val_loss: 0.7301 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "324/324 - 1s - loss: 0.4986 - accuracy: 0.7425 - val_loss: 0.8083 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "324/324 - 1s - loss: 0.5063 - accuracy: 0.7361 - val_loss: 0.7822 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "324/324 - 1s - loss: 0.5048 - accuracy: 0.7382 - val_loss: 0.7558 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "324/324 - 1s - loss: 0.4948 - accuracy: 0.7450 - val_loss: 0.7031 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "324/324 - 1s - loss: 0.4998 - accuracy: 0.7404 - val_loss: 0.6899 - val_accuracy: 0.5162 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "324/324 - 1s - loss: 0.4955 - accuracy: 0.7458 - val_loss: 0.8066 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "324/324 - 1s - loss: 0.5034 - accuracy: 0.7405 - val_loss: 0.7703 - val_accuracy: 0.5008 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "324/324 - 1s - loss: 0.5038 - accuracy: 0.7442 - val_loss: 0.7845 - val_accuracy: 0.5023 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "324/324 - 1s - loss: 0.4982 - accuracy: 0.7419 - val_loss: 0.7149 - val_accuracy: 0.5046 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "324/324 - 1s - loss: 0.4981 - accuracy: 0.7384 - val_loss: 0.6736 - val_accuracy: 0.6829 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "324/324 - 1s - loss: 0.4985 - accuracy: 0.7459 - val_loss: 0.6814 - val_accuracy: 0.5409 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "324/324 - 1s - loss: 0.5082 - accuracy: 0.7286 - val_loss: 0.6825 - val_accuracy: 0.6636 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "324/324 - 1s - loss: 0.5064 - accuracy: 0.7392 - val_loss: 0.6859 - val_accuracy: 0.5077 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "324/324 - 1s - loss: 0.5029 - accuracy: 0.7359 - val_loss: 0.7316 - val_accuracy: 0.5046 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "324/324 - 1s - loss: 0.4979 - accuracy: 0.7432 - val_loss: 0.7846 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "324/324 - 1s - loss: 0.5045 - accuracy: 0.7369 - val_loss: 0.7356 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "324/324 - 1s - loss: 0.5060 - accuracy: 0.7432 - val_loss: 0.7676 - val_accuracy: 0.5031 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "324/324 - 1s - loss: 0.5063 - accuracy: 0.7377 - val_loss: 0.7617 - val_accuracy: 0.5015 - 1s/epoch - 4ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "203/203 [==============================] - 0s 2ms/step\n",
      "SUBJECT: 17\n",
      "N_CLASSES: 3\n",
      "New shape for X: (4860, 31, 50, 4)\n",
      "New shape for y: (4860,)\n",
      "Train index for this split: [   0    3    4 ... 4857 4858 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   1    2   14   18   19   21   23   28   32   35   38   42   50   58\n",
      "   60   65   71   72   74   76   86   87  103  106  115  129  137  142\n",
      "  148  149  155  156  164  166  169  172  176  181  182  186  187  188\n",
      "  189  200  209  213  215  216  219  221  224  242  254  258  259  262\n",
      "  267  270  275  278  282  288  292  293  297  303  304  311  319  324\n",
      "  328  333  342  346  347  351  353  355  360  362  363  365  371  375\n",
      "  384  387  395  397  407  419  420  424  430  451  455  457  461  465\n",
      "  467  469  475  480  481  484  487  488  490  500  504  509  512  522\n",
      "  527  533  542  553  557  558  563  564  568  571  574  576  581  582\n",
      "  590  592  595  602  603  606  607  609  610  615  622  623  629  637\n",
      "  642  645  658  659  662  673  676  679  695  703  705  712  713  715\n",
      "  717  719  721  732  745  748  754  760  769  786  797  808  809  812\n",
      "  824  833  835  851  864  868  872  879  889  890  896  909  911  912\n",
      "  915  916  920  921  924  934  949  950  957  960  968  969  978  979\n",
      "  983  984  986  990 1005 1007 1014 1016 1017 1021 1023 1027 1037 1040\n",
      " 1041 1051 1058 1061 1062 1068 1071 1076 1077 1081 1084 1087 1092 1098\n",
      " 1104 1120 1121 1122 1125 1126 1139 1143 1147 1151 1158 1165 1179 1196\n",
      " 1199 1210 1211 1213 1216 1220 1233 1242 1243 1247 1257 1267 1269 1271\n",
      " 1276 1278 1286 1287 1289 1294 1297 1299 1308 1315 1316 1323 1331 1333\n",
      " 1337 1342 1343 1345 1354 1360 1369 1375 1377 1380 1381 1384 1385 1386\n",
      " 1389 1393 1398 1412 1416 1431 1451 1454 1467 1469 1474 1478 1484 1491\n",
      " 1493 1497 1499 1502 1503 1504 1505 1520 1522 1529 1536 1543 1545 1555\n",
      " 1556 1557 1561 1562 1564 1565 1569 1570 1577 1580 1584 1585 1596 1601\n",
      " 1602 1612 1631 1634 1635 1638 1639 1641 1660 1662 1668 1672 1678 1679\n",
      " 1684 1701 1702 1703 1705 1719 1723 1726 1731 1734 1739 1741 1746 1758\n",
      " 1763 1770 1774 1788 1790 1791 1794 1802 1804 1811 1814 1818 1821 1824\n",
      " 1826 1833 1840 1842 1846 1848 1857 1860 1863 1866 1872 1873 1878 1882\n",
      " 1887 1892 1897 1903 1909 1911 1917 1922 1926 1938 1941 1946 1952 1954\n",
      " 1969 1978 1995 1996 2003 2009 2020 2026 2030 2033 2037 2046 2058 2069\n",
      " 2071 2073 2089 2090 2092 2098 2111 2113 2117 2120 2125 2127 2135 2139\n",
      " 2143 2145 2155 2157 2164 2178 2192 2193 2194 2195 2215 2216 2217 2219\n",
      " 2221 2228 2229 2249 2276 2278 2279 2297 2300 2301 2308 2314 2318 2322\n",
      " 2323 2328 2330 2332 2334 2339 2342 2349 2351 2360 2363 2364 2368 2381\n",
      " 2384 2386 2388 2406 2417 2424 2428 2437 2439 2448 2454 2455 2458 2459\n",
      " 2463 2465 2477 2480 2486 2490 2496 2497 2500 2504 2506 2510 2512 2513\n",
      " 2520 2522 2528 2535 2543 2548 2550 2553 2557 2572 2575 2579 2589 2592\n",
      " 2604 2606 2614 2617 2619 2623 2625 2628 2658 2659 2664 2668 2672 2673\n",
      " 2678 2681 2685 2697 2709 2712 2715 2716 2722 2724 2725 2734 2741 2746\n",
      " 2750 2756 2760 2763 2766 2767 2769 2771 2772 2773 2778 2783 2796 2798\n",
      " 2823 2828 2833 2834 2839 2842 2849 2850 2855 2856 2858 2860 2863 2869\n",
      " 2873 2874 2890 2891 2895 2898 2901 2914 2917 2919 2920 2929 2939 2950\n",
      " 2964 2965 2970 2989 2990 2994 2995 2999 3000 3009 3012 3014 3015 3020\n",
      " 3029 3034 3036 3037 3039 3041 3042 3046 3048 3057 3058 3070 3090 3092\n",
      " 3094 3095 3099 3102 3107 3117 3118 3124 3131 3139 3142 3144 3145 3157\n",
      " 3166 3175 3182 3184 3193 3196 3197 3199 3201 3202 3203 3204 3205 3206\n",
      " 3210 3211 3212 3214 3216 3220 3224 3233 3236 3237 3240 3241 3242 3256\n",
      " 3257 3258 3263 3270 3271 3277 3284 3285 3299 3301 3305 3307 3318 3322\n",
      " 3323 3324 3326 3333 3343 3344 3347 3356 3362 3364 3369 3374 3384 3385\n",
      " 3388 3391 3392 3395 3398 3401 3403 3407 3413 3414 3417 3421 3428 3438\n",
      " 3445 3449 3458 3460 3465 3466 3479 3483 3487 3488 3494 3497 3498 3502\n",
      " 3503 3505 3506 3511 3522 3535 3538 3540 3542 3546 3548 3557 3564 3565\n",
      " 3566 3568 3572 3579 3581 3590 3599 3601 3603 3624 3626 3632 3638 3640\n",
      " 3644 3645 3648 3651 3668 3671 3674 3681 3685 3693 3697 3700 3705 3707\n",
      " 3709 3723 3725 3729 3740 3741 3750 3756 3759 3770 3773 3775 3780 3781\n",
      " 3789 3791 3805 3808 3809 3812 3815 3820 3823 3825 3853 3859 3867 3881\n",
      " 3882 3885 3886 3888 3893 3898 3900 3902 3913 3920 3925 3929 3936 3938\n",
      " 3942 3952 3959 3968 3973 3976 3977 3992 4002 4004 4014 4015 4017 4019\n",
      " 4020 4025 4040 4041 4045 4059 4062 4077 4082 4084 4086 4088 4094 4097\n",
      " 4098 4099 4100 4102 4109 4117 4122 4124 4125 4129 4131 4134 4135 4140\n",
      " 4144 4158 4161 4163 4170 4171 4178 4189 4198 4208 4210 4218 4220 4226\n",
      " 4229 4232 4234 4235 4237 4244 4251 4258 4262 4265 4269 4276 4278 4282\n",
      " 4283 4287 4291 4299 4300 4301 4303 4308 4309 4312 4319 4321 4343 4344\n",
      " 4346 4347 4348 4350 4359 4364 4367 4368 4370 4376 4377 4378 4380 4382\n",
      " 4383 4386 4388 4397 4401 4405 4409 4412 4414 4417 4419 4436 4447 4450\n",
      " 4452 4454 4456 4467 4474 4478 4479 4482 4485 4490 4491 4495 4504 4513\n",
      " 4514 4515 4521 4534 4537 4550 4554 4558 4559 4560 4567 4572 4583 4597\n",
      " 4598 4601 4605 4606 4609 4611 4612 4621 4623 4631 4635 4643 4650 4663\n",
      " 4671 4673 4686 4687 4709 4715 4722 4738 4744 4747 4751 4753 4762 4765\n",
      " 4767 4774 4778 4779 4783 4793 4797 4798 4805 4809 4814 4829 4835 4839\n",
      " 4841 4844 4848 4849 4854 4856]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:03:52.927069: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_306/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.0977 - accuracy: 0.3480 - val_loss: 1.0977 - val_accuracy: 0.3261 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0750 - accuracy: 0.4020 - val_loss: 1.1208 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0583 - accuracy: 0.4257 - val_loss: 1.1207 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0409 - accuracy: 0.4331 - val_loss: 1.1142 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0337 - accuracy: 0.4316 - val_loss: 1.0929 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0272 - accuracy: 0.4424 - val_loss: 1.0901 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0263 - accuracy: 0.4550 - val_loss: 1.1199 - val_accuracy: 0.3642 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0232 - accuracy: 0.4565 - val_loss: 1.1167 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0142 - accuracy: 0.4560 - val_loss: 1.1140 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4601 - val_loss: 1.1119 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0111 - accuracy: 0.4563 - val_loss: 1.1555 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0105 - accuracy: 0.4576 - val_loss: 1.1580 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0112 - accuracy: 0.4645 - val_loss: 1.1283 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 0.9953 - accuracy: 0.4663 - val_loss: 1.1714 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0006 - accuracy: 0.4622 - val_loss: 1.1683 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 0.9904 - accuracy: 0.4617 - val_loss: 1.1663 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 0.9848 - accuracy: 0.4632 - val_loss: 1.1929 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 0.9862 - accuracy: 0.4761 - val_loss: 1.1746 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 0.9824 - accuracy: 0.4730 - val_loss: 1.1983 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 0.9812 - accuracy: 0.4702 - val_loss: 1.2759 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 0.9881 - accuracy: 0.4606 - val_loss: 1.1647 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 0.9779 - accuracy: 0.4794 - val_loss: 1.1645 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 0.9749 - accuracy: 0.4889 - val_loss: 1.3033 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9829 - accuracy: 0.4797 - val_loss: 1.2847 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9841 - accuracy: 0.4697 - val_loss: 1.1479 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 0.9795 - accuracy: 0.4799 - val_loss: 1.2009 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9781 - accuracy: 0.4830 - val_loss: 1.2420 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9798 - accuracy: 0.4769 - val_loss: 1.1642 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9727 - accuracy: 0.4851 - val_loss: 1.1383 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9809 - accuracy: 0.4745 - val_loss: 1.0883 - val_accuracy: 0.3519 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9687 - accuracy: 0.4817 - val_loss: 1.1990 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9690 - accuracy: 0.4838 - val_loss: 1.0861 - val_accuracy: 0.3663 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9688 - accuracy: 0.4812 - val_loss: 1.0908 - val_accuracy: 0.3519 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9673 - accuracy: 0.4802 - val_loss: 1.0935 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9638 - accuracy: 0.4902 - val_loss: 1.2008 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9600 - accuracy: 0.4815 - val_loss: 1.1883 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9677 - accuracy: 0.4781 - val_loss: 1.1332 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9573 - accuracy: 0.4861 - val_loss: 1.2021 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9547 - accuracy: 0.4879 - val_loss: 1.1213 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9570 - accuracy: 0.4838 - val_loss: 1.1055 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9595 - accuracy: 0.4805 - val_loss: 1.1532 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9637 - accuracy: 0.4864 - val_loss: 1.1857 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9454 - accuracy: 0.4943 - val_loss: 1.1823 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9567 - accuracy: 0.4879 - val_loss: 1.2162 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9547 - accuracy: 0.4987 - val_loss: 1.2698 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9487 - accuracy: 0.4915 - val_loss: 1.2646 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9397 - accuracy: 0.4982 - val_loss: 1.2759 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9422 - accuracy: 0.5023 - val_loss: 1.3186 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9506 - accuracy: 0.4961 - val_loss: 1.2485 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9495 - accuracy: 0.4925 - val_loss: 1.2319 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9419 - accuracy: 0.5008 - val_loss: 1.2022 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9411 - accuracy: 0.4910 - val_loss: 1.2973 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9434 - accuracy: 0.5059 - val_loss: 1.3491 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9449 - accuracy: 0.4913 - val_loss: 1.3771 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9403 - accuracy: 0.4954 - val_loss: 1.3915 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9399 - accuracy: 0.5041 - val_loss: 1.2869 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9422 - accuracy: 0.4936 - val_loss: 1.3903 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9376 - accuracy: 0.4949 - val_loss: 1.3716 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9459 - accuracy: 0.4997 - val_loss: 1.4222 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9384 - accuracy: 0.4925 - val_loss: 1.2860 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9499 - accuracy: 0.5015 - val_loss: 1.2042 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9316 - accuracy: 0.5082 - val_loss: 1.2685 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9438 - accuracy: 0.4967 - val_loss: 1.3311 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9388 - accuracy: 0.5054 - val_loss: 1.3603 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9433 - accuracy: 0.4977 - val_loss: 1.3455 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9366 - accuracy: 0.5039 - val_loss: 1.4261 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9281 - accuracy: 0.5064 - val_loss: 1.3714 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9405 - accuracy: 0.4938 - val_loss: 1.3601 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9391 - accuracy: 0.5023 - val_loss: 1.2938 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9322 - accuracy: 0.5031 - val_loss: 1.3047 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9400 - accuracy: 0.5090 - val_loss: 1.2366 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9325 - accuracy: 0.5003 - val_loss: 1.2986 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9282 - accuracy: 0.5123 - val_loss: 1.3625 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9312 - accuracy: 0.5095 - val_loss: 1.2614 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9328 - accuracy: 0.5062 - val_loss: 1.1792 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9261 - accuracy: 0.4974 - val_loss: 1.4235 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9240 - accuracy: 0.5085 - val_loss: 1.4093 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9312 - accuracy: 0.5095 - val_loss: 1.4415 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9224 - accuracy: 0.5093 - val_loss: 1.3801 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9291 - accuracy: 0.5054 - val_loss: 1.3221 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9257 - accuracy: 0.5062 - val_loss: 1.5889 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9323 - accuracy: 0.5139 - val_loss: 1.6531 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9299 - accuracy: 0.5157 - val_loss: 1.5548 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9352 - accuracy: 0.5010 - val_loss: 1.5861 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9322 - accuracy: 0.5062 - val_loss: 1.5997 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9306 - accuracy: 0.5044 - val_loss: 1.5147 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9278 - accuracy: 0.5167 - val_loss: 1.6440 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9233 - accuracy: 0.5147 - val_loss: 1.6207 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5111 - val_loss: 1.5136 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9238 - accuracy: 0.5033 - val_loss: 1.6815 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5136 - val_loss: 1.5952 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9201 - accuracy: 0.5221 - val_loss: 1.5954 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9283 - accuracy: 0.5067 - val_loss: 1.4730 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9222 - accuracy: 0.5082 - val_loss: 1.4817 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9267 - accuracy: 0.5159 - val_loss: 1.5920 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9329 - accuracy: 0.5113 - val_loss: 1.4225 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9213 - accuracy: 0.5172 - val_loss: 1.4010 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9162 - accuracy: 0.5265 - val_loss: 1.4736 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9299 - accuracy: 0.5118 - val_loss: 1.5760 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9349 - accuracy: 0.5126 - val_loss: 1.5177 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9212 - accuracy: 0.5149 - val_loss: 1.4761 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9178 - accuracy: 0.5195 - val_loss: 1.4079 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9258 - accuracy: 0.5141 - val_loss: 1.4360 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9275 - accuracy: 0.5123 - val_loss: 1.5250 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9227 - accuracy: 0.5198 - val_loss: 1.6676 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9132 - accuracy: 0.5159 - val_loss: 1.6847 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.9179 - accuracy: 0.5221 - val_loss: 1.5181 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9090 - accuracy: 0.5224 - val_loss: 1.4990 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.9179 - accuracy: 0.5121 - val_loss: 1.5633 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9116 - accuracy: 0.5211 - val_loss: 1.5316 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9170 - accuracy: 0.5057 - val_loss: 1.4589 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9121 - accuracy: 0.5327 - val_loss: 1.4784 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9100 - accuracy: 0.5185 - val_loss: 1.5081 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9254 - accuracy: 0.5201 - val_loss: 1.5908 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9294 - accuracy: 0.5021 - val_loss: 1.5667 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9142 - accuracy: 0.5262 - val_loss: 1.5485 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9208 - accuracy: 0.5193 - val_loss: 1.6137 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9138 - accuracy: 0.5206 - val_loss: 1.6649 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9237 - accuracy: 0.5129 - val_loss: 1.5359 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9243 - accuracy: 0.5152 - val_loss: 1.5359 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9130 - accuracy: 0.5170 - val_loss: 1.6649 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9140 - accuracy: 0.5203 - val_loss: 1.6517 - val_accuracy: 0.3477 - 1s/epoch - 5ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9086 - accuracy: 0.5134 - val_loss: 1.6636 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9162 - accuracy: 0.5340 - val_loss: 1.6442 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.9124 - accuracy: 0.5244 - val_loss: 1.4645 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.9109 - accuracy: 0.5206 - val_loss: 1.3747 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9188 - accuracy: 0.5175 - val_loss: 1.6018 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.9149 - accuracy: 0.5229 - val_loss: 1.5440 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.9124 - accuracy: 0.5201 - val_loss: 1.4836 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9089 - accuracy: 0.5322 - val_loss: 1.6321 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.9078 - accuracy: 0.5283 - val_loss: 1.5581 - val_accuracy: 0.3498 - 986ms/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.9180 - accuracy: 0.5345 - val_loss: 1.4131 - val_accuracy: 0.3488 - 983ms/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9173 - accuracy: 0.5175 - val_loss: 1.6846 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.9123 - accuracy: 0.5165 - val_loss: 1.8359 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.9038 - accuracy: 0.5221 - val_loss: 1.6721 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.9089 - accuracy: 0.5301 - val_loss: 1.6552 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9069 - accuracy: 0.5334 - val_loss: 1.6494 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.9006 - accuracy: 0.5370 - val_loss: 1.7553 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.9218 - accuracy: 0.5085 - val_loss: 1.5057 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.9170 - accuracy: 0.5039 - val_loss: 1.4534 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9072 - accuracy: 0.5172 - val_loss: 1.4531 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9084 - accuracy: 0.5219 - val_loss: 1.6892 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9049 - accuracy: 0.5255 - val_loss: 1.6133 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.9135 - accuracy: 0.5111 - val_loss: 1.4677 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.9111 - accuracy: 0.5195 - val_loss: 1.6612 - val_accuracy: 0.3529 - 1s/epoch - 5ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9097 - accuracy: 0.5275 - val_loss: 1.6680 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.9102 - accuracy: 0.5311 - val_loss: 1.6576 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.9149 - accuracy: 0.5118 - val_loss: 1.5841 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.8984 - accuracy: 0.5303 - val_loss: 1.7837 - val_accuracy: 0.3519 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.9051 - accuracy: 0.5322 - val_loss: 1.6643 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.9184 - accuracy: 0.5255 - val_loss: 1.6973 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.9034 - accuracy: 0.5358 - val_loss: 1.8902 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.9014 - accuracy: 0.5381 - val_loss: 1.7133 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.9059 - accuracy: 0.5303 - val_loss: 1.4883 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.9014 - accuracy: 0.5298 - val_loss: 1.5991 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.9070 - accuracy: 0.5234 - val_loss: 1.5040 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9060 - accuracy: 0.5306 - val_loss: 1.7274 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.8921 - accuracy: 0.5355 - val_loss: 1.7337 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.9175 - accuracy: 0.5195 - val_loss: 1.5218 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.9044 - accuracy: 0.5293 - val_loss: 1.7297 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9034 - accuracy: 0.5288 - val_loss: 1.8126 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.9143 - accuracy: 0.5237 - val_loss: 1.7269 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.9040 - accuracy: 0.5383 - val_loss: 1.7042 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.9024 - accuracy: 0.5350 - val_loss: 1.8422 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.8975 - accuracy: 0.5337 - val_loss: 1.7431 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.8964 - accuracy: 0.5340 - val_loss: 1.7760 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.9082 - accuracy: 0.5329 - val_loss: 1.8144 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.9067 - accuracy: 0.5288 - val_loss: 1.8840 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.9050 - accuracy: 0.5257 - val_loss: 2.1419 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.9090 - accuracy: 0.5278 - val_loss: 1.8496 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.9114 - accuracy: 0.5267 - val_loss: 1.7540 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.8972 - accuracy: 0.5412 - val_loss: 2.0091 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.8977 - accuracy: 0.5409 - val_loss: 1.9595 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.9070 - accuracy: 0.5337 - val_loss: 1.8677 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9045 - accuracy: 0.5288 - val_loss: 1.8925 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.9092 - accuracy: 0.5260 - val_loss: 1.8471 - val_accuracy: 0.3477 - 1s/epoch - 5ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.8968 - accuracy: 0.5350 - val_loss: 1.8402 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.9045 - accuracy: 0.5360 - val_loss: 1.7714 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.9107 - accuracy: 0.5247 - val_loss: 1.6482 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.8932 - accuracy: 0.5406 - val_loss: 1.7915 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.8982 - accuracy: 0.5352 - val_loss: 1.8094 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.8993 - accuracy: 0.5322 - val_loss: 1.7672 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.9023 - accuracy: 0.5396 - val_loss: 1.8345 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.8948 - accuracy: 0.5342 - val_loss: 1.8159 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.8967 - accuracy: 0.5267 - val_loss: 2.0774 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.9073 - accuracy: 0.5314 - val_loss: 2.0897 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.8970 - accuracy: 0.5319 - val_loss: 1.9565 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.8957 - accuracy: 0.5340 - val_loss: 1.9929 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.9093 - accuracy: 0.5170 - val_loss: 1.8938 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.9099 - accuracy: 0.5275 - val_loss: 1.9117 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.9097 - accuracy: 0.5365 - val_loss: 1.5440 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9080 - accuracy: 0.5301 - val_loss: 1.6559 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.9132 - accuracy: 0.5265 - val_loss: 1.5884 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.9011 - accuracy: 0.5296 - val_loss: 1.7372 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.9042 - accuracy: 0.5368 - val_loss: 1.5506 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.9018 - accuracy: 0.5316 - val_loss: 1.5612 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.8962 - accuracy: 0.5350 - val_loss: 1.6626 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.8917 - accuracy: 0.5350 - val_loss: 1.6254 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.8934 - accuracy: 0.5442 - val_loss: 1.6813 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.8887 - accuracy: 0.5473 - val_loss: 1.5172 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.9011 - accuracy: 0.5260 - val_loss: 1.4430 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.9061 - accuracy: 0.5242 - val_loss: 1.6617 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.8994 - accuracy: 0.5347 - val_loss: 1.5450 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.9009 - accuracy: 0.5350 - val_loss: 1.6512 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.9035 - accuracy: 0.5249 - val_loss: 1.8951 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.9079 - accuracy: 0.5296 - val_loss: 1.4809 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.9090 - accuracy: 0.5370 - val_loss: 1.6338 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.8954 - accuracy: 0.5388 - val_loss: 1.7158 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.8914 - accuracy: 0.5442 - val_loss: 1.6979 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.9088 - accuracy: 0.5167 - val_loss: 1.6594 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.8832 - accuracy: 0.5417 - val_loss: 1.6745 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9022 - accuracy: 0.5409 - val_loss: 1.5786 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9130 - accuracy: 0.5249 - val_loss: 1.6688 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.8953 - accuracy: 0.5412 - val_loss: 1.7756 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.9003 - accuracy: 0.5293 - val_loss: 1.7022 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.8976 - accuracy: 0.5386 - val_loss: 1.7394 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.8954 - accuracy: 0.5298 - val_loss: 1.9100 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.8993 - accuracy: 0.5358 - val_loss: 1.8550 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.8945 - accuracy: 0.5381 - val_loss: 1.7551 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.8957 - accuracy: 0.5435 - val_loss: 1.9053 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.8861 - accuracy: 0.5414 - val_loss: 2.1264 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.9005 - accuracy: 0.5293 - val_loss: 2.0602 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.8995 - accuracy: 0.5394 - val_loss: 1.9633 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.8908 - accuracy: 0.5350 - val_loss: 1.8216 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.9043 - accuracy: 0.5322 - val_loss: 1.6562 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.9019 - accuracy: 0.5303 - val_loss: 1.7770 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.8991 - accuracy: 0.5288 - val_loss: 1.4493 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.8991 - accuracy: 0.5334 - val_loss: 1.6754 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.8874 - accuracy: 0.5406 - val_loss: 1.7065 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.8893 - accuracy: 0.5432 - val_loss: 1.6514 - val_accuracy: 0.3488 - 1s/epoch - 5ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.8991 - accuracy: 0.5419 - val_loss: 1.7940 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.8870 - accuracy: 0.5450 - val_loss: 1.9332 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.8927 - accuracy: 0.5424 - val_loss: 1.8799 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.8896 - accuracy: 0.5473 - val_loss: 2.0379 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.9000 - accuracy: 0.5440 - val_loss: 1.9750 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.9028 - accuracy: 0.5283 - val_loss: 1.6496 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.8994 - accuracy: 0.5301 - val_loss: 1.8198 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.8891 - accuracy: 0.5458 - val_loss: 1.8954 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.8915 - accuracy: 0.5378 - val_loss: 1.9767 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.8983 - accuracy: 0.5401 - val_loss: 1.7189 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9007 - accuracy: 0.5322 - val_loss: 1.6722 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.8891 - accuracy: 0.5391 - val_loss: 1.8315 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.8986 - accuracy: 0.5427 - val_loss: 1.6189 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.8931 - accuracy: 0.5363 - val_loss: 1.4962 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.8846 - accuracy: 0.5460 - val_loss: 1.5879 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.8950 - accuracy: 0.5409 - val_loss: 1.5846 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9030 - accuracy: 0.5291 - val_loss: 1.7989 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.8930 - accuracy: 0.5473 - val_loss: 1.8757 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.8930 - accuracy: 0.5404 - val_loss: 1.7947 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9013 - accuracy: 0.5311 - val_loss: 1.6693 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   1    2    3 ... 4856 4857 4858]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   0   10   12   13   16   29   36   39   40   43   46   66   73   75\n",
      "   85   88   91   99  100  102  105  110  111  117  123  124  127  128\n",
      "  132  133  136  153  157  159  160  174  177  190  192  193  195  204\n",
      "  208  210  212  214  217  232  244  266  269  286  296  309  316  326\n",
      "  332  335  344  368  369  370  373  383  391  392  394  398  399  401\n",
      "  403  404  405  406  410  416  423  441  444  452  453  459  476  492\n",
      "  494  497  511  513  514  518  521  525  531  534  535  537  546  547\n",
      "  551  554  556  565  575  579  596  597  600  601  616  635  636  646\n",
      "  657  663  664  665  669  672  684  685  687  693  694  698  701  714\n",
      "  730  731  733  738  740  742  743  746  749  752  756  759  766  768\n",
      "  770  774  787  789  790  795  801  802  804  816  817  818  822  825\n",
      "  830  832  842  847  853  854  856  857  859  861  862  874  876  882\n",
      "  893  910  913  925  927  945  946  958  965  966  971  972  975  976\n",
      "  977  991  998 1002 1013 1018 1043 1049 1056 1057 1065 1066 1069 1070\n",
      " 1078 1082 1089 1090 1097 1100 1111 1112 1116 1127 1128 1130 1133 1134\n",
      " 1145 1152 1156 1159 1162 1167 1170 1175 1177 1181 1182 1186 1187 1189\n",
      " 1192 1198 1201 1204 1205 1207 1212 1214 1219 1221 1225 1227 1230 1235\n",
      " 1240 1244 1249 1256 1258 1259 1261 1268 1270 1275 1279 1290 1293 1296\n",
      " 1300 1312 1314 1317 1321 1328 1347 1362 1365 1371 1373 1376 1378 1383\n",
      " 1390 1391 1392 1395 1397 1401 1404 1407 1411 1422 1432 1434 1447 1450\n",
      " 1452 1459 1460 1462 1476 1479 1483 1486 1489 1495 1523 1526 1527 1528\n",
      " 1534 1544 1547 1548 1553 1558 1568 1571 1579 1586 1587 1594 1599 1604\n",
      " 1607 1609 1621 1627 1628 1636 1642 1648 1652 1655 1656 1661 1670 1671\n",
      " 1673 1683 1689 1690 1700 1706 1708 1712 1713 1721 1725 1728 1730 1735\n",
      " 1737 1742 1743 1755 1760 1762 1771 1777 1778 1782 1785 1786 1805 1812\n",
      " 1815 1816 1820 1829 1830 1832 1837 1843 1849 1850 1851 1856 1859 1862\n",
      " 1869 1874 1880 1884 1895 1899 1910 1918 1921 1930 1932 1937 1943 1944\n",
      " 1949 1950 1957 1968 1970 1974 1976 1984 1986 1991 2005 2006 2007 2010\n",
      " 2013 2014 2015 2017 2018 2034 2036 2039 2041 2042 2052 2054 2060 2064\n",
      " 2077 2083 2084 2095 2097 2110 2116 2123 2129 2131 2132 2140 2142 2147\n",
      " 2151 2156 2158 2167 2174 2175 2176 2179 2180 2184 2190 2201 2203 2206\n",
      " 2210 2227 2235 2237 2239 2244 2247 2248 2259 2264 2272 2275 2281 2283\n",
      " 2285 2294 2311 2313 2319 2321 2325 2327 2329 2336 2345 2359 2361 2362\n",
      " 2367 2377 2382 2383 2391 2395 2397 2404 2407 2408 2412 2418 2420 2429\n",
      " 2430 2438 2441 2451 2461 2474 2478 2479 2484 2488 2494 2499 2511 2518\n",
      " 2519 2525 2531 2538 2541 2555 2563 2571 2580 2583 2585 2588 2594 2596\n",
      " 2597 2598 2599 2600 2603 2605 2608 2612 2616 2620 2631 2633 2634 2635\n",
      " 2636 2651 2652 2653 2654 2662 2667 2670 2680 2684 2690 2691 2701 2704\n",
      " 2706 2714 2718 2723 2726 2727 2730 2732 2749 2754 2758 2759 2764 2765\n",
      " 2776 2788 2794 2801 2802 2805 2814 2818 2832 2845 2854 2857 2864 2866\n",
      " 2868 2877 2878 2880 2883 2885 2889 2894 2896 2897 2899 2900 2903 2905\n",
      " 2909 2911 2918 2927 2931 2944 2945 2946 2952 2954 2958 2961 2967 2968\n",
      " 2973 2977 2982 2985 2992 2996 3003 3011 3016 3017 3026 3033 3040 3043\n",
      " 3044 3052 3054 3055 3072 3075 3079 3081 3084 3085 3086 3087 3097 3104\n",
      " 3120 3121 3127 3137 3138 3140 3149 3158 3160 3165 3167 3177 3179 3191\n",
      " 3194 3200 3213 3215 3251 3252 3255 3261 3273 3280 3282 3289 3304 3306\n",
      " 3312 3316 3320 3331 3334 3335 3337 3340 3350 3353 3354 3358 3359 3360\n",
      " 3365 3367 3376 3377 3381 3386 3387 3389 3399 3404 3409 3411 3416 3423\n",
      " 3425 3426 3432 3433 3440 3446 3453 3459 3461 3462 3463 3472 3478 3481\n",
      " 3482 3484 3490 3491 3493 3507 3509 3523 3526 3528 3533 3534 3537 3539\n",
      " 3547 3552 3554 3558 3570 3576 3578 3583 3584 3585 3598 3600 3605 3606\n",
      " 3608 3610 3612 3613 3614 3616 3620 3621 3627 3633 3635 3661 3662 3663\n",
      " 3679 3682 3684 3690 3699 3704 3706 3708 3711 3714 3716 3719 3720 3728\n",
      " 3730 3735 3737 3739 3744 3746 3751 3753 3754 3758 3760 3761 3777 3782\n",
      " 3786 3790 3795 3800 3803 3804 3813 3818 3824 3828 3833 3835 3837 3840\n",
      " 3844 3845 3849 3850 3858 3861 3865 3868 3869 3876 3877 3879 3891 3905\n",
      " 3909 3923 3930 3941 3951 3960 3961 3965 3967 3972 3978 3982 3985 3987\n",
      " 3989 3993 3994 3995 4001 4006 4018 4023 4027 4030 4033 4034 4036 4037\n",
      " 4043 4049 4054 4055 4067 4068 4078 4092 4105 4112 4115 4116 4120 4130\n",
      " 4132 4137 4138 4145 4157 4166 4167 4180 4184 4185 4187 4190 4195 4205\n",
      " 4206 4215 4222 4224 4240 4249 4255 4256 4259 4261 4263 4267 4268 4275\n",
      " 4284 4286 4289 4290 4294 4296 4297 4311 4313 4315 4322 4335 4341 4354\n",
      " 4362 4363 4365 4371 4394 4406 4408 4416 4418 4420 4433 4434 4444 4448\n",
      " 4449 4458 4466 4472 4475 4487 4488 4489 4492 4497 4498 4500 4508 4509\n",
      " 4510 4516 4518 4528 4530 4533 4540 4544 4546 4547 4548 4561 4576 4577\n",
      " 4578 4579 4585 4591 4593 4596 4600 4607 4613 4615 4616 4617 4620 4622\n",
      " 4626 4633 4659 4664 4674 4675 4683 4688 4689 4694 4700 4704 4707 4711\n",
      " 4721 4724 4727 4729 4733 4734 4737 4741 4748 4750 4752 4754 4757 4758\n",
      " 4763 4768 4772 4782 4788 4789 4794 4795 4800 4802 4803 4807 4818 4821\n",
      " 4826 4827 4830 4845 4850 4859]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:08:21.413386: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_307/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.0954 - accuracy: 0.3621 - val_loss: 1.0965 - val_accuracy: 0.3220 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0796 - accuracy: 0.4033 - val_loss: 1.0971 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0751 - accuracy: 0.4059 - val_loss: 1.0956 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0502 - accuracy: 0.4228 - val_loss: 1.0962 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0399 - accuracy: 0.4270 - val_loss: 1.1226 - val_accuracy: 0.3210 - 1s/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0255 - accuracy: 0.4514 - val_loss: 1.1796 - val_accuracy: 0.3210 - 1s/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0275 - accuracy: 0.4516 - val_loss: 1.1893 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0121 - accuracy: 0.4570 - val_loss: 1.2026 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0142 - accuracy: 0.4681 - val_loss: 1.2017 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0038 - accuracy: 0.4640 - val_loss: 1.2287 - val_accuracy: 0.3210 - 980ms/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0007 - accuracy: 0.4704 - val_loss: 1.1683 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 0.9876 - accuracy: 0.4697 - val_loss: 1.1419 - val_accuracy: 0.3210 - 1s/epoch - 5ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 0.9936 - accuracy: 0.4668 - val_loss: 1.1506 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 0.9900 - accuracy: 0.4632 - val_loss: 1.1731 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 0.9753 - accuracy: 0.4748 - val_loss: 1.1667 - val_accuracy: 0.3189 - 1s/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 0.9829 - accuracy: 0.4859 - val_loss: 1.1772 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 0.9859 - accuracy: 0.4720 - val_loss: 1.1022 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 0.9755 - accuracy: 0.4794 - val_loss: 1.1798 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 0.9740 - accuracy: 0.4766 - val_loss: 1.1803 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 0.9798 - accuracy: 0.4727 - val_loss: 1.1882 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 0.9737 - accuracy: 0.4879 - val_loss: 1.1684 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 0.9676 - accuracy: 0.4884 - val_loss: 1.1383 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 0.9660 - accuracy: 0.4851 - val_loss: 1.1696 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9670 - accuracy: 0.4869 - val_loss: 1.1283 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9647 - accuracy: 0.4722 - val_loss: 1.0908 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 0.9609 - accuracy: 0.4895 - val_loss: 1.1355 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9609 - accuracy: 0.4892 - val_loss: 1.1226 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9553 - accuracy: 0.5028 - val_loss: 1.0910 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9615 - accuracy: 0.4877 - val_loss: 1.1055 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9562 - accuracy: 0.4897 - val_loss: 1.1037 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9525 - accuracy: 0.4990 - val_loss: 1.1031 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9505 - accuracy: 0.4900 - val_loss: 1.1054 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9469 - accuracy: 0.4990 - val_loss: 1.0933 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9625 - accuracy: 0.4969 - val_loss: 1.1213 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9565 - accuracy: 0.5044 - val_loss: 1.1003 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9594 - accuracy: 0.4841 - val_loss: 1.1011 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9554 - accuracy: 0.5003 - val_loss: 1.1162 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9459 - accuracy: 0.4956 - val_loss: 1.1011 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9473 - accuracy: 0.4956 - val_loss: 1.1110 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9465 - accuracy: 0.4987 - val_loss: 1.1355 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9358 - accuracy: 0.5036 - val_loss: 1.1321 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9457 - accuracy: 0.4987 - val_loss: 1.0959 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9375 - accuracy: 0.5123 - val_loss: 1.0968 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9376 - accuracy: 0.5121 - val_loss: 1.1014 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9495 - accuracy: 0.5000 - val_loss: 1.1162 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9400 - accuracy: 0.5077 - val_loss: 1.2184 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9412 - accuracy: 0.5195 - val_loss: 1.1018 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9435 - accuracy: 0.5028 - val_loss: 1.1021 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9464 - accuracy: 0.4879 - val_loss: 1.1144 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9341 - accuracy: 0.5121 - val_loss: 1.1492 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9370 - accuracy: 0.5108 - val_loss: 1.1416 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9324 - accuracy: 0.5113 - val_loss: 1.1271 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9345 - accuracy: 0.5213 - val_loss: 1.1093 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9412 - accuracy: 0.5126 - val_loss: 1.1264 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9302 - accuracy: 0.5136 - val_loss: 1.1273 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9305 - accuracy: 0.5113 - val_loss: 1.1045 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9395 - accuracy: 0.4990 - val_loss: 1.1023 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9392 - accuracy: 0.5028 - val_loss: 1.1113 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9301 - accuracy: 0.5111 - val_loss: 1.1431 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9315 - accuracy: 0.5087 - val_loss: 1.1569 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9343 - accuracy: 0.5090 - val_loss: 1.1675 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9324 - accuracy: 0.5000 - val_loss: 1.1622 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9285 - accuracy: 0.5175 - val_loss: 1.1751 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9347 - accuracy: 0.5069 - val_loss: 1.1593 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9183 - accuracy: 0.5324 - val_loss: 1.1697 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9305 - accuracy: 0.5165 - val_loss: 1.1524 - val_accuracy: 0.3169 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9370 - accuracy: 0.5121 - val_loss: 1.1806 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9310 - accuracy: 0.5170 - val_loss: 1.2424 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9291 - accuracy: 0.5111 - val_loss: 1.1937 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9313 - accuracy: 0.5067 - val_loss: 1.2272 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9217 - accuracy: 0.5252 - val_loss: 1.2653 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9329 - accuracy: 0.5159 - val_loss: 1.1518 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9363 - accuracy: 0.5157 - val_loss: 1.1428 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9357 - accuracy: 0.5021 - val_loss: 1.1355 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9257 - accuracy: 0.5129 - val_loss: 1.1824 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9340 - accuracy: 0.5057 - val_loss: 1.2917 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9234 - accuracy: 0.5219 - val_loss: 1.2103 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9170 - accuracy: 0.5252 - val_loss: 1.2049 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9246 - accuracy: 0.5190 - val_loss: 1.1716 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9315 - accuracy: 0.5183 - val_loss: 1.1864 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9282 - accuracy: 0.5172 - val_loss: 1.2682 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9197 - accuracy: 0.5239 - val_loss: 1.2122 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9161 - accuracy: 0.5095 - val_loss: 1.2166 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9201 - accuracy: 0.5152 - val_loss: 1.2460 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9300 - accuracy: 0.5129 - val_loss: 1.2344 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9133 - accuracy: 0.5347 - val_loss: 1.2611 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9299 - accuracy: 0.5147 - val_loss: 1.4129 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9265 - accuracy: 0.5219 - val_loss: 1.3473 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9196 - accuracy: 0.5126 - val_loss: 1.2345 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9155 - accuracy: 0.5278 - val_loss: 1.2363 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9267 - accuracy: 0.5285 - val_loss: 1.3475 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9101 - accuracy: 0.5311 - val_loss: 1.3664 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9245 - accuracy: 0.5285 - val_loss: 1.2867 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9298 - accuracy: 0.5121 - val_loss: 1.2604 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9180 - accuracy: 0.5193 - val_loss: 1.3105 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9166 - accuracy: 0.5211 - val_loss: 1.3426 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9119 - accuracy: 0.5185 - val_loss: 1.2053 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9145 - accuracy: 0.5211 - val_loss: 1.1764 - val_accuracy: 0.3200 - 1s/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9233 - accuracy: 0.5237 - val_loss: 1.1675 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9201 - accuracy: 0.5265 - val_loss: 1.2226 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9144 - accuracy: 0.5213 - val_loss: 1.2583 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9105 - accuracy: 0.5309 - val_loss: 1.1637 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9114 - accuracy: 0.5260 - val_loss: 1.2747 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9144 - accuracy: 0.5430 - val_loss: 1.4086 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9178 - accuracy: 0.5273 - val_loss: 1.2912 - val_accuracy: 0.3200 - 1s/epoch - 5ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9030 - accuracy: 0.5324 - val_loss: 1.2515 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.9114 - accuracy: 0.5322 - val_loss: 1.2805 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9214 - accuracy: 0.5188 - val_loss: 1.3041 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.9068 - accuracy: 0.5352 - val_loss: 1.2679 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9266 - accuracy: 0.5211 - val_loss: 1.3418 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9067 - accuracy: 0.5278 - val_loss: 1.4071 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9113 - accuracy: 0.5219 - val_loss: 1.3224 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9145 - accuracy: 0.5244 - val_loss: 1.3093 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9156 - accuracy: 0.5262 - val_loss: 1.3698 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9143 - accuracy: 0.5203 - val_loss: 1.3945 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9159 - accuracy: 0.5252 - val_loss: 1.3928 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9143 - accuracy: 0.5239 - val_loss: 1.2686 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9200 - accuracy: 0.5265 - val_loss: 1.2661 - val_accuracy: 0.3200 - 1s/epoch - 5ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9163 - accuracy: 0.5337 - val_loss: 1.3267 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9117 - accuracy: 0.5291 - val_loss: 1.2626 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9098 - accuracy: 0.5358 - val_loss: 1.3742 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9183 - accuracy: 0.5201 - val_loss: 1.2486 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9083 - accuracy: 0.5311 - val_loss: 1.3277 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9167 - accuracy: 0.5252 - val_loss: 1.3145 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.9120 - accuracy: 0.5355 - val_loss: 1.3515 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.9096 - accuracy: 0.5352 - val_loss: 1.3244 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9048 - accuracy: 0.5350 - val_loss: 1.5399 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.9088 - accuracy: 0.5309 - val_loss: 1.5095 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.9072 - accuracy: 0.5373 - val_loss: 1.4681 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9149 - accuracy: 0.5190 - val_loss: 1.4074 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.9122 - accuracy: 0.5306 - val_loss: 1.3703 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.9154 - accuracy: 0.5203 - val_loss: 1.3268 - val_accuracy: 0.3200 - 1s/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9079 - accuracy: 0.5322 - val_loss: 1.2310 - val_accuracy: 0.3210 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.9069 - accuracy: 0.5360 - val_loss: 1.2577 - val_accuracy: 0.3200 - 1s/epoch - 5ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.9033 - accuracy: 0.5355 - val_loss: 1.1956 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.9180 - accuracy: 0.5167 - val_loss: 1.1328 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9161 - accuracy: 0.5298 - val_loss: 1.2150 - val_accuracy: 0.3179 - 1s/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.8960 - accuracy: 0.5440 - val_loss: 1.2717 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.9206 - accuracy: 0.5226 - val_loss: 1.1723 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.8974 - accuracy: 0.5378 - val_loss: 1.1522 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9070 - accuracy: 0.5406 - val_loss: 1.2686 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9187 - accuracy: 0.5213 - val_loss: 1.1482 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9071 - accuracy: 0.5363 - val_loss: 1.2022 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.9042 - accuracy: 0.5262 - val_loss: 1.2339 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.9075 - accuracy: 0.5386 - val_loss: 1.3150 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9061 - accuracy: 0.5316 - val_loss: 1.2811 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.8959 - accuracy: 0.5298 - val_loss: 1.2686 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.9108 - accuracy: 0.5391 - val_loss: 1.3318 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.9105 - accuracy: 0.5303 - val_loss: 1.3006 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.8969 - accuracy: 0.5342 - val_loss: 1.5054 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.9043 - accuracy: 0.5399 - val_loss: 1.2200 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.9113 - accuracy: 0.5242 - val_loss: 1.1828 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.9137 - accuracy: 0.5283 - val_loss: 1.2243 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.9001 - accuracy: 0.5285 - val_loss: 1.2707 - val_accuracy: 0.3189 - 1s/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.8968 - accuracy: 0.5329 - val_loss: 1.2452 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.8998 - accuracy: 0.5430 - val_loss: 1.1991 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9132 - accuracy: 0.5275 - val_loss: 1.3017 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.9032 - accuracy: 0.5360 - val_loss: 1.2203 - val_accuracy: 0.3169 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.9004 - accuracy: 0.5298 - val_loss: 1.3168 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.8969 - accuracy: 0.5468 - val_loss: 1.3525 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.8980 - accuracy: 0.5342 - val_loss: 1.4252 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.9026 - accuracy: 0.5314 - val_loss: 1.3791 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.9058 - accuracy: 0.5234 - val_loss: 1.2229 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.9059 - accuracy: 0.5365 - val_loss: 1.3697 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9000 - accuracy: 0.5365 - val_loss: 1.4041 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.9134 - accuracy: 0.5368 - val_loss: 1.2960 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.9016 - accuracy: 0.5319 - val_loss: 1.3151 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.8952 - accuracy: 0.5435 - val_loss: 1.4391 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.9019 - accuracy: 0.5453 - val_loss: 1.4408 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.8926 - accuracy: 0.5396 - val_loss: 1.2964 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.9050 - accuracy: 0.5237 - val_loss: 1.1948 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.9090 - accuracy: 0.5278 - val_loss: 1.2082 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.9032 - accuracy: 0.5365 - val_loss: 1.2944 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.9066 - accuracy: 0.5347 - val_loss: 1.3508 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9063 - accuracy: 0.5383 - val_loss: 1.3870 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.9037 - accuracy: 0.5386 - val_loss: 1.3742 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.9063 - accuracy: 0.5391 - val_loss: 1.3081 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.9026 - accuracy: 0.5278 - val_loss: 1.3161 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.8892 - accuracy: 0.5512 - val_loss: 1.4207 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.9040 - accuracy: 0.5298 - val_loss: 1.3246 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.8943 - accuracy: 0.5388 - val_loss: 1.4649 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.8947 - accuracy: 0.5383 - val_loss: 1.2346 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.8999 - accuracy: 0.5404 - val_loss: 1.2224 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.8950 - accuracy: 0.5427 - val_loss: 1.2537 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.8925 - accuracy: 0.5342 - val_loss: 1.2816 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.8867 - accuracy: 0.5401 - val_loss: 1.1579 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.8878 - accuracy: 0.5404 - val_loss: 1.2590 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.9006 - accuracy: 0.5388 - val_loss: 1.2092 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.8948 - accuracy: 0.5378 - val_loss: 1.3149 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.9042 - accuracy: 0.5265 - val_loss: 1.1751 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.8959 - accuracy: 0.5463 - val_loss: 1.1423 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.8933 - accuracy: 0.5507 - val_loss: 1.1463 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.8879 - accuracy: 0.5412 - val_loss: 1.2595 - val_accuracy: 0.3189 - 1s/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.8885 - accuracy: 0.5509 - val_loss: 1.2787 - val_accuracy: 0.3220 - 1s/epoch - 5ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.8894 - accuracy: 0.5373 - val_loss: 1.4240 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.9023 - accuracy: 0.5368 - val_loss: 1.1537 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.8984 - accuracy: 0.5332 - val_loss: 1.2133 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.8942 - accuracy: 0.5404 - val_loss: 1.2182 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.8991 - accuracy: 0.5412 - val_loss: 1.2566 - val_accuracy: 0.3169 - 1s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.8934 - accuracy: 0.5445 - val_loss: 1.1761 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.8913 - accuracy: 0.5409 - val_loss: 1.3059 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.8931 - accuracy: 0.5414 - val_loss: 1.2314 - val_accuracy: 0.3200 - 1s/epoch - 5ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.8941 - accuracy: 0.5409 - val_loss: 1.2485 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.8924 - accuracy: 0.5427 - val_loss: 1.2966 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.8955 - accuracy: 0.5350 - val_loss: 1.3435 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.8814 - accuracy: 0.5419 - val_loss: 1.2776 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.8876 - accuracy: 0.5455 - val_loss: 1.2913 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.8857 - accuracy: 0.5494 - val_loss: 1.2165 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.8926 - accuracy: 0.5476 - val_loss: 1.2157 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.8967 - accuracy: 0.5406 - val_loss: 1.1335 - val_accuracy: 0.3200 - 1s/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.8956 - accuracy: 0.5306 - val_loss: 1.2601 - val_accuracy: 0.3200 - 1s/epoch - 5ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.8894 - accuracy: 0.5502 - val_loss: 1.2621 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9038 - accuracy: 0.5383 - val_loss: 1.1206 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.8994 - accuracy: 0.5360 - val_loss: 1.2084 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.8948 - accuracy: 0.5334 - val_loss: 1.1494 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.8932 - accuracy: 0.5401 - val_loss: 1.2398 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.8883 - accuracy: 0.5280 - val_loss: 1.1970 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.8836 - accuracy: 0.5453 - val_loss: 1.1566 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.8900 - accuracy: 0.5355 - val_loss: 1.2474 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.8921 - accuracy: 0.5337 - val_loss: 1.1436 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.8826 - accuracy: 0.5522 - val_loss: 1.2637 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.8922 - accuracy: 0.5383 - val_loss: 1.1200 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.8890 - accuracy: 0.5381 - val_loss: 1.2202 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.8880 - accuracy: 0.5358 - val_loss: 1.4170 - val_accuracy: 0.3210 - 1s/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.8916 - accuracy: 0.5365 - val_loss: 1.3439 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.8893 - accuracy: 0.5381 - val_loss: 1.2041 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.8958 - accuracy: 0.5360 - val_loss: 1.2434 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.8895 - accuracy: 0.5442 - val_loss: 1.1570 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.8798 - accuracy: 0.5532 - val_loss: 1.1507 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.8829 - accuracy: 0.5502 - val_loss: 1.1528 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.8879 - accuracy: 0.5476 - val_loss: 1.1641 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.8904 - accuracy: 0.5427 - val_loss: 1.1679 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.8911 - accuracy: 0.5437 - val_loss: 1.1604 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.8838 - accuracy: 0.5535 - val_loss: 1.1277 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.8862 - accuracy: 0.5453 - val_loss: 1.1991 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.8890 - accuracy: 0.5455 - val_loss: 1.3884 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.8747 - accuracy: 0.5558 - val_loss: 1.3040 - val_accuracy: 0.3189 - 1s/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.8861 - accuracy: 0.5409 - val_loss: 1.1184 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.8881 - accuracy: 0.5412 - val_loss: 1.1462 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.8958 - accuracy: 0.5404 - val_loss: 1.1217 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9031 - accuracy: 0.5234 - val_loss: 1.1183 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.8893 - accuracy: 0.5417 - val_loss: 1.1127 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.8838 - accuracy: 0.5412 - val_loss: 1.1088 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.8888 - accuracy: 0.5463 - val_loss: 1.1120 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.8899 - accuracy: 0.5414 - val_loss: 1.1482 - val_accuracy: 0.3200 - 1s/epoch - 5ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.8877 - accuracy: 0.5466 - val_loss: 1.2304 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9012 - accuracy: 0.5422 - val_loss: 1.1176 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.8934 - accuracy: 0.5396 - val_loss: 1.1376 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.8819 - accuracy: 0.5520 - val_loss: 1.1618 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9005 - accuracy: 0.5381 - val_loss: 1.1460 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index for this split: [   0    1    2 ... 4856 4857 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   4    7    9   11   26   34   37   41   44   53   54   68   77   80\n",
      "   82   94  104  109  112  116  118  119  125  139  146  147  158  161\n",
      "  162  165  171  173  175  184  201  220  228  236  237  243  250  260\n",
      "  261  265  271  272  273  276  277  279  280  283  284  287  294  295\n",
      "  298  300  302  305  307  310  312  314  315  320  321  329  340  350\n",
      "  352  358  366  367  374  378  379  388  393  396  413  418  425  428\n",
      "  439  443  450  456  458  466  468  473  477  479  482  505  507  508\n",
      "  517  523  528  538  540  548  550  552  555  561  566  570  572  573\n",
      "  584  598  599  605  611  614  617  618  621  624  632  633  647  648\n",
      "  649  653  654  655  660  666  668  670  675  677  680  683  697  706\n",
      "  707  708  709  710  718  720  724  726  727  729  734  736  750  755\n",
      "  767  784  791  794  796  803  807  811  819  826  836  839  843  848\n",
      "  860  866  871  875  883  885  891  897  899  901  903  904  914  917\n",
      "  923  930  932  936  937  938  939  942  944  947  948  956  963  964\n",
      "  974  988  994  996  997 1000 1001 1006 1008 1012 1015 1019 1036 1052\n",
      " 1054 1059 1072 1073 1074 1075 1088 1091 1093 1103 1108 1113 1149 1153\n",
      " 1161 1166 1172 1183 1185 1193 1194 1195 1200 1202 1206 1209 1215 1223\n",
      " 1228 1231 1237 1241 1248 1253 1260 1264 1266 1273 1274 1280 1282 1298\n",
      " 1302 1307 1311 1313 1327 1329 1339 1346 1348 1349 1351 1355 1358 1359\n",
      " 1361 1363 1366 1387 1396 1402 1405 1406 1408 1417 1418 1423 1429 1435\n",
      " 1436 1438 1439 1445 1449 1455 1457 1463 1468 1470 1472 1485 1487 1490\n",
      " 1492 1496 1500 1501 1508 1517 1518 1521 1524 1532 1538 1541 1542 1549\n",
      " 1550 1559 1560 1566 1574 1575 1576 1581 1591 1592 1597 1598 1600 1603\n",
      " 1606 1613 1625 1626 1629 1630 1633 1640 1643 1647 1654 1658 1664 1676\n",
      " 1688 1693 1696 1698 1707 1709 1711 1714 1715 1716 1718 1720 1724 1727\n",
      " 1732 1736 1738 1750 1752 1753 1759 1761 1764 1767 1773 1779 1793 1801\n",
      " 1803 1808 1810 1819 1822 1825 1828 1831 1835 1836 1838 1839 1845 1853\n",
      " 1854 1864 1865 1870 1871 1886 1891 1893 1908 1912 1916 1928 1935 1948\n",
      " 1951 1955 1959 1961 1962 1963 1972 1979 1982 1983 1985 1988 1994 2004\n",
      " 2011 2016 2019 2022 2023 2035 2043 2044 2059 2061 2063 2065 2067 2068\n",
      " 2072 2074 2075 2078 2079 2085 2093 2094 2099 2101 2102 2103 2105 2107\n",
      " 2108 2115 2133 2137 2138 2141 2144 2149 2152 2159 2166 2170 2185 2188\n",
      " 2199 2200 2204 2213 2220 2222 2224 2226 2230 2234 2242 2261 2262 2265\n",
      " 2266 2270 2289 2290 2295 2302 2305 2306 2320 2326 2331 2337 2338 2341\n",
      " 2346 2348 2350 2357 2375 2376 2393 2396 2398 2405 2411 2414 2419 2421\n",
      " 2422 2427 2436 2443 2444 2450 2457 2460 2466 2469 2470 2472 2475 2481\n",
      " 2482 2487 2489 2491 2492 2503 2508 2509 2521 2524 2536 2544 2551 2556\n",
      " 2562 2565 2566 2567 2568 2574 2587 2595 2607 2609 2621 2626 2629 2630\n",
      " 2632 2637 2638 2641 2645 2650 2657 2666 2671 2674 2677 2683 2688 2692\n",
      " 2695 2698 2699 2700 2731 2733 2736 2743 2747 2752 2757 2761 2774 2780\n",
      " 2784 2785 2786 2792 2795 2803 2806 2809 2812 2813 2816 2819 2820 2829\n",
      " 2831 2836 2838 2843 2859 2861 2862 2867 2879 2887 2902 2915 2922 2923\n",
      " 2924 2925 2926 2934 2938 2941 2942 2963 2966 2980 2986 2987 2997 3007\n",
      " 3018 3019 3021 3025 3027 3030 3049 3053 3056 3060 3063 3069 3073 3080\n",
      " 3083 3096 3098 3105 3109 3114 3116 3123 3125 3126 3129 3132 3133 3141\n",
      " 3147 3161 3172 3174 3186 3188 3189 3190 3218 3219 3225 3226 3229 3230\n",
      " 3232 3235 3244 3248 3250 3253 3267 3268 3274 3283 3287 3294 3302 3303\n",
      " 3317 3319 3321 3327 3329 3332 3338 3346 3361 3363 3373 3379 3390 3393\n",
      " 3400 3418 3419 3422 3427 3431 3434 3439 3443 3448 3450 3451 3454 3455\n",
      " 3457 3475 3485 3495 3500 3510 3512 3516 3518 3519 3521 3525 3536 3544\n",
      " 3553 3560 3573 3575 3577 3580 3586 3591 3602 3604 3607 3609 3615 3617\n",
      " 3619 3628 3629 3630 3636 3646 3649 3653 3654 3655 3660 3665 3666 3667\n",
      " 3669 3670 3672 3675 3677 3683 3688 3692 3694 3710 3712 3713 3718 3724\n",
      " 3727 3731 3733 3736 3742 3743 3757 3762 3763 3766 3778 3787 3802 3806\n",
      " 3807 3814 3816 3819 3822 3826 3830 3836 3838 3843 3851 3852 3854 3856\n",
      " 3872 3878 3884 3887 3889 3890 3901 3914 3915 3921 3927 3931 3933 3935\n",
      " 3939 3940 3943 3944 3946 3950 3956 3958 3963 3964 3969 3971 3980 3983\n",
      " 3984 3988 3990 3991 3998 4024 4028 4031 4038 4039 4042 4044 4046 4048\n",
      " 4051 4056 4057 4060 4063 4065 4070 4071 4072 4075 4087 4090 4104 4106\n",
      " 4111 4114 4118 4126 4128 4133 4141 4147 4151 4153 4154 4159 4162 4164\n",
      " 4169 4173 4174 4175 4179 4188 4191 4192 4193 4197 4203 4209 4214 4219\n",
      " 4223 4225 4230 4233 4242 4246 4247 4260 4274 4279 4295 4323 4325 4333\n",
      " 4336 4337 4352 4353 4361 4374 4381 4391 4393 4399 4400 4403 4407 4422\n",
      " 4423 4429 4431 4432 4435 4438 4460 4463 4464 4470 4480 4494 4506 4507\n",
      " 4519 4522 4523 4524 4527 4539 4542 4545 4549 4555 4556 4564 4565 4566\n",
      " 4571 4582 4588 4589 4602 4604 4619 4624 4629 4634 4637 4639 4640 4648\n",
      " 4656 4658 4669 4672 4678 4679 4685 4691 4693 4695 4698 4703 4705 4710\n",
      " 4712 4713 4717 4718 4720 4723 4726 4728 4730 4739 4740 4755 4761 4769\n",
      " 4773 4776 4781 4784 4785 4796 4799 4806 4808 4815 4816 4820 4822 4831\n",
      " 4832 4834 4843 4846 4851 4858]\n",
      "Number of samples for test set: 972\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:12:51.892315: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_308/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.0891 - accuracy: 0.3809 - val_loss: 1.1029 - val_accuracy: 0.3426 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0691 - accuracy: 0.4223 - val_loss: 1.1125 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0571 - accuracy: 0.4288 - val_loss: 1.1442 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0528 - accuracy: 0.4318 - val_loss: 1.1510 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0318 - accuracy: 0.4455 - val_loss: 1.1918 - val_accuracy: 0.3447 - 1s/epoch - 5ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0233 - accuracy: 0.4398 - val_loss: 1.1920 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0256 - accuracy: 0.4439 - val_loss: 1.2199 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0218 - accuracy: 0.4488 - val_loss: 1.1939 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0182 - accuracy: 0.4573 - val_loss: 1.1808 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0037 - accuracy: 0.4694 - val_loss: 1.2132 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0052 - accuracy: 0.4666 - val_loss: 1.2326 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0107 - accuracy: 0.4642 - val_loss: 1.1710 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0034 - accuracy: 0.4514 - val_loss: 1.1611 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0015 - accuracy: 0.4588 - val_loss: 1.1429 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 0.9950 - accuracy: 0.4660 - val_loss: 1.1595 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 0.9921 - accuracy: 0.4892 - val_loss: 1.1289 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 0.9901 - accuracy: 0.4735 - val_loss: 1.1270 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 0.9894 - accuracy: 0.4722 - val_loss: 1.1611 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 0.9896 - accuracy: 0.4748 - val_loss: 1.1021 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 0.9798 - accuracy: 0.4763 - val_loss: 1.1124 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 0.9790 - accuracy: 0.4781 - val_loss: 1.1255 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 0.9830 - accuracy: 0.4684 - val_loss: 1.1272 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 0.9724 - accuracy: 0.4920 - val_loss: 1.1146 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9794 - accuracy: 0.4779 - val_loss: 1.1010 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9687 - accuracy: 0.4825 - val_loss: 1.1482 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 0.9651 - accuracy: 0.4866 - val_loss: 1.1339 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9708 - accuracy: 0.4892 - val_loss: 1.1605 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9632 - accuracy: 0.4856 - val_loss: 1.1563 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9676 - accuracy: 0.4866 - val_loss: 1.1663 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9712 - accuracy: 0.4895 - val_loss: 1.1391 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9702 - accuracy: 0.4923 - val_loss: 1.1059 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9598 - accuracy: 0.4961 - val_loss: 1.1349 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9543 - accuracy: 0.4972 - val_loss: 1.0992 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9587 - accuracy: 0.4913 - val_loss: 1.1336 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9622 - accuracy: 0.4807 - val_loss: 1.1226 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9558 - accuracy: 0.4882 - val_loss: 1.1320 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9499 - accuracy: 0.4938 - val_loss: 1.2331 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9486 - accuracy: 0.5013 - val_loss: 1.1577 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9487 - accuracy: 0.4925 - val_loss: 1.1314 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9474 - accuracy: 0.5015 - val_loss: 1.1048 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9494 - accuracy: 0.4905 - val_loss: 1.1349 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9430 - accuracy: 0.4889 - val_loss: 1.1637 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9567 - accuracy: 0.4915 - val_loss: 1.1185 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9381 - accuracy: 0.5095 - val_loss: 1.1267 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9358 - accuracy: 0.4969 - val_loss: 1.2411 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9515 - accuracy: 0.4923 - val_loss: 1.2063 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9453 - accuracy: 0.4936 - val_loss: 1.1875 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9427 - accuracy: 0.4982 - val_loss: 1.1431 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9478 - accuracy: 0.4961 - val_loss: 1.1460 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9406 - accuracy: 0.5026 - val_loss: 1.1734 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9469 - accuracy: 0.4923 - val_loss: 1.1570 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9452 - accuracy: 0.4972 - val_loss: 1.1840 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9370 - accuracy: 0.4964 - val_loss: 1.1924 - val_accuracy: 0.3313 - 1s/epoch - 5ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9280 - accuracy: 0.5008 - val_loss: 1.2834 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9378 - accuracy: 0.4892 - val_loss: 1.1562 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9388 - accuracy: 0.5021 - val_loss: 1.1449 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9350 - accuracy: 0.5033 - val_loss: 1.1970 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9398 - accuracy: 0.5123 - val_loss: 1.1430 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9291 - accuracy: 0.5013 - val_loss: 1.1432 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9347 - accuracy: 0.4997 - val_loss: 1.1222 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9276 - accuracy: 0.4974 - val_loss: 1.0939 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9356 - accuracy: 0.4985 - val_loss: 1.0962 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9336 - accuracy: 0.4959 - val_loss: 1.1300 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9229 - accuracy: 0.5067 - val_loss: 1.0993 - val_accuracy: 0.3313 - 1s/epoch - 5ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9328 - accuracy: 0.5064 - val_loss: 1.2236 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9281 - accuracy: 0.5077 - val_loss: 1.1327 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9317 - accuracy: 0.5008 - val_loss: 1.1223 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9359 - accuracy: 0.5054 - val_loss: 1.0992 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9305 - accuracy: 0.5103 - val_loss: 1.1501 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9298 - accuracy: 0.5028 - val_loss: 1.1542 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9269 - accuracy: 0.5121 - val_loss: 1.2007 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9283 - accuracy: 0.5154 - val_loss: 1.1285 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9229 - accuracy: 0.5105 - val_loss: 1.1923 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9274 - accuracy: 0.5044 - val_loss: 1.2077 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9322 - accuracy: 0.5028 - val_loss: 1.2446 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9302 - accuracy: 0.5028 - val_loss: 1.3606 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9315 - accuracy: 0.4961 - val_loss: 1.2360 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9233 - accuracy: 0.5064 - val_loss: 1.2034 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9207 - accuracy: 0.5111 - val_loss: 1.2035 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9290 - accuracy: 0.5010 - val_loss: 1.2107 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9292 - accuracy: 0.5188 - val_loss: 1.2237 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9169 - accuracy: 0.5221 - val_loss: 1.2502 - val_accuracy: 0.3447 - 1s/epoch - 5ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9239 - accuracy: 0.5260 - val_loss: 1.1365 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9140 - accuracy: 0.5154 - val_loss: 1.1749 - val_accuracy: 0.3447 - 1s/epoch - 5ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9182 - accuracy: 0.5116 - val_loss: 1.1166 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9115 - accuracy: 0.5201 - val_loss: 1.1458 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9240 - accuracy: 0.5105 - val_loss: 1.1189 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9313 - accuracy: 0.4974 - val_loss: 1.1740 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9166 - accuracy: 0.5090 - val_loss: 1.1504 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9249 - accuracy: 0.5213 - val_loss: 1.1651 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9266 - accuracy: 0.5026 - val_loss: 1.2066 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9126 - accuracy: 0.5152 - val_loss: 1.2377 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9283 - accuracy: 0.5180 - val_loss: 1.2724 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9326 - accuracy: 0.4967 - val_loss: 1.1551 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9123 - accuracy: 0.5147 - val_loss: 1.2031 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9089 - accuracy: 0.5147 - val_loss: 1.2013 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9170 - accuracy: 0.5221 - val_loss: 1.2283 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9212 - accuracy: 0.5162 - val_loss: 1.2641 - val_accuracy: 0.3302 - 1s/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9264 - accuracy: 0.5123 - val_loss: 1.3084 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9308 - accuracy: 0.5139 - val_loss: 1.4645 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9214 - accuracy: 0.5136 - val_loss: 1.3411 - val_accuracy: 0.3313 - 1s/epoch - 5ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9284 - accuracy: 0.5005 - val_loss: 1.2743 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9276 - accuracy: 0.5103 - val_loss: 1.2436 - val_accuracy: 0.3313 - 1s/epoch - 5ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9211 - accuracy: 0.5195 - val_loss: 1.2385 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9082 - accuracy: 0.5249 - val_loss: 1.3029 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9183 - accuracy: 0.5126 - val_loss: 1.3199 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.9142 - accuracy: 0.5190 - val_loss: 1.4136 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9201 - accuracy: 0.5159 - val_loss: 1.3394 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.9160 - accuracy: 0.5105 - val_loss: 1.1528 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9220 - accuracy: 0.5234 - val_loss: 1.1285 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9206 - accuracy: 0.5080 - val_loss: 1.1710 - val_accuracy: 0.3447 - 1s/epoch - 5ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9237 - accuracy: 0.5113 - val_loss: 1.2967 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9198 - accuracy: 0.5201 - val_loss: 1.2568 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9175 - accuracy: 0.5157 - val_loss: 1.2278 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9198 - accuracy: 0.5198 - val_loss: 1.2277 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9100 - accuracy: 0.5296 - val_loss: 1.1619 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9130 - accuracy: 0.5144 - val_loss: 1.1535 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9145 - accuracy: 0.5185 - val_loss: 1.2291 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9097 - accuracy: 0.5219 - val_loss: 1.2725 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9196 - accuracy: 0.5211 - val_loss: 1.2392 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9153 - accuracy: 0.5098 - val_loss: 1.1460 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9125 - accuracy: 0.5177 - val_loss: 1.1419 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9067 - accuracy: 0.5219 - val_loss: 1.2044 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9174 - accuracy: 0.5165 - val_loss: 1.1957 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.9150 - accuracy: 0.5170 - val_loss: 1.2805 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.9141 - accuracy: 0.5098 - val_loss: 1.1382 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9138 - accuracy: 0.5157 - val_loss: 1.2301 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.9151 - accuracy: 0.5213 - val_loss: 1.2534 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.9133 - accuracy: 0.5093 - val_loss: 1.2000 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9068 - accuracy: 0.5195 - val_loss: 1.1802 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.9213 - accuracy: 0.5157 - val_loss: 1.2866 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.9122 - accuracy: 0.5221 - val_loss: 1.2786 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9085 - accuracy: 0.5213 - val_loss: 1.1939 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.9108 - accuracy: 0.5147 - val_loss: 1.1830 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.9199 - accuracy: 0.5201 - val_loss: 1.1793 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.9143 - accuracy: 0.5113 - val_loss: 1.1544 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9157 - accuracy: 0.5213 - val_loss: 1.2340 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.9106 - accuracy: 0.5303 - val_loss: 1.2851 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.8977 - accuracy: 0.5298 - val_loss: 1.2858 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.9046 - accuracy: 0.5260 - val_loss: 1.2552 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9058 - accuracy: 0.5247 - val_loss: 1.2296 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9120 - accuracy: 0.5090 - val_loss: 1.2374 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9155 - accuracy: 0.5165 - val_loss: 1.2042 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.9004 - accuracy: 0.5170 - val_loss: 1.1834 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.9156 - accuracy: 0.5105 - val_loss: 1.1284 - val_accuracy: 0.3313 - 1s/epoch - 5ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9050 - accuracy: 0.5239 - val_loss: 1.2100 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.9065 - accuracy: 0.5208 - val_loss: 1.2257 - val_accuracy: 0.3436 - 1s/epoch - 5ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.9082 - accuracy: 0.5203 - val_loss: 1.2905 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.9072 - accuracy: 0.5311 - val_loss: 1.3633 - val_accuracy: 0.3302 - 1s/epoch - 5ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.9113 - accuracy: 0.5152 - val_loss: 1.2623 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.9007 - accuracy: 0.5278 - val_loss: 1.2104 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.9000 - accuracy: 0.5239 - val_loss: 1.2146 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.8949 - accuracy: 0.5301 - val_loss: 1.1777 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.9219 - accuracy: 0.5167 - val_loss: 1.2413 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.9089 - accuracy: 0.5149 - val_loss: 1.2549 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.9137 - accuracy: 0.5211 - val_loss: 1.1637 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9180 - accuracy: 0.5036 - val_loss: 1.1292 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.9069 - accuracy: 0.5270 - val_loss: 1.1791 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.9160 - accuracy: 0.5126 - val_loss: 1.2918 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.9014 - accuracy: 0.5201 - val_loss: 1.1823 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9078 - accuracy: 0.5247 - val_loss: 1.2242 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.9086 - accuracy: 0.5098 - val_loss: 1.2487 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.9031 - accuracy: 0.5162 - val_loss: 1.2709 - val_accuracy: 0.3436 - 1s/epoch - 5ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.9048 - accuracy: 0.5329 - val_loss: 1.1792 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9014 - accuracy: 0.5334 - val_loss: 1.3422 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.9151 - accuracy: 0.5172 - val_loss: 1.3656 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.9153 - accuracy: 0.5172 - val_loss: 1.3217 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.9094 - accuracy: 0.5237 - val_loss: 1.3001 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.8875 - accuracy: 0.5352 - val_loss: 1.2665 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.9021 - accuracy: 0.5239 - val_loss: 1.3225 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.9107 - accuracy: 0.5208 - val_loss: 1.2673 - val_accuracy: 0.3436 - 1s/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.9108 - accuracy: 0.5093 - val_loss: 1.3395 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.9150 - accuracy: 0.5180 - val_loss: 1.2684 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.9141 - accuracy: 0.5203 - val_loss: 1.1966 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9074 - accuracy: 0.5219 - val_loss: 1.1919 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.9076 - accuracy: 0.5111 - val_loss: 1.1623 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.9115 - accuracy: 0.5221 - val_loss: 1.1397 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.9058 - accuracy: 0.5208 - val_loss: 1.0997 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.9025 - accuracy: 0.5229 - val_loss: 1.1188 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.9020 - accuracy: 0.5247 - val_loss: 1.1705 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.9004 - accuracy: 0.5360 - val_loss: 1.1715 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.9111 - accuracy: 0.5347 - val_loss: 1.2053 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.9026 - accuracy: 0.5280 - val_loss: 1.1947 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.9172 - accuracy: 0.5121 - val_loss: 1.1684 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.9108 - accuracy: 0.5213 - val_loss: 1.2574 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.9128 - accuracy: 0.5298 - val_loss: 1.3285 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.8927 - accuracy: 0.5283 - val_loss: 1.2836 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.9082 - accuracy: 0.5291 - val_loss: 1.2994 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.8989 - accuracy: 0.5224 - val_loss: 1.2372 - val_accuracy: 0.3436 - 1s/epoch - 5ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.8984 - accuracy: 0.5345 - val_loss: 1.1585 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.9017 - accuracy: 0.5265 - val_loss: 1.2054 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9071 - accuracy: 0.5198 - val_loss: 1.1673 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.9007 - accuracy: 0.5129 - val_loss: 1.2036 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.8988 - accuracy: 0.5226 - val_loss: 1.2528 - val_accuracy: 0.3447 - 1s/epoch - 5ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.9054 - accuracy: 0.5262 - val_loss: 1.1828 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.9095 - accuracy: 0.5152 - val_loss: 1.2291 - val_accuracy: 0.3447 - 1s/epoch - 5ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.9031 - accuracy: 0.5270 - val_loss: 1.1995 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.9074 - accuracy: 0.5193 - val_loss: 1.1382 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.9112 - accuracy: 0.5165 - val_loss: 1.1833 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.9035 - accuracy: 0.5188 - val_loss: 1.1683 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.9196 - accuracy: 0.5082 - val_loss: 1.2080 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.9059 - accuracy: 0.5136 - val_loss: 1.1633 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.9054 - accuracy: 0.5252 - val_loss: 1.1732 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.8997 - accuracy: 0.5301 - val_loss: 1.2421 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.9071 - accuracy: 0.5180 - val_loss: 1.1835 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.9137 - accuracy: 0.5255 - val_loss: 1.1094 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.8991 - accuracy: 0.5283 - val_loss: 1.1717 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.9072 - accuracy: 0.5219 - val_loss: 1.2149 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.8999 - accuracy: 0.5239 - val_loss: 1.2397 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.9101 - accuracy: 0.5270 - val_loss: 1.2405 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.9003 - accuracy: 0.5342 - val_loss: 1.1705 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9170 - accuracy: 0.5123 - val_loss: 1.2579 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9009 - accuracy: 0.5172 - val_loss: 1.2808 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.8922 - accuracy: 0.5267 - val_loss: 1.1909 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.9165 - accuracy: 0.5234 - val_loss: 1.1526 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.8992 - accuracy: 0.5244 - val_loss: 1.2763 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.8996 - accuracy: 0.5270 - val_loss: 1.2326 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.8965 - accuracy: 0.5252 - val_loss: 1.2556 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.8999 - accuracy: 0.5262 - val_loss: 1.3697 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.9007 - accuracy: 0.5229 - val_loss: 1.2622 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.9037 - accuracy: 0.5224 - val_loss: 1.2277 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.8961 - accuracy: 0.5260 - val_loss: 1.1713 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.9019 - accuracy: 0.5219 - val_loss: 1.2287 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.8986 - accuracy: 0.5306 - val_loss: 1.1995 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.8972 - accuracy: 0.5193 - val_loss: 1.2394 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.8948 - accuracy: 0.5242 - val_loss: 1.1902 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.9070 - accuracy: 0.5134 - val_loss: 1.1809 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.9052 - accuracy: 0.5257 - val_loss: 1.2498 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.9075 - accuracy: 0.5306 - val_loss: 1.2061 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.8977 - accuracy: 0.5257 - val_loss: 1.2605 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.8956 - accuracy: 0.5358 - val_loss: 1.2054 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.8996 - accuracy: 0.5224 - val_loss: 1.1172 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.8944 - accuracy: 0.5316 - val_loss: 1.1241 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.8926 - accuracy: 0.5322 - val_loss: 1.1541 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.8935 - accuracy: 0.5211 - val_loss: 1.1967 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.9059 - accuracy: 0.5177 - val_loss: 1.1864 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.9029 - accuracy: 0.5221 - val_loss: 1.1933 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9023 - accuracy: 0.5306 - val_loss: 1.2038 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.9048 - accuracy: 0.5319 - val_loss: 1.1372 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.9054 - accuracy: 0.5255 - val_loss: 1.1562 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.8980 - accuracy: 0.5314 - val_loss: 1.2446 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.9036 - accuracy: 0.5314 - val_loss: 1.1819 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.9014 - accuracy: 0.5324 - val_loss: 1.1789 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.9139 - accuracy: 0.5170 - val_loss: 1.3458 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.9040 - accuracy: 0.5267 - val_loss: 1.1891 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.8956 - accuracy: 0.5370 - val_loss: 1.1980 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9058 - accuracy: 0.5159 - val_loss: 1.1234 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.9098 - accuracy: 0.5177 - val_loss: 1.1734 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.9005 - accuracy: 0.5244 - val_loss: 1.3144 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.8932 - accuracy: 0.5298 - val_loss: 1.2416 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index for this split: [   0    1    2 ... 4857 4858 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   3   22   25   27   31   33   45   52   55   56   61   62   63   70\n",
      "   79   81   89   90   92   93   96   98  108  113  114  120  122  126\n",
      "  130  131  134  135  140  145  150  151  154  167  198  199  205  207\n",
      "  211  218  222  223  225  227  229  230  231  234  240  245  246  248\n",
      "  249  252  256  264  268  274  285  291  301  308  313  317  318  322\n",
      "  323  325  336  337  341  345  356  359  361  376  382  385  386  390\n",
      "  400  409  415  422  426  427  432  433  436  437  438  442  446  448\n",
      "  449  454  460  462  471  478  485  491  493  495  498  499  506  516\n",
      "  520  529  530  532  539  541  544  549  562  567  583  585  587  594\n",
      "  620  627  631  640  641  650  651  656  661  671  674  686  688  689\n",
      "  692  696  699  700  704  725  728  739  751  762  773  775  778  781\n",
      "  798  799  810  821  823  827  831  834  837  838  841  844  845  846\n",
      "  849  850  855  858  863  867  870  873  877  880  884  886  887  888\n",
      "  892  894  898  900  905  906  907  926  928  931  933  943  953  962\n",
      "  970  982  987  989  992  993  995 1003 1009 1011 1020 1022 1028 1030\n",
      " 1031 1039 1042 1044 1047 1050 1063 1064 1067 1079 1094 1095 1096 1102\n",
      " 1107 1114 1117 1119 1131 1132 1135 1138 1141 1150 1154 1155 1160 1163\n",
      " 1164 1173 1176 1184 1188 1191 1197 1203 1217 1222 1226 1232 1234 1239\n",
      " 1252 1254 1262 1263 1272 1277 1285 1291 1295 1301 1303 1304 1319 1320\n",
      " 1322 1324 1326 1332 1335 1336 1340 1344 1350 1357 1364 1367 1368 1379\n",
      " 1382 1388 1399 1403 1410 1413 1419 1421 1426 1428 1430 1442 1443 1448\n",
      " 1453 1458 1464 1465 1466 1482 1494 1498 1512 1514 1515 1516 1519 1530\n",
      " 1533 1535 1540 1552 1563 1589 1595 1608 1614 1615 1616 1617 1618 1622\n",
      " 1623 1632 1637 1644 1649 1657 1659 1663 1665 1666 1669 1680 1681 1682\n",
      " 1685 1691 1695 1697 1704 1710 1722 1729 1733 1747 1748 1749 1757 1769\n",
      " 1781 1784 1787 1792 1796 1798 1800 1807 1813 1841 1844 1861 1875 1879\n",
      " 1883 1885 1888 1889 1890 1902 1904 1907 1919 1923 1924 1934 1936 1939\n",
      " 1940 1942 1947 1958 1960 1967 1973 1975 1977 1980 1981 1987 1989 1990\n",
      " 1992 1999 2008 2021 2024 2025 2028 2029 2031 2038 2040 2047 2051 2056\n",
      " 2057 2066 2082 2086 2088 2091 2100 2104 2112 2119 2121 2124 2130 2146\n",
      " 2148 2154 2161 2172 2177 2182 2189 2196 2197 2205 2208 2211 2212 2223\n",
      " 2231 2232 2236 2240 2241 2245 2246 2250 2251 2252 2254 2256 2257 2267\n",
      " 2268 2271 2280 2286 2299 2303 2304 2312 2315 2324 2333 2340 2344 2354\n",
      " 2356 2358 2365 2366 2370 2371 2372 2373 2378 2380 2385 2392 2394 2399\n",
      " 2423 2425 2431 2433 2440 2446 2449 2452 2453 2456 2462 2464 2467 2468\n",
      " 2473 2501 2502 2507 2514 2517 2523 2526 2529 2532 2533 2534 2537 2546\n",
      " 2552 2560 2564 2570 2573 2578 2581 2582 2584 2590 2593 2602 2613 2622\n",
      " 2624 2642 2646 2647 2649 2655 2661 2665 2675 2679 2689 2693 2694 2696\n",
      " 2703 2707 2710 2711 2719 2721 2728 2729 2737 2738 2739 2740 2742 2751\n",
      " 2755 2768 2775 2777 2781 2789 2793 2804 2808 2811 2817 2825 2827 2835\n",
      " 2837 2844 2846 2847 2851 2852 2870 2872 2876 2881 2884 2886 2888 2907\n",
      " 2908 2910 2912 2921 2928 2932 2937 2949 2951 2953 2957 2959 2960 2976\n",
      " 2978 2979 2991 3002 3004 3006 3010 3013 3028 3031 3032 3035 3045 3047\n",
      " 3050 3061 3062 3068 3074 3077 3078 3088 3089 3100 3101 3103 3106 3108\n",
      " 3110 3111 3112 3115 3119 3130 3143 3150 3151 3159 3164 3173 3176 3180\n",
      " 3195 3207 3208 3217 3221 3228 3238 3243 3245 3249 3254 3266 3281 3288\n",
      " 3290 3292 3295 3296 3297 3298 3313 3314 3325 3339 3341 3345 3349 3355\n",
      " 3357 3366 3368 3370 3371 3372 3380 3382 3396 3406 3410 3415 3424 3435\n",
      " 3436 3437 3442 3447 3452 3464 3468 3469 3470 3473 3477 3486 3489 3492\n",
      " 3499 3501 3504 3508 3514 3515 3530 3531 3543 3549 3550 3551 3556 3559\n",
      " 3561 3562 3563 3567 3571 3574 3582 3587 3588 3589 3593 3595 3611 3618\n",
      " 3622 3623 3631 3637 3639 3641 3650 3657 3658 3659 3664 3673 3676 3678\n",
      " 3680 3691 3696 3715 3717 3721 3722 3732 3747 3764 3765 3768 3769 3771\n",
      " 3772 3774 3776 3779 3783 3792 3793 3796 3801 3810 3821 3827 3831 3832\n",
      " 3839 3848 3855 3857 3860 3862 3864 3866 3871 3874 3875 3883 3892 3894\n",
      " 3895 3896 3897 3899 3904 3907 3910 3912 3917 3919 3922 3928 3932 3934\n",
      " 3937 3947 3948 3953 3954 3962 3966 3975 3979 3981 3996 3997 3999 4000\n",
      " 4003 4008 4009 4010 4011 4012 4016 4021 4022 4026 4035 4052 4053 4058\n",
      " 4061 4066 4076 4079 4080 4081 4083 4091 4093 4095 4108 4110 4119 4121\n",
      " 4136 4142 4143 4148 4150 4155 4156 4160 4165 4168 4177 4181 4182 4183\n",
      " 4186 4199 4200 4212 4213 4216 4217 4221 4227 4236 4238 4239 4245 4248\n",
      " 4252 4253 4264 4266 4270 4272 4280 4302 4305 4307 4314 4318 4320 4326\n",
      " 4328 4329 4330 4334 4340 4345 4351 4355 4357 4366 4369 4372 4373 4375\n",
      " 4387 4402 4404 4411 4413 4415 4421 4424 4425 4426 4427 4428 4446 4453\n",
      " 4455 4461 4462 4465 4471 4476 4477 4483 4486 4501 4502 4512 4517 4520\n",
      " 4525 4526 4529 4532 4535 4538 4541 4543 4551 4552 4562 4574 4575 4581\n",
      " 4586 4590 4592 4594 4603 4625 4628 4630 4632 4642 4645 4649 4653 4655\n",
      " 4657 4660 4661 4662 4665 4680 4690 4692 4696 4697 4716 4719 4725 4731\n",
      " 4732 4735 4742 4745 4749 4756 4770 4780 4790 4791 4801 4819 4823 4828\n",
      " 4836 4838 4840 4842 4852 4853]\n",
      "Number of samples for test set: 972\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:17:22.257857: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_309/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.0950 - accuracy: 0.3511 - val_loss: 1.0982 - val_accuracy: 0.3302 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0771 - accuracy: 0.4043 - val_loss: 1.1143 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0634 - accuracy: 0.4228 - val_loss: 1.1304 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0493 - accuracy: 0.4270 - val_loss: 1.1275 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0459 - accuracy: 0.4277 - val_loss: 1.1288 - val_accuracy: 0.3282 - 993ms/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0295 - accuracy: 0.4483 - val_loss: 1.1701 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0324 - accuracy: 0.4432 - val_loss: 1.1880 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0251 - accuracy: 0.4516 - val_loss: 1.2219 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0094 - accuracy: 0.4573 - val_loss: 1.2503 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0082 - accuracy: 0.4660 - val_loss: 1.2439 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0106 - accuracy: 0.4668 - val_loss: 1.2102 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0085 - accuracy: 0.4617 - val_loss: 1.2213 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 0.9997 - accuracy: 0.4689 - val_loss: 1.2181 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 0.9985 - accuracy: 0.4642 - val_loss: 1.2283 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 0.9903 - accuracy: 0.4686 - val_loss: 1.1929 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 0.9962 - accuracy: 0.4686 - val_loss: 1.1290 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 0.9898 - accuracy: 0.4653 - val_loss: 1.1137 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 0.9901 - accuracy: 0.4663 - val_loss: 1.1634 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 0.9831 - accuracy: 0.4678 - val_loss: 1.1304 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 0.9720 - accuracy: 0.4859 - val_loss: 1.1867 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 0.9719 - accuracy: 0.4846 - val_loss: 1.1010 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 0.9681 - accuracy: 0.4820 - val_loss: 1.1522 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 0.9784 - accuracy: 0.4848 - val_loss: 1.1264 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9659 - accuracy: 0.4802 - val_loss: 1.1692 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9586 - accuracy: 0.4892 - val_loss: 1.1698 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 0.9547 - accuracy: 0.4892 - val_loss: 1.2452 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9635 - accuracy: 0.4871 - val_loss: 1.2521 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9593 - accuracy: 0.4931 - val_loss: 1.3091 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9608 - accuracy: 0.4949 - val_loss: 1.2143 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9544 - accuracy: 0.4997 - val_loss: 1.2670 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9499 - accuracy: 0.4977 - val_loss: 1.2188 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9617 - accuracy: 0.4895 - val_loss: 1.2178 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9549 - accuracy: 0.5049 - val_loss: 1.1687 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9421 - accuracy: 0.5087 - val_loss: 1.2195 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9471 - accuracy: 0.5033 - val_loss: 1.1385 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9470 - accuracy: 0.4928 - val_loss: 1.1031 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9539 - accuracy: 0.4915 - val_loss: 1.1081 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9416 - accuracy: 0.5139 - val_loss: 1.1706 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9393 - accuracy: 0.4941 - val_loss: 1.1819 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9331 - accuracy: 0.5033 - val_loss: 1.2167 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9439 - accuracy: 0.4967 - val_loss: 1.2798 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9338 - accuracy: 0.4920 - val_loss: 1.2160 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9466 - accuracy: 0.4961 - val_loss: 1.1371 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9537 - accuracy: 0.4825 - val_loss: 1.1615 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9425 - accuracy: 0.5005 - val_loss: 1.0886 - val_accuracy: 0.3560 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9370 - accuracy: 0.5062 - val_loss: 1.2047 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9293 - accuracy: 0.5026 - val_loss: 1.1542 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9466 - accuracy: 0.5008 - val_loss: 1.2130 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9309 - accuracy: 0.5095 - val_loss: 1.1090 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9385 - accuracy: 0.5085 - val_loss: 1.1479 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9266 - accuracy: 0.5069 - val_loss: 1.2125 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9454 - accuracy: 0.4913 - val_loss: 1.2217 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9292 - accuracy: 0.5023 - val_loss: 1.2888 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9462 - accuracy: 0.4995 - val_loss: 1.1379 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9384 - accuracy: 0.5039 - val_loss: 1.2719 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9284 - accuracy: 0.5054 - val_loss: 1.1191 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9316 - accuracy: 0.5013 - val_loss: 1.1208 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9299 - accuracy: 0.5093 - val_loss: 1.0929 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9229 - accuracy: 0.5129 - val_loss: 1.1844 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9321 - accuracy: 0.5010 - val_loss: 1.1969 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9279 - accuracy: 0.5026 - val_loss: 1.1933 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9262 - accuracy: 0.5100 - val_loss: 1.1886 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9156 - accuracy: 0.5208 - val_loss: 1.2176 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9341 - accuracy: 0.5098 - val_loss: 1.2204 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9308 - accuracy: 0.5177 - val_loss: 1.1869 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9192 - accuracy: 0.5111 - val_loss: 1.1338 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9221 - accuracy: 0.5195 - val_loss: 1.1722 - val_accuracy: 0.3302 - 996ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9275 - accuracy: 0.5059 - val_loss: 1.3065 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9243 - accuracy: 0.5136 - val_loss: 1.4619 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9200 - accuracy: 0.5157 - val_loss: 1.2815 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9291 - accuracy: 0.5229 - val_loss: 1.1922 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9271 - accuracy: 0.5152 - val_loss: 1.1611 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9288 - accuracy: 0.5195 - val_loss: 1.1883 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9243 - accuracy: 0.5085 - val_loss: 1.3085 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9226 - accuracy: 0.5116 - val_loss: 1.2284 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.5100 - val_loss: 1.1315 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9143 - accuracy: 0.5183 - val_loss: 1.3972 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9243 - accuracy: 0.5026 - val_loss: 1.5113 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9234 - accuracy: 0.5087 - val_loss: 1.1242 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9283 - accuracy: 0.5121 - val_loss: 1.0986 - val_accuracy: 0.3560 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9180 - accuracy: 0.5116 - val_loss: 1.0981 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9184 - accuracy: 0.5198 - val_loss: 1.1274 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9083 - accuracy: 0.5213 - val_loss: 1.1556 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9172 - accuracy: 0.5221 - val_loss: 1.4045 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9289 - accuracy: 0.5172 - val_loss: 1.2484 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9088 - accuracy: 0.5270 - val_loss: 1.1709 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9194 - accuracy: 0.5098 - val_loss: 1.2149 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9094 - accuracy: 0.5249 - val_loss: 1.2077 - val_accuracy: 0.3302 - 981ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9208 - accuracy: 0.5247 - val_loss: 1.1818 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9173 - accuracy: 0.5237 - val_loss: 1.1715 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9155 - accuracy: 0.5262 - val_loss: 1.2458 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9139 - accuracy: 0.5257 - val_loss: 1.3905 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9081 - accuracy: 0.5301 - val_loss: 1.1287 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9075 - accuracy: 0.5208 - val_loss: 1.1168 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9133 - accuracy: 0.5154 - val_loss: 1.1466 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9210 - accuracy: 0.5188 - val_loss: 1.1192 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9203 - accuracy: 0.5165 - val_loss: 1.0997 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9087 - accuracy: 0.5221 - val_loss: 1.2423 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9109 - accuracy: 0.5332 - val_loss: 1.1304 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9066 - accuracy: 0.5159 - val_loss: 1.1163 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9120 - accuracy: 0.5231 - val_loss: 1.1194 - val_accuracy: 0.3323 - 979ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9051 - accuracy: 0.5316 - val_loss: 1.1153 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9103 - accuracy: 0.5195 - val_loss: 1.1548 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9079 - accuracy: 0.5247 - val_loss: 1.1399 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9155 - accuracy: 0.5244 - val_loss: 1.1252 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9016 - accuracy: 0.5267 - val_loss: 1.1317 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.8997 - accuracy: 0.5350 - val_loss: 1.4087 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9157 - accuracy: 0.5198 - val_loss: 1.3405 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.9140 - accuracy: 0.5234 - val_loss: 1.2176 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9156 - accuracy: 0.5255 - val_loss: 1.1141 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9046 - accuracy: 0.5219 - val_loss: 1.1064 - val_accuracy: 0.3755 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9082 - accuracy: 0.5229 - val_loss: 1.1053 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9207 - accuracy: 0.5193 - val_loss: 1.1570 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9057 - accuracy: 0.5188 - val_loss: 1.1113 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9103 - accuracy: 0.5216 - val_loss: 1.1523 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9062 - accuracy: 0.5270 - val_loss: 1.3279 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9091 - accuracy: 0.5283 - val_loss: 1.2663 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9079 - accuracy: 0.5231 - val_loss: 1.2354 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9067 - accuracy: 0.5159 - val_loss: 1.3077 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9082 - accuracy: 0.5303 - val_loss: 1.2018 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9066 - accuracy: 0.5234 - val_loss: 1.1829 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9010 - accuracy: 0.5332 - val_loss: 1.1544 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9069 - accuracy: 0.5190 - val_loss: 1.1657 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9004 - accuracy: 0.5504 - val_loss: 1.2860 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.8999 - accuracy: 0.5265 - val_loss: 1.1965 - val_accuracy: 0.3313 - 996ms/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.8990 - accuracy: 0.5337 - val_loss: 1.2272 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9017 - accuracy: 0.5386 - val_loss: 1.2373 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.8954 - accuracy: 0.5394 - val_loss: 1.2794 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.9057 - accuracy: 0.5224 - val_loss: 1.2465 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9008 - accuracy: 0.5188 - val_loss: 1.2310 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.8996 - accuracy: 0.5340 - val_loss: 1.2631 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.8983 - accuracy: 0.5350 - val_loss: 1.2702 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9065 - accuracy: 0.5311 - val_loss: 1.1630 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.8973 - accuracy: 0.5399 - val_loss: 1.1511 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.8890 - accuracy: 0.5440 - val_loss: 1.1369 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.8998 - accuracy: 0.5293 - val_loss: 1.2087 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9053 - accuracy: 0.5337 - val_loss: 1.2118 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.9012 - accuracy: 0.5309 - val_loss: 1.2017 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.9006 - accuracy: 0.5345 - val_loss: 1.2605 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.8965 - accuracy: 0.5399 - val_loss: 1.2752 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9024 - accuracy: 0.5288 - val_loss: 1.2234 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.8972 - accuracy: 0.5334 - val_loss: 1.2494 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9060 - accuracy: 0.5327 - val_loss: 1.3961 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.8973 - accuracy: 0.5414 - val_loss: 1.2754 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.8959 - accuracy: 0.5201 - val_loss: 1.3774 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9043 - accuracy: 0.5185 - val_loss: 1.2101 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.9008 - accuracy: 0.5401 - val_loss: 1.1668 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.8971 - accuracy: 0.5309 - val_loss: 1.2328 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.9037 - accuracy: 0.5296 - val_loss: 1.3000 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.8943 - accuracy: 0.5280 - val_loss: 1.3696 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.9002 - accuracy: 0.5332 - val_loss: 1.4454 - val_accuracy: 0.3302 - 991ms/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.8996 - accuracy: 0.5283 - val_loss: 1.1815 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.8888 - accuracy: 0.5383 - val_loss: 1.2902 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.8904 - accuracy: 0.5301 - val_loss: 1.2062 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.9009 - accuracy: 0.5285 - val_loss: 1.1766 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.9018 - accuracy: 0.5216 - val_loss: 1.4179 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9014 - accuracy: 0.5350 - val_loss: 1.4130 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.9030 - accuracy: 0.5412 - val_loss: 1.3736 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.8955 - accuracy: 0.5352 - val_loss: 1.3590 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.8951 - accuracy: 0.5293 - val_loss: 1.3249 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.8968 - accuracy: 0.5322 - val_loss: 1.2963 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.8932 - accuracy: 0.5345 - val_loss: 1.3207 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.8901 - accuracy: 0.5376 - val_loss: 1.1851 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.8861 - accuracy: 0.5391 - val_loss: 1.3601 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9034 - accuracy: 0.5327 - val_loss: 1.2606 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.8959 - accuracy: 0.5424 - val_loss: 1.2777 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.8909 - accuracy: 0.5419 - val_loss: 1.3211 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.8869 - accuracy: 0.5435 - val_loss: 1.2474 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.8934 - accuracy: 0.5378 - val_loss: 1.3263 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.8997 - accuracy: 0.5332 - val_loss: 1.2436 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.9015 - accuracy: 0.5332 - val_loss: 1.1947 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.8931 - accuracy: 0.5298 - val_loss: 1.1426 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.8891 - accuracy: 0.5448 - val_loss: 1.1611 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.8865 - accuracy: 0.5491 - val_loss: 1.2720 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9070 - accuracy: 0.5273 - val_loss: 1.1561 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.8875 - accuracy: 0.5373 - val_loss: 1.1760 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.8950 - accuracy: 0.5352 - val_loss: 1.1884 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.8797 - accuracy: 0.5391 - val_loss: 1.1852 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.8902 - accuracy: 0.5463 - val_loss: 1.1903 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.8956 - accuracy: 0.5301 - val_loss: 1.1606 - val_accuracy: 0.3323 - 980ms/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.8993 - accuracy: 0.5280 - val_loss: 1.1574 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.8997 - accuracy: 0.5440 - val_loss: 1.1640 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.8825 - accuracy: 0.5404 - val_loss: 1.3269 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.8878 - accuracy: 0.5496 - val_loss: 1.2579 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.8871 - accuracy: 0.5437 - val_loss: 1.2586 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.8934 - accuracy: 0.5363 - val_loss: 1.2357 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.8981 - accuracy: 0.5406 - val_loss: 1.2227 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.8984 - accuracy: 0.5244 - val_loss: 1.1937 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.8905 - accuracy: 0.5450 - val_loss: 1.2188 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.8904 - accuracy: 0.5311 - val_loss: 1.2069 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.8978 - accuracy: 0.5427 - val_loss: 1.2437 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.8892 - accuracy: 0.5419 - val_loss: 1.3695 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.8954 - accuracy: 0.5442 - val_loss: 1.4535 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.8878 - accuracy: 0.5430 - val_loss: 1.2482 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.8758 - accuracy: 0.5496 - val_loss: 1.1858 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.8865 - accuracy: 0.5473 - val_loss: 1.2368 - val_accuracy: 0.3313 - 992ms/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.8878 - accuracy: 0.5406 - val_loss: 1.4060 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.8932 - accuracy: 0.5383 - val_loss: 1.3502 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.8957 - accuracy: 0.5237 - val_loss: 1.2578 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.8982 - accuracy: 0.5316 - val_loss: 1.2032 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.8885 - accuracy: 0.5401 - val_loss: 1.3044 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.8837 - accuracy: 0.5422 - val_loss: 1.3157 - val_accuracy: 0.3302 - 991ms/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.8869 - accuracy: 0.5448 - val_loss: 1.1896 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.8997 - accuracy: 0.5337 - val_loss: 1.1966 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.8864 - accuracy: 0.5404 - val_loss: 1.2024 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.8806 - accuracy: 0.5476 - val_loss: 1.1641 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.8965 - accuracy: 0.5327 - val_loss: 1.3798 - val_accuracy: 0.3292 - 970ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.8995 - accuracy: 0.5370 - val_loss: 1.4156 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.8942 - accuracy: 0.5334 - val_loss: 1.6839 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.8863 - accuracy: 0.5404 - val_loss: 1.5976 - val_accuracy: 0.3292 - 963ms/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.8945 - accuracy: 0.5327 - val_loss: 1.5333 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.8876 - accuracy: 0.5401 - val_loss: 1.4471 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.8742 - accuracy: 0.5463 - val_loss: 1.4899 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.8717 - accuracy: 0.5486 - val_loss: 1.3413 - val_accuracy: 0.3292 - 995ms/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.8874 - accuracy: 0.5332 - val_loss: 1.3145 - val_accuracy: 0.3302 - 986ms/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.8843 - accuracy: 0.5414 - val_loss: 1.2638 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.8863 - accuracy: 0.5373 - val_loss: 1.3272 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.8976 - accuracy: 0.5273 - val_loss: 1.4699 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.8869 - accuracy: 0.5378 - val_loss: 1.5086 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.8822 - accuracy: 0.5466 - val_loss: 1.6411 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.8805 - accuracy: 0.5566 - val_loss: 1.4273 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.8897 - accuracy: 0.5437 - val_loss: 1.4939 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.8866 - accuracy: 0.5514 - val_loss: 1.7213 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.8853 - accuracy: 0.5458 - val_loss: 1.5763 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.8804 - accuracy: 0.5499 - val_loss: 1.2886 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.8829 - accuracy: 0.5514 - val_loss: 1.4889 - val_accuracy: 0.3302 - 1000ms/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.8998 - accuracy: 0.5352 - val_loss: 1.2740 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.8809 - accuracy: 0.5494 - val_loss: 1.4612 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.8861 - accuracy: 0.5430 - val_loss: 1.5017 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.8880 - accuracy: 0.5409 - val_loss: 1.2558 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.8773 - accuracy: 0.5502 - val_loss: 1.4976 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.8821 - accuracy: 0.5496 - val_loss: 1.5011 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.8850 - accuracy: 0.5458 - val_loss: 1.7263 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.8861 - accuracy: 0.5458 - val_loss: 1.8146 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.8972 - accuracy: 0.5427 - val_loss: 1.6462 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.9002 - accuracy: 0.5381 - val_loss: 1.4446 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.8818 - accuracy: 0.5424 - val_loss: 1.4214 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.8901 - accuracy: 0.5391 - val_loss: 1.3630 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.8715 - accuracy: 0.5499 - val_loss: 1.3768 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.8882 - accuracy: 0.5466 - val_loss: 1.2911 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.8860 - accuracy: 0.5448 - val_loss: 1.4813 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.8727 - accuracy: 0.5417 - val_loss: 1.6022 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.8696 - accuracy: 0.5535 - val_loss: 1.5376 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.8890 - accuracy: 0.5337 - val_loss: 1.4676 - val_accuracy: 0.3302 - 986ms/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.8863 - accuracy: 0.5404 - val_loss: 1.3948 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.8796 - accuracy: 0.5491 - val_loss: 1.3737 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.8697 - accuracy: 0.5460 - val_loss: 1.5330 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.8765 - accuracy: 0.5491 - val_loss: 1.3627 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.8950 - accuracy: 0.5363 - val_loss: 1.4927 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.8826 - accuracy: 0.5494 - val_loss: 1.4280 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 4856 4858 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   5    6    8   15   17   20   24   30   47   48   49   51   57   59\n",
      "   64   67   69   78   83   84   95   97  101  107  121  138  141  143\n",
      "  144  152  163  168  170  178  179  180  183  185  191  194  196  197\n",
      "  202  203  206  226  233  235  238  239  241  247  251  253  255  257\n",
      "  263  281  289  290  299  306  327  330  331  334  338  339  343  348\n",
      "  349  354  357  364  372  377  380  381  389  402  408  411  412  414\n",
      "  417  421  429  431  434  435  440  445  447  463  464  470  472  474\n",
      "  483  486  489  496  501  502  503  510  515  519  524  526  536  543\n",
      "  545  559  560  569  577  578  580  586  588  589  591  593  604  608\n",
      "  612  613  619  625  626  628  630  634  638  639  643  644  652  667\n",
      "  678  681  682  690  691  702  711  716  722  723  735  737  741  744\n",
      "  747  753  757  758  761  763  764  765  771  772  776  777  779  780\n",
      "  782  783  785  788  792  793  800  805  806  813  814  815  820  828\n",
      "  829  840  852  865  869  878  881  895  902  908  918  919  922  929\n",
      "  935  940  941  951  952  954  955  959  961  967  973  980  981  985\n",
      "  999 1004 1010 1024 1025 1026 1029 1032 1033 1034 1035 1038 1045 1046\n",
      " 1048 1053 1055 1060 1080 1083 1085 1086 1099 1101 1105 1106 1109 1110\n",
      " 1115 1118 1123 1124 1129 1136 1137 1140 1142 1144 1146 1148 1157 1168\n",
      " 1169 1171 1174 1178 1180 1190 1208 1218 1224 1229 1236 1238 1245 1246\n",
      " 1250 1251 1255 1265 1281 1283 1284 1288 1292 1305 1306 1309 1310 1318\n",
      " 1325 1330 1334 1338 1341 1352 1353 1356 1370 1372 1374 1394 1400 1409\n",
      " 1414 1415 1420 1424 1425 1427 1433 1437 1440 1441 1444 1446 1456 1461\n",
      " 1471 1473 1475 1477 1480 1481 1488 1506 1507 1509 1510 1511 1513 1525\n",
      " 1531 1537 1539 1546 1551 1554 1567 1572 1573 1578 1582 1583 1588 1590\n",
      " 1593 1605 1610 1611 1619 1620 1624 1645 1646 1650 1651 1653 1667 1674\n",
      " 1675 1677 1686 1687 1692 1694 1699 1717 1740 1744 1745 1751 1754 1756\n",
      " 1765 1766 1768 1772 1775 1776 1780 1783 1789 1795 1797 1799 1806 1809\n",
      " 1817 1823 1827 1834 1847 1852 1855 1858 1867 1868 1876 1877 1881 1894\n",
      " 1896 1898 1900 1901 1905 1906 1913 1914 1915 1920 1925 1927 1929 1931\n",
      " 1933 1945 1953 1956 1964 1965 1966 1971 1993 1997 1998 2000 2001 2002\n",
      " 2012 2027 2032 2045 2048 2049 2050 2053 2055 2062 2070 2076 2080 2081\n",
      " 2087 2096 2106 2109 2114 2118 2122 2126 2128 2134 2136 2150 2153 2160\n",
      " 2162 2163 2165 2168 2169 2171 2173 2181 2183 2186 2187 2191 2198 2202\n",
      " 2207 2209 2214 2218 2225 2233 2238 2243 2253 2255 2258 2260 2263 2269\n",
      " 2273 2274 2277 2282 2284 2287 2288 2291 2292 2293 2296 2298 2307 2309\n",
      " 2310 2316 2317 2335 2343 2347 2352 2353 2355 2369 2374 2379 2387 2389\n",
      " 2390 2400 2401 2402 2403 2409 2410 2413 2415 2416 2426 2432 2434 2435\n",
      " 2442 2445 2447 2471 2476 2483 2485 2493 2495 2498 2505 2515 2516 2527\n",
      " 2530 2539 2540 2542 2545 2547 2549 2554 2558 2559 2561 2569 2576 2577\n",
      " 2586 2591 2601 2610 2611 2615 2618 2627 2639 2640 2643 2644 2648 2656\n",
      " 2660 2663 2669 2676 2682 2686 2687 2702 2705 2708 2713 2717 2720 2735\n",
      " 2744 2745 2748 2753 2762 2770 2779 2782 2787 2790 2791 2797 2799 2800\n",
      " 2807 2810 2815 2821 2822 2824 2826 2830 2840 2841 2848 2853 2865 2871\n",
      " 2875 2882 2892 2893 2904 2906 2913 2916 2930 2933 2935 2936 2940 2943\n",
      " 2947 2948 2955 2956 2962 2969 2971 2972 2974 2975 2981 2983 2984 2988\n",
      " 2993 2998 3001 3005 3008 3022 3023 3024 3038 3051 3059 3064 3065 3066\n",
      " 3067 3071 3076 3082 3091 3093 3113 3122 3128 3134 3135 3136 3146 3148\n",
      " 3152 3153 3154 3155 3156 3162 3163 3168 3169 3170 3171 3178 3181 3183\n",
      " 3185 3187 3192 3198 3209 3222 3223 3227 3231 3234 3239 3246 3247 3259\n",
      " 3260 3262 3264 3265 3269 3272 3275 3276 3278 3279 3286 3291 3293 3300\n",
      " 3308 3309 3310 3311 3315 3328 3330 3336 3342 3348 3351 3352 3375 3378\n",
      " 3383 3394 3397 3402 3405 3408 3412 3420 3429 3430 3441 3444 3456 3467\n",
      " 3471 3474 3476 3480 3496 3513 3517 3520 3524 3527 3529 3532 3541 3545\n",
      " 3555 3569 3592 3594 3596 3597 3625 3634 3642 3643 3647 3652 3656 3686\n",
      " 3687 3689 3695 3698 3701 3702 3703 3726 3734 3738 3745 3748 3749 3752\n",
      " 3755 3767 3784 3785 3788 3794 3797 3798 3799 3811 3817 3829 3834 3841\n",
      " 3842 3846 3847 3863 3870 3873 3880 3903 3906 3908 3911 3916 3918 3924\n",
      " 3926 3945 3949 3955 3957 3970 3974 3986 4005 4007 4013 4029 4032 4047\n",
      " 4050 4064 4069 4073 4074 4085 4089 4096 4101 4103 4107 4113 4123 4127\n",
      " 4139 4146 4149 4152 4172 4176 4194 4196 4201 4202 4204 4207 4211 4228\n",
      " 4231 4241 4243 4250 4254 4257 4271 4273 4277 4281 4285 4288 4292 4293\n",
      " 4298 4304 4306 4310 4316 4317 4324 4327 4331 4332 4338 4339 4342 4349\n",
      " 4356 4358 4360 4379 4384 4385 4389 4390 4392 4395 4396 4398 4410 4430\n",
      " 4437 4439 4440 4441 4442 4443 4445 4451 4457 4459 4468 4469 4473 4481\n",
      " 4484 4493 4496 4499 4503 4505 4511 4531 4536 4553 4557 4563 4568 4569\n",
      " 4570 4573 4580 4584 4587 4595 4599 4608 4610 4614 4618 4627 4636 4638\n",
      " 4641 4644 4646 4647 4651 4652 4654 4666 4667 4668 4670 4676 4677 4681\n",
      " 4682 4684 4699 4701 4702 4706 4708 4714 4736 4743 4746 4759 4760 4764\n",
      " 4766 4771 4775 4777 4786 4787 4792 4804 4810 4811 4812 4813 4817 4824\n",
      " 4825 4833 4837 4847 4855 4857]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:21:45.165047: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_310/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.0971 - accuracy: 0.3524 - val_loss: 1.0940 - val_accuracy: 0.3447 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0712 - accuracy: 0.4151 - val_loss: 1.1095 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0513 - accuracy: 0.4241 - val_loss: 1.1811 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0471 - accuracy: 0.4226 - val_loss: 1.1519 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0306 - accuracy: 0.4457 - val_loss: 1.1879 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0227 - accuracy: 0.4542 - val_loss: 1.1618 - val_accuracy: 0.3467 - 1s/epoch - 5ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0148 - accuracy: 0.4524 - val_loss: 1.1879 - val_accuracy: 0.3457 - 1s/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0215 - accuracy: 0.4478 - val_loss: 1.1374 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0094 - accuracy: 0.4596 - val_loss: 1.1480 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0072 - accuracy: 0.4632 - val_loss: 1.1445 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0022 - accuracy: 0.4660 - val_loss: 1.1613 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 0.9922 - accuracy: 0.4653 - val_loss: 1.1791 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 0.9882 - accuracy: 0.4720 - val_loss: 1.1311 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 0.9895 - accuracy: 0.4740 - val_loss: 1.0980 - val_accuracy: 0.3457 - 982ms/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 0.9844 - accuracy: 0.4745 - val_loss: 1.1588 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 0.9798 - accuracy: 0.4823 - val_loss: 1.1301 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 0.9740 - accuracy: 0.4848 - val_loss: 1.1629 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 0.9799 - accuracy: 0.4802 - val_loss: 1.1540 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 0.9771 - accuracy: 0.4864 - val_loss: 1.1417 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 0.9756 - accuracy: 0.4825 - val_loss: 1.1338 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 0.9629 - accuracy: 0.4884 - val_loss: 1.1169 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 0.9551 - accuracy: 0.4920 - val_loss: 1.1420 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 0.9648 - accuracy: 0.4848 - val_loss: 1.0862 - val_accuracy: 0.3580 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 0.9568 - accuracy: 0.4964 - val_loss: 1.0889 - val_accuracy: 0.3467 - 977ms/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 0.9566 - accuracy: 0.4910 - val_loss: 1.1217 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 0.9591 - accuracy: 0.4987 - val_loss: 1.0995 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 0.9659 - accuracy: 0.4835 - val_loss: 1.1050 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 0.9566 - accuracy: 0.4820 - val_loss: 1.1467 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 0.9582 - accuracy: 0.4877 - val_loss: 1.1097 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 0.9506 - accuracy: 0.4928 - val_loss: 1.1414 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 0.9587 - accuracy: 0.5010 - val_loss: 1.1344 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 0.9478 - accuracy: 0.4997 - val_loss: 1.1283 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 0.9456 - accuracy: 0.5031 - val_loss: 1.1583 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 0.9470 - accuracy: 0.4954 - val_loss: 1.1147 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 0.9424 - accuracy: 0.5023 - val_loss: 1.0973 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 0.9445 - accuracy: 0.5013 - val_loss: 1.0895 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 0.9400 - accuracy: 0.5044 - val_loss: 1.1130 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 0.9457 - accuracy: 0.4902 - val_loss: 1.0898 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 0.9510 - accuracy: 0.4877 - val_loss: 1.1150 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 0.9432 - accuracy: 0.4969 - val_loss: 1.0872 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 0.9377 - accuracy: 0.4967 - val_loss: 1.1112 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 0.9414 - accuracy: 0.5013 - val_loss: 1.1254 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 0.9332 - accuracy: 0.4961 - val_loss: 1.1071 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 0.9312 - accuracy: 0.5059 - val_loss: 1.1358 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 0.9332 - accuracy: 0.5129 - val_loss: 1.3260 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 0.9293 - accuracy: 0.4956 - val_loss: 1.1613 - val_accuracy: 0.3447 - 1s/epoch - 5ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 0.9327 - accuracy: 0.5067 - val_loss: 1.2368 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 0.9320 - accuracy: 0.5082 - val_loss: 1.1890 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 0.9282 - accuracy: 0.4938 - val_loss: 1.1461 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 0.9281 - accuracy: 0.5149 - val_loss: 1.2024 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 0.9243 - accuracy: 0.5054 - val_loss: 1.2179 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 0.9351 - accuracy: 0.5005 - val_loss: 1.1206 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 0.9369 - accuracy: 0.5062 - val_loss: 1.1417 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 0.9345 - accuracy: 0.4985 - val_loss: 1.1939 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 0.9331 - accuracy: 0.4982 - val_loss: 1.2183 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 0.9287 - accuracy: 0.5131 - val_loss: 1.2083 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 0.9291 - accuracy: 0.5059 - val_loss: 1.1420 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 0.9187 - accuracy: 0.5252 - val_loss: 1.2240 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 0.9236 - accuracy: 0.5082 - val_loss: 1.2117 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 0.9290 - accuracy: 0.5077 - val_loss: 1.2447 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 0.9237 - accuracy: 0.5121 - val_loss: 1.1282 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 0.9230 - accuracy: 0.5172 - val_loss: 1.1251 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 0.9235 - accuracy: 0.5172 - val_loss: 1.1397 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 0.9262 - accuracy: 0.5113 - val_loss: 1.1615 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 0.9245 - accuracy: 0.4997 - val_loss: 1.1646 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 0.9175 - accuracy: 0.5059 - val_loss: 1.2373 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 0.9204 - accuracy: 0.5054 - val_loss: 1.1874 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 0.9203 - accuracy: 0.5085 - val_loss: 1.2136 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 0.9194 - accuracy: 0.5180 - val_loss: 1.2212 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 0.9260 - accuracy: 0.5075 - val_loss: 1.1471 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 0.9293 - accuracy: 0.5077 - val_loss: 1.1457 - val_accuracy: 0.3457 - 999ms/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 0.9181 - accuracy: 0.5154 - val_loss: 1.1867 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 0.9255 - accuracy: 0.5044 - val_loss: 1.1629 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 0.9215 - accuracy: 0.4982 - val_loss: 1.2651 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 0.9207 - accuracy: 0.5165 - val_loss: 1.2547 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 0.9067 - accuracy: 0.5077 - val_loss: 1.1758 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 0.9225 - accuracy: 0.4977 - val_loss: 1.1596 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 0.9230 - accuracy: 0.5062 - val_loss: 1.1923 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 0.9201 - accuracy: 0.5067 - val_loss: 1.1733 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 0.9177 - accuracy: 0.4992 - val_loss: 1.1694 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 0.9131 - accuracy: 0.5111 - val_loss: 1.1927 - val_accuracy: 0.3457 - 992ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 0.9182 - accuracy: 0.5082 - val_loss: 1.1501 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 0.9271 - accuracy: 0.5095 - val_loss: 1.1051 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 0.9158 - accuracy: 0.5198 - val_loss: 1.2083 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 0.9092 - accuracy: 0.5314 - val_loss: 1.2879 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 0.9141 - accuracy: 0.5129 - val_loss: 1.1914 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 0.9146 - accuracy: 0.5036 - val_loss: 1.1402 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 0.9196 - accuracy: 0.5136 - val_loss: 1.1513 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 0.9122 - accuracy: 0.5136 - val_loss: 1.0989 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 0.9199 - accuracy: 0.5190 - val_loss: 1.0866 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 0.9107 - accuracy: 0.5116 - val_loss: 1.1174 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 0.9117 - accuracy: 0.5175 - val_loss: 1.1543 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 0.9145 - accuracy: 0.5067 - val_loss: 1.1435 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 0.9133 - accuracy: 0.5285 - val_loss: 1.1592 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 0.9210 - accuracy: 0.5103 - val_loss: 1.1279 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 0.9097 - accuracy: 0.5239 - val_loss: 1.1629 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 0.9179 - accuracy: 0.5185 - val_loss: 1.0960 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 0.9138 - accuracy: 0.5116 - val_loss: 1.1061 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 0.9119 - accuracy: 0.5136 - val_loss: 1.1535 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 0.9133 - accuracy: 0.5234 - val_loss: 1.1334 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 0.9074 - accuracy: 0.5144 - val_loss: 1.1231 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 0.9025 - accuracy: 0.5116 - val_loss: 1.2037 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 0.9159 - accuracy: 0.5195 - val_loss: 1.1497 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 0.9172 - accuracy: 0.5131 - val_loss: 1.2322 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 0.9065 - accuracy: 0.5057 - val_loss: 1.1789 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 0.9087 - accuracy: 0.5206 - val_loss: 1.2005 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 0.9076 - accuracy: 0.5134 - val_loss: 1.1627 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 0.9106 - accuracy: 0.5147 - val_loss: 1.1563 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 0.8994 - accuracy: 0.5265 - val_loss: 1.3086 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 0.9098 - accuracy: 0.5123 - val_loss: 1.2775 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 0.9087 - accuracy: 0.5147 - val_loss: 1.4169 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 0.9121 - accuracy: 0.5121 - val_loss: 1.3046 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 0.9054 - accuracy: 0.5242 - val_loss: 1.3101 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 0.9016 - accuracy: 0.5185 - val_loss: 1.2412 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 0.9012 - accuracy: 0.5278 - val_loss: 1.2785 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 0.9118 - accuracy: 0.5080 - val_loss: 1.2070 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 0.9031 - accuracy: 0.5201 - val_loss: 1.2350 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 0.9125 - accuracy: 0.5203 - val_loss: 1.1512 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 0.9093 - accuracy: 0.5144 - val_loss: 1.1523 - val_accuracy: 0.3457 - 992ms/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 0.9123 - accuracy: 0.5123 - val_loss: 1.1151 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 0.9124 - accuracy: 0.5093 - val_loss: 1.1135 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 0.9163 - accuracy: 0.5093 - val_loss: 1.0911 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 0.9042 - accuracy: 0.5275 - val_loss: 1.1552 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 0.9060 - accuracy: 0.5139 - val_loss: 1.1920 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 0.9098 - accuracy: 0.5213 - val_loss: 1.1046 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 0.9079 - accuracy: 0.5188 - val_loss: 1.1111 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 0.9089 - accuracy: 0.5118 - val_loss: 1.1319 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 0.8971 - accuracy: 0.5252 - val_loss: 1.1608 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 0.8971 - accuracy: 0.5172 - val_loss: 1.2183 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 0.9096 - accuracy: 0.5303 - val_loss: 1.1808 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 0.9087 - accuracy: 0.5162 - val_loss: 1.2086 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 0.9013 - accuracy: 0.5185 - val_loss: 1.2428 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 0.9017 - accuracy: 0.5208 - val_loss: 1.2026 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 0.9033 - accuracy: 0.5177 - val_loss: 1.1527 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 0.9009 - accuracy: 0.5157 - val_loss: 1.1080 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 0.9030 - accuracy: 0.5285 - val_loss: 1.2096 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 0.9029 - accuracy: 0.5211 - val_loss: 1.1992 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 0.9137 - accuracy: 0.5111 - val_loss: 1.1736 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 0.8965 - accuracy: 0.5298 - val_loss: 1.2166 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 0.8935 - accuracy: 0.5368 - val_loss: 1.2305 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 0.9019 - accuracy: 0.5226 - val_loss: 1.1830 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9000 - accuracy: 0.5293 - val_loss: 1.1442 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 0.9071 - accuracy: 0.5193 - val_loss: 1.1508 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 0.9005 - accuracy: 0.5265 - val_loss: 1.3133 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 0.9033 - accuracy: 0.5267 - val_loss: 1.3555 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 0.9011 - accuracy: 0.5219 - val_loss: 1.3613 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 0.9042 - accuracy: 0.5229 - val_loss: 1.4530 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 0.9031 - accuracy: 0.5234 - val_loss: 1.3951 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 0.9023 - accuracy: 0.5265 - val_loss: 1.4166 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 0.8873 - accuracy: 0.5288 - val_loss: 1.3820 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 0.8988 - accuracy: 0.5177 - val_loss: 1.3703 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 0.8969 - accuracy: 0.5095 - val_loss: 1.3764 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 0.9078 - accuracy: 0.5201 - val_loss: 1.4421 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 0.8954 - accuracy: 0.5226 - val_loss: 1.4483 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.8957 - accuracy: 0.5347 - val_loss: 1.4606 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 0.9040 - accuracy: 0.5293 - val_loss: 1.3707 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.8952 - accuracy: 0.5360 - val_loss: 1.2958 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 0.9075 - accuracy: 0.5201 - val_loss: 1.1944 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 0.8983 - accuracy: 0.5167 - val_loss: 1.2507 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.8957 - accuracy: 0.5298 - val_loss: 1.3303 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9073 - accuracy: 0.5193 - val_loss: 1.3007 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 0.9031 - accuracy: 0.5234 - val_loss: 1.2014 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 0.8942 - accuracy: 0.5213 - val_loss: 1.2299 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.8968 - accuracy: 0.5203 - val_loss: 1.2402 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9033 - accuracy: 0.5213 - val_loss: 1.3249 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 0.8901 - accuracy: 0.5363 - val_loss: 1.2764 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.8995 - accuracy: 0.5229 - val_loss: 1.2198 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 0.8907 - accuracy: 0.5358 - val_loss: 1.2544 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 0.8961 - accuracy: 0.5311 - val_loss: 1.2100 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.8908 - accuracy: 0.5345 - val_loss: 1.3563 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 0.8939 - accuracy: 0.5322 - val_loss: 1.2315 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 0.9005 - accuracy: 0.5255 - val_loss: 1.3021 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.9022 - accuracy: 0.5303 - val_loss: 1.1948 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 0.8969 - accuracy: 0.5303 - val_loss: 1.1930 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.8937 - accuracy: 0.5242 - val_loss: 1.1842 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 0.8916 - accuracy: 0.5311 - val_loss: 1.2385 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.8936 - accuracy: 0.5345 - val_loss: 1.1783 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 0.8970 - accuracy: 0.5211 - val_loss: 1.2235 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.8830 - accuracy: 0.5471 - val_loss: 1.2655 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.8961 - accuracy: 0.5309 - val_loss: 1.2674 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 0.8957 - accuracy: 0.5255 - val_loss: 1.2069 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 0.8913 - accuracy: 0.5383 - val_loss: 1.2635 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 0.8936 - accuracy: 0.5303 - val_loss: 1.3096 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 0.8935 - accuracy: 0.5332 - val_loss: 1.2709 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 0.8883 - accuracy: 0.5386 - val_loss: 1.2468 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 0.8910 - accuracy: 0.5327 - val_loss: 1.1308 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.8783 - accuracy: 0.5381 - val_loss: 1.1710 - val_accuracy: 0.3447 - 1s/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.8997 - accuracy: 0.5221 - val_loss: 1.1435 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.8879 - accuracy: 0.5211 - val_loss: 1.2646 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 0.8976 - accuracy: 0.5296 - val_loss: 1.3181 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.8962 - accuracy: 0.5417 - val_loss: 1.3020 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9034 - accuracy: 0.5278 - val_loss: 1.2041 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.8901 - accuracy: 0.5249 - val_loss: 1.1626 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.8803 - accuracy: 0.5285 - val_loss: 1.2357 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.8927 - accuracy: 0.5265 - val_loss: 1.1539 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.8880 - accuracy: 0.5360 - val_loss: 1.1205 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 0.8908 - accuracy: 0.5388 - val_loss: 1.1696 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.8842 - accuracy: 0.5396 - val_loss: 1.1935 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 0.8802 - accuracy: 0.5412 - val_loss: 1.3623 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.8929 - accuracy: 0.5247 - val_loss: 1.2514 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.8899 - accuracy: 0.5363 - val_loss: 1.1812 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.8868 - accuracy: 0.5373 - val_loss: 1.1571 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.8920 - accuracy: 0.5303 - val_loss: 1.2337 - val_accuracy: 0.3457 - 969ms/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.8900 - accuracy: 0.5301 - val_loss: 1.1991 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.8851 - accuracy: 0.5378 - val_loss: 1.1746 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.8930 - accuracy: 0.5301 - val_loss: 1.1969 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 0.9035 - accuracy: 0.5270 - val_loss: 1.2583 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.8886 - accuracy: 0.5342 - val_loss: 1.1723 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.8988 - accuracy: 0.5373 - val_loss: 1.1595 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.8980 - accuracy: 0.5332 - val_loss: 1.1500 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.9017 - accuracy: 0.5111 - val_loss: 1.1250 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.8919 - accuracy: 0.5247 - val_loss: 1.1537 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.8897 - accuracy: 0.5332 - val_loss: 1.1548 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 0.8867 - accuracy: 0.5311 - val_loss: 1.1084 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.8943 - accuracy: 0.5340 - val_loss: 1.1835 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.8928 - accuracy: 0.5324 - val_loss: 1.1152 - val_accuracy: 0.3447 - 1s/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.8856 - accuracy: 0.5316 - val_loss: 1.1671 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.8832 - accuracy: 0.5502 - val_loss: 1.1985 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.8879 - accuracy: 0.5311 - val_loss: 1.2499 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 0.8809 - accuracy: 0.5412 - val_loss: 1.2785 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.8873 - accuracy: 0.5409 - val_loss: 1.1580 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.8773 - accuracy: 0.5342 - val_loss: 1.1747 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.8771 - accuracy: 0.5329 - val_loss: 1.1477 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.8779 - accuracy: 0.5406 - val_loss: 1.1550 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 0.8841 - accuracy: 0.5350 - val_loss: 1.1677 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.8931 - accuracy: 0.5309 - val_loss: 1.2715 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.8920 - accuracy: 0.5298 - val_loss: 1.1904 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.8916 - accuracy: 0.5350 - val_loss: 1.2094 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.8969 - accuracy: 0.5306 - val_loss: 1.1427 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.8882 - accuracy: 0.5401 - val_loss: 1.1302 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.8830 - accuracy: 0.5322 - val_loss: 1.2003 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.8892 - accuracy: 0.5376 - val_loss: 1.1731 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.8910 - accuracy: 0.5422 - val_loss: 1.1295 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.8919 - accuracy: 0.5381 - val_loss: 1.1847 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.8890 - accuracy: 0.5468 - val_loss: 1.2332 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.8912 - accuracy: 0.5291 - val_loss: 1.2023 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.8909 - accuracy: 0.5314 - val_loss: 1.2335 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.8784 - accuracy: 0.5455 - val_loss: 1.2712 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.8936 - accuracy: 0.5345 - val_loss: 1.1877 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.8802 - accuracy: 0.5404 - val_loss: 1.1392 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.8784 - accuracy: 0.5545 - val_loss: 1.2623 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.8924 - accuracy: 0.5334 - val_loss: 1.1426 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.8859 - accuracy: 0.5419 - val_loss: 1.2081 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.8819 - accuracy: 0.5378 - val_loss: 1.2113 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.8826 - accuracy: 0.5417 - val_loss: 1.2413 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.8828 - accuracy: 0.5370 - val_loss: 1.2731 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.8885 - accuracy: 0.5427 - val_loss: 1.2308 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.8862 - accuracy: 0.5422 - val_loss: 1.2235 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.8702 - accuracy: 0.5401 - val_loss: 1.2766 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.8863 - accuracy: 0.5342 - val_loss: 1.1443 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PER SUB \n",
    "# SUBJECTS=[1,2,3,4,5,6,7,8,9,11,12,13,14,16,17]\n",
    "# for temp_sub in SUBJECTS:\n",
    "# sub=\"{:02d}\".format(temp_sub)\n",
    "\n",
    "CLASSES= [2,3]\n",
    "for n_classes in CLASSES:\n",
    "    #Define loss function\n",
    "    loss_fn= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    LABELS= list(range(0,n_classes))\n",
    "    numero_classi=n_classes\n",
    "\n",
    "#         dir0= os.path.join(\"FINAL_motor_imagery_classification/2_sec_windows/powerbands/\"+str(n_classes)+\"class/output/\", \"sub_\"+str(sub))\n",
    "    dir0= os.path.join(\"FINAL_motor_imagery_classification/2_sec_windows/powerbands/\"+str(n_classes)+\"class/output/\", \"all\")\n",
    "\n",
    "    os.mkdir(dir0)\n",
    "    dir_input=(\"FINAL_motor_imagery_classification/2_sec_windows/powerbands/\"+str(n_classes)+\"class/input\")\n",
    "\n",
    "    evaluation=[]\n",
    "    iteration=[]\n",
    "    confusion_matrix_x_test=[]\n",
    "    confusion_matrix_y_test= []\n",
    "    validation_acc=[]\n",
    "    PERFORMANCE=[]\n",
    "\n",
    "    print(\"SUBJECT: \"+ str(sub))\n",
    "    print(\"N_CLASSES: \"+ str(n_classes))\n",
    "\n",
    "#     X=sio.loadmat(dir_input+\"/sub_\"+str(sub)+ \"_X.mat\")[\"array_X\"]\n",
    "#     y= sio.loadmat(dir_input+\"/sub_\"+str(sub)+\"_y.mat\")[\"array_y\"]\n",
    "\n",
    "    X=sio.loadmat(dir_input+\"/all_X.mat\")[\"array_X\"]\n",
    "    y= sio.loadmat(dir_input+\"/all_y.mat\")[\"array_y\"]\n",
    "    X= np.transpose(X, (0,1,3,2))\n",
    "#         X=np.clip(X,0,100)\n",
    "#         X= X.reshape(X.shape[0], X.shape[1], -1,1)\n",
    "\n",
    "    y=y.flatten()\n",
    "    print(\"New shape for X: \" + str(X.shape))\n",
    "    print(\"New shape for y: \"+str(y.shape))\n",
    "\n",
    "    dir1=os.path.join(dir0, \"comparison\")\n",
    "    dir2=os.path.join(dir0, \"temporal_convolution\")\n",
    "    dir3=os.path.join(dir0, \"spatial_convolution\")\n",
    "    os.mkdir(dir1)\n",
    "    os.mkdir(dir2)\n",
    "    os.mkdir(dir3)\n",
    "\n",
    "    ################################################################################################################################################################################################################################################################################\n",
    "\n",
    "    n_folds = 5\n",
    "    seed = 21\n",
    "    shuffle_test = True\n",
    "    EPOCHS=250\n",
    "\n",
    "    N_chan=31\n",
    "    N_samples_long=50\n",
    "    N_frequency_bins= 4\n",
    "\n",
    "    kfold = KFold(n_splits = n_folds, shuffle = shuffle_test, random_state = seed)\n",
    "    count=0\n",
    "    sommatoria=0\n",
    "\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        count=count+1\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        print(\"Train index for this split: \"+ str(train_index)) \n",
    "        print(\"Number of samples for train set: \"+str(train_index.shape[0]))\n",
    "        print(\"Test index for this split: \"+ str(test_index))\n",
    "        print(\"Number of samples for test set: \"+str(test_index.shape[0]))\n",
    "\n",
    "        # Define the model architecture - \n",
    "\n",
    "#             model= EEGNet(n_classes, Chans = N_chan, Samples = N_samples_long, \n",
    "#              dropoutRate = Drop_test, kernLength = KernLength_test, F1 = F1_test, \n",
    "#              D = D_test, F2 = F2_test, norm_rate = 0.25, dropoutType = 'Dropout', )\n",
    "\n",
    "        model=Sequential()\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "        model.add(Conv2D(8, (1, 64), padding = 'same',\n",
    "                                       input_shape = (N_chan, N_samples_long, 4),\n",
    "                                       use_bias = False, name=\"temporal_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_1\"))\n",
    "        model.add(DepthwiseConv2D((31, 1), use_bias = False, \n",
    "                                       depth_multiplier = 2,\n",
    "                                       depthwise_constraint = max_norm(1.), name=\"spatial_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_2\"))\n",
    "        model.add(Activation('elu', name=\"activation_1\"))\n",
    "        model.add(AveragePooling2D((1, 4), name=\"pooling_layer_1\"))\n",
    "        model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "\n",
    "        model.add(SeparableConv2D(16, (1, 16),\n",
    "                                       use_bias = False, padding = 'same', name=\"separable_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_3\"))\n",
    "        model.add(Activation('elu', name=\"activation_2\"))\n",
    "        model.add(AveragePooling2D((1, 8), name=\"pooling_layer_2\"))\n",
    "        model.add(Dropout(0.5, name=\"drpout_2\")) #QUI DROPOUT E' LASCIATO A 0.5 come in eegnet paper\n",
    "\n",
    "        model.add(Flatten(name = 'flatten'))\n",
    "\n",
    "        model.add(Dense(numero_classi, name = 'dense', \n",
    "                                 kernel_constraint = max_norm(0.25)))\n",
    "        model.add(Activation('softmax', name = 'softmax'))\n",
    "\n",
    "\n",
    "        # Define the optimizer\n",
    "        optimizer= optimizers.Adam(\n",
    "        learning_rate= 1e-3,\n",
    "        weight_decay= 0\n",
    "        )\n",
    "        model.compile(optimizer=optimizer,\n",
    "                       loss=loss_fn,\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "        evaluation.append(model.fit(X_train, y_train, batch_size=16,\n",
    "                  epochs=EPOCHS, \n",
    "                  validation_data=(X_test, y_test), \n",
    "                  verbose=2, workers=1)\n",
    "                     )\n",
    "\n",
    "\n",
    "        # Iteration = fold, i am just saving the model for that fold\n",
    "        iteration.append(model)\n",
    "\n",
    "        confusion_matrix_x_test.append(X_test)\n",
    "        confusion_matrix_y_test.append(y_test)\n",
    "\n",
    "        #Plotting confusion matrix\n",
    "        pred=model.predict(X_test)\n",
    "        y_test_pred= np.argmax(pred, axis=1)\n",
    "\n",
    "        confusion_matrix= metrics.confusion_matrix(y_test, y_test_pred, normalize='true')\n",
    "        plt.figure()\n",
    "        metrics.ConfusionMatrixDisplay(confusion_matrix).plot()\n",
    "        plt.savefig(dir1+\"/confusion_matrix_kfold_\"+str(count))\n",
    "        plt.close()\n",
    "\n",
    "        validation_acc.append(np.sum(y_test==y_test_pred)/y_test.shape[0])\n",
    "\n",
    "        PERFORMANCE.append(classification_report(y_test, y_test_pred, labels=LABELS, output_dict=True))\n",
    "\n",
    "        #Salvo risultati di singolo fold\n",
    "        sio.savemat(dir1+\"/y_pred_test_kfold\"+str(count), {\"array\": y_test_pred})\n",
    "        sio.savemat(dir1+\"/y_test_kfold\"+str(count), {\"array\": y_test})\n",
    "\n",
    "\n",
    "        # PLOTTO FILTRI TEMPORALI E SPAZIALI E LI SALVO\n",
    "        var= (model.get_layer(\"temporal_conv\").weights)\n",
    "        for lallo in range(8):\n",
    "            plt.figure()\n",
    "            plt.title(\"temp_conv_\"+str(lallo))\n",
    "            plt.plot(var[0][0,:,0][:,lallo]) #this way i access the temporal filters, cambiando ultimo zero\n",
    "            plt.savefig(dir2+\"/temp_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo))\n",
    "            temp= (var[0][0,:,0][:,lallo]).numpy()\n",
    "            sio.savemat(dir2+\"/temp_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo), {\"array\": temp})\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "        var_2= (model.get_layer(\"spatial_conv\").weights)\n",
    "        reshaped_var_2=tf.reshape(var_2[0][:,0,:,:],(31,16))\n",
    "        for lallo in range(16):\n",
    "            nump= reshaped_var_2[:,lallo].numpy()\n",
    "            sio.savemat(dir3+\"/spat_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo), {\"array\": nump})\n",
    "\n",
    "    ###################################################################################################################\n",
    "\n",
    "    #plot accuracy and loss function across epochs\n",
    "    epoch_vec=np.linspace(1,EPOCHS,EPOCHS)\n",
    "    min_temp_loss=10\n",
    "    min_temp_acc=10\n",
    "    max_temp_loss=0\n",
    "    max_temp_acc=0\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        if (np.min(evaluation[idx].history['loss'])<min_temp_loss):\n",
    "            min_temp_loss=np.min(evaluation[idx].history['loss'])\n",
    "        if (np.min(evaluation[idx].history['val_loss'])<min_temp_loss):\n",
    "            min_temp_loss=np.min(evaluation[idx].history['val_loss'])\n",
    "        if (np.max(evaluation[idx].history['loss'])>max_temp_loss):\n",
    "            max_temp_loss=np.max(evaluation[idx].history['loss'])\n",
    "        if (np.max(evaluation[idx].history['val_loss'])>max_temp_loss):\n",
    "            max_temp_loss=np.max(evaluation[idx].history['val_loss'])\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        if (np.min(evaluation[idx].history['accuracy'])<min_temp_acc):\n",
    "            min_temp_acc=np.min(evaluation[idx].history['accuracy'])\n",
    "        if (np.min(evaluation[idx].history['val_accuracy'])<min_temp_acc):\n",
    "            min_temp_acc=np.min(evaluation[idx].history['val_accuracy'])\n",
    "        if (np.max(evaluation[idx].history['accuracy'])>max_temp_acc):\n",
    "            max_temp_acc=np.max(evaluation[idx].history['accuracy'])\n",
    "        if (np.max(evaluation[idx].history['val_accuracy'])>max_temp_acc):\n",
    "            max_temp_acc=np.max(evaluation[idx].history['val_accuracy'])\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        loss_vec_train= evaluation[idx].history['loss']\n",
    "        loss_vec_test= evaluation[idx].history['val_loss']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epoch_vec,loss_vec_test,'b-', label= 'test');\n",
    "        plt.plot(epoch_vec,loss_vec_train,'r-', label='train');\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss across epochs for fold: '+str(idx))\n",
    "        plt.ylim([min_temp_loss, max_temp_loss])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(dir1+\"/loss_kfold_\"+str(idx))\n",
    "        plt.close()\n",
    "\n",
    "    #plot accuracy and loss function across epochs\n",
    "    epoch_vec=np.linspace(1,EPOCHS,EPOCHS)\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        loss_vec_train= evaluation[idx].history['accuracy']\n",
    "        loss_vec_test= evaluation[idx].history['val_accuracy']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epoch_vec,loss_vec_test,'b-', label= 'test');\n",
    "        plt.plot(epoch_vec,loss_vec_train,'r-', label='train');\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy across epochs for fold: '+str(idx))\n",
    "        plt.ylim([min_temp_acc, max_temp_acc])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(dir1+\"/accuracy_kfold_\"+str(idx))\n",
    "        plt.close()\n",
    "\n",
    "    #SALVO VARIABILI STATISTICHE E MODELLO IN MODO DA PLOTTARLO\n",
    "\n",
    "#         acc_temp=[]\n",
    "    accuratezza=np.zeros(n_classes*2)\n",
    "#         for idx in range(n_folds):\n",
    "#             acc_temp.append(PERFORMANCE[idx][\"accuracy\"])\n",
    "    accuratezza[0]=(np.mean(validation_acc))\n",
    "    accuratezza[1]=(statistics.pstdev(validation_acc))\n",
    "\n",
    "\n",
    "    precisione=[]\n",
    "    recall=[]\n",
    "    f1_score=[]\n",
    "    support=[]\n",
    "    for classe in range(numero_classi):\n",
    "        precision_temp=[]\n",
    "        recall_temp=[]\n",
    "        f1_score_temp=[]\n",
    "        support_temp=[]\n",
    "        for idx in range(n_folds):\n",
    "            precision_temp.append(PERFORMANCE[idx][str(classe)][\"precision\"])\n",
    "            recall_temp.append(PERFORMANCE[idx][str(classe)][\"recall\"])\n",
    "            f1_score_temp.append(PERFORMANCE[idx][str(classe)][\"f1-score\"])\n",
    "            support_temp.append(PERFORMANCE[idx][str(classe)][\"support\"])\n",
    "\n",
    "        precisione.append(np.mean(precision_temp))\n",
    "        precisione.append(statistics.pstdev(precision_temp))\n",
    "        recall.append(np.mean(recall_temp))\n",
    "        recall.append(statistics.pstdev(recall_temp))\n",
    "        f1_score.append(np.mean(f1_score_temp))\n",
    "        f1_score.append(statistics.pstdev(f1_score_temp))    \n",
    "        support.append(np.mean(support_temp))\n",
    "        support.append(statistics.pstdev(support_temp)) \n",
    "\n",
    "    sommario=[]\n",
    "    sommario=np.vstack((accuratezza,precisione,recall,f1_score,support))\n",
    "    sio.savemat(dir0+\"/sommario.mat\", {\"array\": sommario})\n",
    "\n",
    "    gianfranco=model.predict(X)\n",
    "    gianfranco2=np.argmax(gianfranco, axis=1)\n",
    "    sio.savemat(dir0+\"/predizione_totale.mat\", {\"array\": gianfranco2})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d835b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT: 17\n",
      "N_CLASSES: 2\n",
      "New shape for X: (4080, 31, 50, 4)\n",
      "New shape for y: (4080,)\n",
      "Train index for this split: [   0    1    3 ... 4077 4078 4079]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   2   10   16   18   21   23   28   29   32   36   38   39   40   42\n",
      "   43   58   65   72   75   76   86   87   88   99  102  103  110  117\n",
      "  124  128  133  136  137  142  153  155  157  159  160  169  190  193\n",
      "  200  204  209  210  212  215  216  217  219  221  224  232  244  258\n",
      "  259  267  269  270  278  282  286  292  297  303  304  309  311  316\n",
      "  319  324  328  332  333  335  342  346  347  351  360  362  365  369\n",
      "  375  383  392  394  395  398  401  403  405  406  423  430  452  453\n",
      "  455  457  459  465  467  469  480  484  487  490  497  504  512  513\n",
      "  521  522  525  527  533  537  542  546  553  554  558  564  568  571\n",
      "  574  575  579  581  592  601  607  615  616  622  637  642  646  657\n",
      "  659  662  664  665  676  679  685  693  698  701  705  713  715  719\n",
      "  721  730  731  732  742  743  746  748  754  756  759  766  769  786\n",
      "  789  795  797  801  808  812  816  817  818  824  842  853  854  859\n",
      "  861  862  864  868  874  876  879  890  904  912  913  915  916  920\n",
      "  924  927  934  945  949  950  957  960  964  966  976  978  983  991\n",
      " 1002 1005 1007 1013 1016 1021 1043 1049 1057 1058 1059 1061 1065 1068\n",
      " 1069 1071 1075 1081 1090 1092 1097 1100 1104 1111 1112 1116 1121 1125\n",
      " 1130 1134 1139 1143 1145 1149 1151 1152 1158 1170 1181 1182 1187 1189\n",
      " 1196 1198 1201 1202 1211 1213 1215 1216 1219 1220 1221 1225 1235 1240\n",
      " 1242 1247 1256 1259 1261 1268 1271 1273 1274 1276 1279 1290 1293 1298\n",
      " 1300 1316 1317 1328 1331 1333 1343 1347 1369 1376 1380 1381 1383 1384\n",
      " 1385 1389 1390 1391 1392 1393 1404 1411 1412 1416 1429 1432 1435 1436\n",
      " 1445 1449 1454 1474 1483 1485 1489 1491 1495 1496 1502 1505 1518 1536\n",
      " 1541 1549 1553 1555 1556 1557 1558 1561 1564 1565 1566 1570 1571 1581\n",
      " 1584 1585 1602 1603 1604 1612 1627 1628 1633 1643 1652 1655 1662 1671\n",
      " 1673 1683 1684 1696 1701 1714 1718 1730 1737 1746 1753 1761 1762 1779\n",
      " 1788 1790 1793 1794 1802 1804 1810 1811 1819 1822 1828 1829 1833 1836\n",
      " 1839 1840 1853 1854 1859 1863 1869 1870 1873 1880 1882 1886 1897 1908\n",
      " 1916 1918 1937 1941 1943 1948 1950 1955 1957 1982 1988 1996 2006 2010\n",
      " 2014 2016 2018 2020 2030 2034 2041 2042 2044 2058 2060 2061 2063 2065\n",
      " 2069 2073 2084 2085 2090 2092 2093 2094 2098 2102 2107 2110 2115 2120\n",
      " 2127 2131 2141 2145 2147 2149 2157 2161 2174 2179 2185 2188 2190 2194\n",
      " 2195 2201 2204 2210 2224 2226 2228 2229 2264 2266 2270 2272 2276 2278\n",
      " 2279 2283 2294 2299 2300 2301 2312 2314 2320 2321 2324 2327 2330 2336\n",
      " 2339 2341 2350 2357 2359 2362 2363 2364 2368 2375 2378 2383 2385 2396\n",
      " 2408 2414 2417 2419 2422 2423 2427 2428 2431 2443 2444 2448 2456 2457\n",
      " 2459 2466 2478 2482 2486 2487 2491 2501 2503 2508 2509 2511 2512 2513\n",
      " 2519 2531 2534 2553 2557 2560 2566 2567 2573 2580 2583 2585 2588 2590\n",
      " 2592 2593 2596 2614 2617 2619 2623 2633 2637 2641 2647 2649 2658 2661\n",
      " 2666 2667 2671 2673 2685 2698 2700 2710 2716 2721 2723 2728 2730 2733\n",
      " 2756 2759 2764 2768 2771 2786 2802 2803 2804 2816 2819 2820 2827 2836\n",
      " 2837 2838 2859 2860 2876 2885 2886 2889 2891 2896 2898 2911 2912 2917\n",
      " 2920 2922 2923 2926 2932 2938 2939 2949 2955 2958 2961 2964 2989 2995\n",
      " 2998 3002 3016 3019 3025 3029 3031 3037 3039 3040 3041 3042 3055 3056\n",
      " 3058 3064 3075 3081 3086 3087 3088 3091 3104 3110 3112 3116 3117 3118\n",
      " 3119 3124 3131 3132 3133 3138 3143 3163 3165 3172 3182 3184 3189 3199\n",
      " 3200 3203 3204 3207 3213 3222 3226 3241 3242 3244 3257 3273 3282 3288\n",
      " 3290 3294 3296 3304 3312 3320 3324 3326 3332 3339 3340 3343 3344 3345\n",
      " 3347 3348 3353 3360 3361 3364 3365 3382 3391 3398 3403 3406 3407 3419\n",
      " 3422 3434 3438 3440 3441 3452 3453 3454 3465 3466 3477 3490 3493 3497\n",
      " 3502 3505 3507 3511 3513 3524 3525 3526 3529 3531 3534 3536 3545 3556\n",
      " 3558 3560 3564 3565 3573 3579 3580 3583 3593 3596 3597 3603 3610 3613\n",
      " 3614 3619 3631 3633 3647 3649 3652 3663 3666 3667 3671 3680 3685 3689\n",
      " 3690 3698 3708 3714 3721 3727 3729 3733 3736 3742 3744 3745 3751 3760\n",
      " 3762 3767 3777 3780 3781 3787 3795 3799 3809 3816 3823 3829 3831 3833\n",
      " 3845 3847 3850 3857 3874 3875 3880 3884 3885 3887 3891 3894 3895 3898\n",
      " 3906 3922 3932 3934 3939 3946 3947 3955 3957 3958 3959 3960 3961 3964\n",
      " 3970 3975 3982 3983 3985 3991 4015 4017 4024 4025 4032 4034 4040 4041\n",
      " 4049 4053 4070 4076]\n",
      "Number of samples for test set: 816\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:26:14.707423: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_311/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6959 - accuracy: 0.4960 - val_loss: 0.6932 - val_accuracy: 0.4865 - 3s/epoch - 12ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6920 - accuracy: 0.5123 - val_loss: 0.6934 - val_accuracy: 0.5061 - 868ms/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6921 - accuracy: 0.5101 - val_loss: 0.6929 - val_accuracy: 0.5331 - 849ms/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6921 - accuracy: 0.5224 - val_loss: 0.6928 - val_accuracy: 0.5049 - 889ms/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6866 - accuracy: 0.5401 - val_loss: 0.6924 - val_accuracy: 0.5123 - 905ms/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6874 - accuracy: 0.5251 - val_loss: 0.6933 - val_accuracy: 0.4926 - 871ms/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6853 - accuracy: 0.5328 - val_loss: 0.6931 - val_accuracy: 0.4975 - 905ms/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6817 - accuracy: 0.5576 - val_loss: 0.6917 - val_accuracy: 0.5049 - 909ms/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6777 - accuracy: 0.5665 - val_loss: 0.6919 - val_accuracy: 0.4914 - 906ms/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.6808 - accuracy: 0.5597 - val_loss: 0.6927 - val_accuracy: 0.5049 - 910ms/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6796 - accuracy: 0.5677 - val_loss: 0.6910 - val_accuracy: 0.5233 - 885ms/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.6729 - accuracy: 0.5748 - val_loss: 0.6910 - val_accuracy: 0.5012 - 875ms/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.6741 - accuracy: 0.5695 - val_loss: 0.6918 - val_accuracy: 0.5417 - 865ms/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.6682 - accuracy: 0.5824 - val_loss: 0.6914 - val_accuracy: 0.4951 - 889ms/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.6722 - accuracy: 0.5594 - val_loss: 0.6942 - val_accuracy: 0.4951 - 897ms/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.6675 - accuracy: 0.5784 - val_loss: 0.6912 - val_accuracy: 0.5025 - 892ms/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.6642 - accuracy: 0.5870 - val_loss: 0.6902 - val_accuracy: 0.5257 - 871ms/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.6660 - accuracy: 0.5950 - val_loss: 0.6916 - val_accuracy: 0.5233 - 868ms/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.6601 - accuracy: 0.5901 - val_loss: 0.6918 - val_accuracy: 0.5123 - 888ms/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.6629 - accuracy: 0.5879 - val_loss: 0.6905 - val_accuracy: 0.5184 - 866ms/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.6560 - accuracy: 0.6008 - val_loss: 0.6892 - val_accuracy: 0.5208 - 885ms/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.6580 - accuracy: 0.5846 - val_loss: 0.6893 - val_accuracy: 0.5196 - 861ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.6555 - accuracy: 0.5953 - val_loss: 0.6886 - val_accuracy: 0.5257 - 905ms/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.6578 - accuracy: 0.6002 - val_loss: 0.6935 - val_accuracy: 0.5098 - 898ms/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.6549 - accuracy: 0.6057 - val_loss: 0.6917 - val_accuracy: 0.5123 - 894ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.6569 - accuracy: 0.6066 - val_loss: 0.6912 - val_accuracy: 0.5110 - 919ms/epoch - 5ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.6505 - accuracy: 0.6152 - val_loss: 0.6917 - val_accuracy: 0.5527 - 900ms/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.6537 - accuracy: 0.6042 - val_loss: 0.6967 - val_accuracy: 0.4951 - 909ms/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.6575 - accuracy: 0.6029 - val_loss: 0.6978 - val_accuracy: 0.4975 - 883ms/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.6498 - accuracy: 0.5990 - val_loss: 0.6907 - val_accuracy: 0.5012 - 901ms/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.6492 - accuracy: 0.6146 - val_loss: 0.6899 - val_accuracy: 0.5502 - 895ms/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.6569 - accuracy: 0.6002 - val_loss: 0.6887 - val_accuracy: 0.5441 - 880ms/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.6464 - accuracy: 0.6115 - val_loss: 0.6899 - val_accuracy: 0.5711 - 895ms/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.6465 - accuracy: 0.6210 - val_loss: 0.7004 - val_accuracy: 0.5037 - 914ms/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.6466 - accuracy: 0.6170 - val_loss: 0.6908 - val_accuracy: 0.5257 - 907ms/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.6425 - accuracy: 0.6176 - val_loss: 0.6926 - val_accuracy: 0.4951 - 897ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.6448 - accuracy: 0.6176 - val_loss: 0.6953 - val_accuracy: 0.4963 - 874ms/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.6475 - accuracy: 0.6247 - val_loss: 0.6931 - val_accuracy: 0.4975 - 879ms/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.6523 - accuracy: 0.6081 - val_loss: 0.6910 - val_accuracy: 0.5208 - 874ms/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.6422 - accuracy: 0.6219 - val_loss: 0.6905 - val_accuracy: 0.5012 - 904ms/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.6480 - accuracy: 0.6127 - val_loss: 0.6940 - val_accuracy: 0.4926 - 901ms/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.6403 - accuracy: 0.6229 - val_loss: 0.6969 - val_accuracy: 0.4926 - 905ms/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.6411 - accuracy: 0.6186 - val_loss: 0.6889 - val_accuracy: 0.5809 - 894ms/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.6342 - accuracy: 0.6369 - val_loss: 0.6906 - val_accuracy: 0.5184 - 915ms/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.6422 - accuracy: 0.6192 - val_loss: 0.6914 - val_accuracy: 0.5000 - 908ms/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.6443 - accuracy: 0.6290 - val_loss: 0.7083 - val_accuracy: 0.4963 - 894ms/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.6376 - accuracy: 0.6241 - val_loss: 0.7156 - val_accuracy: 0.4975 - 897ms/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.6431 - accuracy: 0.6124 - val_loss: 0.7001 - val_accuracy: 0.4951 - 887ms/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.6411 - accuracy: 0.6210 - val_loss: 0.6958 - val_accuracy: 0.4914 - 910ms/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.6399 - accuracy: 0.6317 - val_loss: 0.7048 - val_accuracy: 0.4914 - 889ms/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.6325 - accuracy: 0.6373 - val_loss: 0.7365 - val_accuracy: 0.4963 - 885ms/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.6321 - accuracy: 0.6385 - val_loss: 0.7100 - val_accuracy: 0.4951 - 874ms/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.6401 - accuracy: 0.6302 - val_loss: 0.7067 - val_accuracy: 0.4963 - 899ms/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.6309 - accuracy: 0.6198 - val_loss: 0.7041 - val_accuracy: 0.4926 - 874ms/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.6370 - accuracy: 0.6244 - val_loss: 0.7120 - val_accuracy: 0.4951 - 857ms/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.6413 - accuracy: 0.6268 - val_loss: 0.6929 - val_accuracy: 0.4975 - 881ms/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.6429 - accuracy: 0.6204 - val_loss: 0.7002 - val_accuracy: 0.4963 - 870ms/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.6340 - accuracy: 0.6268 - val_loss: 0.7107 - val_accuracy: 0.4951 - 862ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.6277 - accuracy: 0.6391 - val_loss: 0.7075 - val_accuracy: 0.4951 - 904ms/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.6358 - accuracy: 0.6333 - val_loss: 0.6918 - val_accuracy: 0.4951 - 878ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.6424 - accuracy: 0.6103 - val_loss: 0.6976 - val_accuracy: 0.4926 - 891ms/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.6325 - accuracy: 0.6348 - val_loss: 0.7085 - val_accuracy: 0.4951 - 892ms/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.6340 - accuracy: 0.6293 - val_loss: 0.6952 - val_accuracy: 0.4951 - 894ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.6318 - accuracy: 0.6265 - val_loss: 0.7020 - val_accuracy: 0.4951 - 893ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.6372 - accuracy: 0.6225 - val_loss: 0.7116 - val_accuracy: 0.4975 - 855ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.6275 - accuracy: 0.6360 - val_loss: 0.7133 - val_accuracy: 0.4963 - 851ms/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.6357 - accuracy: 0.6278 - val_loss: 0.7112 - val_accuracy: 0.4939 - 872ms/epoch - 4ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.6267 - accuracy: 0.6409 - val_loss: 0.7302 - val_accuracy: 0.4975 - 895ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.6288 - accuracy: 0.6290 - val_loss: 0.7186 - val_accuracy: 0.4963 - 885ms/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.6244 - accuracy: 0.6376 - val_loss: 0.7197 - val_accuracy: 0.4963 - 898ms/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.6337 - accuracy: 0.6198 - val_loss: 0.7244 - val_accuracy: 0.4951 - 889ms/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.6357 - accuracy: 0.6311 - val_loss: 0.7029 - val_accuracy: 0.4939 - 863ms/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.6327 - accuracy: 0.6354 - val_loss: 0.7184 - val_accuracy: 0.4963 - 867ms/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.6311 - accuracy: 0.6302 - val_loss: 0.7176 - val_accuracy: 0.4951 - 895ms/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.6315 - accuracy: 0.6379 - val_loss: 0.7159 - val_accuracy: 0.4963 - 893ms/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.6250 - accuracy: 0.6388 - val_loss: 0.7252 - val_accuracy: 0.4963 - 866ms/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.6278 - accuracy: 0.6235 - val_loss: 0.7330 - val_accuracy: 0.4963 - 890ms/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.6335 - accuracy: 0.6314 - val_loss: 0.7251 - val_accuracy: 0.4963 - 904ms/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.6310 - accuracy: 0.6302 - val_loss: 0.7605 - val_accuracy: 0.4963 - 911ms/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.6245 - accuracy: 0.6428 - val_loss: 0.7444 - val_accuracy: 0.4963 - 901ms/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.6348 - accuracy: 0.6327 - val_loss: 0.7159 - val_accuracy: 0.4951 - 917ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.6304 - accuracy: 0.6290 - val_loss: 0.7186 - val_accuracy: 0.4939 - 898ms/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.6282 - accuracy: 0.6369 - val_loss: 0.7348 - val_accuracy: 0.4951 - 908ms/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.6269 - accuracy: 0.6373 - val_loss: 0.7282 - val_accuracy: 0.4975 - 897ms/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.6254 - accuracy: 0.6406 - val_loss: 0.7580 - val_accuracy: 0.4988 - 897ms/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.6241 - accuracy: 0.6523 - val_loss: 0.7669 - val_accuracy: 0.4975 - 891ms/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.6329 - accuracy: 0.6244 - val_loss: 0.7904 - val_accuracy: 0.4963 - 912ms/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.6264 - accuracy: 0.6369 - val_loss: 0.7814 - val_accuracy: 0.4975 - 893ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.6254 - accuracy: 0.6351 - val_loss: 0.7380 - val_accuracy: 0.4963 - 884ms/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.6201 - accuracy: 0.6425 - val_loss: 0.7849 - val_accuracy: 0.4963 - 869ms/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.6246 - accuracy: 0.6409 - val_loss: 0.8329 - val_accuracy: 0.4975 - 889ms/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.6242 - accuracy: 0.6369 - val_loss: 0.7964 - val_accuracy: 0.4975 - 872ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.6266 - accuracy: 0.6419 - val_loss: 0.7960 - val_accuracy: 0.4963 - 903ms/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.6211 - accuracy: 0.6382 - val_loss: 0.7668 - val_accuracy: 0.4963 - 859ms/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.6220 - accuracy: 0.6449 - val_loss: 0.7569 - val_accuracy: 0.4975 - 911ms/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.6182 - accuracy: 0.6330 - val_loss: 0.7405 - val_accuracy: 0.4963 - 912ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.6243 - accuracy: 0.6287 - val_loss: 0.7491 - val_accuracy: 0.4975 - 916ms/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.6279 - accuracy: 0.6271 - val_loss: 0.7284 - val_accuracy: 0.4963 - 863ms/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.6217 - accuracy: 0.6397 - val_loss: 0.7311 - val_accuracy: 0.4951 - 891ms/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.6268 - accuracy: 0.6400 - val_loss: 0.7317 - val_accuracy: 0.4963 - 851ms/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.6245 - accuracy: 0.6382 - val_loss: 0.7567 - val_accuracy: 0.4951 - 891ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.6274 - accuracy: 0.6241 - val_loss: 0.7599 - val_accuracy: 0.4963 - 918ms/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.6258 - accuracy: 0.6412 - val_loss: 0.7379 - val_accuracy: 0.4963 - 899ms/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.6239 - accuracy: 0.6397 - val_loss: 0.7115 - val_accuracy: 0.4951 - 875ms/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.6224 - accuracy: 0.6434 - val_loss: 0.7531 - val_accuracy: 0.4951 - 907ms/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.6284 - accuracy: 0.6443 - val_loss: 0.7961 - val_accuracy: 0.4975 - 911ms/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.6162 - accuracy: 0.6556 - val_loss: 0.7819 - val_accuracy: 0.4975 - 903ms/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.6139 - accuracy: 0.6507 - val_loss: 0.7606 - val_accuracy: 0.4975 - 894ms/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.6182 - accuracy: 0.6471 - val_loss: 0.7346 - val_accuracy: 0.4975 - 897ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.6233 - accuracy: 0.6412 - val_loss: 0.7200 - val_accuracy: 0.4963 - 896ms/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.6144 - accuracy: 0.6526 - val_loss: 0.7463 - val_accuracy: 0.4975 - 869ms/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.6210 - accuracy: 0.6320 - val_loss: 0.7702 - val_accuracy: 0.4975 - 901ms/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.6178 - accuracy: 0.6538 - val_loss: 0.7799 - val_accuracy: 0.4975 - 910ms/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.6130 - accuracy: 0.6651 - val_loss: 0.8131 - val_accuracy: 0.4988 - 906ms/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.6193 - accuracy: 0.6324 - val_loss: 0.7604 - val_accuracy: 0.4951 - 904ms/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.6191 - accuracy: 0.6458 - val_loss: 0.7343 - val_accuracy: 0.4951 - 878ms/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.6169 - accuracy: 0.6443 - val_loss: 0.7466 - val_accuracy: 0.4963 - 883ms/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.6141 - accuracy: 0.6590 - val_loss: 0.8141 - val_accuracy: 0.4988 - 881ms/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.6192 - accuracy: 0.6379 - val_loss: 0.7188 - val_accuracy: 0.4963 - 862ms/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.6188 - accuracy: 0.6434 - val_loss: 0.7300 - val_accuracy: 0.4988 - 912ms/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.6287 - accuracy: 0.6333 - val_loss: 0.7232 - val_accuracy: 0.4975 - 895ms/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.6195 - accuracy: 0.6504 - val_loss: 0.7331 - val_accuracy: 0.4975 - 879ms/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.6217 - accuracy: 0.6452 - val_loss: 0.7349 - val_accuracy: 0.4963 - 877ms/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.6165 - accuracy: 0.6510 - val_loss: 0.7611 - val_accuracy: 0.4988 - 903ms/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.6150 - accuracy: 0.6480 - val_loss: 0.8080 - val_accuracy: 0.4975 - 862ms/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.6193 - accuracy: 0.6287 - val_loss: 0.7561 - val_accuracy: 0.4988 - 872ms/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.6201 - accuracy: 0.6529 - val_loss: 0.7405 - val_accuracy: 0.4988 - 900ms/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.6185 - accuracy: 0.6461 - val_loss: 0.7179 - val_accuracy: 0.4963 - 887ms/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.6151 - accuracy: 0.6507 - val_loss: 0.7294 - val_accuracy: 0.4975 - 862ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.6196 - accuracy: 0.6510 - val_loss: 0.7596 - val_accuracy: 0.4988 - 871ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.6100 - accuracy: 0.6562 - val_loss: 0.7692 - val_accuracy: 0.4975 - 872ms/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.6186 - accuracy: 0.6596 - val_loss: 0.7634 - val_accuracy: 0.4939 - 878ms/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.6116 - accuracy: 0.6461 - val_loss: 0.7761 - val_accuracy: 0.4975 - 874ms/epoch - 4ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.6196 - accuracy: 0.6559 - val_loss: 0.7412 - val_accuracy: 0.4963 - 879ms/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.6242 - accuracy: 0.6415 - val_loss: 0.7585 - val_accuracy: 0.4963 - 873ms/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.6167 - accuracy: 0.6452 - val_loss: 0.7538 - val_accuracy: 0.4988 - 869ms/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.6214 - accuracy: 0.6366 - val_loss: 0.7402 - val_accuracy: 0.4939 - 885ms/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.6218 - accuracy: 0.6382 - val_loss: 0.7090 - val_accuracy: 0.4975 - 905ms/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.6151 - accuracy: 0.6495 - val_loss: 0.7237 - val_accuracy: 0.4975 - 889ms/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.6156 - accuracy: 0.6483 - val_loss: 0.7093 - val_accuracy: 0.4988 - 910ms/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.6195 - accuracy: 0.6547 - val_loss: 0.7496 - val_accuracy: 0.4975 - 909ms/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.6075 - accuracy: 0.6581 - val_loss: 0.7855 - val_accuracy: 0.4988 - 896ms/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.6137 - accuracy: 0.6562 - val_loss: 0.7791 - val_accuracy: 0.4988 - 911ms/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.6207 - accuracy: 0.6440 - val_loss: 0.7411 - val_accuracy: 0.4988 - 870ms/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.6082 - accuracy: 0.6541 - val_loss: 0.7298 - val_accuracy: 0.4963 - 863ms/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.6146 - accuracy: 0.6526 - val_loss: 0.7679 - val_accuracy: 0.4988 - 903ms/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.6112 - accuracy: 0.6572 - val_loss: 0.7536 - val_accuracy: 0.4975 - 898ms/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.6172 - accuracy: 0.6486 - val_loss: 0.7658 - val_accuracy: 0.4963 - 907ms/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.6189 - accuracy: 0.6415 - val_loss: 0.7621 - val_accuracy: 0.4988 - 886ms/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.6140 - accuracy: 0.6523 - val_loss: 0.7542 - val_accuracy: 0.4975 - 889ms/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.6137 - accuracy: 0.6507 - val_loss: 0.7512 - val_accuracy: 0.4963 - 859ms/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.6161 - accuracy: 0.6495 - val_loss: 0.7647 - val_accuracy: 0.4988 - 910ms/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.6080 - accuracy: 0.6517 - val_loss: 0.7779 - val_accuracy: 0.4988 - 888ms/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.6087 - accuracy: 0.6556 - val_loss: 0.7530 - val_accuracy: 0.4975 - 885ms/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.6145 - accuracy: 0.6532 - val_loss: 0.7560 - val_accuracy: 0.4988 - 898ms/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.6131 - accuracy: 0.6538 - val_loss: 0.7642 - val_accuracy: 0.4975 - 872ms/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.6108 - accuracy: 0.6636 - val_loss: 0.7509 - val_accuracy: 0.4988 - 847ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.6061 - accuracy: 0.6581 - val_loss: 0.7481 - val_accuracy: 0.4963 - 843ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.6163 - accuracy: 0.6486 - val_loss: 0.7318 - val_accuracy: 0.4963 - 860ms/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.6169 - accuracy: 0.6523 - val_loss: 0.7767 - val_accuracy: 0.4975 - 889ms/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.6143 - accuracy: 0.6639 - val_loss: 0.7533 - val_accuracy: 0.4975 - 897ms/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.6138 - accuracy: 0.6593 - val_loss: 0.7849 - val_accuracy: 0.4975 - 893ms/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.6147 - accuracy: 0.6523 - val_loss: 0.7309 - val_accuracy: 0.4975 - 901ms/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.6137 - accuracy: 0.6480 - val_loss: 0.7991 - val_accuracy: 0.4988 - 897ms/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.6134 - accuracy: 0.6510 - val_loss: 0.7798 - val_accuracy: 0.4988 - 892ms/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.6052 - accuracy: 0.6553 - val_loss: 0.7866 - val_accuracy: 0.4975 - 889ms/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.6102 - accuracy: 0.6492 - val_loss: 0.7429 - val_accuracy: 0.4975 - 855ms/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.6137 - accuracy: 0.6544 - val_loss: 0.7515 - val_accuracy: 0.4975 - 887ms/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.6121 - accuracy: 0.6538 - val_loss: 0.7882 - val_accuracy: 0.4975 - 891ms/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.6057 - accuracy: 0.6575 - val_loss: 0.7678 - val_accuracy: 0.4975 - 870ms/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.6067 - accuracy: 0.6550 - val_loss: 0.7463 - val_accuracy: 0.4951 - 900ms/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.6077 - accuracy: 0.6544 - val_loss: 0.7552 - val_accuracy: 0.4951 - 886ms/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.6115 - accuracy: 0.6461 - val_loss: 0.7715 - val_accuracy: 0.4988 - 860ms/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.6108 - accuracy: 0.6520 - val_loss: 0.8248 - val_accuracy: 0.4988 - 860ms/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.6112 - accuracy: 0.6608 - val_loss: 0.8117 - val_accuracy: 0.4988 - 897ms/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.6141 - accuracy: 0.6538 - val_loss: 0.7633 - val_accuracy: 0.4988 - 886ms/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.6122 - accuracy: 0.6529 - val_loss: 0.7505 - val_accuracy: 0.4975 - 888ms/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.6221 - accuracy: 0.6532 - val_loss: 0.7382 - val_accuracy: 0.4988 - 892ms/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.6126 - accuracy: 0.6590 - val_loss: 0.7270 - val_accuracy: 0.4975 - 864ms/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.6099 - accuracy: 0.6529 - val_loss: 0.7138 - val_accuracy: 0.4963 - 886ms/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.6222 - accuracy: 0.6513 - val_loss: 0.7246 - val_accuracy: 0.4963 - 877ms/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.5997 - accuracy: 0.6562 - val_loss: 0.7410 - val_accuracy: 0.4951 - 871ms/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.6111 - accuracy: 0.6581 - val_loss: 0.7344 - val_accuracy: 0.4951 - 881ms/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.6076 - accuracy: 0.6602 - val_loss: 0.7184 - val_accuracy: 0.4951 - 903ms/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.6071 - accuracy: 0.6651 - val_loss: 0.7290 - val_accuracy: 0.4951 - 893ms/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.6183 - accuracy: 0.6501 - val_loss: 0.7253 - val_accuracy: 0.4975 - 875ms/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.6098 - accuracy: 0.6510 - val_loss: 0.7558 - val_accuracy: 0.4988 - 892ms/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.6037 - accuracy: 0.6679 - val_loss: 0.7812 - val_accuracy: 0.4975 - 906ms/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.6217 - accuracy: 0.6363 - val_loss: 0.8080 - val_accuracy: 0.4988 - 903ms/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.6052 - accuracy: 0.6544 - val_loss: 0.8436 - val_accuracy: 0.4975 - 894ms/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.6097 - accuracy: 0.6608 - val_loss: 0.8087 - val_accuracy: 0.4988 - 883ms/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.6200 - accuracy: 0.6510 - val_loss: 0.7478 - val_accuracy: 0.4988 - 885ms/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.6137 - accuracy: 0.6477 - val_loss: 0.7599 - val_accuracy: 0.4988 - 876ms/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.6097 - accuracy: 0.6569 - val_loss: 0.7472 - val_accuracy: 0.4988 - 900ms/epoch - 4ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.6199 - accuracy: 0.6474 - val_loss: 0.7384 - val_accuracy: 0.4963 - 892ms/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.6166 - accuracy: 0.6526 - val_loss: 0.7283 - val_accuracy: 0.4951 - 912ms/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.6147 - accuracy: 0.6489 - val_loss: 0.7156 - val_accuracy: 0.4963 - 893ms/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.6085 - accuracy: 0.6562 - val_loss: 0.7176 - val_accuracy: 0.4951 - 899ms/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.6064 - accuracy: 0.6621 - val_loss: 0.7532 - val_accuracy: 0.4988 - 910ms/epoch - 4ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.6148 - accuracy: 0.6661 - val_loss: 0.7483 - val_accuracy: 0.4975 - 890ms/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.6141 - accuracy: 0.6630 - val_loss: 0.7327 - val_accuracy: 0.4975 - 918ms/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.6153 - accuracy: 0.6550 - val_loss: 0.7356 - val_accuracy: 0.4963 - 883ms/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.6064 - accuracy: 0.6517 - val_loss: 0.7097 - val_accuracy: 0.4988 - 873ms/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.6092 - accuracy: 0.6569 - val_loss: 0.7410 - val_accuracy: 0.4988 - 889ms/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.6183 - accuracy: 0.6498 - val_loss: 0.7441 - val_accuracy: 0.4975 - 898ms/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.6074 - accuracy: 0.6661 - val_loss: 0.7573 - val_accuracy: 0.4975 - 884ms/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.6039 - accuracy: 0.6562 - val_loss: 0.7242 - val_accuracy: 0.4963 - 911ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.6110 - accuracy: 0.6590 - val_loss: 0.7535 - val_accuracy: 0.4988 - 902ms/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.6090 - accuracy: 0.6612 - val_loss: 0.7645 - val_accuracy: 0.4988 - 899ms/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.6106 - accuracy: 0.6513 - val_loss: 0.7399 - val_accuracy: 0.4975 - 907ms/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.6085 - accuracy: 0.6581 - val_loss: 0.7525 - val_accuracy: 0.4988 - 892ms/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.6127 - accuracy: 0.6529 - val_loss: 0.7284 - val_accuracy: 0.4975 - 911ms/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.6100 - accuracy: 0.6526 - val_loss: 0.7726 - val_accuracy: 0.4975 - 917ms/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.6013 - accuracy: 0.6691 - val_loss: 0.7610 - val_accuracy: 0.4975 - 866ms/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.6050 - accuracy: 0.6596 - val_loss: 0.7859 - val_accuracy: 0.4988 - 919ms/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.6064 - accuracy: 0.6636 - val_loss: 0.8113 - val_accuracy: 0.4988 - 894ms/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.6071 - accuracy: 0.6590 - val_loss: 0.7895 - val_accuracy: 0.4975 - 897ms/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.6100 - accuracy: 0.6645 - val_loss: 0.7615 - val_accuracy: 0.4963 - 876ms/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.6119 - accuracy: 0.6578 - val_loss: 0.7394 - val_accuracy: 0.4988 - 911ms/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.6112 - accuracy: 0.6541 - val_loss: 0.7695 - val_accuracy: 0.4988 - 890ms/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.6028 - accuracy: 0.6541 - val_loss: 0.7449 - val_accuracy: 0.4988 - 889ms/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.6115 - accuracy: 0.6618 - val_loss: 0.7406 - val_accuracy: 0.4975 - 894ms/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.6109 - accuracy: 0.6621 - val_loss: 0.7413 - val_accuracy: 0.4975 - 896ms/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.6068 - accuracy: 0.6636 - val_loss: 0.7126 - val_accuracy: 0.4951 - 896ms/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.6065 - accuracy: 0.6550 - val_loss: 0.7217 - val_accuracy: 0.4975 - 896ms/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.6068 - accuracy: 0.6599 - val_loss: 0.7083 - val_accuracy: 0.4975 - 888ms/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.6016 - accuracy: 0.6544 - val_loss: 0.7710 - val_accuracy: 0.4963 - 897ms/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.6111 - accuracy: 0.6621 - val_loss: 0.7476 - val_accuracy: 0.4988 - 907ms/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.6068 - accuracy: 0.6608 - val_loss: 0.7587 - val_accuracy: 0.4975 - 901ms/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.6132 - accuracy: 0.6572 - val_loss: 0.7813 - val_accuracy: 0.4975 - 902ms/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.6089 - accuracy: 0.6559 - val_loss: 0.7954 - val_accuracy: 0.4988 - 886ms/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.6130 - accuracy: 0.6550 - val_loss: 0.7901 - val_accuracy: 0.4988 - 887ms/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.6054 - accuracy: 0.6495 - val_loss: 0.7944 - val_accuracy: 0.4988 - 884ms/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.6113 - accuracy: 0.6489 - val_loss: 0.7931 - val_accuracy: 0.4975 - 904ms/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.6037 - accuracy: 0.6532 - val_loss: 0.8306 - val_accuracy: 0.4988 - 893ms/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.6095 - accuracy: 0.6608 - val_loss: 0.7746 - val_accuracy: 0.5000 - 885ms/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.6113 - accuracy: 0.6569 - val_loss: 0.7665 - val_accuracy: 0.4975 - 854ms/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.6022 - accuracy: 0.6654 - val_loss: 0.7775 - val_accuracy: 0.4975 - 855ms/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.6090 - accuracy: 0.6661 - val_loss: 0.7383 - val_accuracy: 0.4988 - 882ms/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.6086 - accuracy: 0.6633 - val_loss: 0.7751 - val_accuracy: 0.4988 - 871ms/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.6092 - accuracy: 0.6486 - val_loss: 0.7618 - val_accuracy: 0.4988 - 877ms/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.6075 - accuracy: 0.6584 - val_loss: 0.7981 - val_accuracy: 0.4975 - 909ms/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.6143 - accuracy: 0.6486 - val_loss: 0.7859 - val_accuracy: 0.4975 - 894ms/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.6049 - accuracy: 0.6572 - val_loss: 0.7404 - val_accuracy: 0.4975 - 907ms/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.5974 - accuracy: 0.6587 - val_loss: 0.7617 - val_accuracy: 0.4951 - 912ms/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.6037 - accuracy: 0.6728 - val_loss: 0.7491 - val_accuracy: 0.4975 - 877ms/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.6038 - accuracy: 0.6679 - val_loss: 0.7227 - val_accuracy: 0.4975 - 928ms/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.6098 - accuracy: 0.6526 - val_loss: 0.7746 - val_accuracy: 0.4975 - 915ms/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.6080 - accuracy: 0.6489 - val_loss: 0.7197 - val_accuracy: 0.4975 - 900ms/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.6154 - accuracy: 0.6535 - val_loss: 0.7544 - val_accuracy: 0.4975 - 869ms/epoch - 4ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 4074 4076 4079]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   4   12   14   19   35   44   46   54   68   71   85   91  109  116\n",
      "  118  119  123  125  127  139  146  162  171  172  174  184  187  188\n",
      "  195  201  213  242  254  265  266  271  272  273  275  276  279  284\n",
      "  287  293  294  295  305  310  315  340  350  358  367  368  370  371\n",
      "  374  384  387  391  393  396  399  404  407  410  413  416  418  419\n",
      "  420  425  428  441  450  451  458  466  475  482  492  494  500  505\n",
      "  507  511  523  528  535  540  548  550  551  552  555  556  557  566\n",
      "  584  590  595  596  597  598  602  606  611  617  621  623  624  632\n",
      "  633  635  647  649  658  660  666  668  669  672  675  677  684  694\n",
      "  695  697  703  706  707  708  710  712  717  718  724  726  727  734\n",
      "  736  738  740  770  774  784  787  791  794  802  809  811  819  826\n",
      "  832  835  836  847  851  856  860  871  875  882  885  891  899  901\n",
      "  909  911  921  925  930  937  939  942  944  946  947  948  956  965\n",
      "  968  969  971  977  979  984  988  996  997 1006 1008 1012 1017 1018\n",
      " 1019 1023 1040 1051 1054 1066 1070 1074 1076 1078 1082 1087 1089 1091\n",
      " 1103 1108 1113 1120 1126 1127 1147 1156 1161 1166 1177 1186 1194 1200\n",
      " 1204 1209 1210 1214 1223 1227 1228 1233 1237 1248 1257 1260 1264 1267\n",
      " 1270 1275 1280 1294 1296 1297 1299 1302 1312 1313 1314 1321 1323 1339\n",
      " 1342 1345 1346 1348 1354 1355 1360 1362 1365 1371 1377 1378 1386 1396\n",
      " 1397 1407 1418 1422 1434 1438 1439 1447 1450 1457 1460 1462 1467 1468\n",
      " 1469 1472 1476 1479 1484 1492 1493 1497 1499 1501 1504 1520 1523 1526\n",
      " 1528 1532 1542 1543 1544 1545 1547 1548 1560 1562 1574 1577 1586 1587\n",
      " 1594 1598 1601 1607 1629 1631 1634 1635 1636 1638 1639 1641 1647 1648\n",
      " 1656 1660 1661 1664 1668 1670 1678 1679 1690 1693 1702 1703 1705 1706\n",
      " 1709 1711 1713 1720 1721 1724 1728 1732 1735 1738 1741 1743 1750 1752\n",
      " 1760 1763 1764 1771 1774 1777 1778 1782 1786 1791 1801 1803 1812 1818\n",
      " 1826 1830 1838 1842 1843 1846 1849 1856 1860 1865 1866 1872 1884 1899\n",
      " 1909 1917 1932 1938 1946 1954 1962 1968 1969 1974 1978 1979 1983 1984\n",
      " 1985 1991 1994 1995 2005 2013 2015 2023 2035 2039 2043 2046 2054 2067\n",
      " 2068 2072 2075 2077 2078 2079 2097 2101 2111 2116 2117 2123 2125 2132\n",
      " 2142 2143 2144 2151 2152 2155 2166 2175 2176 2178 2180 2192 2200 2203\n",
      " 2213 2217 2220 2227 2231 2236 2237 2244 2247 2248 2249 2259 2261 2275\n",
      " 2286 2289 2290 2295 2297 2302 2305 2313 2318 2323 2325 2326 2338 2348\n",
      " 2349 2360 2367 2370 2372 2376 2381 2384 2386 2388 2398 2404 2405 2411\n",
      " 2412 2424 2429 2436 2438 2439 2440 2451 2453 2460 2469 2470 2473 2474\n",
      " 2475 2477 2490 2500 2518 2520 2522 2528 2533 2535 2538 2548 2551 2552\n",
      " 2556 2564 2568 2582 2584 2595 2599 2600 2603 2606 2609 2620 2622 2635\n",
      " 2638 2652 2657 2662 2665 2674 2675 2678 2679 2689 2691 2692 2693 2697\n",
      " 2701 2703 2712 2714 2725 2736 2743 2746 2747 2750 2757 2763 2772 2777\n",
      " 2781 2798 2814 2833 2834 2845 2851 2856 2863 2869 2873 2874 2878 2887\n",
      " 2888 2902 2905 2907 2908 2909 2910 2914 2915 2937 2950 2951 2960 2963\n",
      " 2976 2978 2987 2990 2991 2993 2996 3005 3006 3018 3026 3033 3034 3046\n",
      " 3047 3049 3057 3061 3062 3071 3072 3073 3077 3083 3090 3095 3097 3100\n",
      " 3101 3115 3121 3125 3140 3146 3147 3148 3158 3160 3173 3177 3178 3180\n",
      " 3185 3188 3190 3192 3196 3197 3198 3212 3216 3229 3236 3243 3253 3255\n",
      " 3258 3263 3266 3275 3277 3285 3287 3291 3302 3305 3306 3307 3308 3313\n",
      " 3327 3334 3346 3350 3358 3366 3368 3369 3371 3383 3384 3386 3395 3396\n",
      " 3410 3411 3416 3421 3435 3436 3443 3444 3446 3447 3449 3455 3461 3468\n",
      " 3470 3472 3473 3475 3479 3480 3482 3492 3495 3498 3499 3501 3503 3508\n",
      " 3512 3516 3517 3518 3523 3542 3544 3546 3548 3549 3550 3554 3557 3567\n",
      " 3570 3575 3577 3586 3587 3588 3589 3590 3595 3598 3601 3604 3605 3609\n",
      " 3618 3629 3630 3632 3635 3640 3641 3644 3648 3650 3653 3654 3655 3657\n",
      " 3658 3660 3661 3662 3668 3670 3676 3678 3679 3686 3692 3693 3697 3699\n",
      " 3700 3711 3718 3726 3734 3750 3753 3759 3763 3768 3776 3782 3786 3798\n",
      " 3808 3813 3822 3832 3841 3842 3843 3844 3855 3858 3862 3863 3867 3878\n",
      " 3881 3890 3900 3904 3909 3913 3915 3918 3919 3926 3929 3944 3948 3950\n",
      " 3952 3968 3971 3978 3987 3988 3994 3997 3999 4001 4004 4008 4010 4011\n",
      " 4014 4018 4020 4022 4035 4036 4037 4042 4044 4051 4054 4059 4060 4063\n",
      " 4066 4075 4077 4078]\n",
      "Number of samples for test set: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:30:00.598452: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_312/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6935 - accuracy: 0.5055 - val_loss: 0.6919 - val_accuracy: 0.5110 - 3s/epoch - 12ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6896 - val_accuracy: 0.4975 - 873ms/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6912 - accuracy: 0.5267 - val_loss: 0.6902 - val_accuracy: 0.4939 - 889ms/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6900 - accuracy: 0.5365 - val_loss: 0.6925 - val_accuracy: 0.4926 - 889ms/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6895 - accuracy: 0.5383 - val_loss: 0.6888 - val_accuracy: 0.5012 - 898ms/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6865 - accuracy: 0.5456 - val_loss: 0.6934 - val_accuracy: 0.4926 - 884ms/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6872 - accuracy: 0.5545 - val_loss: 0.6920 - val_accuracy: 0.4939 - 888ms/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6856 - accuracy: 0.5417 - val_loss: 0.7092 - val_accuracy: 0.4926 - 847ms/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6858 - accuracy: 0.5506 - val_loss: 0.7114 - val_accuracy: 0.4939 - 875ms/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.6799 - accuracy: 0.5631 - val_loss: 0.7280 - val_accuracy: 0.4939 - 898ms/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6808 - accuracy: 0.5650 - val_loss: 0.7052 - val_accuracy: 0.4926 - 892ms/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.6781 - accuracy: 0.5634 - val_loss: 0.7204 - val_accuracy: 0.4939 - 908ms/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.6729 - accuracy: 0.5726 - val_loss: 0.7156 - val_accuracy: 0.4939 - 902ms/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.6771 - accuracy: 0.5726 - val_loss: 0.7069 - val_accuracy: 0.4926 - 888ms/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.6746 - accuracy: 0.5656 - val_loss: 0.7142 - val_accuracy: 0.4926 - 929ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.6749 - accuracy: 0.5729 - val_loss: 0.6907 - val_accuracy: 0.5012 - 873ms/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.6677 - accuracy: 0.5901 - val_loss: 0.7267 - val_accuracy: 0.4951 - 871ms/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.6677 - accuracy: 0.5898 - val_loss: 0.7026 - val_accuracy: 0.4939 - 884ms/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.6702 - accuracy: 0.5769 - val_loss: 0.6905 - val_accuracy: 0.4988 - 903ms/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.6637 - accuracy: 0.5876 - val_loss: 0.6961 - val_accuracy: 0.4951 - 889ms/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.6668 - accuracy: 0.5925 - val_loss: 0.7092 - val_accuracy: 0.4951 - 877ms/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.6637 - accuracy: 0.5882 - val_loss: 0.6935 - val_accuracy: 0.4951 - 909ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.6608 - accuracy: 0.5947 - val_loss: 0.6928 - val_accuracy: 0.4963 - 901ms/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.6640 - accuracy: 0.5904 - val_loss: 0.6993 - val_accuracy: 0.4914 - 913ms/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.6578 - accuracy: 0.5922 - val_loss: 0.7031 - val_accuracy: 0.4951 - 896ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.6607 - accuracy: 0.5879 - val_loss: 0.6827 - val_accuracy: 0.5380 - 904ms/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.6537 - accuracy: 0.5956 - val_loss: 0.6869 - val_accuracy: 0.5135 - 877ms/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.6579 - accuracy: 0.5922 - val_loss: 0.6890 - val_accuracy: 0.5061 - 864ms/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.6542 - accuracy: 0.5968 - val_loss: 0.6892 - val_accuracy: 0.4963 - 878ms/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.6551 - accuracy: 0.6042 - val_loss: 0.6908 - val_accuracy: 0.4939 - 827ms/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.6603 - accuracy: 0.5934 - val_loss: 0.6799 - val_accuracy: 0.5882 - 868ms/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.6532 - accuracy: 0.6143 - val_loss: 0.6819 - val_accuracy: 0.5282 - 859ms/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.6596 - accuracy: 0.6063 - val_loss: 0.6830 - val_accuracy: 0.5380 - 893ms/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.6518 - accuracy: 0.6109 - val_loss: 0.6804 - val_accuracy: 0.5441 - 897ms/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.6474 - accuracy: 0.6091 - val_loss: 0.6861 - val_accuracy: 0.5025 - 890ms/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.6522 - accuracy: 0.6029 - val_loss: 0.7006 - val_accuracy: 0.4926 - 884ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.6521 - accuracy: 0.6100 - val_loss: 0.6853 - val_accuracy: 0.5135 - 915ms/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.6515 - accuracy: 0.6051 - val_loss: 0.6821 - val_accuracy: 0.5858 - 891ms/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.6455 - accuracy: 0.6078 - val_loss: 0.6839 - val_accuracy: 0.5380 - 869ms/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.6488 - accuracy: 0.6137 - val_loss: 0.6841 - val_accuracy: 0.5282 - 860ms/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.6444 - accuracy: 0.6121 - val_loss: 0.6815 - val_accuracy: 0.5368 - 858ms/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.6509 - accuracy: 0.6042 - val_loss: 0.6834 - val_accuracy: 0.5392 - 888ms/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.6476 - accuracy: 0.6106 - val_loss: 0.6811 - val_accuracy: 0.5404 - 870ms/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.6387 - accuracy: 0.6225 - val_loss: 0.6844 - val_accuracy: 0.5221 - 871ms/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.6434 - accuracy: 0.6198 - val_loss: 0.6837 - val_accuracy: 0.5074 - 880ms/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.6450 - accuracy: 0.6152 - val_loss: 0.6806 - val_accuracy: 0.5490 - 887ms/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.6460 - accuracy: 0.6213 - val_loss: 0.6803 - val_accuracy: 0.5429 - 904ms/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.6447 - accuracy: 0.6085 - val_loss: 0.6786 - val_accuracy: 0.5711 - 898ms/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.6420 - accuracy: 0.6299 - val_loss: 0.6819 - val_accuracy: 0.5650 - 890ms/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.6463 - accuracy: 0.6072 - val_loss: 0.6868 - val_accuracy: 0.5000 - 878ms/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.6406 - accuracy: 0.6213 - val_loss: 0.6924 - val_accuracy: 0.4951 - 872ms/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.6369 - accuracy: 0.6238 - val_loss: 0.6937 - val_accuracy: 0.4926 - 888ms/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.6440 - accuracy: 0.6278 - val_loss: 0.6837 - val_accuracy: 0.5098 - 907ms/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.6380 - accuracy: 0.6287 - val_loss: 0.6801 - val_accuracy: 0.5895 - 913ms/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.6391 - accuracy: 0.6225 - val_loss: 0.6804 - val_accuracy: 0.5343 - 881ms/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.6372 - accuracy: 0.6351 - val_loss: 0.6794 - val_accuracy: 0.5625 - 853ms/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.6390 - accuracy: 0.6317 - val_loss: 0.6807 - val_accuracy: 0.5748 - 927ms/epoch - 5ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.6372 - accuracy: 0.6265 - val_loss: 0.6808 - val_accuracy: 0.6005 - 910ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.6375 - accuracy: 0.6293 - val_loss: 0.6807 - val_accuracy: 0.5417 - 920ms/epoch - 5ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.6299 - accuracy: 0.6320 - val_loss: 0.6806 - val_accuracy: 0.5723 - 912ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.6328 - accuracy: 0.6336 - val_loss: 0.6802 - val_accuracy: 0.5466 - 875ms/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.6332 - accuracy: 0.6284 - val_loss: 0.6831 - val_accuracy: 0.5098 - 865ms/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.6334 - accuracy: 0.6351 - val_loss: 0.6791 - val_accuracy: 0.5699 - 875ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.6299 - accuracy: 0.6446 - val_loss: 0.6906 - val_accuracy: 0.4963 - 876ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.6294 - accuracy: 0.6354 - val_loss: 0.6887 - val_accuracy: 0.5012 - 887ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.6301 - accuracy: 0.6354 - val_loss: 0.6794 - val_accuracy: 0.5576 - 898ms/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.6274 - accuracy: 0.6458 - val_loss: 0.6841 - val_accuracy: 0.5196 - 893ms/epoch - 4ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.6373 - accuracy: 0.6422 - val_loss: 0.6804 - val_accuracy: 0.5711 - 873ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.6325 - accuracy: 0.6376 - val_loss: 0.7143 - val_accuracy: 0.4914 - 892ms/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.6321 - accuracy: 0.6275 - val_loss: 0.7115 - val_accuracy: 0.4951 - 868ms/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.6319 - accuracy: 0.6382 - val_loss: 0.6924 - val_accuracy: 0.5000 - 874ms/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.6285 - accuracy: 0.6302 - val_loss: 0.6997 - val_accuracy: 0.5025 - 893ms/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.6312 - accuracy: 0.6308 - val_loss: 0.6903 - val_accuracy: 0.4988 - 872ms/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.6232 - accuracy: 0.6425 - val_loss: 0.6866 - val_accuracy: 0.5049 - 863ms/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.6217 - accuracy: 0.6544 - val_loss: 0.6832 - val_accuracy: 0.5098 - 894ms/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.6262 - accuracy: 0.6409 - val_loss: 0.7263 - val_accuracy: 0.4939 - 888ms/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.6293 - accuracy: 0.6443 - val_loss: 0.6867 - val_accuracy: 0.5049 - 911ms/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.6269 - accuracy: 0.6394 - val_loss: 0.6781 - val_accuracy: 0.5699 - 852ms/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.6317 - accuracy: 0.6373 - val_loss: 0.6910 - val_accuracy: 0.4988 - 878ms/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.6250 - accuracy: 0.6480 - val_loss: 0.6788 - val_accuracy: 0.5466 - 870ms/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.6278 - accuracy: 0.6357 - val_loss: 0.6872 - val_accuracy: 0.5196 - 853ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.6270 - accuracy: 0.6366 - val_loss: 0.6797 - val_accuracy: 0.5576 - 859ms/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.6259 - accuracy: 0.6431 - val_loss: 0.6976 - val_accuracy: 0.4939 - 845ms/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.6372 - accuracy: 0.6385 - val_loss: 0.6811 - val_accuracy: 0.5306 - 916ms/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.6256 - accuracy: 0.6437 - val_loss: 0.6811 - val_accuracy: 0.5282 - 904ms/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.6224 - accuracy: 0.6449 - val_loss: 0.6770 - val_accuracy: 0.5674 - 902ms/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.6196 - accuracy: 0.6523 - val_loss: 0.6820 - val_accuracy: 0.5196 - 891ms/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.6239 - accuracy: 0.6422 - val_loss: 0.6790 - val_accuracy: 0.5662 - 900ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.6291 - accuracy: 0.6379 - val_loss: 0.6810 - val_accuracy: 0.5294 - 909ms/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.6253 - accuracy: 0.6428 - val_loss: 0.6947 - val_accuracy: 0.4914 - 908ms/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.6244 - accuracy: 0.6492 - val_loss: 0.6849 - val_accuracy: 0.5012 - 902ms/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.6196 - accuracy: 0.6461 - val_loss: 0.6801 - val_accuracy: 0.5233 - 826ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.6218 - accuracy: 0.6464 - val_loss: 0.6971 - val_accuracy: 0.5000 - 895ms/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.6254 - accuracy: 0.6541 - val_loss: 0.6929 - val_accuracy: 0.4975 - 888ms/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.6174 - accuracy: 0.6474 - val_loss: 0.7071 - val_accuracy: 0.4939 - 921ms/epoch - 5ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.6245 - accuracy: 0.6428 - val_loss: 0.6942 - val_accuracy: 0.4988 - 901ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.6282 - accuracy: 0.6415 - val_loss: 0.7041 - val_accuracy: 0.5000 - 901ms/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.6136 - accuracy: 0.6526 - val_loss: 0.7063 - val_accuracy: 0.5000 - 880ms/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.6256 - accuracy: 0.6363 - val_loss: 0.7273 - val_accuracy: 0.4963 - 876ms/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.6146 - accuracy: 0.6446 - val_loss: 0.7157 - val_accuracy: 0.4939 - 879ms/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.6200 - accuracy: 0.6449 - val_loss: 0.7371 - val_accuracy: 0.4926 - 907ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.6176 - accuracy: 0.6550 - val_loss: 0.7302 - val_accuracy: 0.4902 - 863ms/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.6234 - accuracy: 0.6541 - val_loss: 0.7156 - val_accuracy: 0.4939 - 882ms/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.6143 - accuracy: 0.6477 - val_loss: 0.7111 - val_accuracy: 0.4939 - 885ms/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.6257 - accuracy: 0.6443 - val_loss: 0.7007 - val_accuracy: 0.4926 - 882ms/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.6218 - accuracy: 0.6437 - val_loss: 0.6964 - val_accuracy: 0.4939 - 857ms/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.6209 - accuracy: 0.6492 - val_loss: 0.6902 - val_accuracy: 0.5025 - 879ms/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.6198 - accuracy: 0.6532 - val_loss: 0.6865 - val_accuracy: 0.5049 - 875ms/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.6194 - accuracy: 0.6547 - val_loss: 0.6971 - val_accuracy: 0.4890 - 902ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.6175 - accuracy: 0.6492 - val_loss: 0.7072 - val_accuracy: 0.4963 - 875ms/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.6143 - accuracy: 0.6523 - val_loss: 0.7169 - val_accuracy: 0.4951 - 879ms/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.6294 - accuracy: 0.6443 - val_loss: 0.7072 - val_accuracy: 0.4951 - 897ms/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.6117 - accuracy: 0.6608 - val_loss: 0.7084 - val_accuracy: 0.4926 - 906ms/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.6185 - accuracy: 0.6550 - val_loss: 0.7061 - val_accuracy: 0.4914 - 904ms/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.6242 - accuracy: 0.6535 - val_loss: 0.7174 - val_accuracy: 0.4926 - 894ms/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.6112 - accuracy: 0.6642 - val_loss: 0.7001 - val_accuracy: 0.4926 - 885ms/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.6112 - accuracy: 0.6590 - val_loss: 0.7072 - val_accuracy: 0.4914 - 902ms/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.6259 - accuracy: 0.6403 - val_loss: 0.6880 - val_accuracy: 0.5037 - 906ms/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.6232 - accuracy: 0.6354 - val_loss: 0.6851 - val_accuracy: 0.5037 - 906ms/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.6258 - accuracy: 0.6538 - val_loss: 0.6917 - val_accuracy: 0.5012 - 906ms/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.6161 - accuracy: 0.6464 - val_loss: 0.7003 - val_accuracy: 0.4926 - 914ms/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.6160 - accuracy: 0.6449 - val_loss: 0.7090 - val_accuracy: 0.4902 - 911ms/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.6201 - accuracy: 0.6523 - val_loss: 0.7014 - val_accuracy: 0.4902 - 918ms/epoch - 5ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.6143 - accuracy: 0.6587 - val_loss: 0.7123 - val_accuracy: 0.4951 - 914ms/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.6178 - accuracy: 0.6590 - val_loss: 0.7042 - val_accuracy: 0.4914 - 922ms/epoch - 5ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.6148 - accuracy: 0.6544 - val_loss: 0.6892 - val_accuracy: 0.4975 - 909ms/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.6168 - accuracy: 0.6547 - val_loss: 0.6983 - val_accuracy: 0.4975 - 903ms/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.6135 - accuracy: 0.6639 - val_loss: 0.6910 - val_accuracy: 0.4975 - 879ms/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.6100 - accuracy: 0.6556 - val_loss: 0.6915 - val_accuracy: 0.4963 - 905ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.6094 - accuracy: 0.6593 - val_loss: 0.6936 - val_accuracy: 0.4951 - 899ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.6133 - accuracy: 0.6612 - val_loss: 0.6941 - val_accuracy: 0.4988 - 893ms/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.6113 - accuracy: 0.6648 - val_loss: 0.6947 - val_accuracy: 0.5000 - 920ms/epoch - 5ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.6124 - accuracy: 0.6520 - val_loss: 0.6975 - val_accuracy: 0.4914 - 899ms/epoch - 4ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.6127 - accuracy: 0.6547 - val_loss: 0.7113 - val_accuracy: 0.4926 - 905ms/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.6019 - accuracy: 0.6719 - val_loss: 0.7306 - val_accuracy: 0.4914 - 916ms/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.6059 - accuracy: 0.6612 - val_loss: 0.7193 - val_accuracy: 0.4890 - 904ms/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.6141 - accuracy: 0.6501 - val_loss: 0.7129 - val_accuracy: 0.4914 - 891ms/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.6178 - accuracy: 0.6520 - val_loss: 0.7548 - val_accuracy: 0.4926 - 904ms/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.6092 - accuracy: 0.6550 - val_loss: 0.7383 - val_accuracy: 0.4914 - 901ms/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.6127 - accuracy: 0.6566 - val_loss: 0.7075 - val_accuracy: 0.4914 - 880ms/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.6104 - accuracy: 0.6639 - val_loss: 0.6926 - val_accuracy: 0.5000 - 895ms/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.6086 - accuracy: 0.6566 - val_loss: 0.6940 - val_accuracy: 0.5000 - 925ms/epoch - 5ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.6092 - accuracy: 0.6553 - val_loss: 0.6868 - val_accuracy: 0.5012 - 915ms/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.6126 - accuracy: 0.6562 - val_loss: 0.6850 - val_accuracy: 0.5417 - 893ms/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.6153 - accuracy: 0.6569 - val_loss: 0.7240 - val_accuracy: 0.4926 - 914ms/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.6098 - accuracy: 0.6483 - val_loss: 0.7047 - val_accuracy: 0.4926 - 900ms/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.6064 - accuracy: 0.6737 - val_loss: 0.7027 - val_accuracy: 0.4939 - 881ms/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.6127 - accuracy: 0.6501 - val_loss: 0.6984 - val_accuracy: 0.4975 - 894ms/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.6158 - accuracy: 0.6636 - val_loss: 0.6990 - val_accuracy: 0.4975 - 906ms/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.6165 - accuracy: 0.6612 - val_loss: 0.6938 - val_accuracy: 0.5012 - 905ms/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.6097 - accuracy: 0.6544 - val_loss: 0.6942 - val_accuracy: 0.4963 - 896ms/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.6170 - accuracy: 0.6489 - val_loss: 0.7394 - val_accuracy: 0.4926 - 886ms/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.6126 - accuracy: 0.6520 - val_loss: 0.7141 - val_accuracy: 0.4902 - 913ms/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.6050 - accuracy: 0.6608 - val_loss: 0.7159 - val_accuracy: 0.4926 - 906ms/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.6106 - accuracy: 0.6602 - val_loss: 0.7009 - val_accuracy: 0.5000 - 929ms/epoch - 5ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.6115 - accuracy: 0.6572 - val_loss: 0.6861 - val_accuracy: 0.5049 - 916ms/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.6157 - accuracy: 0.6599 - val_loss: 0.6837 - val_accuracy: 0.5699 - 894ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.6087 - accuracy: 0.6569 - val_loss: 0.6948 - val_accuracy: 0.4963 - 908ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.5997 - accuracy: 0.6667 - val_loss: 0.7139 - val_accuracy: 0.4926 - 866ms/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.6068 - accuracy: 0.6651 - val_loss: 0.7319 - val_accuracy: 0.4877 - 886ms/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.6078 - accuracy: 0.6553 - val_loss: 0.6890 - val_accuracy: 0.5012 - 902ms/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.6063 - accuracy: 0.6679 - val_loss: 0.6864 - val_accuracy: 0.5025 - 901ms/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.6041 - accuracy: 0.6590 - val_loss: 0.6935 - val_accuracy: 0.5012 - 901ms/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.6174 - accuracy: 0.6566 - val_loss: 0.7055 - val_accuracy: 0.4902 - 899ms/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.6177 - accuracy: 0.6569 - val_loss: 0.6991 - val_accuracy: 0.4939 - 917ms/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.6158 - accuracy: 0.6593 - val_loss: 0.6837 - val_accuracy: 0.5245 - 895ms/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.6157 - accuracy: 0.6618 - val_loss: 0.6847 - val_accuracy: 0.5196 - 907ms/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.6111 - accuracy: 0.6559 - val_loss: 0.7126 - val_accuracy: 0.4902 - 918ms/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.6088 - accuracy: 0.6581 - val_loss: 0.6877 - val_accuracy: 0.5098 - 908ms/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.6101 - accuracy: 0.6550 - val_loss: 0.7013 - val_accuracy: 0.5000 - 922ms/epoch - 5ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.6055 - accuracy: 0.6590 - val_loss: 0.7135 - val_accuracy: 0.4926 - 923ms/epoch - 5ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.6123 - accuracy: 0.6517 - val_loss: 0.6874 - val_accuracy: 0.5061 - 926ms/epoch - 5ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.6011 - accuracy: 0.6670 - val_loss: 0.7093 - val_accuracy: 0.4963 - 909ms/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.6054 - accuracy: 0.6703 - val_loss: 0.6928 - val_accuracy: 0.5000 - 904ms/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.6097 - accuracy: 0.6618 - val_loss: 0.7084 - val_accuracy: 0.4890 - 903ms/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.6080 - accuracy: 0.6624 - val_loss: 0.6993 - val_accuracy: 0.4939 - 914ms/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.6096 - accuracy: 0.6556 - val_loss: 0.6929 - val_accuracy: 0.5012 - 885ms/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.6081 - accuracy: 0.6520 - val_loss: 0.6946 - val_accuracy: 0.5000 - 909ms/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.6083 - accuracy: 0.6657 - val_loss: 0.6836 - val_accuracy: 0.5135 - 898ms/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.6043 - accuracy: 0.6624 - val_loss: 0.7008 - val_accuracy: 0.4914 - 929ms/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.6146 - accuracy: 0.6581 - val_loss: 0.6958 - val_accuracy: 0.5000 - 919ms/epoch - 5ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.6065 - accuracy: 0.6605 - val_loss: 0.6838 - val_accuracy: 0.5110 - 912ms/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.6081 - accuracy: 0.6566 - val_loss: 0.7025 - val_accuracy: 0.4988 - 917ms/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.6041 - accuracy: 0.6648 - val_loss: 0.7103 - val_accuracy: 0.4914 - 908ms/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.6052 - accuracy: 0.6657 - val_loss: 0.7224 - val_accuracy: 0.4939 - 905ms/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.6131 - accuracy: 0.6483 - val_loss: 0.7288 - val_accuracy: 0.4902 - 906ms/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.6107 - accuracy: 0.6550 - val_loss: 0.7016 - val_accuracy: 0.4963 - 889ms/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.5969 - accuracy: 0.6725 - val_loss: 0.7128 - val_accuracy: 0.4902 - 871ms/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.6018 - accuracy: 0.6639 - val_loss: 0.6951 - val_accuracy: 0.4975 - 857ms/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.6012 - accuracy: 0.6605 - val_loss: 0.6847 - val_accuracy: 0.5061 - 894ms/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.6061 - accuracy: 0.6746 - val_loss: 0.7144 - val_accuracy: 0.4939 - 919ms/epoch - 5ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.6036 - accuracy: 0.6645 - val_loss: 0.7191 - val_accuracy: 0.4902 - 858ms/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.6052 - accuracy: 0.6593 - val_loss: 0.7265 - val_accuracy: 0.4890 - 921ms/epoch - 5ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.6078 - accuracy: 0.6624 - val_loss: 0.7837 - val_accuracy: 0.4926 - 910ms/epoch - 4ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.6106 - accuracy: 0.6587 - val_loss: 0.7340 - val_accuracy: 0.4914 - 909ms/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.6119 - accuracy: 0.6553 - val_loss: 0.7344 - val_accuracy: 0.4926 - 897ms/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.6091 - accuracy: 0.6615 - val_loss: 0.7712 - val_accuracy: 0.4914 - 912ms/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.6107 - accuracy: 0.6489 - val_loss: 0.7417 - val_accuracy: 0.4890 - 899ms/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.6088 - accuracy: 0.6642 - val_loss: 0.7118 - val_accuracy: 0.4890 - 883ms/epoch - 4ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.5998 - accuracy: 0.6697 - val_loss: 0.7126 - val_accuracy: 0.4914 - 875ms/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.6051 - accuracy: 0.6605 - val_loss: 0.6904 - val_accuracy: 0.5049 - 873ms/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.6071 - accuracy: 0.6532 - val_loss: 0.7120 - val_accuracy: 0.4902 - 855ms/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.6089 - accuracy: 0.6520 - val_loss: 0.7215 - val_accuracy: 0.4877 - 899ms/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.6040 - accuracy: 0.6624 - val_loss: 0.7155 - val_accuracy: 0.4890 - 874ms/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.6044 - accuracy: 0.6697 - val_loss: 0.7534 - val_accuracy: 0.4902 - 893ms/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.6070 - accuracy: 0.6608 - val_loss: 0.7295 - val_accuracy: 0.4902 - 889ms/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.6039 - accuracy: 0.6627 - val_loss: 0.7036 - val_accuracy: 0.4914 - 892ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.6045 - accuracy: 0.6725 - val_loss: 0.6860 - val_accuracy: 0.5098 - 903ms/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.6071 - accuracy: 0.6550 - val_loss: 0.6826 - val_accuracy: 0.5355 - 925ms/epoch - 5ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.6048 - accuracy: 0.6664 - val_loss: 0.6890 - val_accuracy: 0.4988 - 936ms/epoch - 5ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.6032 - accuracy: 0.6612 - val_loss: 0.7033 - val_accuracy: 0.4939 - 901ms/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.6054 - accuracy: 0.6673 - val_loss: 0.7108 - val_accuracy: 0.4902 - 917ms/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.5958 - accuracy: 0.6811 - val_loss: 0.7162 - val_accuracy: 0.4926 - 904ms/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.5988 - accuracy: 0.6667 - val_loss: 0.6844 - val_accuracy: 0.5098 - 923ms/epoch - 5ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.5951 - accuracy: 0.6762 - val_loss: 0.6900 - val_accuracy: 0.5098 - 901ms/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.6172 - accuracy: 0.6504 - val_loss: 0.6969 - val_accuracy: 0.4963 - 892ms/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.6025 - accuracy: 0.6618 - val_loss: 0.6859 - val_accuracy: 0.5135 - 919ms/epoch - 5ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.5987 - accuracy: 0.6752 - val_loss: 0.7110 - val_accuracy: 0.4988 - 902ms/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.6067 - accuracy: 0.6605 - val_loss: 0.6926 - val_accuracy: 0.4963 - 899ms/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.6007 - accuracy: 0.6688 - val_loss: 0.6809 - val_accuracy: 0.5490 - 904ms/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.6132 - accuracy: 0.6667 - val_loss: 0.6917 - val_accuracy: 0.5025 - 925ms/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.6048 - accuracy: 0.6728 - val_loss: 0.7017 - val_accuracy: 0.4914 - 888ms/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.6031 - accuracy: 0.6771 - val_loss: 0.7090 - val_accuracy: 0.4951 - 899ms/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.6050 - accuracy: 0.6670 - val_loss: 0.7168 - val_accuracy: 0.4926 - 920ms/epoch - 5ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.6051 - accuracy: 0.6615 - val_loss: 0.7357 - val_accuracy: 0.4902 - 911ms/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.6087 - accuracy: 0.6526 - val_loss: 0.7076 - val_accuracy: 0.4939 - 876ms/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.6047 - accuracy: 0.6602 - val_loss: 0.7255 - val_accuracy: 0.4926 - 899ms/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.6026 - accuracy: 0.6627 - val_loss: 0.7239 - val_accuracy: 0.4902 - 894ms/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.6062 - accuracy: 0.6661 - val_loss: 0.7337 - val_accuracy: 0.4890 - 910ms/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.6078 - accuracy: 0.6562 - val_loss: 0.6980 - val_accuracy: 0.5037 - 889ms/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.6029 - accuracy: 0.6630 - val_loss: 0.7168 - val_accuracy: 0.4939 - 846ms/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.6059 - accuracy: 0.6605 - val_loss: 0.7329 - val_accuracy: 0.4914 - 888ms/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.5950 - accuracy: 0.6691 - val_loss: 0.7422 - val_accuracy: 0.4877 - 905ms/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.6038 - accuracy: 0.6639 - val_loss: 0.7368 - val_accuracy: 0.4914 - 911ms/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.6113 - accuracy: 0.6599 - val_loss: 0.8103 - val_accuracy: 0.4902 - 900ms/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.6032 - accuracy: 0.6642 - val_loss: 0.7671 - val_accuracy: 0.4914 - 909ms/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.6015 - accuracy: 0.6676 - val_loss: 0.7208 - val_accuracy: 0.4877 - 882ms/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.6015 - accuracy: 0.6719 - val_loss: 0.7483 - val_accuracy: 0.4926 - 931ms/epoch - 5ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.5972 - accuracy: 0.6777 - val_loss: 0.7463 - val_accuracy: 0.4902 - 900ms/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.6085 - accuracy: 0.6596 - val_loss: 0.7422 - val_accuracy: 0.4914 - 830ms/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.6000 - accuracy: 0.6706 - val_loss: 0.7325 - val_accuracy: 0.4926 - 910ms/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.6014 - accuracy: 0.6691 - val_loss: 0.7088 - val_accuracy: 0.4914 - 895ms/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.6056 - accuracy: 0.6562 - val_loss: 0.7472 - val_accuracy: 0.4914 - 935ms/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.6088 - accuracy: 0.6667 - val_loss: 0.7456 - val_accuracy: 0.4939 - 917ms/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.6117 - accuracy: 0.6535 - val_loss: 0.7618 - val_accuracy: 0.4926 - 913ms/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.6036 - accuracy: 0.6667 - val_loss: 0.7785 - val_accuracy: 0.4939 - 856ms/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.6045 - accuracy: 0.6608 - val_loss: 0.7542 - val_accuracy: 0.4914 - 864ms/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.5973 - accuracy: 0.6710 - val_loss: 0.7418 - val_accuracy: 0.4890 - 897ms/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.6060 - accuracy: 0.6679 - val_loss: 0.7292 - val_accuracy: 0.4914 - 906ms/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.6051 - accuracy: 0.6529 - val_loss: 0.7172 - val_accuracy: 0.4939 - 921ms/epoch - 5ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    2    3 ... 4077 4078 4079]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   1    9   13   25   26   33   34   37   41   55   60   66   73   74\n",
      "   77   81   82   89   92   93   94   96  104  112  126  129  131  140\n",
      "  147  149  156  164  165  166  167  173  182  199  211  222  223  229\n",
      "  234  237  240  243  245  248  250  252  261  264  277  283  285  291\n",
      "  296  300  301  307  312  317  318  321  322  323  325  336  341  344\n",
      "  352  353  356  373  376  378  379  382  385  386  390  397  400  415\n",
      "  422  426  432  433  436  437  439  443  448  456  462  473  478  479\n",
      "  485  488  495  498  499  508  516  518  520  529  530  534  538  541\n",
      "  547  549  561  562  565  567  570  576  582  583  599  605  618  620\n",
      "  631  641  648  651  653  655  663  671  686  692  699  704  709  714\n",
      "  720  725  739  745  750  755  760  762  767  768  775  778  781  798\n",
      "  803  804  807  810  821  830  831  834  837  838  839  843  844  846\n",
      "  848  849  857  866  867  870  877  888  889  892  893  897  898  906\n",
      "  910  914  917  923  926  928  932  938  943  953  958  963  974  982\n",
      "  992  993  994 1000 1001 1003 1009 1014 1015 1020 1028 1039 1042 1044\n",
      " 1047 1063 1064 1072 1077 1079 1084 1088 1093 1094 1095 1102 1114 1128\n",
      " 1133 1135 1138 1150 1153 1154 1155 1160 1162 1163 1164 1165 1172 1188\n",
      " 1192 1193 1195 1205 1206 1212 1217 1226 1241 1252 1253 1258 1263 1266\n",
      " 1282 1291 1295 1304 1307 1308 1311 1319 1320 1326 1327 1336 1337 1350\n",
      " 1351 1359 1367 1373 1375 1382 1388 1399 1402 1403 1405 1406 1408 1413\n",
      " 1417 1419 1421 1423 1426 1448 1451 1463 1464 1465 1470 1487 1490 1494\n",
      " 1498 1508 1514 1517 1524 1527 1529 1530 1534 1550 1552 1559 1569 1589\n",
      " 1592 1597 1600 1606 1608 1609 1613 1614 1615 1616 1623 1625 1626 1640\n",
      " 1644 1649 1657 1658 1663 1665 1681 1682 1691 1695 1704 1707 1708 1715\n",
      " 1716 1722 1723 1725 1726 1727 1731 1734 1736 1739 1757 1767 1769 1770\n",
      " 1781 1787 1792 1805 1808 1815 1835 1841 1844 1845 1850 1851 1857 1864\n",
      " 1875 1883 1885 1887 1888 1891 1902 1903 1904 1907 1910 1911 1912 1919\n",
      " 1922 1923 1924 1926 1934 1935 1936 1939 1951 1952 1963 1972 1973 1980\n",
      " 1987 1989 1990 1992 2003 2004 2011 2017 2019 2022 2024 2025 2033 2036\n",
      " 2037 2038 2047 2051 2056 2057 2064 2071 2074 2089 2091 2095 2099 2100\n",
      " 2105 2108 2113 2119 2121 2124 2129 2133 2137 2138 2140 2146 2154 2158\n",
      " 2164 2167 2184 2189 2193 2196 2206 2216 2221 2222 2223 2230 2239 2242\n",
      " 2251 2254 2262 2280 2285 2304 2306 2308 2311 2328 2331 2332 2333 2334\n",
      " 2337 2340 2344 2346 2354 2366 2371 2373 2380 2391 2392 2397 2406 2418\n",
      " 2420 2421 2430 2437 2450 2454 2455 2464 2465 2479 2481 2484 2488 2492\n",
      " 2497 2499 2502 2504 2510 2514 2525 2526 2536 2544 2555 2562 2563 2565\n",
      " 2571 2572 2574 2581 2587 2589 2598 2604 2612 2613 2621 2625 2642 2645\n",
      " 2650 2653 2655 2664 2670 2672 2677 2680 2681 2683 2688 2690 2696 2707\n",
      " 2709 2711 2715 2722 2724 2726 2727 2729 2731 2732 2738 2739 2740 2749\n",
      " 2760 2762 2765 2769 2773 2775 2776 2780 2784 2785 2788 2792 2793 2794\n",
      " 2809 2811 2812 2818 2825 2828 2839 2842 2843 2846 2847 2849 2850 2852\n",
      " 2855 2857 2858 2861 2868 2872 2881 2882 2883 2890 2894 2897 2918 2928\n",
      " 2931 2942 2946 2952 2953 2959 2980 2986 2994 2999 3000 3004 3007 3010\n",
      " 3011 3013 3014 3021 3030 3032 3038 3045 3054 3059 3068 3074 3078 3079\n",
      " 3080 3085 3096 3098 3099 3103 3107 3108 3114 3120 3123 3130 3137 3142\n",
      " 3144 3149 3167 3170 3174 3181 3183 3186 3193 3195 3202 3208 3210 3211\n",
      " 3214 3215 3218 3220 3221 3227 3228 3232 3233 3240 3248 3254 3264 3267\n",
      " 3274 3281 3284 3295 3298 3299 3316 3317 3319 3333 3349 3354 3355 3373\n",
      " 3377 3378 3380 3389 3393 3414 3415 3417 3418 3420 3423 3425 3431 3433\n",
      " 3448 3450 3457 3458 3478 3481 3485 3486 3488 3489 3496 3509 3510 3521\n",
      " 3522 3530 3535 3539 3551 3553 3562 3563 3571 3574 3576 3581 3599 3608\n",
      " 3615 3620 3627 3628 3636 3643 3656 3665 3669 3673 3674 3675 3682 3683\n",
      " 3688 3691 3694 3703 3704 3705 3706 3709 3713 3739 3740 3741 3743 3746\n",
      " 3748 3749 3752 3757 3769 3774 3778 3784 3796 3803 3804 3807 3810 3811\n",
      " 3812 3814 3817 3818 3819 3820 3827 3828 3835 3848 3849 3852 3854 3859\n",
      " 3865 3868 3871 3873 3876 3877 3882 3883 3888 3892 3893 3896 3901 3905\n",
      " 3910 3911 3920 3924 3927 3931 3933 3940 3941 3943 3949 3951 3954 3962\n",
      " 3963 3965 3973 3984 3989 3995 4002 4006 4009 4021 4026 4027 4031 4046\n",
      " 4052 4062 4065 4072]\n",
      "Number of samples for test set: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:33:47.765062: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_313/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6955 - accuracy: 0.4917 - val_loss: 0.6937 - val_accuracy: 0.5319 - 3s/epoch - 13ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6925 - accuracy: 0.5119 - val_loss: 0.6929 - val_accuracy: 0.5331 - 888ms/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6924 - accuracy: 0.5150 - val_loss: 0.6930 - val_accuracy: 0.4706 - 921ms/epoch - 5ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6918 - accuracy: 0.5052 - val_loss: 0.6926 - val_accuracy: 0.5319 - 884ms/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6908 - accuracy: 0.5153 - val_loss: 0.6937 - val_accuracy: 0.5331 - 906ms/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6893 - accuracy: 0.5214 - val_loss: 0.6936 - val_accuracy: 0.5380 - 905ms/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6895 - accuracy: 0.5248 - val_loss: 0.6926 - val_accuracy: 0.5306 - 910ms/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6870 - accuracy: 0.5398 - val_loss: 0.6921 - val_accuracy: 0.5331 - 920ms/epoch - 5ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6867 - accuracy: 0.5441 - val_loss: 0.6909 - val_accuracy: 0.5331 - 884ms/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.6843 - accuracy: 0.5475 - val_loss: 0.6900 - val_accuracy: 0.5380 - 891ms/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6805 - accuracy: 0.5579 - val_loss: 0.6912 - val_accuracy: 0.5294 - 893ms/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.6744 - accuracy: 0.5680 - val_loss: 0.6918 - val_accuracy: 0.5478 - 914ms/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.6790 - accuracy: 0.5699 - val_loss: 0.6924 - val_accuracy: 0.5343 - 837ms/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.6718 - accuracy: 0.5748 - val_loss: 0.6932 - val_accuracy: 0.5564 - 890ms/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.6753 - accuracy: 0.5689 - val_loss: 0.6936 - val_accuracy: 0.5625 - 881ms/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.6745 - accuracy: 0.5711 - val_loss: 0.6919 - val_accuracy: 0.5515 - 887ms/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.6735 - accuracy: 0.5784 - val_loss: 0.6952 - val_accuracy: 0.5392 - 882ms/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.6726 - accuracy: 0.5680 - val_loss: 0.6946 - val_accuracy: 0.4877 - 925ms/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.6716 - accuracy: 0.5748 - val_loss: 0.6933 - val_accuracy: 0.4816 - 928ms/epoch - 5ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.6679 - accuracy: 0.5809 - val_loss: 0.6914 - val_accuracy: 0.5576 - 893ms/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.6662 - accuracy: 0.5741 - val_loss: 0.6915 - val_accuracy: 0.5270 - 862ms/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.6650 - accuracy: 0.5861 - val_loss: 0.6935 - val_accuracy: 0.5600 - 903ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.6660 - accuracy: 0.5904 - val_loss: 0.6909 - val_accuracy: 0.5368 - 829ms/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.6651 - accuracy: 0.5968 - val_loss: 0.6931 - val_accuracy: 0.5343 - 842ms/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.6705 - accuracy: 0.5790 - val_loss: 0.6920 - val_accuracy: 0.5319 - 880ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.6661 - accuracy: 0.5797 - val_loss: 0.6956 - val_accuracy: 0.5282 - 901ms/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.6637 - accuracy: 0.5833 - val_loss: 0.6936 - val_accuracy: 0.5699 - 933ms/epoch - 5ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.6661 - accuracy: 0.5800 - val_loss: 0.6917 - val_accuracy: 0.5637 - 911ms/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.6590 - accuracy: 0.5990 - val_loss: 0.6959 - val_accuracy: 0.5184 - 875ms/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.6645 - accuracy: 0.5839 - val_loss: 0.6916 - val_accuracy: 0.5723 - 878ms/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.6599 - accuracy: 0.5962 - val_loss: 0.6936 - val_accuracy: 0.5245 - 883ms/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.6576 - accuracy: 0.6051 - val_loss: 0.6928 - val_accuracy: 0.5282 - 907ms/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.6572 - accuracy: 0.5907 - val_loss: 0.6952 - val_accuracy: 0.5600 - 901ms/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.6606 - accuracy: 0.5892 - val_loss: 0.6928 - val_accuracy: 0.5245 - 902ms/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.6578 - accuracy: 0.5999 - val_loss: 0.6946 - val_accuracy: 0.5270 - 858ms/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.6628 - accuracy: 0.5934 - val_loss: 0.6965 - val_accuracy: 0.5233 - 909ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.6525 - accuracy: 0.6020 - val_loss: 0.6931 - val_accuracy: 0.5270 - 882ms/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.6527 - accuracy: 0.6051 - val_loss: 0.6909 - val_accuracy: 0.5392 - 885ms/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.6583 - accuracy: 0.5993 - val_loss: 0.6932 - val_accuracy: 0.5699 - 886ms/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.6556 - accuracy: 0.6032 - val_loss: 0.6930 - val_accuracy: 0.5686 - 886ms/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.6491 - accuracy: 0.6069 - val_loss: 0.7038 - val_accuracy: 0.5294 - 915ms/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.6484 - accuracy: 0.6112 - val_loss: 0.6944 - val_accuracy: 0.5245 - 872ms/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.6431 - accuracy: 0.6241 - val_loss: 0.6914 - val_accuracy: 0.5270 - 875ms/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.6509 - accuracy: 0.6063 - val_loss: 0.7006 - val_accuracy: 0.5294 - 886ms/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.6407 - accuracy: 0.6317 - val_loss: 0.6901 - val_accuracy: 0.5282 - 903ms/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.6462 - accuracy: 0.6271 - val_loss: 0.6903 - val_accuracy: 0.5441 - 888ms/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.6489 - accuracy: 0.6081 - val_loss: 0.7007 - val_accuracy: 0.4657 - 914ms/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.6449 - accuracy: 0.6115 - val_loss: 0.7080 - val_accuracy: 0.4669 - 898ms/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.6458 - accuracy: 0.6250 - val_loss: 0.7155 - val_accuracy: 0.4669 - 891ms/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.6443 - accuracy: 0.6048 - val_loss: 0.7087 - val_accuracy: 0.4669 - 901ms/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.6433 - accuracy: 0.6271 - val_loss: 0.7260 - val_accuracy: 0.4681 - 883ms/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.6421 - accuracy: 0.6140 - val_loss: 0.7054 - val_accuracy: 0.4706 - 890ms/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.6400 - accuracy: 0.6170 - val_loss: 0.6928 - val_accuracy: 0.5025 - 896ms/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.6393 - accuracy: 0.6354 - val_loss: 0.6900 - val_accuracy: 0.5870 - 896ms/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.6362 - accuracy: 0.6253 - val_loss: 0.6984 - val_accuracy: 0.4669 - 913ms/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.6394 - accuracy: 0.6213 - val_loss: 0.7139 - val_accuracy: 0.4694 - 895ms/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.6375 - accuracy: 0.6247 - val_loss: 0.7215 - val_accuracy: 0.4694 - 903ms/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.6371 - accuracy: 0.6201 - val_loss: 0.7094 - val_accuracy: 0.4718 - 882ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.6382 - accuracy: 0.6317 - val_loss: 0.7217 - val_accuracy: 0.4681 - 900ms/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.6335 - accuracy: 0.6394 - val_loss: 0.7238 - val_accuracy: 0.4681 - 879ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.6374 - accuracy: 0.6210 - val_loss: 0.6965 - val_accuracy: 0.5025 - 871ms/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.6377 - accuracy: 0.6140 - val_loss: 0.7050 - val_accuracy: 0.4669 - 903ms/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.6328 - accuracy: 0.6305 - val_loss: 0.7003 - val_accuracy: 0.4779 - 888ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.6312 - accuracy: 0.6336 - val_loss: 0.6950 - val_accuracy: 0.5723 - 901ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.6392 - accuracy: 0.6143 - val_loss: 0.6964 - val_accuracy: 0.5196 - 884ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.6262 - accuracy: 0.6477 - val_loss: 0.6977 - val_accuracy: 0.4779 - 884ms/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.6249 - accuracy: 0.6333 - val_loss: 0.7072 - val_accuracy: 0.4694 - 891ms/epoch - 4ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.6342 - accuracy: 0.6320 - val_loss: 0.7007 - val_accuracy: 0.4841 - 882ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.6322 - accuracy: 0.6330 - val_loss: 0.6976 - val_accuracy: 0.5466 - 890ms/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.6323 - accuracy: 0.6412 - val_loss: 0.7011 - val_accuracy: 0.4718 - 897ms/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.6213 - accuracy: 0.6480 - val_loss: 0.7134 - val_accuracy: 0.4669 - 914ms/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.6191 - accuracy: 0.6458 - val_loss: 0.7218 - val_accuracy: 0.4706 - 896ms/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.6315 - accuracy: 0.6354 - val_loss: 0.6921 - val_accuracy: 0.5159 - 880ms/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.6312 - accuracy: 0.6379 - val_loss: 0.6981 - val_accuracy: 0.4914 - 880ms/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.6311 - accuracy: 0.6278 - val_loss: 0.7047 - val_accuracy: 0.4718 - 879ms/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.6313 - accuracy: 0.6437 - val_loss: 0.7001 - val_accuracy: 0.4841 - 885ms/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.6342 - accuracy: 0.6363 - val_loss: 0.7161 - val_accuracy: 0.4681 - 911ms/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.6277 - accuracy: 0.6425 - val_loss: 0.7045 - val_accuracy: 0.4669 - 910ms/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.6222 - accuracy: 0.6409 - val_loss: 0.7006 - val_accuracy: 0.4706 - 874ms/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.6309 - accuracy: 0.6314 - val_loss: 0.6954 - val_accuracy: 0.5404 - 873ms/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.6270 - accuracy: 0.6336 - val_loss: 0.6907 - val_accuracy: 0.5502 - 909ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.6192 - accuracy: 0.6394 - val_loss: 0.7150 - val_accuracy: 0.5331 - 918ms/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.6233 - accuracy: 0.6492 - val_loss: 0.7010 - val_accuracy: 0.5331 - 914ms/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.6213 - accuracy: 0.6425 - val_loss: 0.6971 - val_accuracy: 0.5846 - 912ms/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.6209 - accuracy: 0.6477 - val_loss: 0.6919 - val_accuracy: 0.5368 - 872ms/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.6222 - accuracy: 0.6400 - val_loss: 0.6965 - val_accuracy: 0.5355 - 875ms/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.6193 - accuracy: 0.6526 - val_loss: 0.6948 - val_accuracy: 0.5294 - 884ms/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.6229 - accuracy: 0.6403 - val_loss: 0.6997 - val_accuracy: 0.4645 - 909ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.6200 - accuracy: 0.6394 - val_loss: 0.7028 - val_accuracy: 0.4681 - 898ms/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.6242 - accuracy: 0.6471 - val_loss: 0.7056 - val_accuracy: 0.4657 - 895ms/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.6256 - accuracy: 0.6422 - val_loss: 0.6961 - val_accuracy: 0.5380 - 915ms/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.6221 - accuracy: 0.6474 - val_loss: 0.6919 - val_accuracy: 0.5404 - 912ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.6259 - accuracy: 0.6320 - val_loss: 0.6992 - val_accuracy: 0.5355 - 883ms/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.6249 - accuracy: 0.6477 - val_loss: 0.7039 - val_accuracy: 0.4755 - 909ms/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.6222 - accuracy: 0.6434 - val_loss: 0.6943 - val_accuracy: 0.5490 - 894ms/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.6135 - accuracy: 0.6575 - val_loss: 0.6927 - val_accuracy: 0.5331 - 914ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.6226 - accuracy: 0.6351 - val_loss: 0.7032 - val_accuracy: 0.4681 - 892ms/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.6236 - accuracy: 0.6446 - val_loss: 0.6988 - val_accuracy: 0.4939 - 932ms/epoch - 5ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.6255 - accuracy: 0.6492 - val_loss: 0.7104 - val_accuracy: 0.4681 - 892ms/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.6206 - accuracy: 0.6489 - val_loss: 0.7224 - val_accuracy: 0.4657 - 883ms/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.6169 - accuracy: 0.6471 - val_loss: 0.6913 - val_accuracy: 0.5343 - 845ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.6204 - accuracy: 0.6489 - val_loss: 0.6953 - val_accuracy: 0.5392 - 920ms/epoch - 5ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.6226 - accuracy: 0.6480 - val_loss: 0.6912 - val_accuracy: 0.5429 - 889ms/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.6209 - accuracy: 0.6538 - val_loss: 0.6924 - val_accuracy: 0.5294 - 898ms/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.6159 - accuracy: 0.6538 - val_loss: 0.6925 - val_accuracy: 0.5711 - 894ms/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.6185 - accuracy: 0.6587 - val_loss: 0.6952 - val_accuracy: 0.5650 - 913ms/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.6144 - accuracy: 0.6474 - val_loss: 0.7048 - val_accuracy: 0.4681 - 904ms/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.6112 - accuracy: 0.6691 - val_loss: 0.7122 - val_accuracy: 0.4645 - 917ms/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.6226 - accuracy: 0.6483 - val_loss: 0.7401 - val_accuracy: 0.4694 - 918ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.6094 - accuracy: 0.6513 - val_loss: 0.7017 - val_accuracy: 0.4939 - 891ms/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.6172 - accuracy: 0.6627 - val_loss: 0.7052 - val_accuracy: 0.4792 - 902ms/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.6081 - accuracy: 0.6670 - val_loss: 0.7130 - val_accuracy: 0.4657 - 870ms/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.6126 - accuracy: 0.6590 - val_loss: 0.7055 - val_accuracy: 0.4706 - 893ms/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.6144 - accuracy: 0.6510 - val_loss: 0.7138 - val_accuracy: 0.4657 - 893ms/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.6105 - accuracy: 0.6602 - val_loss: 0.7413 - val_accuracy: 0.4694 - 928ms/epoch - 5ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.6135 - accuracy: 0.6590 - val_loss: 0.6932 - val_accuracy: 0.5527 - 906ms/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.6204 - accuracy: 0.6419 - val_loss: 0.6931 - val_accuracy: 0.5600 - 905ms/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.6150 - accuracy: 0.6510 - val_loss: 0.6904 - val_accuracy: 0.5600 - 903ms/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.6163 - accuracy: 0.6464 - val_loss: 0.6902 - val_accuracy: 0.5331 - 893ms/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.6074 - accuracy: 0.6636 - val_loss: 0.6994 - val_accuracy: 0.4841 - 853ms/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.6177 - accuracy: 0.6510 - val_loss: 0.7127 - val_accuracy: 0.4681 - 890ms/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.6146 - accuracy: 0.6468 - val_loss: 0.6954 - val_accuracy: 0.5699 - 908ms/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.6101 - accuracy: 0.6645 - val_loss: 0.7139 - val_accuracy: 0.4694 - 902ms/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.6177 - accuracy: 0.6529 - val_loss: 0.7225 - val_accuracy: 0.4657 - 917ms/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.6201 - accuracy: 0.6369 - val_loss: 0.6954 - val_accuracy: 0.5784 - 911ms/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.6141 - accuracy: 0.6593 - val_loss: 0.7008 - val_accuracy: 0.4816 - 902ms/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.6155 - accuracy: 0.6596 - val_loss: 0.7110 - val_accuracy: 0.4645 - 908ms/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.6150 - accuracy: 0.6569 - val_loss: 0.7283 - val_accuracy: 0.4657 - 889ms/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.6148 - accuracy: 0.6532 - val_loss: 0.7334 - val_accuracy: 0.4681 - 888ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.6098 - accuracy: 0.6562 - val_loss: 0.7695 - val_accuracy: 0.4681 - 912ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.6107 - accuracy: 0.6562 - val_loss: 0.7237 - val_accuracy: 0.4657 - 905ms/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.6124 - accuracy: 0.6575 - val_loss: 0.7694 - val_accuracy: 0.4669 - 865ms/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.6195 - accuracy: 0.6550 - val_loss: 0.7332 - val_accuracy: 0.4718 - 932ms/epoch - 5ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.6072 - accuracy: 0.6507 - val_loss: 0.7290 - val_accuracy: 0.4694 - 917ms/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.6118 - accuracy: 0.6559 - val_loss: 0.7059 - val_accuracy: 0.4681 - 916ms/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.6088 - accuracy: 0.6642 - val_loss: 0.7046 - val_accuracy: 0.4804 - 890ms/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.6196 - accuracy: 0.6504 - val_loss: 0.6986 - val_accuracy: 0.4939 - 878ms/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.6100 - accuracy: 0.6596 - val_loss: 0.7097 - val_accuracy: 0.4632 - 894ms/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.6098 - accuracy: 0.6676 - val_loss: 0.7211 - val_accuracy: 0.4620 - 914ms/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.6164 - accuracy: 0.6547 - val_loss: 0.7055 - val_accuracy: 0.4657 - 885ms/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.6104 - accuracy: 0.6474 - val_loss: 0.7557 - val_accuracy: 0.4669 - 899ms/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.6144 - accuracy: 0.6483 - val_loss: 0.6896 - val_accuracy: 0.5294 - 897ms/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.6113 - accuracy: 0.6443 - val_loss: 0.7279 - val_accuracy: 0.4608 - 869ms/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.6071 - accuracy: 0.6664 - val_loss: 0.7404 - val_accuracy: 0.4645 - 886ms/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.6028 - accuracy: 0.6676 - val_loss: 0.8054 - val_accuracy: 0.4669 - 881ms/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.6124 - accuracy: 0.6566 - val_loss: 0.7197 - val_accuracy: 0.4669 - 876ms/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.6136 - accuracy: 0.6489 - val_loss: 0.6970 - val_accuracy: 0.5576 - 871ms/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.6165 - accuracy: 0.6550 - val_loss: 0.7236 - val_accuracy: 0.4657 - 873ms/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.6110 - accuracy: 0.6507 - val_loss: 0.7113 - val_accuracy: 0.4583 - 902ms/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.6062 - accuracy: 0.6688 - val_loss: 0.7673 - val_accuracy: 0.4681 - 900ms/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.6077 - accuracy: 0.6661 - val_loss: 0.7686 - val_accuracy: 0.4694 - 935ms/epoch - 5ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.6056 - accuracy: 0.6700 - val_loss: 0.7164 - val_accuracy: 0.4669 - 902ms/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.6032 - accuracy: 0.6645 - val_loss: 0.7215 - val_accuracy: 0.4608 - 918ms/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.6094 - accuracy: 0.6569 - val_loss: 0.6979 - val_accuracy: 0.5429 - 903ms/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.6066 - accuracy: 0.6532 - val_loss: 0.7537 - val_accuracy: 0.4694 - 905ms/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.6097 - accuracy: 0.6575 - val_loss: 0.7150 - val_accuracy: 0.4608 - 927ms/epoch - 5ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.6065 - accuracy: 0.6624 - val_loss: 0.6970 - val_accuracy: 0.5196 - 888ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.6094 - accuracy: 0.6575 - val_loss: 0.6975 - val_accuracy: 0.5331 - 924ms/epoch - 5ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.6113 - accuracy: 0.6618 - val_loss: 0.7259 - val_accuracy: 0.4620 - 873ms/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.5981 - accuracy: 0.6700 - val_loss: 0.7142 - val_accuracy: 0.4694 - 891ms/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.6099 - accuracy: 0.6575 - val_loss: 0.7905 - val_accuracy: 0.4645 - 894ms/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.6006 - accuracy: 0.6645 - val_loss: 0.7319 - val_accuracy: 0.4669 - 883ms/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.6077 - accuracy: 0.6621 - val_loss: 0.6991 - val_accuracy: 0.4890 - 913ms/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.6037 - accuracy: 0.6670 - val_loss: 0.7065 - val_accuracy: 0.4669 - 916ms/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.6065 - accuracy: 0.6596 - val_loss: 0.6958 - val_accuracy: 0.5882 - 896ms/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.6077 - accuracy: 0.6578 - val_loss: 0.7061 - val_accuracy: 0.4632 - 874ms/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.6077 - accuracy: 0.6664 - val_loss: 0.7393 - val_accuracy: 0.4681 - 908ms/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.6020 - accuracy: 0.6566 - val_loss: 0.7004 - val_accuracy: 0.4890 - 906ms/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.6087 - accuracy: 0.6556 - val_loss: 0.6958 - val_accuracy: 0.5417 - 890ms/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.6146 - accuracy: 0.6569 - val_loss: 0.7007 - val_accuracy: 0.4853 - 906ms/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.6095 - accuracy: 0.6624 - val_loss: 0.7590 - val_accuracy: 0.4669 - 885ms/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.6069 - accuracy: 0.6654 - val_loss: 0.7936 - val_accuracy: 0.4657 - 849ms/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.6040 - accuracy: 0.6642 - val_loss: 0.8056 - val_accuracy: 0.4669 - 858ms/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.6048 - accuracy: 0.6615 - val_loss: 0.8227 - val_accuracy: 0.4669 - 871ms/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.6064 - accuracy: 0.6553 - val_loss: 0.7413 - val_accuracy: 0.4706 - 868ms/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.6039 - accuracy: 0.6648 - val_loss: 0.7986 - val_accuracy: 0.4669 - 873ms/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.6058 - accuracy: 0.6593 - val_loss: 0.8159 - val_accuracy: 0.4669 - 891ms/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.6097 - accuracy: 0.6624 - val_loss: 0.8039 - val_accuracy: 0.4669 - 905ms/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.6162 - accuracy: 0.6517 - val_loss: 0.7814 - val_accuracy: 0.4669 - 885ms/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.6057 - accuracy: 0.6541 - val_loss: 0.7779 - val_accuracy: 0.4669 - 920ms/epoch - 5ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.6020 - accuracy: 0.6651 - val_loss: 0.7532 - val_accuracy: 0.4681 - 908ms/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.6103 - accuracy: 0.6587 - val_loss: 0.8031 - val_accuracy: 0.4657 - 909ms/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.6013 - accuracy: 0.6725 - val_loss: 0.7616 - val_accuracy: 0.4706 - 905ms/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.6105 - accuracy: 0.6559 - val_loss: 0.8097 - val_accuracy: 0.4657 - 903ms/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.5985 - accuracy: 0.6783 - val_loss: 0.7254 - val_accuracy: 0.4669 - 912ms/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.6031 - accuracy: 0.6682 - val_loss: 0.7381 - val_accuracy: 0.4694 - 876ms/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.6046 - accuracy: 0.6602 - val_loss: 0.7222 - val_accuracy: 0.4632 - 890ms/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.6026 - accuracy: 0.6621 - val_loss: 0.7850 - val_accuracy: 0.4681 - 891ms/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.6054 - accuracy: 0.6734 - val_loss: 0.7230 - val_accuracy: 0.4681 - 905ms/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.5990 - accuracy: 0.6633 - val_loss: 0.7037 - val_accuracy: 0.4730 - 900ms/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.6048 - accuracy: 0.6661 - val_loss: 0.6969 - val_accuracy: 0.5184 - 894ms/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.6008 - accuracy: 0.6670 - val_loss: 0.7107 - val_accuracy: 0.4632 - 905ms/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.6098 - accuracy: 0.6615 - val_loss: 0.6952 - val_accuracy: 0.5466 - 890ms/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.6166 - accuracy: 0.6538 - val_loss: 0.7115 - val_accuracy: 0.4645 - 878ms/epoch - 4ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.6046 - accuracy: 0.6633 - val_loss: 0.7062 - val_accuracy: 0.4694 - 862ms/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.6002 - accuracy: 0.6667 - val_loss: 0.7628 - val_accuracy: 0.4681 - 894ms/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.6012 - accuracy: 0.6685 - val_loss: 0.7691 - val_accuracy: 0.4669 - 896ms/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.5930 - accuracy: 0.6740 - val_loss: 0.8039 - val_accuracy: 0.4657 - 909ms/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.6058 - accuracy: 0.6664 - val_loss: 0.8230 - val_accuracy: 0.4669 - 924ms/epoch - 5ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.5953 - accuracy: 0.6743 - val_loss: 0.8217 - val_accuracy: 0.4669 - 920ms/epoch - 5ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.5992 - accuracy: 0.6682 - val_loss: 0.7207 - val_accuracy: 0.4706 - 886ms/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.6092 - accuracy: 0.6599 - val_loss: 0.7205 - val_accuracy: 0.4620 - 889ms/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.5962 - accuracy: 0.6670 - val_loss: 0.7862 - val_accuracy: 0.4681 - 887ms/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.5928 - accuracy: 0.6786 - val_loss: 0.8068 - val_accuracy: 0.4657 - 881ms/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.6029 - accuracy: 0.6532 - val_loss: 0.8072 - val_accuracy: 0.4681 - 928ms/epoch - 5ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.6057 - accuracy: 0.6654 - val_loss: 0.7721 - val_accuracy: 0.4681 - 886ms/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.5990 - accuracy: 0.6679 - val_loss: 0.7778 - val_accuracy: 0.4681 - 907ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.6080 - accuracy: 0.6587 - val_loss: 0.7218 - val_accuracy: 0.4657 - 915ms/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.6092 - accuracy: 0.6599 - val_loss: 0.6984 - val_accuracy: 0.5086 - 895ms/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.5965 - accuracy: 0.6703 - val_loss: 0.7285 - val_accuracy: 0.4632 - 900ms/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.6055 - accuracy: 0.6657 - val_loss: 0.8816 - val_accuracy: 0.4657 - 914ms/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.5973 - accuracy: 0.6716 - val_loss: 0.8454 - val_accuracy: 0.4657 - 899ms/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.5958 - accuracy: 0.6805 - val_loss: 0.8135 - val_accuracy: 0.4681 - 917ms/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.5990 - accuracy: 0.6728 - val_loss: 0.7457 - val_accuracy: 0.4681 - 895ms/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.6051 - accuracy: 0.6608 - val_loss: 0.8312 - val_accuracy: 0.4669 - 934ms/epoch - 5ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.6045 - accuracy: 0.6657 - val_loss: 0.8133 - val_accuracy: 0.4669 - 926ms/epoch - 5ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.6047 - accuracy: 0.6688 - val_loss: 0.7864 - val_accuracy: 0.4694 - 916ms/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.6028 - accuracy: 0.6581 - val_loss: 0.7998 - val_accuracy: 0.4681 - 882ms/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.6023 - accuracy: 0.6728 - val_loss: 0.7548 - val_accuracy: 0.4681 - 882ms/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.5999 - accuracy: 0.6762 - val_loss: 0.7328 - val_accuracy: 0.4657 - 887ms/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.5999 - accuracy: 0.6777 - val_loss: 0.8584 - val_accuracy: 0.4657 - 902ms/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.6018 - accuracy: 0.6801 - val_loss: 0.8704 - val_accuracy: 0.4657 - 886ms/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.6054 - accuracy: 0.6682 - val_loss: 0.7591 - val_accuracy: 0.4694 - 910ms/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.6089 - accuracy: 0.6599 - val_loss: 0.8142 - val_accuracy: 0.4669 - 899ms/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.5914 - accuracy: 0.6777 - val_loss: 0.8027 - val_accuracy: 0.4669 - 894ms/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.6002 - accuracy: 0.6719 - val_loss: 0.7157 - val_accuracy: 0.4608 - 907ms/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.6058 - accuracy: 0.6572 - val_loss: 0.7751 - val_accuracy: 0.4669 - 898ms/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.6072 - accuracy: 0.6657 - val_loss: 0.7445 - val_accuracy: 0.4657 - 917ms/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.6075 - accuracy: 0.6532 - val_loss: 0.7737 - val_accuracy: 0.4657 - 899ms/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.5934 - accuracy: 0.6740 - val_loss: 0.8078 - val_accuracy: 0.4669 - 905ms/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.6099 - accuracy: 0.6645 - val_loss: 0.7254 - val_accuracy: 0.4657 - 883ms/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.6059 - accuracy: 0.6679 - val_loss: 0.7604 - val_accuracy: 0.4681 - 892ms/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.6048 - accuracy: 0.6670 - val_loss: 0.7875 - val_accuracy: 0.4694 - 891ms/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.6117 - accuracy: 0.6667 - val_loss: 0.7167 - val_accuracy: 0.4657 - 885ms/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.5896 - accuracy: 0.6759 - val_loss: 0.7152 - val_accuracy: 0.4645 - 880ms/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.5968 - accuracy: 0.6780 - val_loss: 0.7363 - val_accuracy: 0.4657 - 905ms/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.5960 - accuracy: 0.6703 - val_loss: 0.7656 - val_accuracy: 0.4657 - 936ms/epoch - 5ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.6030 - accuracy: 0.6664 - val_loss: 0.7671 - val_accuracy: 0.4681 - 890ms/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.6070 - accuracy: 0.6612 - val_loss: 0.7355 - val_accuracy: 0.4669 - 870ms/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.5972 - accuracy: 0.6725 - val_loss: 0.7291 - val_accuracy: 0.4681 - 926ms/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.6074 - accuracy: 0.6587 - val_loss: 0.7333 - val_accuracy: 0.4681 - 926ms/epoch - 5ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.6001 - accuracy: 0.6700 - val_loss: 0.7421 - val_accuracy: 0.4657 - 890ms/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.5978 - accuracy: 0.6682 - val_loss: 0.7175 - val_accuracy: 0.4669 - 919ms/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.5934 - accuracy: 0.6691 - val_loss: 0.7499 - val_accuracy: 0.4681 - 889ms/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.6046 - accuracy: 0.6636 - val_loss: 0.7814 - val_accuracy: 0.4694 - 906ms/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.6024 - accuracy: 0.6722 - val_loss: 0.7793 - val_accuracy: 0.4681 - 900ms/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.5962 - accuracy: 0.6746 - val_loss: 0.8497 - val_accuracy: 0.4681 - 922ms/epoch - 5ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.6073 - accuracy: 0.6605 - val_loss: 0.7668 - val_accuracy: 0.4681 - 911ms/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.5980 - accuracy: 0.6740 - val_loss: 0.8327 - val_accuracy: 0.4694 - 909ms/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.5929 - accuracy: 0.6795 - val_loss: 0.7845 - val_accuracy: 0.4669 - 870ms/epoch - 4ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 4077 4078 4079]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   3    6   20   22   31   45   47   51   52   61   62   63   70   78\n",
      "   79   84   90   97  100  101  105  108  113  114  120  122  130  134\n",
      "  135  138  145  148  150  151  152  170  176  178  180  183  185  186\n",
      "  189  194  196  198  205  206  207  218  225  227  230  231  239  247\n",
      "  249  255  256  260  263  268  274  280  281  290  298  306  308  313\n",
      "  320  326  329  334  337  338  345  349  357  359  363  366  380  411\n",
      "  412  414  417  421  427  429  431  435  438  442  444  446  454  460\n",
      "  463  468  471  481  491  493  501  502  503  506  509  515  532  536\n",
      "  539  563  569  573  585  587  588  589  594  608  625  626  627  628\n",
      "  638  640  643  650  652  654  656  661  667  674  678  680  682  688\n",
      "  689  691  696  700  711  716  722  723  728  729  735  737  744  749\n",
      "  751  753  771  773  776  779  782  783  788  800  806  813  815  822\n",
      "  823  828  841  845  852  855  863  865  872  873  880  881  884  887\n",
      "  894  895  900  902  903  908  919  931  933  936  951  954  959  961\n",
      "  962  970  972  980  981  985  986  987  989  995 1011 1022 1026 1029\n",
      " 1030 1031 1033 1035 1036 1037 1038 1041 1046 1050 1067 1073 1083 1085\n",
      " 1086 1096 1098 1101 1107 1115 1117 1119 1124 1131 1132 1140 1141 1159\n",
      " 1168 1169 1171 1173 1174 1176 1180 1183 1184 1190 1191 1197 1199 1203\n",
      " 1218 1222 1224 1232 1234 1236 1238 1239 1243 1246 1254 1255 1262 1265\n",
      " 1272 1278 1283 1284 1288 1292 1301 1303 1324 1325 1332 1335 1340 1344\n",
      " 1352 1353 1357 1363 1364 1366 1370 1379 1395 1400 1401 1409 1410 1414\n",
      " 1424 1428 1430 1441 1442 1443 1444 1446 1453 1456 1458 1461 1466 1471\n",
      " 1473 1481 1486 1500 1506 1509 1512 1516 1519 1521 1533 1535 1540 1567\n",
      " 1573 1578 1588 1593 1595 1596 1599 1605 1610 1617 1618 1624 1637 1645\n",
      " 1650 1651 1653 1659 1666 1675 1677 1680 1685 1686 1689 1692 1697 1710\n",
      " 1719 1729 1733 1740 1745 1748 1749 1751 1755 1759 1768 1773 1783 1795\n",
      " 1796 1798 1799 1800 1806 1807 1809 1813 1816 1820 1823 1824 1827 1831\n",
      " 1834 1837 1847 1855 1858 1861 1862 1868 1871 1876 1878 1879 1881 1889\n",
      " 1890 1896 1898 1901 1921 1925 1927 1928 1929 1933 1940 1947 1956 1959\n",
      " 1960 1967 1970 1971 1975 1976 1977 1998 2000 2001 2002 2008 2009 2012\n",
      " 2021 2027 2028 2029 2031 2032 2040 2045 2048 2052 2053 2055 2059 2062\n",
      " 2066 2070 2076 2086 2087 2103 2104 2109 2112 2114 2118 2128 2130 2135\n",
      " 2136 2148 2150 2156 2160 2163 2171 2172 2177 2181 2182 2183 2186 2187\n",
      " 2197 2199 2205 2207 2211 2212 2214 2219 2225 2232 2235 2238 2241 2243\n",
      " 2245 2246 2250 2252 2256 2257 2263 2265 2268 2271 2281 2282 2287 2291\n",
      " 2292 2303 2309 2356 2358 2361 2365 2369 2379 2394 2395 2399 2400 2410\n",
      " 2425 2426 2434 2435 2442 2446 2449 2452 2458 2463 2472 2476 2480 2489\n",
      " 2493 2494 2495 2496 2498 2505 2506 2507 2515 2516 2517 2524 2529 2532\n",
      " 2540 2542 2546 2547 2550 2554 2569 2570 2576 2577 2579 2602 2607 2610\n",
      " 2615 2618 2624 2626 2627 2628 2629 2630 2639 2643 2646 2648 2651 2656\n",
      " 2659 2687 2702 2705 2706 2713 2717 2719 2734 2735 2737 2745 2758 2761\n",
      " 2782 2787 2795 2796 2799 2806 2815 2823 2824 2832 2835 2848 2853 2854\n",
      " 2862 2864 2867 2875 2877 2879 2880 2893 2895 2899 2900 2906 2913 2919\n",
      " 2921 2927 2930 2941 2943 2944 2954 2957 2965 2968 2971 2975 2977 2982\n",
      " 2985 2992 3009 3012 3015 3023 3027 3035 3036 3043 3044 3048 3052 3053\n",
      " 3063 3069 3070 3076 3082 3084 3089 3094 3102 3105 3109 3111 3127 3128\n",
      " 3129 3141 3150 3151 3154 3157 3164 3166 3169 3175 3176 3191 3194 3206\n",
      " 3219 3224 3230 3235 3237 3238 3245 3249 3250 3251 3252 3256 3259 3268\n",
      " 3271 3272 3276 3280 3283 3292 3301 3311 3314 3318 3321 3322 3323 3335\n",
      " 3337 3338 3341 3356 3357 3359 3362 3376 3379 3385 3390 3400 3401 3404\n",
      " 3409 3412 3426 3427 3428 3429 3432 3439 3445 3451 3462 3464 3469 3471\n",
      " 3476 3484 3504 3520 3528 3533 3537 3538 3547 3552 3561 3568 3572 3582\n",
      " 3594 3600 3607 3622 3623 3624 3625 3639 3645 3646 3651 3672 3677 3681\n",
      " 3696 3707 3712 3715 3716 3717 3719 3724 3730 3735 3737 3738 3756 3761\n",
      " 3764 3765 3766 3772 3775 3783 3789 3790 3791 3797 3800 3802 3806 3815\n",
      " 3821 3824 3826 3837 3839 3846 3853 3856 3860 3861 3864 3869 3889 3897\n",
      " 3899 3902 3903 3907 3917 3921 3925 3937 3938 3942 3953 3956 3969 3972\n",
      " 3977 3980 3990 3998 4003 4005 4007 4012 4016 4023 4030 4039 4043 4050\n",
      " 4058 4061 4064 4069]\n",
      "Number of samples for test set: 816\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:37:35.345829: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_314/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6965 - accuracy: 0.4997 - val_loss: 0.6940 - val_accuracy: 0.4902 - 3s/epoch - 12ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6935 - accuracy: 0.5046 - val_loss: 0.6942 - val_accuracy: 0.4902 - 915ms/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6911 - accuracy: 0.5245 - val_loss: 0.6939 - val_accuracy: 0.4939 - 916ms/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6910 - accuracy: 0.5116 - val_loss: 0.6947 - val_accuracy: 0.4914 - 908ms/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6902 - accuracy: 0.5279 - val_loss: 0.6954 - val_accuracy: 0.4890 - 900ms/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6889 - accuracy: 0.5493 - val_loss: 0.6938 - val_accuracy: 0.4926 - 875ms/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6821 - accuracy: 0.5613 - val_loss: 0.6938 - val_accuracy: 0.4951 - 881ms/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6827 - accuracy: 0.5509 - val_loss: 0.6907 - val_accuracy: 0.5147 - 848ms/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6782 - accuracy: 0.5689 - val_loss: 0.6917 - val_accuracy: 0.5404 - 871ms/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.6798 - accuracy: 0.5591 - val_loss: 0.6906 - val_accuracy: 0.5502 - 895ms/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6757 - accuracy: 0.5674 - val_loss: 0.6908 - val_accuracy: 0.5098 - 895ms/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.6751 - accuracy: 0.5723 - val_loss: 0.6912 - val_accuracy: 0.5147 - 898ms/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.6749 - accuracy: 0.5714 - val_loss: 0.6905 - val_accuracy: 0.5159 - 916ms/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.6723 - accuracy: 0.5766 - val_loss: 0.6905 - val_accuracy: 0.5502 - 917ms/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.6727 - accuracy: 0.5726 - val_loss: 0.6895 - val_accuracy: 0.5184 - 919ms/epoch - 5ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.6760 - accuracy: 0.5797 - val_loss: 0.6896 - val_accuracy: 0.5196 - 916ms/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.6723 - accuracy: 0.5683 - val_loss: 0.6916 - val_accuracy: 0.5123 - 908ms/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.6706 - accuracy: 0.5928 - val_loss: 0.6961 - val_accuracy: 0.5110 - 904ms/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.6671 - accuracy: 0.5916 - val_loss: 0.7054 - val_accuracy: 0.5074 - 882ms/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.6660 - accuracy: 0.5879 - val_loss: 0.6974 - val_accuracy: 0.5110 - 882ms/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.6678 - accuracy: 0.5784 - val_loss: 0.7006 - val_accuracy: 0.5110 - 866ms/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.6701 - accuracy: 0.5717 - val_loss: 0.7037 - val_accuracy: 0.5110 - 883ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.6679 - accuracy: 0.5781 - val_loss: 0.6960 - val_accuracy: 0.5135 - 895ms/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.6684 - accuracy: 0.5843 - val_loss: 0.6987 - val_accuracy: 0.5123 - 895ms/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.6684 - accuracy: 0.5818 - val_loss: 0.7022 - val_accuracy: 0.5123 - 891ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.6622 - accuracy: 0.6002 - val_loss: 0.6992 - val_accuracy: 0.5135 - 912ms/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.6644 - accuracy: 0.5882 - val_loss: 0.6937 - val_accuracy: 0.5110 - 869ms/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.6633 - accuracy: 0.5934 - val_loss: 0.6986 - val_accuracy: 0.5123 - 887ms/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.6590 - accuracy: 0.6020 - val_loss: 0.7161 - val_accuracy: 0.5123 - 861ms/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.6624 - accuracy: 0.5934 - val_loss: 0.6901 - val_accuracy: 0.5123 - 908ms/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.6580 - accuracy: 0.6054 - val_loss: 0.6986 - val_accuracy: 0.5086 - 900ms/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.6664 - accuracy: 0.5833 - val_loss: 0.6976 - val_accuracy: 0.5123 - 902ms/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.6601 - accuracy: 0.5999 - val_loss: 0.6987 - val_accuracy: 0.5098 - 900ms/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.6574 - accuracy: 0.6103 - val_loss: 0.7012 - val_accuracy: 0.5098 - 886ms/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.6540 - accuracy: 0.6124 - val_loss: 0.7156 - val_accuracy: 0.5098 - 883ms/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.6592 - accuracy: 0.6091 - val_loss: 0.6944 - val_accuracy: 0.5110 - 891ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.6546 - accuracy: 0.6127 - val_loss: 0.6996 - val_accuracy: 0.5098 - 894ms/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.6523 - accuracy: 0.5959 - val_loss: 0.7000 - val_accuracy: 0.5123 - 922ms/epoch - 5ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.6588 - accuracy: 0.6042 - val_loss: 0.7026 - val_accuracy: 0.5098 - 899ms/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.6494 - accuracy: 0.6198 - val_loss: 0.7152 - val_accuracy: 0.5098 - 883ms/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.6562 - accuracy: 0.5983 - val_loss: 0.7127 - val_accuracy: 0.5098 - 896ms/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.6534 - accuracy: 0.6152 - val_loss: 0.7058 - val_accuracy: 0.5098 - 845ms/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.6502 - accuracy: 0.6081 - val_loss: 0.7304 - val_accuracy: 0.5098 - 858ms/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.6483 - accuracy: 0.6149 - val_loss: 0.7147 - val_accuracy: 0.5098 - 883ms/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.6513 - accuracy: 0.6195 - val_loss: 0.7106 - val_accuracy: 0.5110 - 883ms/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.6544 - accuracy: 0.6085 - val_loss: 0.7000 - val_accuracy: 0.5098 - 869ms/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.6491 - accuracy: 0.6143 - val_loss: 0.7274 - val_accuracy: 0.5086 - 893ms/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.6469 - accuracy: 0.6121 - val_loss: 0.7077 - val_accuracy: 0.5123 - 920ms/epoch - 5ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.6548 - accuracy: 0.6106 - val_loss: 0.6984 - val_accuracy: 0.5123 - 898ms/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.6451 - accuracy: 0.6213 - val_loss: 0.7146 - val_accuracy: 0.5123 - 899ms/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.6488 - accuracy: 0.6094 - val_loss: 0.7174 - val_accuracy: 0.5110 - 898ms/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.6411 - accuracy: 0.6219 - val_loss: 0.7274 - val_accuracy: 0.5110 - 896ms/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.6436 - accuracy: 0.6161 - val_loss: 0.6956 - val_accuracy: 0.5123 - 895ms/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.6480 - accuracy: 0.6262 - val_loss: 0.7105 - val_accuracy: 0.5110 - 901ms/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.6496 - accuracy: 0.6094 - val_loss: 0.7358 - val_accuracy: 0.5098 - 896ms/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.6436 - accuracy: 0.6192 - val_loss: 0.7585 - val_accuracy: 0.5098 - 889ms/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.6372 - accuracy: 0.6189 - val_loss: 0.7206 - val_accuracy: 0.5098 - 921ms/epoch - 5ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.6399 - accuracy: 0.6268 - val_loss: 0.7153 - val_accuracy: 0.5110 - 918ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.6482 - accuracy: 0.6210 - val_loss: 0.7309 - val_accuracy: 0.5110 - 881ms/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.6374 - accuracy: 0.6213 - val_loss: 0.7390 - val_accuracy: 0.5110 - 856ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.6409 - accuracy: 0.6164 - val_loss: 0.7715 - val_accuracy: 0.5098 - 869ms/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.6406 - accuracy: 0.6238 - val_loss: 0.7403 - val_accuracy: 0.5098 - 887ms/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.6427 - accuracy: 0.6164 - val_loss: 0.7791 - val_accuracy: 0.5098 - 890ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.6378 - accuracy: 0.6195 - val_loss: 0.7753 - val_accuracy: 0.5098 - 914ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.6353 - accuracy: 0.6345 - val_loss: 0.7889 - val_accuracy: 0.5098 - 896ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.6441 - accuracy: 0.6232 - val_loss: 0.8084 - val_accuracy: 0.5110 - 914ms/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.6358 - accuracy: 0.6394 - val_loss: 0.8371 - val_accuracy: 0.5110 - 874ms/epoch - 4ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.6380 - accuracy: 0.6376 - val_loss: 0.8168 - val_accuracy: 0.5098 - 909ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.6368 - accuracy: 0.6293 - val_loss: 0.7855 - val_accuracy: 0.5110 - 891ms/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.6393 - accuracy: 0.6281 - val_loss: 0.7586 - val_accuracy: 0.5110 - 885ms/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.6363 - accuracy: 0.6204 - val_loss: 0.7884 - val_accuracy: 0.5110 - 893ms/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.6312 - accuracy: 0.6394 - val_loss: 0.7942 - val_accuracy: 0.5098 - 906ms/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.6401 - accuracy: 0.6369 - val_loss: 0.7960 - val_accuracy: 0.5110 - 891ms/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.6410 - accuracy: 0.6388 - val_loss: 0.7338 - val_accuracy: 0.5123 - 934ms/epoch - 5ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.6344 - accuracy: 0.6302 - val_loss: 0.7276 - val_accuracy: 0.5110 - 909ms/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.6388 - accuracy: 0.6247 - val_loss: 0.7612 - val_accuracy: 0.5110 - 898ms/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.6364 - accuracy: 0.6275 - val_loss: 0.7960 - val_accuracy: 0.5110 - 920ms/epoch - 5ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.6361 - accuracy: 0.6271 - val_loss: 0.7677 - val_accuracy: 0.5098 - 865ms/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.6379 - accuracy: 0.6388 - val_loss: 0.7825 - val_accuracy: 0.5110 - 893ms/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.6339 - accuracy: 0.6354 - val_loss: 0.8573 - val_accuracy: 0.5098 - 880ms/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.6359 - accuracy: 0.6293 - val_loss: 0.8234 - val_accuracy: 0.5110 - 898ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.6352 - accuracy: 0.6250 - val_loss: 0.8094 - val_accuracy: 0.5110 - 891ms/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.6354 - accuracy: 0.6293 - val_loss: 0.7800 - val_accuracy: 0.5098 - 911ms/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.6370 - accuracy: 0.6308 - val_loss: 0.7704 - val_accuracy: 0.5110 - 900ms/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.6309 - accuracy: 0.6437 - val_loss: 0.7698 - val_accuracy: 0.5110 - 882ms/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.6267 - accuracy: 0.6360 - val_loss: 0.8289 - val_accuracy: 0.5098 - 899ms/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.6388 - accuracy: 0.6299 - val_loss: 0.7648 - val_accuracy: 0.5110 - 919ms/epoch - 5ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.6334 - accuracy: 0.6360 - val_loss: 0.7873 - val_accuracy: 0.5098 - 916ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.6368 - accuracy: 0.6290 - val_loss: 0.8410 - val_accuracy: 0.5098 - 893ms/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.6335 - accuracy: 0.6348 - val_loss: 0.7828 - val_accuracy: 0.5110 - 887ms/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.6322 - accuracy: 0.6394 - val_loss: 0.7821 - val_accuracy: 0.5086 - 890ms/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.6356 - accuracy: 0.6336 - val_loss: 0.7637 - val_accuracy: 0.5098 - 862ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.6325 - accuracy: 0.6385 - val_loss: 0.8001 - val_accuracy: 0.5110 - 867ms/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.6410 - accuracy: 0.6287 - val_loss: 0.7660 - val_accuracy: 0.5110 - 851ms/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.6332 - accuracy: 0.6345 - val_loss: 0.7787 - val_accuracy: 0.5098 - 905ms/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.6309 - accuracy: 0.6425 - val_loss: 0.7780 - val_accuracy: 0.5098 - 912ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.6341 - accuracy: 0.6400 - val_loss: 0.7217 - val_accuracy: 0.5110 - 842ms/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.6260 - accuracy: 0.6351 - val_loss: 0.7528 - val_accuracy: 0.5123 - 897ms/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.6365 - accuracy: 0.6287 - val_loss: 0.7627 - val_accuracy: 0.5110 - 894ms/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.6325 - accuracy: 0.6302 - val_loss: 0.7968 - val_accuracy: 0.5110 - 876ms/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.6193 - accuracy: 0.6578 - val_loss: 0.8154 - val_accuracy: 0.5110 - 889ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.6291 - accuracy: 0.6489 - val_loss: 0.8676 - val_accuracy: 0.5123 - 854ms/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.6312 - accuracy: 0.6351 - val_loss: 0.8207 - val_accuracy: 0.5110 - 853ms/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.6222 - accuracy: 0.6373 - val_loss: 0.8725 - val_accuracy: 0.5098 - 813ms/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.6304 - accuracy: 0.6320 - val_loss: 0.8576 - val_accuracy: 0.5110 - 896ms/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.6204 - accuracy: 0.6495 - val_loss: 0.8553 - val_accuracy: 0.5110 - 916ms/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.6262 - accuracy: 0.6391 - val_loss: 0.8570 - val_accuracy: 0.5110 - 926ms/epoch - 5ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.6241 - accuracy: 0.6455 - val_loss: 0.8075 - val_accuracy: 0.5110 - 904ms/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.6334 - accuracy: 0.6373 - val_loss: 0.7728 - val_accuracy: 0.5098 - 895ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.6253 - accuracy: 0.6446 - val_loss: 0.7428 - val_accuracy: 0.5086 - 914ms/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.6260 - accuracy: 0.6425 - val_loss: 0.7958 - val_accuracy: 0.5098 - 876ms/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.6276 - accuracy: 0.6333 - val_loss: 0.7855 - val_accuracy: 0.5110 - 839ms/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.6177 - accuracy: 0.6464 - val_loss: 0.7739 - val_accuracy: 0.5110 - 897ms/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.6225 - accuracy: 0.6477 - val_loss: 0.8063 - val_accuracy: 0.5110 - 887ms/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.6277 - accuracy: 0.6354 - val_loss: 0.7544 - val_accuracy: 0.5110 - 896ms/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.6285 - accuracy: 0.6369 - val_loss: 0.7739 - val_accuracy: 0.5110 - 880ms/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.6238 - accuracy: 0.6474 - val_loss: 0.7428 - val_accuracy: 0.5110 - 907ms/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.6238 - accuracy: 0.6363 - val_loss: 0.7825 - val_accuracy: 0.5110 - 900ms/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.6260 - accuracy: 0.6385 - val_loss: 0.7664 - val_accuracy: 0.5123 - 919ms/epoch - 5ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.6244 - accuracy: 0.6443 - val_loss: 0.7561 - val_accuracy: 0.5110 - 921ms/epoch - 5ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.6254 - accuracy: 0.6403 - val_loss: 0.7908 - val_accuracy: 0.5110 - 899ms/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.6204 - accuracy: 0.6464 - val_loss: 0.8215 - val_accuracy: 0.5098 - 903ms/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.6253 - accuracy: 0.6474 - val_loss: 0.8613 - val_accuracy: 0.5110 - 905ms/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.6264 - accuracy: 0.6366 - val_loss: 0.8182 - val_accuracy: 0.5110 - 911ms/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.6281 - accuracy: 0.6437 - val_loss: 0.8637 - val_accuracy: 0.5110 - 895ms/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.6351 - accuracy: 0.6302 - val_loss: 0.7605 - val_accuracy: 0.5098 - 869ms/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.6231 - accuracy: 0.6422 - val_loss: 0.8114 - val_accuracy: 0.5098 - 893ms/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.6302 - accuracy: 0.6366 - val_loss: 0.8377 - val_accuracy: 0.5098 - 904ms/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.6150 - accuracy: 0.6621 - val_loss: 0.8108 - val_accuracy: 0.5110 - 874ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.6260 - accuracy: 0.6388 - val_loss: 0.8110 - val_accuracy: 0.5110 - 852ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.6243 - accuracy: 0.6406 - val_loss: 0.7810 - val_accuracy: 0.5098 - 882ms/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.6241 - accuracy: 0.6440 - val_loss: 0.8102 - val_accuracy: 0.5110 - 851ms/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.6231 - accuracy: 0.6517 - val_loss: 0.8414 - val_accuracy: 0.5098 - 875ms/epoch - 4ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.6116 - accuracy: 0.6636 - val_loss: 0.8696 - val_accuracy: 0.5110 - 851ms/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.6180 - accuracy: 0.6477 - val_loss: 0.8146 - val_accuracy: 0.5098 - 848ms/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.6205 - accuracy: 0.6513 - val_loss: 0.8722 - val_accuracy: 0.5110 - 922ms/epoch - 5ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.6218 - accuracy: 0.6431 - val_loss: 0.7901 - val_accuracy: 0.5098 - 890ms/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.6194 - accuracy: 0.6477 - val_loss: 0.8197 - val_accuracy: 0.5098 - 913ms/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.6177 - accuracy: 0.6480 - val_loss: 0.8190 - val_accuracy: 0.5098 - 891ms/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.6193 - accuracy: 0.6412 - val_loss: 0.8618 - val_accuracy: 0.5110 - 902ms/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.6162 - accuracy: 0.6523 - val_loss: 0.8924 - val_accuracy: 0.5110 - 911ms/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.6198 - accuracy: 0.6464 - val_loss: 0.9680 - val_accuracy: 0.5110 - 900ms/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.6218 - accuracy: 0.6498 - val_loss: 0.8252 - val_accuracy: 0.5110 - 894ms/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.6173 - accuracy: 0.6602 - val_loss: 0.8677 - val_accuracy: 0.5110 - 902ms/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.6235 - accuracy: 0.6458 - val_loss: 0.7892 - val_accuracy: 0.5098 - 890ms/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.6252 - accuracy: 0.6446 - val_loss: 0.8517 - val_accuracy: 0.5110 - 893ms/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.6143 - accuracy: 0.6578 - val_loss: 0.9132 - val_accuracy: 0.5123 - 899ms/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.6225 - accuracy: 0.6492 - val_loss: 0.8801 - val_accuracy: 0.5110 - 877ms/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.6209 - accuracy: 0.6550 - val_loss: 0.9429 - val_accuracy: 0.5110 - 877ms/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.6222 - accuracy: 0.6520 - val_loss: 0.9007 - val_accuracy: 0.5110 - 886ms/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.6202 - accuracy: 0.6431 - val_loss: 1.0209 - val_accuracy: 0.5110 - 875ms/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.6231 - accuracy: 0.6461 - val_loss: 0.9099 - val_accuracy: 0.5110 - 866ms/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.6245 - accuracy: 0.6357 - val_loss: 0.9163 - val_accuracy: 0.5098 - 881ms/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.6212 - accuracy: 0.6495 - val_loss: 0.9124 - val_accuracy: 0.5110 - 926ms/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.6167 - accuracy: 0.6507 - val_loss: 0.8875 - val_accuracy: 0.5086 - 870ms/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.6164 - accuracy: 0.6529 - val_loss: 0.8603 - val_accuracy: 0.5086 - 906ms/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.6117 - accuracy: 0.6581 - val_loss: 0.9197 - val_accuracy: 0.5110 - 889ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.6171 - accuracy: 0.6559 - val_loss: 0.8569 - val_accuracy: 0.5086 - 887ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.6218 - accuracy: 0.6468 - val_loss: 0.8952 - val_accuracy: 0.5110 - 898ms/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.6164 - accuracy: 0.6480 - val_loss: 0.9087 - val_accuracy: 0.5086 - 877ms/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.6131 - accuracy: 0.6538 - val_loss: 0.9168 - val_accuracy: 0.5086 - 885ms/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.6232 - accuracy: 0.6351 - val_loss: 0.8642 - val_accuracy: 0.5110 - 904ms/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.6216 - accuracy: 0.6455 - val_loss: 0.9032 - val_accuracy: 0.5110 - 886ms/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.6291 - accuracy: 0.6351 - val_loss: 0.9490 - val_accuracy: 0.5110 - 888ms/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.6108 - accuracy: 0.6529 - val_loss: 0.8769 - val_accuracy: 0.5086 - 901ms/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.6124 - accuracy: 0.6517 - val_loss: 0.9261 - val_accuracy: 0.5110 - 886ms/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.6093 - accuracy: 0.6657 - val_loss: 0.9170 - val_accuracy: 0.5123 - 887ms/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.6097 - accuracy: 0.6523 - val_loss: 0.9372 - val_accuracy: 0.5098 - 925ms/epoch - 5ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.6164 - accuracy: 0.6535 - val_loss: 0.8580 - val_accuracy: 0.5110 - 843ms/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.6128 - accuracy: 0.6547 - val_loss: 0.7779 - val_accuracy: 0.5086 - 893ms/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.6142 - accuracy: 0.6569 - val_loss: 0.8695 - val_accuracy: 0.5086 - 905ms/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.6109 - accuracy: 0.6507 - val_loss: 0.8869 - val_accuracy: 0.5110 - 881ms/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.6189 - accuracy: 0.6532 - val_loss: 0.8702 - val_accuracy: 0.5123 - 911ms/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.6129 - accuracy: 0.6593 - val_loss: 0.9119 - val_accuracy: 0.5123 - 871ms/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.6158 - accuracy: 0.6486 - val_loss: 0.9357 - val_accuracy: 0.5123 - 907ms/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.6177 - accuracy: 0.6523 - val_loss: 0.8467 - val_accuracy: 0.5110 - 911ms/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.6216 - accuracy: 0.6550 - val_loss: 0.8983 - val_accuracy: 0.5098 - 910ms/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.6178 - accuracy: 0.6538 - val_loss: 1.0183 - val_accuracy: 0.5123 - 900ms/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.6100 - accuracy: 0.6605 - val_loss: 1.0044 - val_accuracy: 0.5123 - 907ms/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.6216 - accuracy: 0.6461 - val_loss: 0.9595 - val_accuracy: 0.5098 - 900ms/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.6169 - accuracy: 0.6532 - val_loss: 0.9737 - val_accuracy: 0.5110 - 906ms/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.6197 - accuracy: 0.6422 - val_loss: 0.9028 - val_accuracy: 0.5110 - 870ms/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.6176 - accuracy: 0.6498 - val_loss: 0.9072 - val_accuracy: 0.5110 - 878ms/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.6184 - accuracy: 0.6449 - val_loss: 0.8705 - val_accuracy: 0.5110 - 873ms/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.6149 - accuracy: 0.6544 - val_loss: 0.8682 - val_accuracy: 0.5110 - 911ms/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.6203 - accuracy: 0.6517 - val_loss: 0.8927 - val_accuracy: 0.5110 - 903ms/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.6186 - accuracy: 0.6431 - val_loss: 0.9279 - val_accuracy: 0.5110 - 933ms/epoch - 5ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.6147 - accuracy: 0.6593 - val_loss: 0.9182 - val_accuracy: 0.5110 - 908ms/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.6137 - accuracy: 0.6523 - val_loss: 1.0088 - val_accuracy: 0.5110 - 908ms/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.6152 - accuracy: 0.6593 - val_loss: 0.9261 - val_accuracy: 0.5110 - 906ms/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.6225 - accuracy: 0.6434 - val_loss: 1.0490 - val_accuracy: 0.5110 - 903ms/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.6094 - accuracy: 0.6535 - val_loss: 0.8985 - val_accuracy: 0.5110 - 907ms/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.6165 - accuracy: 0.6566 - val_loss: 0.9328 - val_accuracy: 0.5110 - 908ms/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.6102 - accuracy: 0.6615 - val_loss: 0.8977 - val_accuracy: 0.5110 - 896ms/epoch - 4ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.6158 - accuracy: 0.6578 - val_loss: 0.9443 - val_accuracy: 0.5110 - 883ms/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.6047 - accuracy: 0.6722 - val_loss: 0.8853 - val_accuracy: 0.5098 - 892ms/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.6108 - accuracy: 0.6679 - val_loss: 1.0091 - val_accuracy: 0.5110 - 910ms/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.6188 - accuracy: 0.6544 - val_loss: 0.9031 - val_accuracy: 0.5110 - 898ms/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.6118 - accuracy: 0.6474 - val_loss: 0.8513 - val_accuracy: 0.5110 - 900ms/epoch - 4ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.6132 - accuracy: 0.6517 - val_loss: 0.9510 - val_accuracy: 0.5110 - 887ms/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.6184 - accuracy: 0.6440 - val_loss: 0.8725 - val_accuracy: 0.5098 - 844ms/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.6148 - accuracy: 0.6486 - val_loss: 0.8788 - val_accuracy: 0.5110 - 883ms/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.6125 - accuracy: 0.6633 - val_loss: 0.9268 - val_accuracy: 0.5110 - 863ms/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.6077 - accuracy: 0.6587 - val_loss: 0.9698 - val_accuracy: 0.5110 - 872ms/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.6159 - accuracy: 0.6608 - val_loss: 1.0121 - val_accuracy: 0.5123 - 878ms/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.6086 - accuracy: 0.6556 - val_loss: 1.0823 - val_accuracy: 0.5098 - 873ms/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.6122 - accuracy: 0.6544 - val_loss: 0.9827 - val_accuracy: 0.5110 - 908ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.6234 - accuracy: 0.6382 - val_loss: 0.9027 - val_accuracy: 0.5098 - 912ms/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.6034 - accuracy: 0.6532 - val_loss: 1.0374 - val_accuracy: 0.5110 - 907ms/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.6171 - accuracy: 0.6486 - val_loss: 1.0314 - val_accuracy: 0.5110 - 906ms/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.6127 - accuracy: 0.6483 - val_loss: 1.0344 - val_accuracy: 0.5110 - 903ms/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.6144 - accuracy: 0.6627 - val_loss: 1.0528 - val_accuracy: 0.5110 - 893ms/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.6102 - accuracy: 0.6529 - val_loss: 1.0362 - val_accuracy: 0.5110 - 914ms/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.6164 - accuracy: 0.6406 - val_loss: 0.9015 - val_accuracy: 0.5110 - 911ms/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.6076 - accuracy: 0.6612 - val_loss: 1.0178 - val_accuracy: 0.5110 - 899ms/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.6083 - accuracy: 0.6645 - val_loss: 1.0229 - val_accuracy: 0.5110 - 912ms/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.6081 - accuracy: 0.6520 - val_loss: 1.0371 - val_accuracy: 0.5110 - 892ms/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.6098 - accuracy: 0.6593 - val_loss: 1.1221 - val_accuracy: 0.5110 - 908ms/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.6127 - accuracy: 0.6615 - val_loss: 1.0181 - val_accuracy: 0.5110 - 901ms/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.6150 - accuracy: 0.6529 - val_loss: 1.0355 - val_accuracy: 0.5110 - 903ms/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.6091 - accuracy: 0.6642 - val_loss: 0.9672 - val_accuracy: 0.5110 - 911ms/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.6059 - accuracy: 0.6743 - val_loss: 1.0865 - val_accuracy: 0.5110 - 902ms/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.6082 - accuracy: 0.6661 - val_loss: 1.0451 - val_accuracy: 0.5110 - 917ms/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.6093 - accuracy: 0.6587 - val_loss: 0.9431 - val_accuracy: 0.5110 - 908ms/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.6157 - accuracy: 0.6523 - val_loss: 0.9912 - val_accuracy: 0.5110 - 918ms/epoch - 5ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.6096 - accuracy: 0.6535 - val_loss: 1.0113 - val_accuracy: 0.5123 - 891ms/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.6090 - accuracy: 0.6556 - val_loss: 1.0387 - val_accuracy: 0.5110 - 897ms/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.6089 - accuracy: 0.6676 - val_loss: 1.0885 - val_accuracy: 0.5110 - 907ms/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.6202 - accuracy: 0.6464 - val_loss: 0.9735 - val_accuracy: 0.5110 - 898ms/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.6095 - accuracy: 0.6664 - val_loss: 0.9952 - val_accuracy: 0.5110 - 884ms/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.6180 - accuracy: 0.6556 - val_loss: 1.0066 - val_accuracy: 0.5110 - 896ms/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.6041 - accuracy: 0.6740 - val_loss: 0.9446 - val_accuracy: 0.5110 - 892ms/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.6029 - accuracy: 0.6630 - val_loss: 0.9729 - val_accuracy: 0.5123 - 904ms/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.6173 - accuracy: 0.6529 - val_loss: 0.9554 - val_accuracy: 0.5123 - 910ms/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.6074 - accuracy: 0.6599 - val_loss: 0.9534 - val_accuracy: 0.5110 - 923ms/epoch - 5ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.6069 - accuracy: 0.6673 - val_loss: 0.9481 - val_accuracy: 0.5110 - 895ms/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.6113 - accuracy: 0.6639 - val_loss: 0.8574 - val_accuracy: 0.5123 - 891ms/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.6088 - accuracy: 0.6566 - val_loss: 0.8677 - val_accuracy: 0.5098 - 905ms/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.6063 - accuracy: 0.6608 - val_loss: 0.8648 - val_accuracy: 0.5110 - 909ms/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.6143 - accuracy: 0.6602 - val_loss: 0.8871 - val_accuracy: 0.5110 - 901ms/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.6053 - accuracy: 0.6685 - val_loss: 1.0224 - val_accuracy: 0.5110 - 890ms/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.6067 - accuracy: 0.6654 - val_loss: 0.9655 - val_accuracy: 0.5123 - 884ms/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.6038 - accuracy: 0.6661 - val_loss: 1.0017 - val_accuracy: 0.5123 - 923ms/epoch - 5ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.6149 - accuracy: 0.6556 - val_loss: 1.0088 - val_accuracy: 0.5110 - 905ms/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.6076 - accuracy: 0.6676 - val_loss: 0.9072 - val_accuracy: 0.5110 - 907ms/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.6009 - accuracy: 0.6612 - val_loss: 0.9528 - val_accuracy: 0.5110 - 891ms/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.6107 - accuracy: 0.6627 - val_loss: 0.9810 - val_accuracy: 0.5110 - 916ms/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.6132 - accuracy: 0.6581 - val_loss: 0.9354 - val_accuracy: 0.5123 - 869ms/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.6118 - accuracy: 0.6639 - val_loss: 1.0252 - val_accuracy: 0.5110 - 894ms/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.6036 - accuracy: 0.6599 - val_loss: 0.9719 - val_accuracy: 0.5123 - 862ms/epoch - 4ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   1    2    3 ... 4076 4077 4078]\n",
      "Number of samples for train set: 3264\n",
      "Test index for this split: [   0    5    7    8   11   15   17   24   27   30   48   49   50   53\n",
      "   56   57   59   64   67   69   80   83   95   98  106  107  111  115\n",
      "  121  132  141  143  144  154  158  161  163  168  175  177  179  181\n",
      "  191  192  197  202  203  208  214  220  226  228  233  235  236  238\n",
      "  241  246  251  253  257  262  288  289  299  302  314  327  330  331\n",
      "  339  343  348  354  355  361  364  372  377  381  388  389  402  408\n",
      "  409  424  434  440  445  447  449  461  464  470  472  474  476  477\n",
      "  483  486  489  496  510  514  517  519  524  526  531  543  544  545\n",
      "  559  560  572  577  578  580  586  591  593  600  603  604  609  610\n",
      "  612  613  614  619  629  630  634  636  639  644  645  670  673  681\n",
      "  683  687  690  702  733  741  747  752  757  758  761  763  764  765\n",
      "  772  777  780  785  790  792  793  796  799  805  814  820  825  827\n",
      "  829  833  840  850  858  869  878  883  886  896  905  907  918  922\n",
      "  929  935  940  941  952  955  967  973  975  990  998  999 1004 1010\n",
      " 1024 1025 1027 1032 1034 1045 1048 1052 1053 1055 1056 1060 1062 1080\n",
      " 1099 1105 1106 1109 1110 1118 1122 1123 1129 1136 1137 1142 1144 1146\n",
      " 1148 1157 1167 1175 1178 1179 1185 1207 1208 1229 1230 1231 1244 1245\n",
      " 1249 1250 1251 1269 1277 1281 1285 1286 1287 1289 1305 1306 1309 1310\n",
      " 1315 1318 1322 1329 1330 1334 1338 1341 1349 1356 1358 1361 1368 1372\n",
      " 1374 1387 1394 1398 1415 1420 1425 1427 1431 1433 1437 1440 1452 1455\n",
      " 1459 1475 1477 1478 1480 1482 1488 1503 1507 1510 1511 1513 1515 1522\n",
      " 1525 1531 1537 1538 1539 1546 1551 1554 1563 1568 1572 1575 1576 1579\n",
      " 1580 1582 1583 1590 1591 1611 1619 1620 1621 1622 1630 1632 1642 1646\n",
      " 1654 1667 1669 1672 1674 1676 1687 1688 1694 1698 1699 1700 1712 1717\n",
      " 1742 1744 1747 1754 1756 1758 1765 1766 1772 1775 1776 1780 1784 1785\n",
      " 1789 1797 1814 1817 1821 1825 1832 1848 1852 1867 1874 1877 1892 1893\n",
      " 1894 1895 1900 1905 1906 1913 1914 1915 1920 1930 1931 1942 1944 1945\n",
      " 1949 1953 1958 1961 1964 1965 1966 1981 1986 1993 1997 1999 2007 2026\n",
      " 2049 2050 2080 2081 2082 2083 2088 2096 2106 2122 2126 2134 2139 2153\n",
      " 2159 2162 2165 2168 2169 2170 2173 2191 2198 2202 2208 2209 2215 2218\n",
      " 2233 2234 2240 2253 2255 2258 2260 2267 2269 2273 2274 2277 2284 2288\n",
      " 2293 2296 2298 2307 2310 2315 2316 2317 2319 2322 2329 2335 2342 2343\n",
      " 2345 2347 2351 2352 2353 2355 2374 2377 2382 2387 2389 2390 2393 2401\n",
      " 2402 2403 2407 2409 2413 2415 2416 2432 2433 2441 2445 2447 2461 2462\n",
      " 2467 2468 2471 2483 2485 2521 2523 2527 2530 2537 2539 2541 2543 2545\n",
      " 2549 2558 2559 2561 2575 2578 2586 2591 2594 2597 2601 2605 2608 2611\n",
      " 2616 2631 2632 2634 2636 2640 2644 2654 2660 2663 2668 2669 2676 2682\n",
      " 2684 2686 2694 2695 2699 2704 2708 2718 2720 2741 2742 2744 2748 2751\n",
      " 2752 2753 2754 2755 2766 2767 2770 2774 2778 2779 2783 2789 2790 2791\n",
      " 2797 2800 2801 2805 2807 2808 2810 2813 2817 2821 2822 2826 2829 2830\n",
      " 2831 2840 2841 2844 2865 2866 2870 2871 2884 2892 2901 2903 2904 2916\n",
      " 2924 2925 2929 2933 2934 2935 2936 2940 2945 2947 2948 2956 2962 2966\n",
      " 2967 2969 2970 2972 2973 2974 2979 2981 2983 2984 2988 2997 3001 3003\n",
      " 3008 3017 3020 3022 3024 3028 3050 3051 3060 3065 3066 3067 3092 3093\n",
      " 3106 3113 3122 3126 3134 3135 3136 3139 3145 3152 3153 3155 3156 3159\n",
      " 3161 3162 3168 3171 3179 3187 3201 3205 3209 3217 3223 3225 3231 3234\n",
      " 3239 3246 3247 3260 3261 3262 3265 3269 3270 3278 3279 3286 3289 3293\n",
      " 3297 3300 3303 3309 3310 3315 3325 3328 3329 3330 3331 3336 3342 3351\n",
      " 3352 3363 3367 3370 3372 3374 3375 3381 3387 3388 3392 3394 3397 3399\n",
      " 3402 3405 3408 3413 3424 3430 3437 3442 3456 3459 3460 3463 3467 3474\n",
      " 3483 3487 3491 3494 3500 3506 3514 3515 3519 3527 3532 3540 3541 3543\n",
      " 3555 3559 3566 3569 3578 3584 3585 3591 3592 3602 3606 3611 3612 3616\n",
      " 3617 3621 3626 3634 3637 3638 3642 3659 3664 3684 3687 3695 3701 3702\n",
      " 3710 3720 3722 3723 3725 3728 3731 3732 3747 3754 3755 3758 3770 3771\n",
      " 3773 3779 3785 3788 3792 3793 3794 3801 3805 3825 3830 3834 3836 3838\n",
      " 3840 3851 3866 3870 3872 3879 3886 3908 3912 3914 3916 3923 3928 3930\n",
      " 3935 3936 3945 3966 3967 3974 3976 3979 3981 3986 3992 3993 3996 4000\n",
      " 4013 4019 4028 4029 4033 4038 4045 4047 4048 4055 4056 4057 4067 4068\n",
      " 4071 4073 4074 4079]\n",
      "Number of samples for test set: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:41:22.232331: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_315/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 3s - loss: 0.6964 - accuracy: 0.4957 - val_loss: 0.6940 - val_accuracy: 0.4755 - 3s/epoch - 13ms/step\n",
      "Epoch 2/250\n",
      "204/204 - 1s - loss: 0.6914 - accuracy: 0.5233 - val_loss: 0.6944 - val_accuracy: 0.4767 - 897ms/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "204/204 - 1s - loss: 0.6915 - accuracy: 0.5270 - val_loss: 0.6934 - val_accuracy: 0.4828 - 877ms/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "204/204 - 1s - loss: 0.6876 - accuracy: 0.5383 - val_loss: 0.6937 - val_accuracy: 0.4816 - 872ms/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "204/204 - 1s - loss: 0.6878 - accuracy: 0.5309 - val_loss: 0.6934 - val_accuracy: 0.4963 - 880ms/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "204/204 - 1s - loss: 0.6845 - accuracy: 0.5478 - val_loss: 0.6938 - val_accuracy: 0.5196 - 885ms/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "204/204 - 1s - loss: 0.6827 - accuracy: 0.5561 - val_loss: 0.6921 - val_accuracy: 0.5208 - 895ms/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "204/204 - 1s - loss: 0.6844 - accuracy: 0.5573 - val_loss: 0.6942 - val_accuracy: 0.5233 - 877ms/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "204/204 - 1s - loss: 0.6775 - accuracy: 0.5545 - val_loss: 0.6952 - val_accuracy: 0.5282 - 881ms/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "204/204 - 1s - loss: 0.6788 - accuracy: 0.5597 - val_loss: 0.6940 - val_accuracy: 0.5196 - 910ms/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "204/204 - 1s - loss: 0.6792 - accuracy: 0.5588 - val_loss: 0.6987 - val_accuracy: 0.5233 - 902ms/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "204/204 - 1s - loss: 0.6724 - accuracy: 0.5763 - val_loss: 0.6963 - val_accuracy: 0.5208 - 889ms/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "204/204 - 1s - loss: 0.6708 - accuracy: 0.5708 - val_loss: 0.6951 - val_accuracy: 0.5221 - 889ms/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "204/204 - 1s - loss: 0.6728 - accuracy: 0.5643 - val_loss: 0.6961 - val_accuracy: 0.5208 - 915ms/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "204/204 - 1s - loss: 0.6721 - accuracy: 0.5778 - val_loss: 0.7057 - val_accuracy: 0.5221 - 887ms/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "204/204 - 1s - loss: 0.6723 - accuracy: 0.5680 - val_loss: 0.6976 - val_accuracy: 0.5233 - 848ms/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "204/204 - 1s - loss: 0.6687 - accuracy: 0.5763 - val_loss: 0.6968 - val_accuracy: 0.5196 - 892ms/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "204/204 - 1s - loss: 0.6670 - accuracy: 0.5830 - val_loss: 0.7031 - val_accuracy: 0.5233 - 933ms/epoch - 5ms/step\n",
      "Epoch 19/250\n",
      "204/204 - 1s - loss: 0.6650 - accuracy: 0.5827 - val_loss: 0.7010 - val_accuracy: 0.5208 - 882ms/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "204/204 - 1s - loss: 0.6678 - accuracy: 0.5760 - val_loss: 0.6944 - val_accuracy: 0.5233 - 886ms/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "204/204 - 1s - loss: 0.6650 - accuracy: 0.5867 - val_loss: 0.7010 - val_accuracy: 0.5196 - 917ms/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "204/204 - 1s - loss: 0.6613 - accuracy: 0.5885 - val_loss: 0.7011 - val_accuracy: 0.5221 - 919ms/epoch - 5ms/step\n",
      "Epoch 23/250\n",
      "204/204 - 1s - loss: 0.6572 - accuracy: 0.5977 - val_loss: 0.6985 - val_accuracy: 0.5208 - 921ms/epoch - 5ms/step\n",
      "Epoch 24/250\n",
      "204/204 - 1s - loss: 0.6589 - accuracy: 0.5938 - val_loss: 0.7005 - val_accuracy: 0.5208 - 904ms/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "204/204 - 1s - loss: 0.6593 - accuracy: 0.5953 - val_loss: 0.6950 - val_accuracy: 0.5380 - 904ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "204/204 - 1s - loss: 0.6583 - accuracy: 0.5925 - val_loss: 0.6955 - val_accuracy: 0.5233 - 890ms/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "204/204 - 1s - loss: 0.6552 - accuracy: 0.5980 - val_loss: 0.7004 - val_accuracy: 0.5221 - 908ms/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "204/204 - 1s - loss: 0.6555 - accuracy: 0.6005 - val_loss: 0.7020 - val_accuracy: 0.5196 - 910ms/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "204/204 - 1s - loss: 0.6545 - accuracy: 0.6029 - val_loss: 0.7355 - val_accuracy: 0.5221 - 885ms/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "204/204 - 1s - loss: 0.6542 - accuracy: 0.5999 - val_loss: 0.7343 - val_accuracy: 0.5221 - 918ms/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "204/204 - 1s - loss: 0.6521 - accuracy: 0.5974 - val_loss: 0.7385 - val_accuracy: 0.5221 - 896ms/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "204/204 - 1s - loss: 0.6569 - accuracy: 0.5980 - val_loss: 0.7174 - val_accuracy: 0.5208 - 888ms/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "204/204 - 1s - loss: 0.6536 - accuracy: 0.6060 - val_loss: 0.7230 - val_accuracy: 0.5221 - 884ms/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "204/204 - 1s - loss: 0.6536 - accuracy: 0.6002 - val_loss: 0.7214 - val_accuracy: 0.5221 - 869ms/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "204/204 - 1s - loss: 0.6474 - accuracy: 0.6063 - val_loss: 0.7191 - val_accuracy: 0.5233 - 856ms/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "204/204 - 1s - loss: 0.6441 - accuracy: 0.6173 - val_loss: 0.7513 - val_accuracy: 0.5221 - 915ms/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "204/204 - 1s - loss: 0.6454 - accuracy: 0.6054 - val_loss: 0.7395 - val_accuracy: 0.5233 - 889ms/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "204/204 - 1s - loss: 0.6484 - accuracy: 0.6149 - val_loss: 0.7379 - val_accuracy: 0.5233 - 877ms/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "204/204 - 1s - loss: 0.6496 - accuracy: 0.6026 - val_loss: 0.7548 - val_accuracy: 0.5221 - 899ms/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "204/204 - 1s - loss: 0.6484 - accuracy: 0.6081 - val_loss: 0.7201 - val_accuracy: 0.5221 - 904ms/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "204/204 - 1s - loss: 0.6490 - accuracy: 0.6124 - val_loss: 0.7123 - val_accuracy: 0.5196 - 922ms/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "204/204 - 1s - loss: 0.6514 - accuracy: 0.5993 - val_loss: 0.7027 - val_accuracy: 0.5184 - 901ms/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "204/204 - 1s - loss: 0.6485 - accuracy: 0.6131 - val_loss: 0.7155 - val_accuracy: 0.5184 - 895ms/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "204/204 - 1s - loss: 0.6456 - accuracy: 0.6026 - val_loss: 0.7099 - val_accuracy: 0.5208 - 885ms/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "204/204 - 1s - loss: 0.6469 - accuracy: 0.6124 - val_loss: 0.7010 - val_accuracy: 0.5184 - 877ms/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "204/204 - 1s - loss: 0.6494 - accuracy: 0.6155 - val_loss: 0.7154 - val_accuracy: 0.5196 - 872ms/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "204/204 - 1s - loss: 0.6461 - accuracy: 0.6265 - val_loss: 0.6985 - val_accuracy: 0.5184 - 886ms/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "204/204 - 1s - loss: 0.6378 - accuracy: 0.6320 - val_loss: 0.6972 - val_accuracy: 0.5159 - 889ms/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "204/204 - 1s - loss: 0.6392 - accuracy: 0.6189 - val_loss: 0.7129 - val_accuracy: 0.5208 - 884ms/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "204/204 - 1s - loss: 0.6379 - accuracy: 0.6259 - val_loss: 0.7245 - val_accuracy: 0.5208 - 915ms/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "204/204 - 1s - loss: 0.6424 - accuracy: 0.6204 - val_loss: 0.7312 - val_accuracy: 0.5221 - 921ms/epoch - 5ms/step\n",
      "Epoch 52/250\n",
      "204/204 - 1s - loss: 0.6386 - accuracy: 0.6253 - val_loss: 0.7010 - val_accuracy: 0.5196 - 851ms/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "204/204 - 1s - loss: 0.6418 - accuracy: 0.6201 - val_loss: 0.7138 - val_accuracy: 0.5208 - 863ms/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "204/204 - 1s - loss: 0.6426 - accuracy: 0.6204 - val_loss: 0.7117 - val_accuracy: 0.5196 - 884ms/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "204/204 - 1s - loss: 0.6397 - accuracy: 0.6232 - val_loss: 0.6984 - val_accuracy: 0.5208 - 891ms/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "204/204 - 1s - loss: 0.6462 - accuracy: 0.6127 - val_loss: 0.6999 - val_accuracy: 0.5221 - 878ms/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "204/204 - 1s - loss: 0.6380 - accuracy: 0.6195 - val_loss: 0.6978 - val_accuracy: 0.5172 - 880ms/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "204/204 - 1s - loss: 0.6441 - accuracy: 0.6109 - val_loss: 0.6960 - val_accuracy: 0.5257 - 902ms/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "204/204 - 1s - loss: 0.6403 - accuracy: 0.6201 - val_loss: 0.7277 - val_accuracy: 0.5208 - 905ms/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "204/204 - 1s - loss: 0.6377 - accuracy: 0.6259 - val_loss: 0.7108 - val_accuracy: 0.5196 - 897ms/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "204/204 - 1s - loss: 0.6361 - accuracy: 0.6158 - val_loss: 0.7274 - val_accuracy: 0.5208 - 881ms/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "204/204 - 1s - loss: 0.6398 - accuracy: 0.6149 - val_loss: 0.7304 - val_accuracy: 0.5221 - 906ms/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "204/204 - 1s - loss: 0.6366 - accuracy: 0.6222 - val_loss: 0.7245 - val_accuracy: 0.5208 - 897ms/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "204/204 - 1s - loss: 0.6354 - accuracy: 0.6278 - val_loss: 0.7697 - val_accuracy: 0.5233 - 894ms/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "204/204 - 1s - loss: 0.6343 - accuracy: 0.6299 - val_loss: 0.7409 - val_accuracy: 0.5233 - 885ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "204/204 - 1s - loss: 0.6404 - accuracy: 0.6253 - val_loss: 0.7499 - val_accuracy: 0.5233 - 919ms/epoch - 5ms/step\n",
      "Epoch 67/250\n",
      "204/204 - 1s - loss: 0.6416 - accuracy: 0.6201 - val_loss: 0.7390 - val_accuracy: 0.5196 - 893ms/epoch - 4ms/step\n",
      "Epoch 68/250\n",
      "204/204 - 1s - loss: 0.6382 - accuracy: 0.6204 - val_loss: 0.7055 - val_accuracy: 0.5208 - 865ms/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "204/204 - 1s - loss: 0.6348 - accuracy: 0.6311 - val_loss: 0.7529 - val_accuracy: 0.5233 - 883ms/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "204/204 - 1s - loss: 0.6295 - accuracy: 0.6345 - val_loss: 0.7380 - val_accuracy: 0.5221 - 894ms/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "204/204 - 1s - loss: 0.6390 - accuracy: 0.6213 - val_loss: 0.7510 - val_accuracy: 0.5233 - 891ms/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "204/204 - 1s - loss: 0.6329 - accuracy: 0.6363 - val_loss: 0.7517 - val_accuracy: 0.5233 - 902ms/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "204/204 - 1s - loss: 0.6334 - accuracy: 0.6360 - val_loss: 0.7573 - val_accuracy: 0.5221 - 905ms/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "204/204 - 1s - loss: 0.6331 - accuracy: 0.6357 - val_loss: 0.7199 - val_accuracy: 0.5196 - 872ms/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "204/204 - 1s - loss: 0.6328 - accuracy: 0.6287 - val_loss: 0.7142 - val_accuracy: 0.5184 - 857ms/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "204/204 - 1s - loss: 0.6353 - accuracy: 0.6268 - val_loss: 0.7219 - val_accuracy: 0.5196 - 893ms/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "204/204 - 1s - loss: 0.6372 - accuracy: 0.6216 - val_loss: 0.7229 - val_accuracy: 0.5159 - 905ms/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "204/204 - 1s - loss: 0.6373 - accuracy: 0.6250 - val_loss: 0.7023 - val_accuracy: 0.5172 - 909ms/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "204/204 - 1s - loss: 0.6423 - accuracy: 0.6198 - val_loss: 0.7020 - val_accuracy: 0.5159 - 903ms/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "204/204 - 1s - loss: 0.6268 - accuracy: 0.6397 - val_loss: 0.7069 - val_accuracy: 0.5172 - 890ms/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "204/204 - 1s - loss: 0.6277 - accuracy: 0.6314 - val_loss: 0.7032 - val_accuracy: 0.5172 - 888ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "204/204 - 1s - loss: 0.6377 - accuracy: 0.6262 - val_loss: 0.7047 - val_accuracy: 0.5172 - 914ms/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "204/204 - 1s - loss: 0.6277 - accuracy: 0.6391 - val_loss: 0.6952 - val_accuracy: 0.5221 - 898ms/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "204/204 - 1s - loss: 0.6362 - accuracy: 0.6330 - val_loss: 0.7003 - val_accuracy: 0.5172 - 890ms/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "204/204 - 1s - loss: 0.6287 - accuracy: 0.6394 - val_loss: 0.7364 - val_accuracy: 0.5233 - 870ms/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "204/204 - 1s - loss: 0.6352 - accuracy: 0.6216 - val_loss: 0.7579 - val_accuracy: 0.5221 - 879ms/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "204/204 - 1s - loss: 0.6286 - accuracy: 0.6348 - val_loss: 0.7164 - val_accuracy: 0.5172 - 882ms/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "204/204 - 1s - loss: 0.6264 - accuracy: 0.6336 - val_loss: 0.7304 - val_accuracy: 0.5184 - 898ms/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "204/204 - 1s - loss: 0.6297 - accuracy: 0.6308 - val_loss: 0.7196 - val_accuracy: 0.5184 - 908ms/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "204/204 - 1s - loss: 0.6265 - accuracy: 0.6437 - val_loss: 0.7057 - val_accuracy: 0.5172 - 889ms/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "204/204 - 1s - loss: 0.6288 - accuracy: 0.6385 - val_loss: 0.7119 - val_accuracy: 0.5172 - 867ms/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "204/204 - 1s - loss: 0.6258 - accuracy: 0.6388 - val_loss: 0.7053 - val_accuracy: 0.5184 - 915ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "204/204 - 1s - loss: 0.6286 - accuracy: 0.6369 - val_loss: 0.6984 - val_accuracy: 0.5172 - 903ms/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "204/204 - 1s - loss: 0.6290 - accuracy: 0.6342 - val_loss: 0.6968 - val_accuracy: 0.5172 - 888ms/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "204/204 - 1s - loss: 0.6199 - accuracy: 0.6388 - val_loss: 0.7027 - val_accuracy: 0.5172 - 876ms/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "204/204 - 1s - loss: 0.6272 - accuracy: 0.6458 - val_loss: 0.7095 - val_accuracy: 0.5159 - 902ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "204/204 - 1s - loss: 0.6314 - accuracy: 0.6351 - val_loss: 0.7135 - val_accuracy: 0.5184 - 865ms/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "204/204 - 1s - loss: 0.6266 - accuracy: 0.6382 - val_loss: 0.7100 - val_accuracy: 0.5159 - 889ms/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "204/204 - 1s - loss: 0.6297 - accuracy: 0.6324 - val_loss: 0.7310 - val_accuracy: 0.5159 - 909ms/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "204/204 - 1s - loss: 0.6335 - accuracy: 0.6397 - val_loss: 0.7446 - val_accuracy: 0.5208 - 880ms/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "204/204 - 1s - loss: 0.6224 - accuracy: 0.6471 - val_loss: 0.7173 - val_accuracy: 0.5159 - 872ms/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "204/204 - 1s - loss: 0.6242 - accuracy: 0.6351 - val_loss: 0.7349 - val_accuracy: 0.5172 - 904ms/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "204/204 - 1s - loss: 0.6287 - accuracy: 0.6461 - val_loss: 0.7343 - val_accuracy: 0.5172 - 878ms/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "204/204 - 1s - loss: 0.6146 - accuracy: 0.6348 - val_loss: 0.7790 - val_accuracy: 0.5233 - 885ms/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "204/204 - 1s - loss: 0.6210 - accuracy: 0.6363 - val_loss: 0.7466 - val_accuracy: 0.5208 - 863ms/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "204/204 - 1s - loss: 0.6228 - accuracy: 0.6428 - val_loss: 0.7720 - val_accuracy: 0.5233 - 853ms/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "204/204 - 1s - loss: 0.6159 - accuracy: 0.6412 - val_loss: 0.8225 - val_accuracy: 0.5233 - 869ms/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "204/204 - 1s - loss: 0.6290 - accuracy: 0.6351 - val_loss: 0.7561 - val_accuracy: 0.5196 - 866ms/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "204/204 - 1s - loss: 0.6241 - accuracy: 0.6471 - val_loss: 0.8091 - val_accuracy: 0.5233 - 898ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "204/204 - 1s - loss: 0.6297 - accuracy: 0.6360 - val_loss: 0.7652 - val_accuracy: 0.5221 - 873ms/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "204/204 - 1s - loss: 0.6290 - accuracy: 0.6471 - val_loss: 0.7718 - val_accuracy: 0.5208 - 877ms/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "204/204 - 1s - loss: 0.6229 - accuracy: 0.6382 - val_loss: 0.7745 - val_accuracy: 0.5208 - 903ms/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "204/204 - 1s - loss: 0.6176 - accuracy: 0.6489 - val_loss: 0.7858 - val_accuracy: 0.5221 - 906ms/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "204/204 - 1s - loss: 0.6289 - accuracy: 0.6415 - val_loss: 0.7629 - val_accuracy: 0.5196 - 885ms/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "204/204 - 1s - loss: 0.6148 - accuracy: 0.6474 - val_loss: 0.7311 - val_accuracy: 0.5172 - 904ms/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "204/204 - 1s - loss: 0.6327 - accuracy: 0.6415 - val_loss: 0.7230 - val_accuracy: 0.5147 - 893ms/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "204/204 - 1s - loss: 0.6217 - accuracy: 0.6480 - val_loss: 0.7279 - val_accuracy: 0.5184 - 864ms/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "204/204 - 1s - loss: 0.6231 - accuracy: 0.6486 - val_loss: 0.7940 - val_accuracy: 0.5196 - 879ms/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "204/204 - 1s - loss: 0.6266 - accuracy: 0.6431 - val_loss: 0.6965 - val_accuracy: 0.5208 - 914ms/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "204/204 - 1s - loss: 0.6301 - accuracy: 0.6391 - val_loss: 0.7307 - val_accuracy: 0.5221 - 901ms/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "204/204 - 1s - loss: 0.6215 - accuracy: 0.6489 - val_loss: 0.7007 - val_accuracy: 0.5184 - 881ms/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "204/204 - 1s - loss: 0.6221 - accuracy: 0.6348 - val_loss: 0.7094 - val_accuracy: 0.5172 - 905ms/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "204/204 - 1s - loss: 0.6248 - accuracy: 0.6406 - val_loss: 0.7082 - val_accuracy: 0.5159 - 879ms/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "204/204 - 1s - loss: 0.6208 - accuracy: 0.6553 - val_loss: 0.7541 - val_accuracy: 0.5184 - 907ms/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "204/204 - 1s - loss: 0.6185 - accuracy: 0.6474 - val_loss: 0.7676 - val_accuracy: 0.5221 - 859ms/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "204/204 - 1s - loss: 0.6204 - accuracy: 0.6535 - val_loss: 0.7309 - val_accuracy: 0.5208 - 850ms/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "204/204 - 1s - loss: 0.6178 - accuracy: 0.6547 - val_loss: 0.7163 - val_accuracy: 0.5196 - 851ms/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "204/204 - 1s - loss: 0.6209 - accuracy: 0.6513 - val_loss: 0.7068 - val_accuracy: 0.5172 - 851ms/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "204/204 - 1s - loss: 0.6102 - accuracy: 0.6569 - val_loss: 0.7428 - val_accuracy: 0.5172 - 878ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "204/204 - 1s - loss: 0.6179 - accuracy: 0.6541 - val_loss: 0.7468 - val_accuracy: 0.5196 - 875ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "204/204 - 1s - loss: 0.6265 - accuracy: 0.6385 - val_loss: 0.7075 - val_accuracy: 0.5159 - 860ms/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "204/204 - 1s - loss: 0.6111 - accuracy: 0.6590 - val_loss: 0.7285 - val_accuracy: 0.5172 - 871ms/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "204/204 - 1s - loss: 0.6194 - accuracy: 0.6562 - val_loss: 0.7988 - val_accuracy: 0.5221 - 879ms/epoch - 4ms/step\n",
      "Epoch 134/250\n",
      "204/204 - 1s - loss: 0.6170 - accuracy: 0.6492 - val_loss: 0.7188 - val_accuracy: 0.5184 - 901ms/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "204/204 - 1s - loss: 0.6183 - accuracy: 0.6415 - val_loss: 0.7273 - val_accuracy: 0.5172 - 899ms/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "204/204 - 1s - loss: 0.6173 - accuracy: 0.6575 - val_loss: 0.7266 - val_accuracy: 0.5172 - 891ms/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "204/204 - 1s - loss: 0.6270 - accuracy: 0.6480 - val_loss: 0.6989 - val_accuracy: 0.5196 - 946ms/epoch - 5ms/step\n",
      "Epoch 138/250\n",
      "204/204 - 1s - loss: 0.6125 - accuracy: 0.6517 - val_loss: 0.7113 - val_accuracy: 0.5196 - 934ms/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "204/204 - 1s - loss: 0.6200 - accuracy: 0.6422 - val_loss: 0.7061 - val_accuracy: 0.5172 - 911ms/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "204/204 - 1s - loss: 0.6179 - accuracy: 0.6483 - val_loss: 0.8034 - val_accuracy: 0.5184 - 902ms/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "204/204 - 1s - loss: 0.6113 - accuracy: 0.6605 - val_loss: 0.7506 - val_accuracy: 0.5184 - 891ms/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "204/204 - 1s - loss: 0.6155 - accuracy: 0.6412 - val_loss: 0.7179 - val_accuracy: 0.5123 - 901ms/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "204/204 - 1s - loss: 0.6130 - accuracy: 0.6630 - val_loss: 0.7233 - val_accuracy: 0.5172 - 906ms/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "204/204 - 1s - loss: 0.6131 - accuracy: 0.6553 - val_loss: 0.7267 - val_accuracy: 0.5159 - 914ms/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "204/204 - 1s - loss: 0.6171 - accuracy: 0.6513 - val_loss: 0.7337 - val_accuracy: 0.5172 - 877ms/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "204/204 - 1s - loss: 0.6195 - accuracy: 0.6526 - val_loss: 0.7432 - val_accuracy: 0.5184 - 901ms/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "204/204 - 1s - loss: 0.6146 - accuracy: 0.6572 - val_loss: 0.7322 - val_accuracy: 0.5159 - 880ms/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "204/204 - 1s - loss: 0.6161 - accuracy: 0.6523 - val_loss: 0.7120 - val_accuracy: 0.5159 - 906ms/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "204/204 - 1s - loss: 0.6218 - accuracy: 0.6504 - val_loss: 0.7403 - val_accuracy: 0.5159 - 879ms/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "204/204 - 1s - loss: 0.6147 - accuracy: 0.6489 - val_loss: 0.7248 - val_accuracy: 0.5159 - 903ms/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "204/204 - 1s - loss: 0.6185 - accuracy: 0.6489 - val_loss: 0.7705 - val_accuracy: 0.5221 - 877ms/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "204/204 - 1s - loss: 0.6096 - accuracy: 0.6688 - val_loss: 0.7545 - val_accuracy: 0.5184 - 920ms/epoch - 5ms/step\n",
      "Epoch 153/250\n",
      "204/204 - 1s - loss: 0.6136 - accuracy: 0.6523 - val_loss: 0.7391 - val_accuracy: 0.5172 - 910ms/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "204/204 - 1s - loss: 0.6134 - accuracy: 0.6526 - val_loss: 0.7539 - val_accuracy: 0.5172 - 933ms/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "204/204 - 1s - loss: 0.6101 - accuracy: 0.6562 - val_loss: 0.8044 - val_accuracy: 0.5184 - 922ms/epoch - 5ms/step\n",
      "Epoch 156/250\n",
      "204/204 - 1s - loss: 0.6227 - accuracy: 0.6489 - val_loss: 0.8062 - val_accuracy: 0.5221 - 904ms/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "204/204 - 1s - loss: 0.6185 - accuracy: 0.6446 - val_loss: 0.8577 - val_accuracy: 0.5221 - 899ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "204/204 - 1s - loss: 0.6243 - accuracy: 0.6397 - val_loss: 0.7353 - val_accuracy: 0.5184 - 894ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "204/204 - 1s - loss: 0.6078 - accuracy: 0.6654 - val_loss: 0.7160 - val_accuracy: 0.5159 - 929ms/epoch - 5ms/step\n",
      "Epoch 160/250\n",
      "204/204 - 1s - loss: 0.6115 - accuracy: 0.6556 - val_loss: 0.7125 - val_accuracy: 0.5159 - 916ms/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "204/204 - 1s - loss: 0.6177 - accuracy: 0.6452 - val_loss: 0.7577 - val_accuracy: 0.5172 - 902ms/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "204/204 - 1s - loss: 0.6126 - accuracy: 0.6412 - val_loss: 0.6997 - val_accuracy: 0.5184 - 900ms/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "204/204 - 1s - loss: 0.6123 - accuracy: 0.6547 - val_loss: 0.7052 - val_accuracy: 0.5172 - 918ms/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "204/204 - 1s - loss: 0.6133 - accuracy: 0.6556 - val_loss: 0.6963 - val_accuracy: 0.5208 - 917ms/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "204/204 - 1s - loss: 0.6092 - accuracy: 0.6566 - val_loss: 0.7044 - val_accuracy: 0.5159 - 918ms/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "204/204 - 1s - loss: 0.6174 - accuracy: 0.6437 - val_loss: 0.7161 - val_accuracy: 0.5172 - 922ms/epoch - 5ms/step\n",
      "Epoch 167/250\n",
      "204/204 - 1s - loss: 0.6241 - accuracy: 0.6382 - val_loss: 0.7426 - val_accuracy: 0.5184 - 894ms/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "204/204 - 1s - loss: 0.6124 - accuracy: 0.6507 - val_loss: 0.7808 - val_accuracy: 0.5221 - 919ms/epoch - 5ms/step\n",
      "Epoch 169/250\n",
      "204/204 - 1s - loss: 0.6112 - accuracy: 0.6471 - val_loss: 0.7737 - val_accuracy: 0.5184 - 902ms/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "204/204 - 1s - loss: 0.6170 - accuracy: 0.6523 - val_loss: 0.7583 - val_accuracy: 0.5196 - 906ms/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "204/204 - 1s - loss: 0.6142 - accuracy: 0.6559 - val_loss: 0.7455 - val_accuracy: 0.5159 - 892ms/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "204/204 - 1s - loss: 0.6118 - accuracy: 0.6556 - val_loss: 0.8118 - val_accuracy: 0.5208 - 873ms/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "204/204 - 1s - loss: 0.6128 - accuracy: 0.6572 - val_loss: 0.7456 - val_accuracy: 0.5159 - 904ms/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "204/204 - 1s - loss: 0.6160 - accuracy: 0.6489 - val_loss: 0.7766 - val_accuracy: 0.5184 - 896ms/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "204/204 - 1s - loss: 0.6076 - accuracy: 0.6651 - val_loss: 0.7763 - val_accuracy: 0.5184 - 892ms/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "204/204 - 1s - loss: 0.6146 - accuracy: 0.6535 - val_loss: 0.7251 - val_accuracy: 0.5172 - 917ms/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "204/204 - 1s - loss: 0.6118 - accuracy: 0.6590 - val_loss: 0.7175 - val_accuracy: 0.5159 - 917ms/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "204/204 - 1s - loss: 0.6083 - accuracy: 0.6578 - val_loss: 0.7022 - val_accuracy: 0.5184 - 885ms/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "204/204 - 1s - loss: 0.6138 - accuracy: 0.6553 - val_loss: 0.7192 - val_accuracy: 0.5159 - 860ms/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "204/204 - 1s - loss: 0.6132 - accuracy: 0.6513 - val_loss: 0.7400 - val_accuracy: 0.5184 - 890ms/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "204/204 - 1s - loss: 0.6106 - accuracy: 0.6618 - val_loss: 0.7109 - val_accuracy: 0.5135 - 893ms/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "204/204 - 1s - loss: 0.6084 - accuracy: 0.6556 - val_loss: 0.7822 - val_accuracy: 0.5221 - 905ms/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "204/204 - 1s - loss: 0.6146 - accuracy: 0.6489 - val_loss: 0.7443 - val_accuracy: 0.5184 - 912ms/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "204/204 - 1s - loss: 0.6165 - accuracy: 0.6538 - val_loss: 0.7068 - val_accuracy: 0.5159 - 900ms/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "204/204 - 1s - loss: 0.6118 - accuracy: 0.6584 - val_loss: 0.7083 - val_accuracy: 0.5172 - 908ms/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "204/204 - 1s - loss: 0.6143 - accuracy: 0.6590 - val_loss: 0.7056 - val_accuracy: 0.5245 - 901ms/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "204/204 - 1s - loss: 0.6111 - accuracy: 0.6578 - val_loss: 0.7072 - val_accuracy: 0.5147 - 898ms/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "204/204 - 1s - loss: 0.6186 - accuracy: 0.6495 - val_loss: 0.6984 - val_accuracy: 0.5172 - 892ms/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "204/204 - 1s - loss: 0.6114 - accuracy: 0.6636 - val_loss: 0.6973 - val_accuracy: 0.4902 - 915ms/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "204/204 - 1s - loss: 0.6160 - accuracy: 0.6504 - val_loss: 0.6952 - val_accuracy: 0.5159 - 905ms/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "204/204 - 1s - loss: 0.6124 - accuracy: 0.6590 - val_loss: 0.7371 - val_accuracy: 0.5159 - 904ms/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "204/204 - 1s - loss: 0.6096 - accuracy: 0.6575 - val_loss: 0.7587 - val_accuracy: 0.5159 - 934ms/epoch - 5ms/step\n",
      "Epoch 193/250\n",
      "204/204 - 1s - loss: 0.6101 - accuracy: 0.6621 - val_loss: 0.7139 - val_accuracy: 0.5147 - 918ms/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "204/204 - 1s - loss: 0.6171 - accuracy: 0.6654 - val_loss: 0.7451 - val_accuracy: 0.5184 - 892ms/epoch - 4ms/step\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 - 1s - loss: 0.6112 - accuracy: 0.6578 - val_loss: 0.7335 - val_accuracy: 0.5172 - 923ms/epoch - 5ms/step\n",
      "Epoch 196/250\n",
      "204/204 - 1s - loss: 0.6149 - accuracy: 0.6474 - val_loss: 0.7535 - val_accuracy: 0.5184 - 889ms/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "204/204 - 1s - loss: 0.6082 - accuracy: 0.6566 - val_loss: 0.7273 - val_accuracy: 0.5172 - 894ms/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "204/204 - 1s - loss: 0.6147 - accuracy: 0.6538 - val_loss: 0.6991 - val_accuracy: 0.5159 - 883ms/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "204/204 - 1s - loss: 0.6148 - accuracy: 0.6510 - val_loss: 0.7105 - val_accuracy: 0.5147 - 917ms/epoch - 4ms/step\n",
      "Epoch 200/250\n",
      "204/204 - 1s - loss: 0.6044 - accuracy: 0.6639 - val_loss: 0.7036 - val_accuracy: 0.5159 - 912ms/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "204/204 - 1s - loss: 0.6142 - accuracy: 0.6587 - val_loss: 0.6975 - val_accuracy: 0.5159 - 933ms/epoch - 5ms/step\n",
      "Epoch 202/250\n",
      "204/204 - 1s - loss: 0.6079 - accuracy: 0.6630 - val_loss: 0.7384 - val_accuracy: 0.5159 - 890ms/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "204/204 - 1s - loss: 0.6155 - accuracy: 0.6621 - val_loss: 0.7894 - val_accuracy: 0.5196 - 892ms/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "204/204 - 1s - loss: 0.6132 - accuracy: 0.6547 - val_loss: 0.8408 - val_accuracy: 0.5233 - 887ms/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "204/204 - 1s - loss: 0.6240 - accuracy: 0.6339 - val_loss: 0.7484 - val_accuracy: 0.5159 - 876ms/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "204/204 - 1s - loss: 0.6105 - accuracy: 0.6633 - val_loss: 0.7186 - val_accuracy: 0.5147 - 909ms/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "204/204 - 1s - loss: 0.6087 - accuracy: 0.6694 - val_loss: 0.7030 - val_accuracy: 0.5184 - 882ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "204/204 - 1s - loss: 0.6012 - accuracy: 0.6547 - val_loss: 0.7000 - val_accuracy: 0.5147 - 885ms/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "204/204 - 1s - loss: 0.6138 - accuracy: 0.6562 - val_loss: 0.6947 - val_accuracy: 0.5490 - 912ms/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "204/204 - 1s - loss: 0.6103 - accuracy: 0.6608 - val_loss: 0.7305 - val_accuracy: 0.5184 - 890ms/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "204/204 - 1s - loss: 0.6089 - accuracy: 0.6612 - val_loss: 0.7546 - val_accuracy: 0.5196 - 899ms/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "204/204 - 1s - loss: 0.6077 - accuracy: 0.6575 - val_loss: 0.7856 - val_accuracy: 0.5208 - 896ms/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "204/204 - 1s - loss: 0.6089 - accuracy: 0.6562 - val_loss: 0.7342 - val_accuracy: 0.5159 - 894ms/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "204/204 - 1s - loss: 0.5999 - accuracy: 0.6605 - val_loss: 0.7066 - val_accuracy: 0.5196 - 906ms/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "204/204 - 1s - loss: 0.6173 - accuracy: 0.6529 - val_loss: 0.6956 - val_accuracy: 0.5184 - 904ms/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "204/204 - 1s - loss: 0.6160 - accuracy: 0.6596 - val_loss: 0.8511 - val_accuracy: 0.5208 - 901ms/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "204/204 - 1s - loss: 0.6166 - accuracy: 0.6526 - val_loss: 0.8084 - val_accuracy: 0.5172 - 870ms/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "204/204 - 1s - loss: 0.6082 - accuracy: 0.6700 - val_loss: 0.8630 - val_accuracy: 0.5208 - 895ms/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "204/204 - 1s - loss: 0.6122 - accuracy: 0.6517 - val_loss: 0.8240 - val_accuracy: 0.5196 - 904ms/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "204/204 - 1s - loss: 0.6125 - accuracy: 0.6535 - val_loss: 0.7930 - val_accuracy: 0.5196 - 927ms/epoch - 5ms/step\n",
      "Epoch 221/250\n",
      "204/204 - 1s - loss: 0.6112 - accuracy: 0.6636 - val_loss: 0.8083 - val_accuracy: 0.5184 - 906ms/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "204/204 - 1s - loss: 0.6086 - accuracy: 0.6550 - val_loss: 0.8016 - val_accuracy: 0.5196 - 886ms/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "204/204 - 1s - loss: 0.6107 - accuracy: 0.6535 - val_loss: 0.7443 - val_accuracy: 0.5159 - 902ms/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "204/204 - 1s - loss: 0.6077 - accuracy: 0.6553 - val_loss: 0.7889 - val_accuracy: 0.5196 - 899ms/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "204/204 - 1s - loss: 0.6020 - accuracy: 0.6746 - val_loss: 0.8038 - val_accuracy: 0.5221 - 880ms/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "204/204 - 1s - loss: 0.6070 - accuracy: 0.6556 - val_loss: 0.7143 - val_accuracy: 0.5159 - 897ms/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "204/204 - 1s - loss: 0.6126 - accuracy: 0.6489 - val_loss: 0.7644 - val_accuracy: 0.5172 - 918ms/epoch - 5ms/step\n",
      "Epoch 228/250\n",
      "204/204 - 1s - loss: 0.6162 - accuracy: 0.6498 - val_loss: 0.7029 - val_accuracy: 0.5135 - 906ms/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "204/204 - 1s - loss: 0.6159 - accuracy: 0.6581 - val_loss: 0.7625 - val_accuracy: 0.5159 - 893ms/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "204/204 - 1s - loss: 0.6158 - accuracy: 0.6633 - val_loss: 0.7519 - val_accuracy: 0.5172 - 868ms/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "204/204 - 1s - loss: 0.6122 - accuracy: 0.6510 - val_loss: 0.7362 - val_accuracy: 0.5172 - 926ms/epoch - 5ms/step\n",
      "Epoch 232/250\n",
      "204/204 - 1s - loss: 0.6162 - accuracy: 0.6523 - val_loss: 0.7543 - val_accuracy: 0.5196 - 919ms/epoch - 5ms/step\n",
      "Epoch 233/250\n",
      "204/204 - 1s - loss: 0.6090 - accuracy: 0.6556 - val_loss: 0.9881 - val_accuracy: 0.5196 - 921ms/epoch - 5ms/step\n",
      "Epoch 234/250\n",
      "204/204 - 1s - loss: 0.6066 - accuracy: 0.6596 - val_loss: 0.7500 - val_accuracy: 0.5159 - 901ms/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "204/204 - 1s - loss: 0.6104 - accuracy: 0.6553 - val_loss: 0.7283 - val_accuracy: 0.5159 - 913ms/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "204/204 - 1s - loss: 0.6139 - accuracy: 0.6605 - val_loss: 0.7143 - val_accuracy: 0.5159 - 905ms/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "204/204 - 1s - loss: 0.6069 - accuracy: 0.6621 - val_loss: 0.7005 - val_accuracy: 0.5135 - 885ms/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "204/204 - 1s - loss: 0.6065 - accuracy: 0.6657 - val_loss: 0.7313 - val_accuracy: 0.5159 - 912ms/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "204/204 - 1s - loss: 0.6136 - accuracy: 0.6547 - val_loss: 0.7454 - val_accuracy: 0.5172 - 898ms/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "204/204 - 1s - loss: 0.6089 - accuracy: 0.6590 - val_loss: 0.8331 - val_accuracy: 0.5208 - 903ms/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "204/204 - 1s - loss: 0.6082 - accuracy: 0.6648 - val_loss: 0.8902 - val_accuracy: 0.5221 - 907ms/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "204/204 - 1s - loss: 0.6021 - accuracy: 0.6587 - val_loss: 0.8000 - val_accuracy: 0.5172 - 884ms/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "204/204 - 1s - loss: 0.6060 - accuracy: 0.6642 - val_loss: 0.7328 - val_accuracy: 0.5172 - 913ms/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "204/204 - 1s - loss: 0.6110 - accuracy: 0.6578 - val_loss: 0.7533 - val_accuracy: 0.5172 - 902ms/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "204/204 - 1s - loss: 0.6093 - accuracy: 0.6510 - val_loss: 0.7271 - val_accuracy: 0.5184 - 886ms/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "204/204 - 1s - loss: 0.6034 - accuracy: 0.6578 - val_loss: 0.7443 - val_accuracy: 0.5159 - 919ms/epoch - 5ms/step\n",
      "Epoch 247/250\n",
      "204/204 - 1s - loss: 0.6114 - accuracy: 0.6673 - val_loss: 0.7191 - val_accuracy: 0.5172 - 884ms/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "204/204 - 1s - loss: 0.5992 - accuracy: 0.6691 - val_loss: 0.6917 - val_accuracy: 0.5184 - 911ms/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "204/204 - 1s - loss: 0.6157 - accuracy: 0.6486 - val_loss: 0.7185 - val_accuracy: 0.5172 - 892ms/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "204/204 - 1s - loss: 0.6096 - accuracy: 0.6559 - val_loss: 0.8320 - val_accuracy: 0.5221 - 890ms/epoch - 4ms/step\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "128/128 [==============================] - 0s 2ms/step\n",
      "SUBJECT: 17\n",
      "N_CLASSES: 3\n",
      "New shape for X: (4860, 31, 50, 4)\n",
      "New shape for y: (4860,)\n",
      "Train index for this split: [   0    3    4 ... 4857 4858 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   1    2   14   18   19   21   23   28   32   35   38   42   50   58\n",
      "   60   65   71   72   74   76   86   87  103  106  115  129  137  142\n",
      "  148  149  155  156  164  166  169  172  176  181  182  186  187  188\n",
      "  189  200  209  213  215  216  219  221  224  242  254  258  259  262\n",
      "  267  270  275  278  282  288  292  293  297  303  304  311  319  324\n",
      "  328  333  342  346  347  351  353  355  360  362  363  365  371  375\n",
      "  384  387  395  397  407  419  420  424  430  451  455  457  461  465\n",
      "  467  469  475  480  481  484  487  488  490  500  504  509  512  522\n",
      "  527  533  542  553  557  558  563  564  568  571  574  576  581  582\n",
      "  590  592  595  602  603  606  607  609  610  615  622  623  629  637\n",
      "  642  645  658  659  662  673  676  679  695  703  705  712  713  715\n",
      "  717  719  721  732  745  748  754  760  769  786  797  808  809  812\n",
      "  824  833  835  851  864  868  872  879  889  890  896  909  911  912\n",
      "  915  916  920  921  924  934  949  950  957  960  968  969  978  979\n",
      "  983  984  986  990 1005 1007 1014 1016 1017 1021 1023 1027 1037 1040\n",
      " 1041 1051 1058 1061 1062 1068 1071 1076 1077 1081 1084 1087 1092 1098\n",
      " 1104 1120 1121 1122 1125 1126 1139 1143 1147 1151 1158 1165 1179 1196\n",
      " 1199 1210 1211 1213 1216 1220 1233 1242 1243 1247 1257 1267 1269 1271\n",
      " 1276 1278 1286 1287 1289 1294 1297 1299 1308 1315 1316 1323 1331 1333\n",
      " 1337 1342 1343 1345 1354 1360 1369 1375 1377 1380 1381 1384 1385 1386\n",
      " 1389 1393 1398 1412 1416 1431 1451 1454 1467 1469 1474 1478 1484 1491\n",
      " 1493 1497 1499 1502 1503 1504 1505 1520 1522 1529 1536 1543 1545 1555\n",
      " 1556 1557 1561 1562 1564 1565 1569 1570 1577 1580 1584 1585 1596 1601\n",
      " 1602 1612 1631 1634 1635 1638 1639 1641 1660 1662 1668 1672 1678 1679\n",
      " 1684 1701 1702 1703 1705 1719 1723 1726 1731 1734 1739 1741 1746 1758\n",
      " 1763 1770 1774 1788 1790 1791 1794 1802 1804 1811 1814 1818 1821 1824\n",
      " 1826 1833 1840 1842 1846 1848 1857 1860 1863 1866 1872 1873 1878 1882\n",
      " 1887 1892 1897 1903 1909 1911 1917 1922 1926 1938 1941 1946 1952 1954\n",
      " 1969 1978 1995 1996 2003 2009 2020 2026 2030 2033 2037 2046 2058 2069\n",
      " 2071 2073 2089 2090 2092 2098 2111 2113 2117 2120 2125 2127 2135 2139\n",
      " 2143 2145 2155 2157 2164 2178 2192 2193 2194 2195 2215 2216 2217 2219\n",
      " 2221 2228 2229 2249 2276 2278 2279 2297 2300 2301 2308 2314 2318 2322\n",
      " 2323 2328 2330 2332 2334 2339 2342 2349 2351 2360 2363 2364 2368 2381\n",
      " 2384 2386 2388 2406 2417 2424 2428 2437 2439 2448 2454 2455 2458 2459\n",
      " 2463 2465 2477 2480 2486 2490 2496 2497 2500 2504 2506 2510 2512 2513\n",
      " 2520 2522 2528 2535 2543 2548 2550 2553 2557 2572 2575 2579 2589 2592\n",
      " 2604 2606 2614 2617 2619 2623 2625 2628 2658 2659 2664 2668 2672 2673\n",
      " 2678 2681 2685 2697 2709 2712 2715 2716 2722 2724 2725 2734 2741 2746\n",
      " 2750 2756 2760 2763 2766 2767 2769 2771 2772 2773 2778 2783 2796 2798\n",
      " 2823 2828 2833 2834 2839 2842 2849 2850 2855 2856 2858 2860 2863 2869\n",
      " 2873 2874 2890 2891 2895 2898 2901 2914 2917 2919 2920 2929 2939 2950\n",
      " 2964 2965 2970 2989 2990 2994 2995 2999 3000 3009 3012 3014 3015 3020\n",
      " 3029 3034 3036 3037 3039 3041 3042 3046 3048 3057 3058 3070 3090 3092\n",
      " 3094 3095 3099 3102 3107 3117 3118 3124 3131 3139 3142 3144 3145 3157\n",
      " 3166 3175 3182 3184 3193 3196 3197 3199 3201 3202 3203 3204 3205 3206\n",
      " 3210 3211 3212 3214 3216 3220 3224 3233 3236 3237 3240 3241 3242 3256\n",
      " 3257 3258 3263 3270 3271 3277 3284 3285 3299 3301 3305 3307 3318 3322\n",
      " 3323 3324 3326 3333 3343 3344 3347 3356 3362 3364 3369 3374 3384 3385\n",
      " 3388 3391 3392 3395 3398 3401 3403 3407 3413 3414 3417 3421 3428 3438\n",
      " 3445 3449 3458 3460 3465 3466 3479 3483 3487 3488 3494 3497 3498 3502\n",
      " 3503 3505 3506 3511 3522 3535 3538 3540 3542 3546 3548 3557 3564 3565\n",
      " 3566 3568 3572 3579 3581 3590 3599 3601 3603 3624 3626 3632 3638 3640\n",
      " 3644 3645 3648 3651 3668 3671 3674 3681 3685 3693 3697 3700 3705 3707\n",
      " 3709 3723 3725 3729 3740 3741 3750 3756 3759 3770 3773 3775 3780 3781\n",
      " 3789 3791 3805 3808 3809 3812 3815 3820 3823 3825 3853 3859 3867 3881\n",
      " 3882 3885 3886 3888 3893 3898 3900 3902 3913 3920 3925 3929 3936 3938\n",
      " 3942 3952 3959 3968 3973 3976 3977 3992 4002 4004 4014 4015 4017 4019\n",
      " 4020 4025 4040 4041 4045 4059 4062 4077 4082 4084 4086 4088 4094 4097\n",
      " 4098 4099 4100 4102 4109 4117 4122 4124 4125 4129 4131 4134 4135 4140\n",
      " 4144 4158 4161 4163 4170 4171 4178 4189 4198 4208 4210 4218 4220 4226\n",
      " 4229 4232 4234 4235 4237 4244 4251 4258 4262 4265 4269 4276 4278 4282\n",
      " 4283 4287 4291 4299 4300 4301 4303 4308 4309 4312 4319 4321 4343 4344\n",
      " 4346 4347 4348 4350 4359 4364 4367 4368 4370 4376 4377 4378 4380 4382\n",
      " 4383 4386 4388 4397 4401 4405 4409 4412 4414 4417 4419 4436 4447 4450\n",
      " 4452 4454 4456 4467 4474 4478 4479 4482 4485 4490 4491 4495 4504 4513\n",
      " 4514 4515 4521 4534 4537 4550 4554 4558 4559 4560 4567 4572 4583 4597\n",
      " 4598 4601 4605 4606 4609 4611 4612 4621 4623 4631 4635 4643 4650 4663\n",
      " 4671 4673 4686 4687 4709 4715 4722 4738 4744 4747 4751 4753 4762 4765\n",
      " 4767 4774 4778 4779 4783 4793 4797 4798 4805 4809 4814 4829 4835 4839\n",
      " 4841 4844 4848 4849 4854 4856]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:45:12.341408: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_316/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.1003 - accuracy: 0.3405 - val_loss: 1.0992 - val_accuracy: 0.3447 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0996 - accuracy: 0.3418 - val_loss: 1.0993 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0988 - accuracy: 0.3410 - val_loss: 1.1000 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0973 - accuracy: 0.3547 - val_loss: 1.1017 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0937 - accuracy: 0.3660 - val_loss: 1.1095 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0922 - accuracy: 0.3619 - val_loss: 1.1045 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0908 - accuracy: 0.3627 - val_loss: 1.0985 - val_accuracy: 0.3385 - 1s/epoch - 5ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0900 - accuracy: 0.3686 - val_loss: 1.0975 - val_accuracy: 0.3519 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0908 - accuracy: 0.3727 - val_loss: 1.1001 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0857 - accuracy: 0.3753 - val_loss: 1.1017 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0843 - accuracy: 0.3794 - val_loss: 1.1070 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0865 - accuracy: 0.3953 - val_loss: 1.1116 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0786 - accuracy: 0.3891 - val_loss: 1.1148 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0802 - accuracy: 0.3881 - val_loss: 1.1053 - val_accuracy: 0.3519 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0767 - accuracy: 0.3933 - val_loss: 1.1088 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0733 - accuracy: 0.3925 - val_loss: 1.1057 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 1.0735 - accuracy: 0.3938 - val_loss: 1.0970 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0705 - accuracy: 0.4017 - val_loss: 1.0941 - val_accuracy: 0.3693 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0724 - accuracy: 0.4128 - val_loss: 1.0966 - val_accuracy: 0.3796 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0647 - accuracy: 0.4030 - val_loss: 1.0938 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 1.0672 - accuracy: 0.3902 - val_loss: 1.0959 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 1.0680 - accuracy: 0.4136 - val_loss: 1.0944 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 1.0703 - accuracy: 0.4074 - val_loss: 1.0961 - val_accuracy: 0.3549 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 1.0640 - accuracy: 0.4113 - val_loss: 1.1060 - val_accuracy: 0.3519 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 1.0676 - accuracy: 0.3974 - val_loss: 1.0971 - val_accuracy: 0.3549 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 1.0596 - accuracy: 0.4172 - val_loss: 1.1013 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 1.0637 - accuracy: 0.4064 - val_loss: 1.0916 - val_accuracy: 0.3560 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 1.0662 - accuracy: 0.4072 - val_loss: 1.1063 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 1.0535 - accuracy: 0.4180 - val_loss: 1.0915 - val_accuracy: 0.3745 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 1.0604 - accuracy: 0.4082 - val_loss: 1.1030 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 1.0606 - accuracy: 0.4200 - val_loss: 1.1008 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 1.0570 - accuracy: 0.4205 - val_loss: 1.0958 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 1.0585 - accuracy: 0.4048 - val_loss: 1.0931 - val_accuracy: 0.3539 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 1.0577 - accuracy: 0.4272 - val_loss: 1.1157 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 1.0517 - accuracy: 0.4226 - val_loss: 1.0971 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 1.0540 - accuracy: 0.4154 - val_loss: 1.1120 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 1.0466 - accuracy: 0.4367 - val_loss: 1.1208 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 1.0542 - accuracy: 0.4216 - val_loss: 1.1099 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 1.0515 - accuracy: 0.4228 - val_loss: 1.1120 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 1.0462 - accuracy: 0.4177 - val_loss: 1.1017 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 1.0565 - accuracy: 0.4223 - val_loss: 1.0972 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 1.0461 - accuracy: 0.4275 - val_loss: 1.1096 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 1.0467 - accuracy: 0.4275 - val_loss: 1.0972 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 1.0523 - accuracy: 0.4187 - val_loss: 1.0910 - val_accuracy: 0.4105 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 1.0509 - accuracy: 0.4208 - val_loss: 1.1057 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 1.0501 - accuracy: 0.4257 - val_loss: 1.1510 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 1.0505 - accuracy: 0.4234 - val_loss: 1.1260 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 1.0412 - accuracy: 0.4334 - val_loss: 1.1254 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 1.0496 - accuracy: 0.4303 - val_loss: 1.1175 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 1.0513 - accuracy: 0.4180 - val_loss: 1.0990 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 1.0433 - accuracy: 0.4329 - val_loss: 1.1391 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 1.0485 - accuracy: 0.4311 - val_loss: 1.1334 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 1.0451 - accuracy: 0.4275 - val_loss: 1.1351 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 1.0409 - accuracy: 0.4313 - val_loss: 1.1027 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 1.0402 - accuracy: 0.4344 - val_loss: 1.1347 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 1.0454 - accuracy: 0.4288 - val_loss: 1.1343 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 1.0421 - accuracy: 0.4375 - val_loss: 1.0981 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 1.0462 - accuracy: 0.4396 - val_loss: 1.1090 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 1.0416 - accuracy: 0.4372 - val_loss: 1.1104 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 1.0397 - accuracy: 0.4421 - val_loss: 1.1041 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 1.0429 - accuracy: 0.4357 - val_loss: 1.1050 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 1.0397 - accuracy: 0.4421 - val_loss: 1.1076 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 1.0382 - accuracy: 0.4272 - val_loss: 1.1287 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 1.0389 - accuracy: 0.4414 - val_loss: 1.0932 - val_accuracy: 0.4403 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 1.0388 - accuracy: 0.4334 - val_loss: 1.0985 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 1.0359 - accuracy: 0.4403 - val_loss: 1.1427 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 1.0359 - accuracy: 0.4349 - val_loss: 1.1348 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 1.0401 - accuracy: 0.4424 - val_loss: 1.1486 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 1.0356 - accuracy: 0.4393 - val_loss: 1.1550 - val_accuracy: 0.3385 - 996ms/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 1.0382 - accuracy: 0.4354 - val_loss: 1.1979 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 1.0327 - accuracy: 0.4401 - val_loss: 1.1909 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 1.0345 - accuracy: 0.4437 - val_loss: 1.1520 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 1.0299 - accuracy: 0.4468 - val_loss: 1.1336 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 1.0400 - accuracy: 0.4288 - val_loss: 1.1123 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 1.0324 - accuracy: 0.4300 - val_loss: 1.1409 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 1.0359 - accuracy: 0.4470 - val_loss: 1.1562 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 1.0347 - accuracy: 0.4434 - val_loss: 1.1230 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 1.0310 - accuracy: 0.4444 - val_loss: 1.1064 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 1.0303 - accuracy: 0.4378 - val_loss: 1.1440 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 1.0330 - accuracy: 0.4406 - val_loss: 1.1555 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 1.0354 - accuracy: 0.4434 - val_loss: 1.1171 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 1.0318 - accuracy: 0.4390 - val_loss: 1.1024 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 1.0294 - accuracy: 0.4439 - val_loss: 1.1044 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 1.0314 - accuracy: 0.4442 - val_loss: 1.1614 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 1.0265 - accuracy: 0.4414 - val_loss: 1.1791 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 1.0282 - accuracy: 0.4506 - val_loss: 1.2124 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 1.0242 - accuracy: 0.4478 - val_loss: 1.1717 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 1.0269 - accuracy: 0.4591 - val_loss: 1.1526 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 1.0283 - accuracy: 0.4367 - val_loss: 1.1452 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 1.0255 - accuracy: 0.4527 - val_loss: 1.1574 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 1.0289 - accuracy: 0.4434 - val_loss: 1.1398 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 1.0253 - accuracy: 0.4462 - val_loss: 1.1185 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 1.0305 - accuracy: 0.4522 - val_loss: 1.2035 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 1.0215 - accuracy: 0.4527 - val_loss: 1.1280 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 1.0241 - accuracy: 0.4516 - val_loss: 1.1720 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 1.0301 - accuracy: 0.4465 - val_loss: 1.1887 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 1.0225 - accuracy: 0.4540 - val_loss: 1.1416 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 1.0243 - accuracy: 0.4560 - val_loss: 1.1278 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 1.0204 - accuracy: 0.4522 - val_loss: 1.1280 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 1.0255 - accuracy: 0.4565 - val_loss: 1.1363 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 1.0218 - accuracy: 0.4563 - val_loss: 1.1038 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 1.0253 - accuracy: 0.4522 - val_loss: 1.1025 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 1.0255 - accuracy: 0.4583 - val_loss: 1.1075 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 1.0238 - accuracy: 0.4506 - val_loss: 1.0920 - val_accuracy: 0.3971 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 1.0277 - accuracy: 0.4450 - val_loss: 1.0942 - val_accuracy: 0.3930 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 1.0316 - accuracy: 0.4506 - val_loss: 1.1051 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 1.0146 - accuracy: 0.4568 - val_loss: 1.1417 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 1.0192 - accuracy: 0.4606 - val_loss: 1.1062 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 1.0256 - accuracy: 0.4493 - val_loss: 1.1357 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 1.0210 - accuracy: 0.4498 - val_loss: 1.1233 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 1.0233 - accuracy: 0.4527 - val_loss: 1.1065 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 1.0185 - accuracy: 0.4671 - val_loss: 1.1206 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 1.0267 - accuracy: 0.4504 - val_loss: 1.1240 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 1.0216 - accuracy: 0.4483 - val_loss: 1.1640 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 1.0187 - accuracy: 0.4594 - val_loss: 1.1749 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 1.0224 - accuracy: 0.4604 - val_loss: 1.1872 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 1.0266 - accuracy: 0.4475 - val_loss: 1.1672 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 1.0227 - accuracy: 0.4640 - val_loss: 1.1496 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 1.0161 - accuracy: 0.4588 - val_loss: 1.1229 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 1.0215 - accuracy: 0.4491 - val_loss: 1.1259 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 1.0253 - accuracy: 0.4524 - val_loss: 1.1320 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 1.0142 - accuracy: 0.4570 - val_loss: 1.1964 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 1.0199 - accuracy: 0.4509 - val_loss: 1.1089 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 1.0203 - accuracy: 0.4524 - val_loss: 1.1848 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 1.0240 - accuracy: 0.4493 - val_loss: 1.1355 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 1.0197 - accuracy: 0.4671 - val_loss: 1.1277 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 1.0208 - accuracy: 0.4673 - val_loss: 1.1017 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 1.0276 - accuracy: 0.4462 - val_loss: 1.0970 - val_accuracy: 0.3580 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 1.0208 - accuracy: 0.4529 - val_loss: 1.0905 - val_accuracy: 0.3735 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 1.0223 - accuracy: 0.4522 - val_loss: 1.1303 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 1.0249 - accuracy: 0.4506 - val_loss: 1.1003 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 1.0141 - accuracy: 0.4594 - val_loss: 1.0988 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 1.0151 - accuracy: 0.4671 - val_loss: 1.1023 - val_accuracy: 0.3539 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 1.0232 - accuracy: 0.4465 - val_loss: 1.0957 - val_accuracy: 0.3591 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 1.0151 - accuracy: 0.4560 - val_loss: 1.0983 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 1.0096 - accuracy: 0.4622 - val_loss: 1.2164 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 1.0177 - accuracy: 0.4614 - val_loss: 1.2021 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 1.0168 - accuracy: 0.4563 - val_loss: 1.1677 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 1.0229 - accuracy: 0.4444 - val_loss: 1.1744 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 1.0171 - accuracy: 0.4612 - val_loss: 1.1906 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 1.0199 - accuracy: 0.4493 - val_loss: 1.1919 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 1.0128 - accuracy: 0.4609 - val_loss: 1.1181 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 1.0208 - accuracy: 0.4511 - val_loss: 1.1142 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 1.0252 - accuracy: 0.4486 - val_loss: 1.1171 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 1.0160 - accuracy: 0.4524 - val_loss: 1.1084 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 1.0153 - accuracy: 0.4624 - val_loss: 1.2179 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 1.0202 - accuracy: 0.4609 - val_loss: 1.2311 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 1.0102 - accuracy: 0.4576 - val_loss: 1.2781 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 1.0107 - accuracy: 0.4704 - val_loss: 1.2619 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 1.0198 - accuracy: 0.4565 - val_loss: 1.1528 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 1.0154 - accuracy: 0.4447 - val_loss: 1.1101 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 1.0105 - accuracy: 0.4635 - val_loss: 1.1509 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 1.0129 - accuracy: 0.4576 - val_loss: 1.1904 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 1.0033 - accuracy: 0.4738 - val_loss: 1.1808 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 1.0158 - accuracy: 0.4524 - val_loss: 1.1035 - val_accuracy: 0.3704 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 1.0135 - accuracy: 0.4591 - val_loss: 1.1325 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4694 - val_loss: 1.1719 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 1.0035 - accuracy: 0.4704 - val_loss: 1.1538 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 1.0187 - accuracy: 0.4547 - val_loss: 1.2044 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 1.0150 - accuracy: 0.4570 - val_loss: 1.1560 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4704 - val_loss: 1.1665 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 1.0133 - accuracy: 0.4648 - val_loss: 1.1606 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 1.0194 - accuracy: 0.4635 - val_loss: 1.2413 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 1.0078 - accuracy: 0.4658 - val_loss: 1.2350 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 1.0108 - accuracy: 0.4617 - val_loss: 1.2348 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 1.0054 - accuracy: 0.4794 - val_loss: 1.2279 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 1.0145 - accuracy: 0.4506 - val_loss: 1.2023 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 1.0062 - accuracy: 0.4655 - val_loss: 1.1435 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 1.0129 - accuracy: 0.4635 - val_loss: 1.1612 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 1.0092 - accuracy: 0.4673 - val_loss: 1.1784 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 1.0110 - accuracy: 0.4709 - val_loss: 1.1809 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4632 - val_loss: 1.1518 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 1.0137 - accuracy: 0.4766 - val_loss: 1.1862 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 1.0097 - accuracy: 0.4673 - val_loss: 1.2339 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 1.0141 - accuracy: 0.4676 - val_loss: 1.2188 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 1.0106 - accuracy: 0.4707 - val_loss: 1.2139 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4635 - val_loss: 1.2066 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 1.0018 - accuracy: 0.4745 - val_loss: 1.1710 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 1.0102 - accuracy: 0.4697 - val_loss: 1.1978 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 1.0080 - accuracy: 0.4619 - val_loss: 1.2215 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 1.0046 - accuracy: 0.4645 - val_loss: 1.2549 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4681 - val_loss: 1.1567 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 1.0065 - accuracy: 0.4637 - val_loss: 1.1548 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 1.0183 - accuracy: 0.4676 - val_loss: 1.2388 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 1.0080 - accuracy: 0.4691 - val_loss: 1.1474 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 1.0073 - accuracy: 0.4668 - val_loss: 1.1348 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 1.0140 - accuracy: 0.4694 - val_loss: 1.1696 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 1.0112 - accuracy: 0.4756 - val_loss: 1.2647 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 1.0099 - accuracy: 0.4676 - val_loss: 1.1767 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 1.0139 - accuracy: 0.4666 - val_loss: 1.1385 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 1.0083 - accuracy: 0.4709 - val_loss: 1.1747 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 1.0122 - accuracy: 0.4694 - val_loss: 1.2696 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 1.0133 - accuracy: 0.4573 - val_loss: 1.2484 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 1.0127 - accuracy: 0.4637 - val_loss: 1.1966 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 1.0189 - accuracy: 0.4648 - val_loss: 1.1248 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 1.0091 - accuracy: 0.4769 - val_loss: 1.1322 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 1.0177 - accuracy: 0.4663 - val_loss: 1.1794 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 1.0148 - accuracy: 0.4794 - val_loss: 1.2039 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 1.0134 - accuracy: 0.4555 - val_loss: 1.2454 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 1.0130 - accuracy: 0.4686 - val_loss: 1.1467 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 1.0061 - accuracy: 0.4805 - val_loss: 1.1771 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 1.0129 - accuracy: 0.4588 - val_loss: 1.1498 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 1.0094 - accuracy: 0.4686 - val_loss: 1.2180 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 1.0082 - accuracy: 0.4534 - val_loss: 1.2114 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 1.0079 - accuracy: 0.4905 - val_loss: 1.1738 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 1.0064 - accuracy: 0.4820 - val_loss: 1.1734 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 1.0068 - accuracy: 0.4702 - val_loss: 1.2174 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 1.0125 - accuracy: 0.4614 - val_loss: 1.1821 - val_accuracy: 0.3364 - 1s/epoch - 5ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 1.0122 - accuracy: 0.4735 - val_loss: 1.1991 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 1.0112 - accuracy: 0.4699 - val_loss: 1.1590 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 1.0097 - accuracy: 0.4673 - val_loss: 1.2447 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 1.0023 - accuracy: 0.4781 - val_loss: 1.2134 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 1.0078 - accuracy: 0.4712 - val_loss: 1.1951 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 1.0022 - accuracy: 0.4653 - val_loss: 1.1695 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 1.0123 - accuracy: 0.4645 - val_loss: 1.1342 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 1.0068 - accuracy: 0.4784 - val_loss: 1.1277 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 1.0036 - accuracy: 0.4799 - val_loss: 1.1387 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 1.0044 - accuracy: 0.4771 - val_loss: 1.1469 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 1.0040 - accuracy: 0.4658 - val_loss: 1.1701 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 1.0001 - accuracy: 0.4743 - val_loss: 1.2367 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 1.0110 - accuracy: 0.4730 - val_loss: 1.2364 - val_accuracy: 0.3364 - 1s/epoch - 5ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.9980 - accuracy: 0.4810 - val_loss: 1.1932 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 1.0068 - accuracy: 0.4717 - val_loss: 1.1385 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 1.0027 - accuracy: 0.4743 - val_loss: 1.1347 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 1.0110 - accuracy: 0.4681 - val_loss: 1.2057 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 1.0035 - accuracy: 0.4722 - val_loss: 1.1624 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 1.0090 - accuracy: 0.4678 - val_loss: 1.1252 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4637 - val_loss: 1.1174 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 1.0120 - accuracy: 0.4624 - val_loss: 1.1446 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 1.0036 - accuracy: 0.4776 - val_loss: 1.1201 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 1.0123 - accuracy: 0.4715 - val_loss: 1.1041 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 1.0019 - accuracy: 0.4733 - val_loss: 1.0980 - val_accuracy: 0.3683 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 1.0017 - accuracy: 0.4787 - val_loss: 1.1327 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 1.0050 - accuracy: 0.4763 - val_loss: 1.1421 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.9998 - accuracy: 0.4715 - val_loss: 1.1906 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 1.0028 - accuracy: 0.4792 - val_loss: 1.1937 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 1.0133 - accuracy: 0.4650 - val_loss: 1.1217 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9994 - accuracy: 0.4769 - val_loss: 1.2038 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 1.0070 - accuracy: 0.4637 - val_loss: 1.2121 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 1.0055 - accuracy: 0.4699 - val_loss: 1.2157 - val_accuracy: 0.3364 - 1s/epoch - 5ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 1.0111 - accuracy: 0.4715 - val_loss: 1.1866 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 1.0001 - accuracy: 0.4761 - val_loss: 1.2328 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 1.0141 - accuracy: 0.4632 - val_loss: 1.1988 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 1.0156 - accuracy: 0.4640 - val_loss: 1.2105 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 1.0018 - accuracy: 0.4694 - val_loss: 1.1837 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 1.0065 - accuracy: 0.4712 - val_loss: 1.1598 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 1.0059 - accuracy: 0.4792 - val_loss: 1.1588 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 1.0053 - accuracy: 0.4694 - val_loss: 1.1714 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 1.0004 - accuracy: 0.4776 - val_loss: 1.1682 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 1.0108 - accuracy: 0.4691 - val_loss: 1.2148 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index for this split: [   1    2    3 ... 4856 4857 4858]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   0   10   12   13   16   29   36   39   40   43   46   66   73   75\n",
      "   85   88   91   99  100  102  105  110  111  117  123  124  127  128\n",
      "  132  133  136  153  157  159  160  174  177  190  192  193  195  204\n",
      "  208  210  212  214  217  232  244  266  269  286  296  309  316  326\n",
      "  332  335  344  368  369  370  373  383  391  392  394  398  399  401\n",
      "  403  404  405  406  410  416  423  441  444  452  453  459  476  492\n",
      "  494  497  511  513  514  518  521  525  531  534  535  537  546  547\n",
      "  551  554  556  565  575  579  596  597  600  601  616  635  636  646\n",
      "  657  663  664  665  669  672  684  685  687  693  694  698  701  714\n",
      "  730  731  733  738  740  742  743  746  749  752  756  759  766  768\n",
      "  770  774  787  789  790  795  801  802  804  816  817  818  822  825\n",
      "  830  832  842  847  853  854  856  857  859  861  862  874  876  882\n",
      "  893  910  913  925  927  945  946  958  965  966  971  972  975  976\n",
      "  977  991  998 1002 1013 1018 1043 1049 1056 1057 1065 1066 1069 1070\n",
      " 1078 1082 1089 1090 1097 1100 1111 1112 1116 1127 1128 1130 1133 1134\n",
      " 1145 1152 1156 1159 1162 1167 1170 1175 1177 1181 1182 1186 1187 1189\n",
      " 1192 1198 1201 1204 1205 1207 1212 1214 1219 1221 1225 1227 1230 1235\n",
      " 1240 1244 1249 1256 1258 1259 1261 1268 1270 1275 1279 1290 1293 1296\n",
      " 1300 1312 1314 1317 1321 1328 1347 1362 1365 1371 1373 1376 1378 1383\n",
      " 1390 1391 1392 1395 1397 1401 1404 1407 1411 1422 1432 1434 1447 1450\n",
      " 1452 1459 1460 1462 1476 1479 1483 1486 1489 1495 1523 1526 1527 1528\n",
      " 1534 1544 1547 1548 1553 1558 1568 1571 1579 1586 1587 1594 1599 1604\n",
      " 1607 1609 1621 1627 1628 1636 1642 1648 1652 1655 1656 1661 1670 1671\n",
      " 1673 1683 1689 1690 1700 1706 1708 1712 1713 1721 1725 1728 1730 1735\n",
      " 1737 1742 1743 1755 1760 1762 1771 1777 1778 1782 1785 1786 1805 1812\n",
      " 1815 1816 1820 1829 1830 1832 1837 1843 1849 1850 1851 1856 1859 1862\n",
      " 1869 1874 1880 1884 1895 1899 1910 1918 1921 1930 1932 1937 1943 1944\n",
      " 1949 1950 1957 1968 1970 1974 1976 1984 1986 1991 2005 2006 2007 2010\n",
      " 2013 2014 2015 2017 2018 2034 2036 2039 2041 2042 2052 2054 2060 2064\n",
      " 2077 2083 2084 2095 2097 2110 2116 2123 2129 2131 2132 2140 2142 2147\n",
      " 2151 2156 2158 2167 2174 2175 2176 2179 2180 2184 2190 2201 2203 2206\n",
      " 2210 2227 2235 2237 2239 2244 2247 2248 2259 2264 2272 2275 2281 2283\n",
      " 2285 2294 2311 2313 2319 2321 2325 2327 2329 2336 2345 2359 2361 2362\n",
      " 2367 2377 2382 2383 2391 2395 2397 2404 2407 2408 2412 2418 2420 2429\n",
      " 2430 2438 2441 2451 2461 2474 2478 2479 2484 2488 2494 2499 2511 2518\n",
      " 2519 2525 2531 2538 2541 2555 2563 2571 2580 2583 2585 2588 2594 2596\n",
      " 2597 2598 2599 2600 2603 2605 2608 2612 2616 2620 2631 2633 2634 2635\n",
      " 2636 2651 2652 2653 2654 2662 2667 2670 2680 2684 2690 2691 2701 2704\n",
      " 2706 2714 2718 2723 2726 2727 2730 2732 2749 2754 2758 2759 2764 2765\n",
      " 2776 2788 2794 2801 2802 2805 2814 2818 2832 2845 2854 2857 2864 2866\n",
      " 2868 2877 2878 2880 2883 2885 2889 2894 2896 2897 2899 2900 2903 2905\n",
      " 2909 2911 2918 2927 2931 2944 2945 2946 2952 2954 2958 2961 2967 2968\n",
      " 2973 2977 2982 2985 2992 2996 3003 3011 3016 3017 3026 3033 3040 3043\n",
      " 3044 3052 3054 3055 3072 3075 3079 3081 3084 3085 3086 3087 3097 3104\n",
      " 3120 3121 3127 3137 3138 3140 3149 3158 3160 3165 3167 3177 3179 3191\n",
      " 3194 3200 3213 3215 3251 3252 3255 3261 3273 3280 3282 3289 3304 3306\n",
      " 3312 3316 3320 3331 3334 3335 3337 3340 3350 3353 3354 3358 3359 3360\n",
      " 3365 3367 3376 3377 3381 3386 3387 3389 3399 3404 3409 3411 3416 3423\n",
      " 3425 3426 3432 3433 3440 3446 3453 3459 3461 3462 3463 3472 3478 3481\n",
      " 3482 3484 3490 3491 3493 3507 3509 3523 3526 3528 3533 3534 3537 3539\n",
      " 3547 3552 3554 3558 3570 3576 3578 3583 3584 3585 3598 3600 3605 3606\n",
      " 3608 3610 3612 3613 3614 3616 3620 3621 3627 3633 3635 3661 3662 3663\n",
      " 3679 3682 3684 3690 3699 3704 3706 3708 3711 3714 3716 3719 3720 3728\n",
      " 3730 3735 3737 3739 3744 3746 3751 3753 3754 3758 3760 3761 3777 3782\n",
      " 3786 3790 3795 3800 3803 3804 3813 3818 3824 3828 3833 3835 3837 3840\n",
      " 3844 3845 3849 3850 3858 3861 3865 3868 3869 3876 3877 3879 3891 3905\n",
      " 3909 3923 3930 3941 3951 3960 3961 3965 3967 3972 3978 3982 3985 3987\n",
      " 3989 3993 3994 3995 4001 4006 4018 4023 4027 4030 4033 4034 4036 4037\n",
      " 4043 4049 4054 4055 4067 4068 4078 4092 4105 4112 4115 4116 4120 4130\n",
      " 4132 4137 4138 4145 4157 4166 4167 4180 4184 4185 4187 4190 4195 4205\n",
      " 4206 4215 4222 4224 4240 4249 4255 4256 4259 4261 4263 4267 4268 4275\n",
      " 4284 4286 4289 4290 4294 4296 4297 4311 4313 4315 4322 4335 4341 4354\n",
      " 4362 4363 4365 4371 4394 4406 4408 4416 4418 4420 4433 4434 4444 4448\n",
      " 4449 4458 4466 4472 4475 4487 4488 4489 4492 4497 4498 4500 4508 4509\n",
      " 4510 4516 4518 4528 4530 4533 4540 4544 4546 4547 4548 4561 4576 4577\n",
      " 4578 4579 4585 4591 4593 4596 4600 4607 4613 4615 4616 4617 4620 4622\n",
      " 4626 4633 4659 4664 4674 4675 4683 4688 4689 4694 4700 4704 4707 4711\n",
      " 4721 4724 4727 4729 4733 4734 4737 4741 4748 4750 4752 4754 4757 4758\n",
      " 4763 4768 4772 4782 4788 4789 4794 4795 4800 4802 4803 4807 4818 4821\n",
      " 4826 4827 4830 4845 4850 4859]\n",
      "Number of samples for test set: 972\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:49:41.188120: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_317/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.1020 - accuracy: 0.3413 - val_loss: 1.0973 - val_accuracy: 0.3200 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0954 - accuracy: 0.3565 - val_loss: 1.0953 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0974 - accuracy: 0.3472 - val_loss: 1.0951 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0929 - accuracy: 0.3657 - val_loss: 1.0943 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0915 - accuracy: 0.3663 - val_loss: 1.0960 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0907 - accuracy: 0.3781 - val_loss: 1.0963 - val_accuracy: 0.3539 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0890 - accuracy: 0.3807 - val_loss: 1.0934 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0864 - accuracy: 0.3912 - val_loss: 1.0948 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0864 - accuracy: 0.3745 - val_loss: 1.1016 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0851 - accuracy: 0.3773 - val_loss: 1.1055 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0801 - accuracy: 0.3930 - val_loss: 1.1214 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0807 - accuracy: 0.3994 - val_loss: 1.1187 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0783 - accuracy: 0.3987 - val_loss: 1.1083 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0757 - accuracy: 0.4087 - val_loss: 1.1433 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0746 - accuracy: 0.4033 - val_loss: 1.1388 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0748 - accuracy: 0.4051 - val_loss: 1.1133 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 1.0715 - accuracy: 0.4084 - val_loss: 1.1198 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0711 - accuracy: 0.4151 - val_loss: 1.1197 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0674 - accuracy: 0.4182 - val_loss: 1.1214 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0665 - accuracy: 0.4092 - val_loss: 1.1169 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 1.0604 - accuracy: 0.4192 - val_loss: 1.1087 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 1.0601 - accuracy: 0.4223 - val_loss: 1.1092 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 1.0626 - accuracy: 0.4200 - val_loss: 1.1160 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 1.0639 - accuracy: 0.4146 - val_loss: 1.1400 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 1.0561 - accuracy: 0.4231 - val_loss: 1.1370 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 1.0554 - accuracy: 0.4375 - val_loss: 1.1269 - val_accuracy: 0.3097 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 1.0576 - accuracy: 0.4298 - val_loss: 1.1363 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 1.0595 - accuracy: 0.4210 - val_loss: 1.1385 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 1.0564 - accuracy: 0.4177 - val_loss: 1.1354 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 1.0578 - accuracy: 0.4144 - val_loss: 1.1288 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 1.0532 - accuracy: 0.4324 - val_loss: 1.1323 - val_accuracy: 0.3158 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 1.0514 - accuracy: 0.4244 - val_loss: 1.1572 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 1.0496 - accuracy: 0.4475 - val_loss: 1.1468 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 1.0517 - accuracy: 0.4344 - val_loss: 1.1705 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 1.0515 - accuracy: 0.4375 - val_loss: 1.1244 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 1.0461 - accuracy: 0.4396 - val_loss: 1.1162 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 1.0438 - accuracy: 0.4318 - val_loss: 1.1370 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 1.0470 - accuracy: 0.4339 - val_loss: 1.1059 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 1.0423 - accuracy: 0.4462 - val_loss: 1.1629 - val_accuracy: 0.3138 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 1.0459 - accuracy: 0.4429 - val_loss: 1.1504 - val_accuracy: 0.3169 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 1.0449 - accuracy: 0.4411 - val_loss: 1.1295 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 1.0445 - accuracy: 0.4370 - val_loss: 1.1425 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 1.0486 - accuracy: 0.4321 - val_loss: 1.1329 - val_accuracy: 0.3117 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 1.0439 - accuracy: 0.4406 - val_loss: 1.1117 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 1.0455 - accuracy: 0.4462 - val_loss: 1.0991 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 1.0386 - accuracy: 0.4450 - val_loss: 1.1053 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 1.0452 - accuracy: 0.4447 - val_loss: 1.1028 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 1.0386 - accuracy: 0.4506 - val_loss: 1.0989 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 1.0329 - accuracy: 0.4475 - val_loss: 1.0959 - val_accuracy: 0.3580 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 1.0327 - accuracy: 0.4414 - val_loss: 1.1004 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 1.0379 - accuracy: 0.4439 - val_loss: 1.1393 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 1.0410 - accuracy: 0.4475 - val_loss: 1.1279 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 1.0357 - accuracy: 0.4563 - val_loss: 1.1021 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 1.0314 - accuracy: 0.4537 - val_loss: 1.0985 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 1.0314 - accuracy: 0.4624 - val_loss: 1.0997 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 1.0289 - accuracy: 0.4694 - val_loss: 1.0906 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 1.0325 - accuracy: 0.4563 - val_loss: 1.0912 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 1.0303 - accuracy: 0.4568 - val_loss: 1.1024 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 1.0319 - accuracy: 0.4601 - val_loss: 1.1218 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 1.0286 - accuracy: 0.4619 - val_loss: 1.1114 - val_accuracy: 0.3179 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 1.0315 - accuracy: 0.4480 - val_loss: 1.1221 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 1.0273 - accuracy: 0.4699 - val_loss: 1.1182 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 1.0265 - accuracy: 0.4635 - val_loss: 1.1044 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 1.0260 - accuracy: 0.4486 - val_loss: 1.0948 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 1.0229 - accuracy: 0.4596 - val_loss: 1.0892 - val_accuracy: 0.3704 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 1.0337 - accuracy: 0.4439 - val_loss: 1.1003 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 1.0215 - accuracy: 0.4596 - val_loss: 1.0978 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 1.0310 - accuracy: 0.4573 - val_loss: 1.1202 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 1.0302 - accuracy: 0.4650 - val_loss: 1.0930 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 1.0344 - accuracy: 0.4604 - val_loss: 1.0935 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 1.0274 - accuracy: 0.4645 - val_loss: 1.0998 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 1.0229 - accuracy: 0.4673 - val_loss: 1.1044 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 1.0225 - accuracy: 0.4624 - val_loss: 1.1036 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 1.0238 - accuracy: 0.4712 - val_loss: 1.1148 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 1.0201 - accuracy: 0.4745 - val_loss: 1.1005 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 1.0287 - accuracy: 0.4655 - val_loss: 1.0963 - val_accuracy: 0.3807 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 1.0304 - accuracy: 0.4516 - val_loss: 1.0931 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 1.0222 - accuracy: 0.4648 - val_loss: 1.0951 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 1.0217 - accuracy: 0.4681 - val_loss: 1.0884 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 1.0266 - accuracy: 0.4658 - val_loss: 1.0910 - val_accuracy: 0.3673 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 1.0231 - accuracy: 0.4635 - val_loss: 1.1037 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 1.0168 - accuracy: 0.4712 - val_loss: 1.1146 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 1.0196 - accuracy: 0.4766 - val_loss: 1.0928 - val_accuracy: 0.3776 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 1.0239 - accuracy: 0.4558 - val_loss: 1.0933 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 1.0180 - accuracy: 0.4807 - val_loss: 1.1029 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 1.0207 - accuracy: 0.4715 - val_loss: 1.0923 - val_accuracy: 0.3560 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 1.0179 - accuracy: 0.4725 - val_loss: 1.0969 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 1.0158 - accuracy: 0.4820 - val_loss: 1.0958 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 1.0123 - accuracy: 0.4756 - val_loss: 1.0931 - val_accuracy: 0.3642 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 1.0120 - accuracy: 0.4766 - val_loss: 1.0994 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 1.0210 - accuracy: 0.4699 - val_loss: 1.0946 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 1.0178 - accuracy: 0.4694 - val_loss: 1.1167 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 1.0151 - accuracy: 0.4586 - val_loss: 1.0904 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 1.0166 - accuracy: 0.4697 - val_loss: 1.1004 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 1.0148 - accuracy: 0.4712 - val_loss: 1.1010 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 1.0162 - accuracy: 0.4735 - val_loss: 1.1057 - val_accuracy: 0.3241 - 994ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 1.0158 - accuracy: 0.4789 - val_loss: 1.0981 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 1.0137 - accuracy: 0.4758 - val_loss: 1.0970 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 1.0139 - accuracy: 0.4686 - val_loss: 1.1005 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4743 - val_loss: 1.1187 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 1.0171 - accuracy: 0.4738 - val_loss: 1.0972 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 1.0109 - accuracy: 0.4781 - val_loss: 1.1022 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 1.0201 - accuracy: 0.4720 - val_loss: 1.0988 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 1.0087 - accuracy: 0.4841 - val_loss: 1.0946 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 1.0055 - accuracy: 0.4807 - val_loss: 1.0935 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 1.0150 - accuracy: 0.4761 - val_loss: 1.0965 - val_accuracy: 0.3683 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 1.0127 - accuracy: 0.4735 - val_loss: 1.0920 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 1.0109 - accuracy: 0.4812 - val_loss: 1.0967 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 1.0168 - accuracy: 0.4720 - val_loss: 1.1072 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 1.0153 - accuracy: 0.4704 - val_loss: 1.1065 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 1.0132 - accuracy: 0.4748 - val_loss: 1.1031 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 1.0139 - accuracy: 0.4653 - val_loss: 1.1085 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 1.0112 - accuracy: 0.4843 - val_loss: 1.1102 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 1.0144 - accuracy: 0.4861 - val_loss: 1.1069 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 1.0076 - accuracy: 0.4900 - val_loss: 1.1211 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 1.0068 - accuracy: 0.4884 - val_loss: 1.1059 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 1.0087 - accuracy: 0.4763 - val_loss: 1.0979 - val_accuracy: 0.3549 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 1.0080 - accuracy: 0.4771 - val_loss: 1.1007 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 1.0074 - accuracy: 0.4799 - val_loss: 1.0986 - val_accuracy: 0.3868 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 1.0215 - accuracy: 0.4722 - val_loss: 1.0993 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 1.0144 - accuracy: 0.4833 - val_loss: 1.0990 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 1.0094 - accuracy: 0.4853 - val_loss: 1.0953 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 1.0168 - accuracy: 0.4709 - val_loss: 1.0991 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 1.0055 - accuracy: 0.4866 - val_loss: 1.0938 - val_accuracy: 0.3642 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 1.0124 - accuracy: 0.4774 - val_loss: 1.0973 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 1.0011 - accuracy: 0.4941 - val_loss: 1.0969 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 1.0055 - accuracy: 0.4848 - val_loss: 1.1107 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 1.0132 - accuracy: 0.4743 - val_loss: 1.1153 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 1.0149 - accuracy: 0.4823 - val_loss: 1.1281 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 1.0085 - accuracy: 0.4838 - val_loss: 1.1120 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 1.0043 - accuracy: 0.4784 - val_loss: 1.1304 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 1.0098 - accuracy: 0.4833 - val_loss: 1.1399 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 1.0029 - accuracy: 0.4949 - val_loss: 1.1137 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 1.0068 - accuracy: 0.4946 - val_loss: 1.1162 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 1.0047 - accuracy: 0.4853 - val_loss: 1.1086 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 1.0077 - accuracy: 0.4784 - val_loss: 1.0990 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4846 - val_loss: 1.1295 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 1.0018 - accuracy: 0.4805 - val_loss: 1.1248 - val_accuracy: 0.3230 - 1s/epoch - 5ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 1.0123 - accuracy: 0.4817 - val_loss: 1.1426 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 1.0092 - accuracy: 0.4833 - val_loss: 1.1360 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 1.0060 - accuracy: 0.4887 - val_loss: 1.1134 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 0.9960 - accuracy: 0.4972 - val_loss: 1.1224 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 1.0036 - accuracy: 0.4810 - val_loss: 1.1135 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 1.0024 - accuracy: 0.4956 - val_loss: 1.1142 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 1.0003 - accuracy: 0.4923 - val_loss: 1.0978 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 1.0028 - accuracy: 0.4856 - val_loss: 1.1029 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 1.0123 - accuracy: 0.4792 - val_loss: 1.1337 - val_accuracy: 0.3632 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 1.0008 - accuracy: 0.4825 - val_loss: 1.0911 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 1.0100 - accuracy: 0.4812 - val_loss: 1.0985 - val_accuracy: 0.3693 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 1.0047 - accuracy: 0.4869 - val_loss: 1.0961 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 1.0106 - accuracy: 0.4812 - val_loss: 1.1033 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 1.0088 - accuracy: 0.4861 - val_loss: 1.1117 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 1.0034 - accuracy: 0.4861 - val_loss: 1.1008 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 1.0051 - accuracy: 0.4913 - val_loss: 1.1098 - val_accuracy: 0.3807 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 0.9978 - accuracy: 0.4918 - val_loss: 1.0950 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 1.0027 - accuracy: 0.4843 - val_loss: 1.0999 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 0.9998 - accuracy: 0.4784 - val_loss: 1.1082 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 1.0078 - accuracy: 0.4787 - val_loss: 1.1301 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 1.0055 - accuracy: 0.4823 - val_loss: 1.1121 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 0.9979 - accuracy: 0.4961 - val_loss: 1.1149 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9980 - accuracy: 0.4941 - val_loss: 1.1200 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 1.0043 - accuracy: 0.4884 - val_loss: 1.1100 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 1.0122 - accuracy: 0.4838 - val_loss: 1.1144 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 0.9986 - accuracy: 0.4943 - val_loss: 1.1149 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 0.9998 - accuracy: 0.4877 - val_loss: 1.0981 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 1.0041 - accuracy: 0.4951 - val_loss: 1.0968 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 0.9946 - accuracy: 0.4866 - val_loss: 1.1060 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 1.0025 - accuracy: 0.4812 - val_loss: 1.0994 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 1.0085 - accuracy: 0.4781 - val_loss: 1.1209 - val_accuracy: 0.3385 - 1s/epoch - 5ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 0.9971 - accuracy: 0.5013 - val_loss: 1.0986 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 1.0007 - accuracy: 0.4969 - val_loss: 1.1140 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 1.0030 - accuracy: 0.4861 - val_loss: 1.1288 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 0.9989 - accuracy: 0.4954 - val_loss: 1.1032 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 1.0014 - accuracy: 0.4864 - val_loss: 1.1064 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 0.9976 - accuracy: 0.4961 - val_loss: 1.1179 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 1.0030 - accuracy: 0.4887 - val_loss: 1.1069 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 0.9926 - accuracy: 0.4910 - val_loss: 1.1091 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 1.0020 - accuracy: 0.4913 - val_loss: 1.1360 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 0.9979 - accuracy: 0.4869 - val_loss: 1.1108 - val_accuracy: 0.3282 - 1s/epoch - 5ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 0.9991 - accuracy: 0.4956 - val_loss: 1.0984 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 1.0029 - accuracy: 0.4745 - val_loss: 1.0900 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 1.0012 - accuracy: 0.4889 - val_loss: 1.1371 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 1.0009 - accuracy: 0.4802 - val_loss: 1.1294 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 1.0057 - accuracy: 0.4869 - val_loss: 1.1404 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 1.0022 - accuracy: 0.4835 - val_loss: 1.1147 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 1.0026 - accuracy: 0.4869 - val_loss: 1.1064 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 0.9979 - accuracy: 0.4982 - val_loss: 1.1025 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 0.9967 - accuracy: 0.4954 - val_loss: 1.1103 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 0.9909 - accuracy: 0.4902 - val_loss: 1.1137 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 1.0010 - accuracy: 0.4843 - val_loss: 1.1047 - val_accuracy: 0.3889 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 1.0047 - accuracy: 0.4933 - val_loss: 1.1058 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9971 - accuracy: 0.4974 - val_loss: 1.1165 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 1.0032 - accuracy: 0.4961 - val_loss: 1.1284 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 1.0015 - accuracy: 0.5010 - val_loss: 1.1010 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 0.9921 - accuracy: 0.4951 - val_loss: 1.1060 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 0.9998 - accuracy: 0.4990 - val_loss: 1.1097 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 1.0035 - accuracy: 0.4877 - val_loss: 1.0950 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 1.0103 - accuracy: 0.4918 - val_loss: 1.1164 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 1.0010 - accuracy: 0.4985 - val_loss: 1.1340 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 0.9944 - accuracy: 0.4900 - val_loss: 1.0987 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.9960 - accuracy: 0.4905 - val_loss: 1.1210 - val_accuracy: 0.3663 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 0.9992 - accuracy: 0.4830 - val_loss: 1.1147 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 0.9954 - accuracy: 0.4941 - val_loss: 1.1158 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 0.9980 - accuracy: 0.4938 - val_loss: 1.1183 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 0.9890 - accuracy: 0.4979 - val_loss: 1.0946 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 0.9985 - accuracy: 0.4882 - val_loss: 1.0962 - val_accuracy: 0.3549 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 1.0005 - accuracy: 0.4951 - val_loss: 1.0954 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 1.0002 - accuracy: 0.4851 - val_loss: 1.0953 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 0.9968 - accuracy: 0.4892 - val_loss: 1.0976 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 0.9920 - accuracy: 0.4946 - val_loss: 1.1068 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 0.9940 - accuracy: 0.4812 - val_loss: 1.1020 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9978 - accuracy: 0.4838 - val_loss: 1.0974 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9981 - accuracy: 0.4933 - val_loss: 1.0964 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 1.0009 - accuracy: 0.5018 - val_loss: 1.0945 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 0.9997 - accuracy: 0.4848 - val_loss: 1.0911 - val_accuracy: 0.3981 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.9956 - accuracy: 0.4931 - val_loss: 1.1191 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.9898 - accuracy: 0.4910 - val_loss: 1.1143 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 1.0023 - accuracy: 0.4913 - val_loss: 1.0970 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.9991 - accuracy: 0.4820 - val_loss: 1.1069 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 1.0010 - accuracy: 0.4848 - val_loss: 1.1123 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 1.0047 - accuracy: 0.4895 - val_loss: 1.1025 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.9857 - accuracy: 0.4905 - val_loss: 1.1017 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.9995 - accuracy: 0.4889 - val_loss: 1.0988 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 1.0001 - accuracy: 0.5021 - val_loss: 1.1167 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 1.0061 - accuracy: 0.4877 - val_loss: 1.1003 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 0.9956 - accuracy: 0.4889 - val_loss: 1.1033 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 0.9988 - accuracy: 0.4799 - val_loss: 1.1227 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 1.0040 - accuracy: 0.4853 - val_loss: 1.0963 - val_accuracy: 0.4115 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 0.9949 - accuracy: 0.4990 - val_loss: 1.0990 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 0.9986 - accuracy: 0.4946 - val_loss: 1.0988 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 1.0010 - accuracy: 0.4923 - val_loss: 1.1092 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.9971 - accuracy: 0.4835 - val_loss: 1.0970 - val_accuracy: 0.3827 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 1.0035 - accuracy: 0.4936 - val_loss: 1.0990 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.9949 - accuracy: 0.4910 - val_loss: 1.1224 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 0.9961 - accuracy: 0.4928 - val_loss: 1.1033 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 1.0023 - accuracy: 0.4882 - val_loss: 1.1602 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 0.9894 - accuracy: 0.4925 - val_loss: 1.1471 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9986 - accuracy: 0.4843 - val_loss: 1.1222 - val_accuracy: 0.3220 - 1s/epoch - 5ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.9923 - accuracy: 0.4997 - val_loss: 1.1311 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 0.9991 - accuracy: 0.5015 - val_loss: 1.1119 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9965 - accuracy: 0.4902 - val_loss: 1.1021 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 1.0013 - accuracy: 0.4897 - val_loss: 1.1004 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.9932 - accuracy: 0.5044 - val_loss: 1.1078 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 1.0073 - accuracy: 0.4841 - val_loss: 1.1098 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 1.0017 - accuracy: 0.4892 - val_loss: 1.1336 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 1.0039 - accuracy: 0.4853 - val_loss: 1.1376 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 1.0013 - accuracy: 0.4949 - val_loss: 1.1174 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.9926 - accuracy: 0.4946 - val_loss: 1.1110 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.9895 - accuracy: 0.4995 - val_loss: 1.1084 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9975 - accuracy: 0.4895 - val_loss: 1.0977 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "Train index for this split: [   0    1    2 ... 4856 4857 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   4    7    9   11   26   34   37   41   44   53   54   68   77   80\n",
      "   82   94  104  109  112  116  118  119  125  139  146  147  158  161\n",
      "  162  165  171  173  175  184  201  220  228  236  237  243  250  260\n",
      "  261  265  271  272  273  276  277  279  280  283  284  287  294  295\n",
      "  298  300  302  305  307  310  312  314  315  320  321  329  340  350\n",
      "  352  358  366  367  374  378  379  388  393  396  413  418  425  428\n",
      "  439  443  450  456  458  466  468  473  477  479  482  505  507  508\n",
      "  517  523  528  538  540  548  550  552  555  561  566  570  572  573\n",
      "  584  598  599  605  611  614  617  618  621  624  632  633  647  648\n",
      "  649  653  654  655  660  666  668  670  675  677  680  683  697  706\n",
      "  707  708  709  710  718  720  724  726  727  729  734  736  750  755\n",
      "  767  784  791  794  796  803  807  811  819  826  836  839  843  848\n",
      "  860  866  871  875  883  885  891  897  899  901  903  904  914  917\n",
      "  923  930  932  936  937  938  939  942  944  947  948  956  963  964\n",
      "  974  988  994  996  997 1000 1001 1006 1008 1012 1015 1019 1036 1052\n",
      " 1054 1059 1072 1073 1074 1075 1088 1091 1093 1103 1108 1113 1149 1153\n",
      " 1161 1166 1172 1183 1185 1193 1194 1195 1200 1202 1206 1209 1215 1223\n",
      " 1228 1231 1237 1241 1248 1253 1260 1264 1266 1273 1274 1280 1282 1298\n",
      " 1302 1307 1311 1313 1327 1329 1339 1346 1348 1349 1351 1355 1358 1359\n",
      " 1361 1363 1366 1387 1396 1402 1405 1406 1408 1417 1418 1423 1429 1435\n",
      " 1436 1438 1439 1445 1449 1455 1457 1463 1468 1470 1472 1485 1487 1490\n",
      " 1492 1496 1500 1501 1508 1517 1518 1521 1524 1532 1538 1541 1542 1549\n",
      " 1550 1559 1560 1566 1574 1575 1576 1581 1591 1592 1597 1598 1600 1603\n",
      " 1606 1613 1625 1626 1629 1630 1633 1640 1643 1647 1654 1658 1664 1676\n",
      " 1688 1693 1696 1698 1707 1709 1711 1714 1715 1716 1718 1720 1724 1727\n",
      " 1732 1736 1738 1750 1752 1753 1759 1761 1764 1767 1773 1779 1793 1801\n",
      " 1803 1808 1810 1819 1822 1825 1828 1831 1835 1836 1838 1839 1845 1853\n",
      " 1854 1864 1865 1870 1871 1886 1891 1893 1908 1912 1916 1928 1935 1948\n",
      " 1951 1955 1959 1961 1962 1963 1972 1979 1982 1983 1985 1988 1994 2004\n",
      " 2011 2016 2019 2022 2023 2035 2043 2044 2059 2061 2063 2065 2067 2068\n",
      " 2072 2074 2075 2078 2079 2085 2093 2094 2099 2101 2102 2103 2105 2107\n",
      " 2108 2115 2133 2137 2138 2141 2144 2149 2152 2159 2166 2170 2185 2188\n",
      " 2199 2200 2204 2213 2220 2222 2224 2226 2230 2234 2242 2261 2262 2265\n",
      " 2266 2270 2289 2290 2295 2302 2305 2306 2320 2326 2331 2337 2338 2341\n",
      " 2346 2348 2350 2357 2375 2376 2393 2396 2398 2405 2411 2414 2419 2421\n",
      " 2422 2427 2436 2443 2444 2450 2457 2460 2466 2469 2470 2472 2475 2481\n",
      " 2482 2487 2489 2491 2492 2503 2508 2509 2521 2524 2536 2544 2551 2556\n",
      " 2562 2565 2566 2567 2568 2574 2587 2595 2607 2609 2621 2626 2629 2630\n",
      " 2632 2637 2638 2641 2645 2650 2657 2666 2671 2674 2677 2683 2688 2692\n",
      " 2695 2698 2699 2700 2731 2733 2736 2743 2747 2752 2757 2761 2774 2780\n",
      " 2784 2785 2786 2792 2795 2803 2806 2809 2812 2813 2816 2819 2820 2829\n",
      " 2831 2836 2838 2843 2859 2861 2862 2867 2879 2887 2902 2915 2922 2923\n",
      " 2924 2925 2926 2934 2938 2941 2942 2963 2966 2980 2986 2987 2997 3007\n",
      " 3018 3019 3021 3025 3027 3030 3049 3053 3056 3060 3063 3069 3073 3080\n",
      " 3083 3096 3098 3105 3109 3114 3116 3123 3125 3126 3129 3132 3133 3141\n",
      " 3147 3161 3172 3174 3186 3188 3189 3190 3218 3219 3225 3226 3229 3230\n",
      " 3232 3235 3244 3248 3250 3253 3267 3268 3274 3283 3287 3294 3302 3303\n",
      " 3317 3319 3321 3327 3329 3332 3338 3346 3361 3363 3373 3379 3390 3393\n",
      " 3400 3418 3419 3422 3427 3431 3434 3439 3443 3448 3450 3451 3454 3455\n",
      " 3457 3475 3485 3495 3500 3510 3512 3516 3518 3519 3521 3525 3536 3544\n",
      " 3553 3560 3573 3575 3577 3580 3586 3591 3602 3604 3607 3609 3615 3617\n",
      " 3619 3628 3629 3630 3636 3646 3649 3653 3654 3655 3660 3665 3666 3667\n",
      " 3669 3670 3672 3675 3677 3683 3688 3692 3694 3710 3712 3713 3718 3724\n",
      " 3727 3731 3733 3736 3742 3743 3757 3762 3763 3766 3778 3787 3802 3806\n",
      " 3807 3814 3816 3819 3822 3826 3830 3836 3838 3843 3851 3852 3854 3856\n",
      " 3872 3878 3884 3887 3889 3890 3901 3914 3915 3921 3927 3931 3933 3935\n",
      " 3939 3940 3943 3944 3946 3950 3956 3958 3963 3964 3969 3971 3980 3983\n",
      " 3984 3988 3990 3991 3998 4024 4028 4031 4038 4039 4042 4044 4046 4048\n",
      " 4051 4056 4057 4060 4063 4065 4070 4071 4072 4075 4087 4090 4104 4106\n",
      " 4111 4114 4118 4126 4128 4133 4141 4147 4151 4153 4154 4159 4162 4164\n",
      " 4169 4173 4174 4175 4179 4188 4191 4192 4193 4197 4203 4209 4214 4219\n",
      " 4223 4225 4230 4233 4242 4246 4247 4260 4274 4279 4295 4323 4325 4333\n",
      " 4336 4337 4352 4353 4361 4374 4381 4391 4393 4399 4400 4403 4407 4422\n",
      " 4423 4429 4431 4432 4435 4438 4460 4463 4464 4470 4480 4494 4506 4507\n",
      " 4519 4522 4523 4524 4527 4539 4542 4545 4549 4555 4556 4564 4565 4566\n",
      " 4571 4582 4588 4589 4602 4604 4619 4624 4629 4634 4637 4639 4640 4648\n",
      " 4656 4658 4669 4672 4678 4679 4685 4691 4693 4695 4698 4703 4705 4710\n",
      " 4712 4713 4717 4718 4720 4723 4726 4728 4730 4739 4740 4755 4761 4769\n",
      " 4773 4776 4781 4784 4785 4796 4799 4806 4808 4815 4816 4820 4822 4831\n",
      " 4832 4834 4843 4846 4851 4858]\n",
      "Number of samples for test set: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:54:09.068680: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_318/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.1009 - accuracy: 0.3282 - val_loss: 1.0963 - val_accuracy: 0.3591 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0957 - accuracy: 0.3601 - val_loss: 1.0963 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0958 - accuracy: 0.3501 - val_loss: 1.0948 - val_accuracy: 0.3591 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0922 - accuracy: 0.3652 - val_loss: 1.0948 - val_accuracy: 0.3591 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0912 - accuracy: 0.3783 - val_loss: 1.0951 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0903 - accuracy: 0.3704 - val_loss: 1.0942 - val_accuracy: 0.3457 - 986ms/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0858 - accuracy: 0.3773 - val_loss: 1.0944 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0871 - accuracy: 0.3722 - val_loss: 1.0980 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0851 - accuracy: 0.3791 - val_loss: 1.0967 - val_accuracy: 0.3426 - 996ms/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0792 - accuracy: 0.3976 - val_loss: 1.1054 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0791 - accuracy: 0.3835 - val_loss: 1.0989 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0755 - accuracy: 0.3866 - val_loss: 1.0962 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0764 - accuracy: 0.4118 - val_loss: 1.0970 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0732 - accuracy: 0.3951 - val_loss: 1.1066 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0656 - accuracy: 0.4025 - val_loss: 1.0949 - val_accuracy: 0.3519 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0679 - accuracy: 0.3997 - val_loss: 1.1147 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 1.0639 - accuracy: 0.4087 - val_loss: 1.1050 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0620 - accuracy: 0.4133 - val_loss: 1.1150 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0640 - accuracy: 0.4023 - val_loss: 1.1090 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0582 - accuracy: 0.4187 - val_loss: 1.1099 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 1.0669 - accuracy: 0.4074 - val_loss: 1.1130 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 1.0555 - accuracy: 0.4113 - val_loss: 1.1176 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 1.0660 - accuracy: 0.4154 - val_loss: 1.1104 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 1.0563 - accuracy: 0.4169 - val_loss: 1.1097 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 1.0630 - accuracy: 0.4028 - val_loss: 1.1090 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 1.0559 - accuracy: 0.4218 - val_loss: 1.1114 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 1.0592 - accuracy: 0.4084 - val_loss: 1.0983 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 1.0575 - accuracy: 0.4249 - val_loss: 1.1030 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 1.0550 - accuracy: 0.4138 - val_loss: 1.1046 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 1.0541 - accuracy: 0.4172 - val_loss: 1.1030 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 1.0552 - accuracy: 0.4167 - val_loss: 1.1057 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 1.0505 - accuracy: 0.4241 - val_loss: 1.1027 - val_accuracy: 0.3416 - 996ms/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 1.0513 - accuracy: 0.4306 - val_loss: 1.1138 - val_accuracy: 0.3426 - 941ms/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 1.0500 - accuracy: 0.4254 - val_loss: 1.1112 - val_accuracy: 0.3416 - 973ms/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 1.0501 - accuracy: 0.4241 - val_loss: 1.1159 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 1.0503 - accuracy: 0.4295 - val_loss: 1.1120 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 1.0499 - accuracy: 0.4223 - val_loss: 1.1049 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 1.0456 - accuracy: 0.4277 - val_loss: 1.1001 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 1.0483 - accuracy: 0.4162 - val_loss: 1.0952 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 1.0486 - accuracy: 0.4396 - val_loss: 1.0964 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 1.0459 - accuracy: 0.4280 - val_loss: 1.0966 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 1.0472 - accuracy: 0.4370 - val_loss: 1.0942 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 1.0527 - accuracy: 0.4326 - val_loss: 1.0966 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 1.0484 - accuracy: 0.4308 - val_loss: 1.0952 - val_accuracy: 0.4012 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 1.0436 - accuracy: 0.4393 - val_loss: 1.0932 - val_accuracy: 0.3591 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 1.0425 - accuracy: 0.4385 - val_loss: 1.0955 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 1.0460 - accuracy: 0.4290 - val_loss: 1.0943 - val_accuracy: 0.3652 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 1.0435 - accuracy: 0.4306 - val_loss: 1.0951 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 1.0422 - accuracy: 0.4393 - val_loss: 1.0950 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 1.0463 - accuracy: 0.4298 - val_loss: 1.0951 - val_accuracy: 0.3570 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 1.0418 - accuracy: 0.4339 - val_loss: 1.0954 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 1.0346 - accuracy: 0.4354 - val_loss: 1.0990 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 1.0424 - accuracy: 0.4396 - val_loss: 1.0939 - val_accuracy: 0.3848 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 1.0367 - accuracy: 0.4326 - val_loss: 1.0983 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 1.0410 - accuracy: 0.4403 - val_loss: 1.0978 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 1.0426 - accuracy: 0.4298 - val_loss: 1.0964 - val_accuracy: 0.3745 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 1.0343 - accuracy: 0.4349 - val_loss: 1.0987 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 1.0415 - accuracy: 0.4388 - val_loss: 1.1032 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 1.0356 - accuracy: 0.4408 - val_loss: 1.1211 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 1.0364 - accuracy: 0.4457 - val_loss: 1.1116 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 1.0363 - accuracy: 0.4390 - val_loss: 1.1040 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 1.0308 - accuracy: 0.4468 - val_loss: 1.1213 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 1.0363 - accuracy: 0.4403 - val_loss: 1.1174 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 1.0279 - accuracy: 0.4465 - val_loss: 1.0978 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 1.0344 - accuracy: 0.4406 - val_loss: 1.1148 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 1.0357 - accuracy: 0.4424 - val_loss: 1.1163 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 1.0322 - accuracy: 0.4475 - val_loss: 1.1037 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 1.0389 - accuracy: 0.4401 - val_loss: 1.1169 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 1.0326 - accuracy: 0.4447 - val_loss: 1.1238 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 1.0383 - accuracy: 0.4380 - val_loss: 1.1267 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 1.0364 - accuracy: 0.4442 - val_loss: 1.1328 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 1.0330 - accuracy: 0.4480 - val_loss: 1.1199 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 1.0314 - accuracy: 0.4550 - val_loss: 1.1169 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 1.0300 - accuracy: 0.4501 - val_loss: 1.1147 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 1.0264 - accuracy: 0.4493 - val_loss: 1.1049 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 1.0338 - accuracy: 0.4524 - val_loss: 1.1112 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 1.0343 - accuracy: 0.4416 - val_loss: 1.0987 - val_accuracy: 0.4033 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 1.0329 - accuracy: 0.4529 - val_loss: 1.1081 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 1.0253 - accuracy: 0.4419 - val_loss: 1.1198 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 1.0214 - accuracy: 0.4617 - val_loss: 1.1114 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 1.0257 - accuracy: 0.4563 - val_loss: 1.1074 - val_accuracy: 0.3354 - 965ms/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 1.0307 - accuracy: 0.4496 - val_loss: 1.1173 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 1.0182 - accuracy: 0.4689 - val_loss: 1.1031 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 1.0316 - accuracy: 0.4465 - val_loss: 1.1152 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 1.0258 - accuracy: 0.4555 - val_loss: 1.1140 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 1.0257 - accuracy: 0.4560 - val_loss: 1.1045 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 1.0248 - accuracy: 0.4457 - val_loss: 1.1254 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 1.0255 - accuracy: 0.4488 - val_loss: 1.1135 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 1.0247 - accuracy: 0.4527 - val_loss: 1.1105 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 1.0274 - accuracy: 0.4624 - val_loss: 1.1233 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 1.0304 - accuracy: 0.4583 - val_loss: 1.1220 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 1.0195 - accuracy: 0.4666 - val_loss: 1.1562 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 1.0255 - accuracy: 0.4480 - val_loss: 1.1262 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 1.0202 - accuracy: 0.4534 - val_loss: 1.1205 - val_accuracy: 0.3364 - 986ms/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 1.0189 - accuracy: 0.4527 - val_loss: 1.1089 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 1.0220 - accuracy: 0.4498 - val_loss: 1.1152 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 1.0219 - accuracy: 0.4570 - val_loss: 1.1193 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 1.0228 - accuracy: 0.4658 - val_loss: 1.1285 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 1.0225 - accuracy: 0.4660 - val_loss: 1.1178 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 1.0168 - accuracy: 0.4617 - val_loss: 1.1253 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 1.0222 - accuracy: 0.4663 - val_loss: 1.1337 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 1.0182 - accuracy: 0.4702 - val_loss: 1.1180 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 1.0162 - accuracy: 0.4676 - val_loss: 1.1051 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 1.0278 - accuracy: 0.4522 - val_loss: 1.1140 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 1.0161 - accuracy: 0.4802 - val_loss: 1.1358 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 1.0138 - accuracy: 0.4774 - val_loss: 1.1253 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 1.0238 - accuracy: 0.4640 - val_loss: 1.1548 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 1.0266 - accuracy: 0.4470 - val_loss: 1.1396 - val_accuracy: 0.3354 - 988ms/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 1.0181 - accuracy: 0.4650 - val_loss: 1.1241 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 1.0199 - accuracy: 0.4570 - val_loss: 1.1249 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 1.0296 - accuracy: 0.4614 - val_loss: 1.1135 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 1.0232 - accuracy: 0.4689 - val_loss: 1.1331 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 1.0264 - accuracy: 0.4604 - val_loss: 1.1202 - val_accuracy: 0.3395 - 981ms/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 1.0210 - accuracy: 0.4655 - val_loss: 1.1071 - val_accuracy: 0.3364 - 950ms/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 1.0218 - accuracy: 0.4642 - val_loss: 1.1171 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 1.0136 - accuracy: 0.4792 - val_loss: 1.1103 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 1.0260 - accuracy: 0.4586 - val_loss: 1.1142 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 1.0259 - accuracy: 0.4666 - val_loss: 1.1210 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 1.0194 - accuracy: 0.4727 - val_loss: 1.1149 - val_accuracy: 0.3333 - 991ms/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 1.0152 - accuracy: 0.4671 - val_loss: 1.1188 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 1.0249 - accuracy: 0.4681 - val_loss: 1.1456 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 1.0243 - accuracy: 0.4673 - val_loss: 1.1438 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 1.0203 - accuracy: 0.4671 - val_loss: 1.1286 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 1.0131 - accuracy: 0.4704 - val_loss: 1.1716 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 1.0092 - accuracy: 0.4715 - val_loss: 1.1515 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 1.0179 - accuracy: 0.4658 - val_loss: 1.1772 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 1.0220 - accuracy: 0.4663 - val_loss: 1.1679 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 1.0224 - accuracy: 0.4738 - val_loss: 1.1590 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 1.0152 - accuracy: 0.4776 - val_loss: 1.1581 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 1.0131 - accuracy: 0.4745 - val_loss: 1.1373 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 1.0216 - accuracy: 0.4658 - val_loss: 1.1472 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 1.0201 - accuracy: 0.4686 - val_loss: 1.1206 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 1.0173 - accuracy: 0.4663 - val_loss: 1.1583 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 1.0164 - accuracy: 0.4720 - val_loss: 1.1587 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 1.0095 - accuracy: 0.4920 - val_loss: 1.1391 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 1.0078 - accuracy: 0.4851 - val_loss: 1.1385 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 1.0209 - accuracy: 0.4663 - val_loss: 1.1459 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 1.0103 - accuracy: 0.4830 - val_loss: 1.1718 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 1.0127 - accuracy: 0.4748 - val_loss: 1.1256 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 1.0163 - accuracy: 0.4648 - val_loss: 1.1274 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 1.0089 - accuracy: 0.4771 - val_loss: 1.1316 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4727 - val_loss: 1.0997 - val_accuracy: 0.3992 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 1.0113 - accuracy: 0.4766 - val_loss: 1.1181 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 1.0088 - accuracy: 0.4820 - val_loss: 1.1342 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 1.0230 - accuracy: 0.4758 - val_loss: 1.1568 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 1.0138 - accuracy: 0.4758 - val_loss: 1.1568 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 1.0092 - accuracy: 0.4859 - val_loss: 1.1923 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4817 - val_loss: 1.1710 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 1.0156 - accuracy: 0.4753 - val_loss: 1.1239 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 1.0042 - accuracy: 0.4843 - val_loss: 1.1127 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 1.0124 - accuracy: 0.4810 - val_loss: 1.1390 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 1.0158 - accuracy: 0.4805 - val_loss: 1.2044 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 1.0020 - accuracy: 0.4787 - val_loss: 1.1957 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 1.0093 - accuracy: 0.4779 - val_loss: 1.1719 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 1.0048 - accuracy: 0.4828 - val_loss: 1.1794 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 1.0074 - accuracy: 0.4779 - val_loss: 1.1590 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4805 - val_loss: 1.1344 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 1.0119 - accuracy: 0.4769 - val_loss: 1.1192 - val_accuracy: 0.4177 - 993ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 1.0160 - accuracy: 0.4812 - val_loss: 1.1422 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 1.0031 - accuracy: 0.4848 - val_loss: 1.1505 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 1.0023 - accuracy: 0.4887 - val_loss: 1.1660 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 1.0043 - accuracy: 0.4856 - val_loss: 1.1511 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 1.0111 - accuracy: 0.4792 - val_loss: 1.1503 - val_accuracy: 0.3302 - 961ms/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 1.0101 - accuracy: 0.4810 - val_loss: 1.1319 - val_accuracy: 0.3374 - 995ms/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 1.0089 - accuracy: 0.4763 - val_loss: 1.1405 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 1.0083 - accuracy: 0.4869 - val_loss: 1.1437 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 1.0101 - accuracy: 0.4882 - val_loss: 1.1743 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 1.0116 - accuracy: 0.4709 - val_loss: 1.1687 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 1.0092 - accuracy: 0.4820 - val_loss: 1.1594 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 1.0105 - accuracy: 0.4900 - val_loss: 1.1607 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 1.0078 - accuracy: 0.4851 - val_loss: 1.1395 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 1.0091 - accuracy: 0.4874 - val_loss: 1.1747 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 1.0078 - accuracy: 0.4733 - val_loss: 1.2141 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 1.0125 - accuracy: 0.4727 - val_loss: 1.1990 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 1.0075 - accuracy: 0.4882 - val_loss: 1.2009 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 1.0048 - accuracy: 0.4871 - val_loss: 1.1953 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 1.0116 - accuracy: 0.4802 - val_loss: 1.2044 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 1.0022 - accuracy: 0.4802 - val_loss: 1.1768 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 1.0083 - accuracy: 0.4812 - val_loss: 1.2052 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 1.0125 - accuracy: 0.4684 - val_loss: 1.1772 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 1.0158 - accuracy: 0.4735 - val_loss: 1.1975 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 1.0040 - accuracy: 0.4835 - val_loss: 1.1986 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 1.0144 - accuracy: 0.4756 - val_loss: 1.1862 - val_accuracy: 0.3313 - 981ms/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 1.0036 - accuracy: 0.4815 - val_loss: 1.1845 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 1.0000 - accuracy: 0.4884 - val_loss: 1.1830 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 1.0107 - accuracy: 0.4815 - val_loss: 1.1685 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 1.0091 - accuracy: 0.4805 - val_loss: 1.1613 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 1.0132 - accuracy: 0.4859 - val_loss: 1.1563 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 1.0058 - accuracy: 0.4843 - val_loss: 1.1975 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 1.0121 - accuracy: 0.4753 - val_loss: 1.2135 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 0.9997 - accuracy: 0.4861 - val_loss: 1.2152 - val_accuracy: 0.3313 - 999ms/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 0.9995 - accuracy: 0.4877 - val_loss: 1.1784 - val_accuracy: 0.3313 - 992ms/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 0.9989 - accuracy: 0.4805 - val_loss: 1.1951 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 0.9968 - accuracy: 0.4928 - val_loss: 1.1910 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 1.0145 - accuracy: 0.4756 - val_loss: 1.1616 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 1.0062 - accuracy: 0.4817 - val_loss: 1.1414 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 1.0083 - accuracy: 0.4805 - val_loss: 1.1565 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 0.9982 - accuracy: 0.4889 - val_loss: 1.1513 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 1.0079 - accuracy: 0.4853 - val_loss: 1.1607 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 1.0114 - accuracy: 0.4699 - val_loss: 1.1568 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 0.9951 - accuracy: 0.4936 - val_loss: 1.1742 - val_accuracy: 0.3323 - 962ms/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 1.0020 - accuracy: 0.4910 - val_loss: 1.1243 - val_accuracy: 0.3344 - 990ms/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 1.0052 - accuracy: 0.4859 - val_loss: 1.1315 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 1.0050 - accuracy: 0.4848 - val_loss: 1.1370 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 1.0031 - accuracy: 0.4789 - val_loss: 1.1280 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 1.0079 - accuracy: 0.4843 - val_loss: 1.1078 - val_accuracy: 0.3961 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 1.0035 - accuracy: 0.4910 - val_loss: 1.1398 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.9987 - accuracy: 0.4833 - val_loss: 1.1178 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 1.0038 - accuracy: 0.4856 - val_loss: 1.1738 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 1.0059 - accuracy: 0.4889 - val_loss: 1.1680 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 1.0082 - accuracy: 0.4787 - val_loss: 1.1288 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9982 - accuracy: 0.4869 - val_loss: 1.1912 - val_accuracy: 0.3333 - 1s/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 0.9937 - accuracy: 0.4907 - val_loss: 1.1578 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 1.0006 - accuracy: 0.4925 - val_loss: 1.1460 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 1.0003 - accuracy: 0.4915 - val_loss: 1.1388 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.9980 - accuracy: 0.4892 - val_loss: 1.1610 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 0.9997 - accuracy: 0.4943 - val_loss: 1.2071 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 1.0105 - accuracy: 0.4797 - val_loss: 1.1943 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 1.0002 - accuracy: 0.4928 - val_loss: 1.1743 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 1.0030 - accuracy: 0.4902 - val_loss: 1.1452 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 0.9954 - accuracy: 0.4889 - val_loss: 1.1682 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 1.0049 - accuracy: 0.4925 - val_loss: 1.1704 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 0.9921 - accuracy: 0.4895 - val_loss: 1.1792 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 1.0028 - accuracy: 0.4969 - val_loss: 1.1845 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 1.0001 - accuracy: 0.4864 - val_loss: 1.1964 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 1.0031 - accuracy: 0.4954 - val_loss: 1.1427 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 1.0040 - accuracy: 0.4848 - val_loss: 1.1542 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.9957 - accuracy: 0.4846 - val_loss: 1.2066 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 1.0024 - accuracy: 0.4879 - val_loss: 1.1649 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 1.0042 - accuracy: 0.4810 - val_loss: 1.1484 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.9974 - accuracy: 0.4920 - val_loss: 1.1678 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.9983 - accuracy: 0.5000 - val_loss: 1.1782 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 0.9930 - accuracy: 0.4902 - val_loss: 1.1972 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.9933 - accuracy: 0.5111 - val_loss: 1.2272 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 1.0044 - accuracy: 0.4874 - val_loss: 1.1888 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 0.9981 - accuracy: 0.4959 - val_loss: 1.2016 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 1.0001 - accuracy: 0.4900 - val_loss: 1.1620 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9966 - accuracy: 0.4936 - val_loss: 1.1991 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 1.0017 - accuracy: 0.4833 - val_loss: 1.2479 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 1.0012 - accuracy: 0.4902 - val_loss: 1.1911 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9997 - accuracy: 0.5010 - val_loss: 1.2206 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 0.9978 - accuracy: 0.4823 - val_loss: 1.1980 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.9999 - accuracy: 0.4913 - val_loss: 1.1670 - val_accuracy: 0.3323 - 997ms/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 1.0035 - accuracy: 0.4884 - val_loss: 1.1492 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.9987 - accuracy: 0.4874 - val_loss: 1.1631 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 1.0080 - accuracy: 0.4915 - val_loss: 1.1877 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9943 - accuracy: 0.5003 - val_loss: 1.1935 - val_accuracy: 0.3333 - 996ms/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 0.9997 - accuracy: 0.4892 - val_loss: 1.1488 - val_accuracy: 0.3344 - 959ms/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.9930 - accuracy: 0.4949 - val_loss: 1.1423 - val_accuracy: 0.3344 - 991ms/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9946 - accuracy: 0.4918 - val_loss: 1.1237 - val_accuracy: 0.4115 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index for this split: [   0    1    2 ... 4857 4858 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   3   22   25   27   31   33   45   52   55   56   61   62   63   70\n",
      "   79   81   89   90   92   93   96   98  108  113  114  120  122  126\n",
      "  130  131  134  135  140  145  150  151  154  167  198  199  205  207\n",
      "  211  218  222  223  225  227  229  230  231  234  240  245  246  248\n",
      "  249  252  256  264  268  274  285  291  301  308  313  317  318  322\n",
      "  323  325  336  337  341  345  356  359  361  376  382  385  386  390\n",
      "  400  409  415  422  426  427  432  433  436  437  438  442  446  448\n",
      "  449  454  460  462  471  478  485  491  493  495  498  499  506  516\n",
      "  520  529  530  532  539  541  544  549  562  567  583  585  587  594\n",
      "  620  627  631  640  641  650  651  656  661  671  674  686  688  689\n",
      "  692  696  699  700  704  725  728  739  751  762  773  775  778  781\n",
      "  798  799  810  821  823  827  831  834  837  838  841  844  845  846\n",
      "  849  850  855  858  863  867  870  873  877  880  884  886  887  888\n",
      "  892  894  898  900  905  906  907  926  928  931  933  943  953  962\n",
      "  970  982  987  989  992  993  995 1003 1009 1011 1020 1022 1028 1030\n",
      " 1031 1039 1042 1044 1047 1050 1063 1064 1067 1079 1094 1095 1096 1102\n",
      " 1107 1114 1117 1119 1131 1132 1135 1138 1141 1150 1154 1155 1160 1163\n",
      " 1164 1173 1176 1184 1188 1191 1197 1203 1217 1222 1226 1232 1234 1239\n",
      " 1252 1254 1262 1263 1272 1277 1285 1291 1295 1301 1303 1304 1319 1320\n",
      " 1322 1324 1326 1332 1335 1336 1340 1344 1350 1357 1364 1367 1368 1379\n",
      " 1382 1388 1399 1403 1410 1413 1419 1421 1426 1428 1430 1442 1443 1448\n",
      " 1453 1458 1464 1465 1466 1482 1494 1498 1512 1514 1515 1516 1519 1530\n",
      " 1533 1535 1540 1552 1563 1589 1595 1608 1614 1615 1616 1617 1618 1622\n",
      " 1623 1632 1637 1644 1649 1657 1659 1663 1665 1666 1669 1680 1681 1682\n",
      " 1685 1691 1695 1697 1704 1710 1722 1729 1733 1747 1748 1749 1757 1769\n",
      " 1781 1784 1787 1792 1796 1798 1800 1807 1813 1841 1844 1861 1875 1879\n",
      " 1883 1885 1888 1889 1890 1902 1904 1907 1919 1923 1924 1934 1936 1939\n",
      " 1940 1942 1947 1958 1960 1967 1973 1975 1977 1980 1981 1987 1989 1990\n",
      " 1992 1999 2008 2021 2024 2025 2028 2029 2031 2038 2040 2047 2051 2056\n",
      " 2057 2066 2082 2086 2088 2091 2100 2104 2112 2119 2121 2124 2130 2146\n",
      " 2148 2154 2161 2172 2177 2182 2189 2196 2197 2205 2208 2211 2212 2223\n",
      " 2231 2232 2236 2240 2241 2245 2246 2250 2251 2252 2254 2256 2257 2267\n",
      " 2268 2271 2280 2286 2299 2303 2304 2312 2315 2324 2333 2340 2344 2354\n",
      " 2356 2358 2365 2366 2370 2371 2372 2373 2378 2380 2385 2392 2394 2399\n",
      " 2423 2425 2431 2433 2440 2446 2449 2452 2453 2456 2462 2464 2467 2468\n",
      " 2473 2501 2502 2507 2514 2517 2523 2526 2529 2532 2533 2534 2537 2546\n",
      " 2552 2560 2564 2570 2573 2578 2581 2582 2584 2590 2593 2602 2613 2622\n",
      " 2624 2642 2646 2647 2649 2655 2661 2665 2675 2679 2689 2693 2694 2696\n",
      " 2703 2707 2710 2711 2719 2721 2728 2729 2737 2738 2739 2740 2742 2751\n",
      " 2755 2768 2775 2777 2781 2789 2793 2804 2808 2811 2817 2825 2827 2835\n",
      " 2837 2844 2846 2847 2851 2852 2870 2872 2876 2881 2884 2886 2888 2907\n",
      " 2908 2910 2912 2921 2928 2932 2937 2949 2951 2953 2957 2959 2960 2976\n",
      " 2978 2979 2991 3002 3004 3006 3010 3013 3028 3031 3032 3035 3045 3047\n",
      " 3050 3061 3062 3068 3074 3077 3078 3088 3089 3100 3101 3103 3106 3108\n",
      " 3110 3111 3112 3115 3119 3130 3143 3150 3151 3159 3164 3173 3176 3180\n",
      " 3195 3207 3208 3217 3221 3228 3238 3243 3245 3249 3254 3266 3281 3288\n",
      " 3290 3292 3295 3296 3297 3298 3313 3314 3325 3339 3341 3345 3349 3355\n",
      " 3357 3366 3368 3370 3371 3372 3380 3382 3396 3406 3410 3415 3424 3435\n",
      " 3436 3437 3442 3447 3452 3464 3468 3469 3470 3473 3477 3486 3489 3492\n",
      " 3499 3501 3504 3508 3514 3515 3530 3531 3543 3549 3550 3551 3556 3559\n",
      " 3561 3562 3563 3567 3571 3574 3582 3587 3588 3589 3593 3595 3611 3618\n",
      " 3622 3623 3631 3637 3639 3641 3650 3657 3658 3659 3664 3673 3676 3678\n",
      " 3680 3691 3696 3715 3717 3721 3722 3732 3747 3764 3765 3768 3769 3771\n",
      " 3772 3774 3776 3779 3783 3792 3793 3796 3801 3810 3821 3827 3831 3832\n",
      " 3839 3848 3855 3857 3860 3862 3864 3866 3871 3874 3875 3883 3892 3894\n",
      " 3895 3896 3897 3899 3904 3907 3910 3912 3917 3919 3922 3928 3932 3934\n",
      " 3937 3947 3948 3953 3954 3962 3966 3975 3979 3981 3996 3997 3999 4000\n",
      " 4003 4008 4009 4010 4011 4012 4016 4021 4022 4026 4035 4052 4053 4058\n",
      " 4061 4066 4076 4079 4080 4081 4083 4091 4093 4095 4108 4110 4119 4121\n",
      " 4136 4142 4143 4148 4150 4155 4156 4160 4165 4168 4177 4181 4182 4183\n",
      " 4186 4199 4200 4212 4213 4216 4217 4221 4227 4236 4238 4239 4245 4248\n",
      " 4252 4253 4264 4266 4270 4272 4280 4302 4305 4307 4314 4318 4320 4326\n",
      " 4328 4329 4330 4334 4340 4345 4351 4355 4357 4366 4369 4372 4373 4375\n",
      " 4387 4402 4404 4411 4413 4415 4421 4424 4425 4426 4427 4428 4446 4453\n",
      " 4455 4461 4462 4465 4471 4476 4477 4483 4486 4501 4502 4512 4517 4520\n",
      " 4525 4526 4529 4532 4535 4538 4541 4543 4551 4552 4562 4574 4575 4581\n",
      " 4586 4590 4592 4594 4603 4625 4628 4630 4632 4642 4645 4649 4653 4655\n",
      " 4657 4660 4661 4662 4665 4680 4690 4692 4696 4697 4716 4719 4725 4731\n",
      " 4732 4735 4742 4745 4749 4756 4770 4780 4790 4791 4801 4819 4823 4828\n",
      " 4836 4838 4840 4842 4852 4853]\n",
      "Number of samples for test set: 972\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 00:58:32.027354: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_319/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.1040 - accuracy: 0.3362 - val_loss: 1.0956 - val_accuracy: 0.3560 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0952 - accuracy: 0.3555 - val_loss: 1.0962 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0918 - accuracy: 0.3768 - val_loss: 1.0945 - val_accuracy: 0.3673 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0913 - accuracy: 0.3701 - val_loss: 1.1002 - val_accuracy: 0.3539 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0863 - accuracy: 0.3719 - val_loss: 1.0956 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0897 - accuracy: 0.3747 - val_loss: 1.1000 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0874 - accuracy: 0.3719 - val_loss: 1.0962 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0844 - accuracy: 0.3873 - val_loss: 1.0962 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0811 - accuracy: 0.3938 - val_loss: 1.1026 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0831 - accuracy: 0.3848 - val_loss: 1.0947 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0791 - accuracy: 0.3853 - val_loss: 1.0969 - val_accuracy: 0.3498 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0813 - accuracy: 0.3799 - val_loss: 1.0995 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0734 - accuracy: 0.4015 - val_loss: 1.0979 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0758 - accuracy: 0.3915 - val_loss: 1.0963 - val_accuracy: 0.3745 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0732 - accuracy: 0.4010 - val_loss: 1.0971 - val_accuracy: 0.3786 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0719 - accuracy: 0.3994 - val_loss: 1.0983 - val_accuracy: 0.3683 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 1.0733 - accuracy: 0.3953 - val_loss: 1.0983 - val_accuracy: 0.3673 - 1s/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0702 - accuracy: 0.3917 - val_loss: 1.1006 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0695 - accuracy: 0.4084 - val_loss: 1.0965 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0663 - accuracy: 0.4092 - val_loss: 1.1170 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 1.0646 - accuracy: 0.4190 - val_loss: 1.1106 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 1.0633 - accuracy: 0.4105 - val_loss: 1.0930 - val_accuracy: 0.3807 - 1s/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 1.0656 - accuracy: 0.3981 - val_loss: 1.0993 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 1.0634 - accuracy: 0.4051 - val_loss: 1.0994 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 1.0607 - accuracy: 0.4177 - val_loss: 1.1010 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 1.0626 - accuracy: 0.4097 - val_loss: 1.1085 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 1.0608 - accuracy: 0.4234 - val_loss: 1.1370 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 1.0629 - accuracy: 0.4159 - val_loss: 1.1254 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 1.0560 - accuracy: 0.4282 - val_loss: 1.1647 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 1.0529 - accuracy: 0.4329 - val_loss: 1.1910 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 1.0530 - accuracy: 0.4324 - val_loss: 1.1702 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 1.0510 - accuracy: 0.4370 - val_loss: 1.1912 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 1.0537 - accuracy: 0.4306 - val_loss: 1.1733 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 1.0506 - accuracy: 0.4396 - val_loss: 1.1499 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 1.0492 - accuracy: 0.4408 - val_loss: 1.1430 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 1.0485 - accuracy: 0.4313 - val_loss: 1.1190 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 1.0492 - accuracy: 0.4429 - val_loss: 1.1835 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 1.0484 - accuracy: 0.4390 - val_loss: 1.1391 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 1.0423 - accuracy: 0.4442 - val_loss: 1.1296 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 1.0443 - accuracy: 0.4534 - val_loss: 1.1069 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 1.0386 - accuracy: 0.4468 - val_loss: 1.1538 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 1.0400 - accuracy: 0.4504 - val_loss: 1.1447 - val_accuracy: 0.3241 - 1s/epoch - 5ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 1.0437 - accuracy: 0.4411 - val_loss: 1.1308 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 1.0473 - accuracy: 0.4429 - val_loss: 1.1585 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 1.0435 - accuracy: 0.4486 - val_loss: 1.1213 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 1.0386 - accuracy: 0.4591 - val_loss: 1.1210 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 1.0418 - accuracy: 0.4527 - val_loss: 1.1440 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 1.0408 - accuracy: 0.4465 - val_loss: 1.1808 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 1.0362 - accuracy: 0.4547 - val_loss: 1.1261 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 1.0327 - accuracy: 0.4614 - val_loss: 1.1731 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 1.0424 - accuracy: 0.4527 - val_loss: 1.1881 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 1.0351 - accuracy: 0.4493 - val_loss: 1.2228 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 1.0399 - accuracy: 0.4570 - val_loss: 1.1335 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 1.0420 - accuracy: 0.4537 - val_loss: 1.1474 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 1.0365 - accuracy: 0.4516 - val_loss: 1.1500 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 1.0383 - accuracy: 0.4488 - val_loss: 1.1554 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 1.0380 - accuracy: 0.4617 - val_loss: 1.1658 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 1.0354 - accuracy: 0.4606 - val_loss: 1.2065 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 1.0340 - accuracy: 0.4583 - val_loss: 1.2063 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 1.0362 - accuracy: 0.4619 - val_loss: 1.1822 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 1.0298 - accuracy: 0.4594 - val_loss: 1.1743 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 1.0325 - accuracy: 0.4565 - val_loss: 1.1993 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 1.0277 - accuracy: 0.4545 - val_loss: 1.1591 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 1.0315 - accuracy: 0.4606 - val_loss: 1.1766 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 1.0326 - accuracy: 0.4583 - val_loss: 1.1825 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 1.0233 - accuracy: 0.4722 - val_loss: 1.1936 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 1.0342 - accuracy: 0.4480 - val_loss: 1.1867 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 1.0339 - accuracy: 0.4522 - val_loss: 1.1849 - val_accuracy: 0.3272 - 1s/epoch - 5ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 1.0264 - accuracy: 0.4779 - val_loss: 1.1472 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 1.0367 - accuracy: 0.4560 - val_loss: 1.1469 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 1.0320 - accuracy: 0.4614 - val_loss: 1.1797 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 1.0305 - accuracy: 0.4594 - val_loss: 1.1778 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 1.0332 - accuracy: 0.4617 - val_loss: 1.1416 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 1.0305 - accuracy: 0.4660 - val_loss: 1.1561 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 1.0268 - accuracy: 0.4617 - val_loss: 1.1885 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 1.0251 - accuracy: 0.4642 - val_loss: 1.1834 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 1.0248 - accuracy: 0.4632 - val_loss: 1.1600 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 1.0235 - accuracy: 0.4702 - val_loss: 1.1659 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 1.0327 - accuracy: 0.4568 - val_loss: 1.1860 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 1.0332 - accuracy: 0.4583 - val_loss: 1.1515 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 1.0205 - accuracy: 0.4709 - val_loss: 1.1709 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 1.0294 - accuracy: 0.4630 - val_loss: 1.1582 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 1.0269 - accuracy: 0.4676 - val_loss: 1.1583 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 1.0255 - accuracy: 0.4645 - val_loss: 1.1555 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 1.0271 - accuracy: 0.4635 - val_loss: 1.1488 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 1.0287 - accuracy: 0.4673 - val_loss: 1.1763 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 1.0295 - accuracy: 0.4563 - val_loss: 1.1888 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 1.0207 - accuracy: 0.4676 - val_loss: 1.1545 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 1.0184 - accuracy: 0.4738 - val_loss: 1.1490 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 1.0242 - accuracy: 0.4735 - val_loss: 1.1544 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 1.0188 - accuracy: 0.4702 - val_loss: 1.1598 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 1.0216 - accuracy: 0.4673 - val_loss: 1.1366 - val_accuracy: 0.3241 - 989ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 1.0152 - accuracy: 0.4769 - val_loss: 1.1487 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 1.0252 - accuracy: 0.4606 - val_loss: 1.1612 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 1.0261 - accuracy: 0.4596 - val_loss: 1.1788 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 1.0247 - accuracy: 0.4681 - val_loss: 1.1805 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 1.0262 - accuracy: 0.4630 - val_loss: 1.1524 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 1.0176 - accuracy: 0.4648 - val_loss: 1.1536 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 1.0273 - accuracy: 0.4648 - val_loss: 1.1255 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 1.0196 - accuracy: 0.4614 - val_loss: 1.1656 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 1.0177 - accuracy: 0.4689 - val_loss: 1.1033 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 1.0203 - accuracy: 0.4681 - val_loss: 1.1099 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 1.0246 - accuracy: 0.4640 - val_loss: 1.1108 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 1.0223 - accuracy: 0.4606 - val_loss: 1.1214 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 1.0142 - accuracy: 0.4802 - val_loss: 1.1414 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 1.0165 - accuracy: 0.4717 - val_loss: 1.1460 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 1.0158 - accuracy: 0.4748 - val_loss: 1.1358 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 1.0150 - accuracy: 0.4758 - val_loss: 1.1305 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 1.0207 - accuracy: 0.4684 - val_loss: 1.1225 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 1.0150 - accuracy: 0.4779 - val_loss: 1.1687 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 1.0204 - accuracy: 0.4789 - val_loss: 1.1214 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 1.0164 - accuracy: 0.4704 - val_loss: 1.1325 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 1.0320 - accuracy: 0.4758 - val_loss: 1.1440 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 1.0225 - accuracy: 0.4671 - val_loss: 1.1521 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 1.0161 - accuracy: 0.4817 - val_loss: 1.1665 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 1.0136 - accuracy: 0.4751 - val_loss: 1.1581 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 1.0219 - accuracy: 0.4619 - val_loss: 1.1476 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 1.0251 - accuracy: 0.4686 - val_loss: 1.1352 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 1.0189 - accuracy: 0.4666 - val_loss: 1.1174 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 1.0240 - accuracy: 0.4712 - val_loss: 1.1420 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 1.0251 - accuracy: 0.4663 - val_loss: 1.1491 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4763 - val_loss: 1.1284 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 1.0213 - accuracy: 0.4612 - val_loss: 1.1192 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 1.0182 - accuracy: 0.4725 - val_loss: 1.1125 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 1.0182 - accuracy: 0.4745 - val_loss: 1.1478 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 1.0194 - accuracy: 0.4776 - val_loss: 1.1384 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 1.0178 - accuracy: 0.4740 - val_loss: 1.1396 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 1.0155 - accuracy: 0.4766 - val_loss: 1.1423 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 1.0075 - accuracy: 0.4805 - val_loss: 1.1243 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 1.0125 - accuracy: 0.4751 - val_loss: 1.1603 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 1.0118 - accuracy: 0.4776 - val_loss: 1.1400 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 1.0155 - accuracy: 0.4835 - val_loss: 1.1157 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 1.0162 - accuracy: 0.4699 - val_loss: 1.1152 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 1.0156 - accuracy: 0.4668 - val_loss: 1.1373 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 1.0121 - accuracy: 0.4678 - val_loss: 1.1572 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 1.0244 - accuracy: 0.4609 - val_loss: 1.2137 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 1.0209 - accuracy: 0.4730 - val_loss: 1.1751 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 1.0144 - accuracy: 0.4684 - val_loss: 1.1219 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 1.0227 - accuracy: 0.4648 - val_loss: 1.1370 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 1.0082 - accuracy: 0.4810 - val_loss: 1.2046 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 1.0144 - accuracy: 0.4709 - val_loss: 1.1637 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 1.0218 - accuracy: 0.4555 - val_loss: 1.2004 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 1.0111 - accuracy: 0.4769 - val_loss: 1.1831 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 1.0174 - accuracy: 0.4738 - val_loss: 1.1443 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 1.0113 - accuracy: 0.4825 - val_loss: 1.1692 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 1.0113 - accuracy: 0.4877 - val_loss: 1.1544 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 1.0243 - accuracy: 0.4660 - val_loss: 1.2203 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 1.0161 - accuracy: 0.4707 - val_loss: 1.2064 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 1.0164 - accuracy: 0.4769 - val_loss: 1.1486 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 1.0129 - accuracy: 0.4694 - val_loss: 1.1507 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 1.0177 - accuracy: 0.4730 - val_loss: 1.1515 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 1.0131 - accuracy: 0.4697 - val_loss: 1.2064 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 1.0066 - accuracy: 0.4841 - val_loss: 1.1994 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 1.0181 - accuracy: 0.4740 - val_loss: 1.2209 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 1.0281 - accuracy: 0.4609 - val_loss: 1.1913 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 1.0042 - accuracy: 0.4771 - val_loss: 1.1748 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 1.0160 - accuracy: 0.4660 - val_loss: 1.1724 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 1.0160 - accuracy: 0.4635 - val_loss: 1.1872 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 1.0076 - accuracy: 0.4835 - val_loss: 1.1633 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 1.0134 - accuracy: 0.4787 - val_loss: 1.2015 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 1.0155 - accuracy: 0.4720 - val_loss: 1.1620 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 1.0051 - accuracy: 0.4838 - val_loss: 1.1710 - val_accuracy: 0.3241 - 1s/epoch - 5ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 1.0131 - accuracy: 0.4869 - val_loss: 1.2024 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 1.0089 - accuracy: 0.4859 - val_loss: 1.2105 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 1.0180 - accuracy: 0.4743 - val_loss: 1.1768 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 1.0119 - accuracy: 0.4769 - val_loss: 1.1498 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 1.0079 - accuracy: 0.4774 - val_loss: 1.1740 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 1.0075 - accuracy: 0.4812 - val_loss: 1.1617 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 1.0135 - accuracy: 0.4766 - val_loss: 1.1974 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 1.0089 - accuracy: 0.4851 - val_loss: 1.1555 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 1.0114 - accuracy: 0.4823 - val_loss: 1.1967 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 1.0132 - accuracy: 0.4766 - val_loss: 1.1769 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4815 - val_loss: 1.1625 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 1.0101 - accuracy: 0.4877 - val_loss: 1.1857 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 1.0169 - accuracy: 0.4753 - val_loss: 1.1802 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 1.0115 - accuracy: 0.4812 - val_loss: 1.1645 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 1.0058 - accuracy: 0.4807 - val_loss: 1.1761 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 1.0093 - accuracy: 0.4815 - val_loss: 1.1455 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 1.0059 - accuracy: 0.4781 - val_loss: 1.1357 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 1.0117 - accuracy: 0.4758 - val_loss: 1.1918 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 1.0077 - accuracy: 0.4771 - val_loss: 1.2102 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 1.0111 - accuracy: 0.4838 - val_loss: 1.1860 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 1.0089 - accuracy: 0.4784 - val_loss: 1.1595 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 1.0010 - accuracy: 0.4923 - val_loss: 1.1423 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 1.0127 - accuracy: 0.4823 - val_loss: 1.1772 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 1.0091 - accuracy: 0.4979 - val_loss: 1.1844 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 1.0049 - accuracy: 0.4897 - val_loss: 1.1866 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 1.0184 - accuracy: 0.4678 - val_loss: 1.1660 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 1.0105 - accuracy: 0.4830 - val_loss: 1.1984 - val_accuracy: 0.3282 - 993ms/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 1.0084 - accuracy: 0.4853 - val_loss: 1.1305 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 1.0056 - accuracy: 0.4892 - val_loss: 1.1554 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 1.0171 - accuracy: 0.4740 - val_loss: 1.1621 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4753 - val_loss: 1.1727 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 1.0059 - accuracy: 0.4794 - val_loss: 1.1657 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 1.0089 - accuracy: 0.4751 - val_loss: 1.1589 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 1.0059 - accuracy: 0.4884 - val_loss: 1.1616 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 1.0068 - accuracy: 0.4817 - val_loss: 1.1629 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 1.0043 - accuracy: 0.4820 - val_loss: 1.1247 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 1.0154 - accuracy: 0.4730 - val_loss: 1.1677 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 1.0118 - accuracy: 0.4753 - val_loss: 1.1701 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 1.0093 - accuracy: 0.4776 - val_loss: 1.1435 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 1.0055 - accuracy: 0.4792 - val_loss: 1.1958 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 1.0099 - accuracy: 0.4830 - val_loss: 1.1593 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 1.0052 - accuracy: 0.4761 - val_loss: 1.2047 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 1.0147 - accuracy: 0.4789 - val_loss: 1.2155 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 1.0081 - accuracy: 0.4859 - val_loss: 1.2232 - val_accuracy: 0.3272 - 1s/epoch - 5ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 1.0148 - accuracy: 0.4730 - val_loss: 1.1524 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.9993 - accuracy: 0.4869 - val_loss: 1.1977 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 1.0124 - accuracy: 0.4789 - val_loss: 1.2135 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 1.0115 - accuracy: 0.4807 - val_loss: 1.2241 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 1.0056 - accuracy: 0.4833 - val_loss: 1.1963 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 1.0083 - accuracy: 0.4841 - val_loss: 1.1605 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 1.0167 - accuracy: 0.4733 - val_loss: 1.1215 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 1.0122 - accuracy: 0.4802 - val_loss: 1.1925 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 1.0095 - accuracy: 0.4848 - val_loss: 1.1473 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 1.0203 - accuracy: 0.4691 - val_loss: 1.1698 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 1.0059 - accuracy: 0.4697 - val_loss: 1.2038 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 1.0064 - accuracy: 0.4943 - val_loss: 1.1919 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 1.0021 - accuracy: 0.4730 - val_loss: 1.2196 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 1.0120 - accuracy: 0.4758 - val_loss: 1.1904 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 1.0032 - accuracy: 0.4835 - val_loss: 1.2254 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 1.0027 - accuracy: 0.4823 - val_loss: 1.1765 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 1.0077 - accuracy: 0.4859 - val_loss: 1.1354 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 1.0098 - accuracy: 0.4817 - val_loss: 1.1961 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 1.0072 - accuracy: 0.4825 - val_loss: 1.2067 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 1.0073 - accuracy: 0.4931 - val_loss: 1.1781 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 1.0099 - accuracy: 0.4784 - val_loss: 1.2165 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 0.9930 - accuracy: 0.4918 - val_loss: 1.1799 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 1.0020 - accuracy: 0.4913 - val_loss: 1.2005 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 1.0110 - accuracy: 0.4712 - val_loss: 1.1803 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4769 - val_loss: 1.1709 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 1.0048 - accuracy: 0.4817 - val_loss: 1.1930 - val_accuracy: 0.3282 - 1s/epoch - 5ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 1.0097 - accuracy: 0.4697 - val_loss: 1.1724 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 0.9974 - accuracy: 0.4807 - val_loss: 1.1690 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 1.0034 - accuracy: 0.4789 - val_loss: 1.1851 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 1.0060 - accuracy: 0.4792 - val_loss: 1.1875 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 1.0063 - accuracy: 0.4815 - val_loss: 1.1820 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 1.0049 - accuracy: 0.4823 - val_loss: 1.2066 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 1.0059 - accuracy: 0.4943 - val_loss: 1.2038 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 1.0036 - accuracy: 0.4833 - val_loss: 1.1719 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 1.0059 - accuracy: 0.4830 - val_loss: 1.1919 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 1.0015 - accuracy: 0.4789 - val_loss: 1.2232 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 1.0023 - accuracy: 0.4925 - val_loss: 1.1932 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 1.0092 - accuracy: 0.4735 - val_loss: 1.1866 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 1.0063 - accuracy: 0.4792 - val_loss: 1.2283 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 1.0144 - accuracy: 0.4792 - val_loss: 1.1933 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 1.0027 - accuracy: 0.4799 - val_loss: 1.2069 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 1.0067 - accuracy: 0.4820 - val_loss: 1.2278 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 1.0094 - accuracy: 0.4864 - val_loss: 1.2339 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9986 - accuracy: 0.4853 - val_loss: 1.2518 - val_accuracy: 0.3272 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/malfonzo/akulejo/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train index for this split: [   0    1    2 ... 4856 4858 4859]\n",
      "Number of samples for train set: 3888\n",
      "Test index for this split: [   5    6    8   15   17   20   24   30   47   48   49   51   57   59\n",
      "   64   67   69   78   83   84   95   97  101  107  121  138  141  143\n",
      "  144  152  163  168  170  178  179  180  183  185  191  194  196  197\n",
      "  202  203  206  226  233  235  238  239  241  247  251  253  255  257\n",
      "  263  281  289  290  299  306  327  330  331  334  338  339  343  348\n",
      "  349  354  357  364  372  377  380  381  389  402  408  411  412  414\n",
      "  417  421  429  431  434  435  440  445  447  463  464  470  472  474\n",
      "  483  486  489  496  501  502  503  510  515  519  524  526  536  543\n",
      "  545  559  560  569  577  578  580  586  588  589  591  593  604  608\n",
      "  612  613  619  625  626  628  630  634  638  639  643  644  652  667\n",
      "  678  681  682  690  691  702  711  716  722  723  735  737  741  744\n",
      "  747  753  757  758  761  763  764  765  771  772  776  777  779  780\n",
      "  782  783  785  788  792  793  800  805  806  813  814  815  820  828\n",
      "  829  840  852  865  869  878  881  895  902  908  918  919  922  929\n",
      "  935  940  941  951  952  954  955  959  961  967  973  980  981  985\n",
      "  999 1004 1010 1024 1025 1026 1029 1032 1033 1034 1035 1038 1045 1046\n",
      " 1048 1053 1055 1060 1080 1083 1085 1086 1099 1101 1105 1106 1109 1110\n",
      " 1115 1118 1123 1124 1129 1136 1137 1140 1142 1144 1146 1148 1157 1168\n",
      " 1169 1171 1174 1178 1180 1190 1208 1218 1224 1229 1236 1238 1245 1246\n",
      " 1250 1251 1255 1265 1281 1283 1284 1288 1292 1305 1306 1309 1310 1318\n",
      " 1325 1330 1334 1338 1341 1352 1353 1356 1370 1372 1374 1394 1400 1409\n",
      " 1414 1415 1420 1424 1425 1427 1433 1437 1440 1441 1444 1446 1456 1461\n",
      " 1471 1473 1475 1477 1480 1481 1488 1506 1507 1509 1510 1511 1513 1525\n",
      " 1531 1537 1539 1546 1551 1554 1567 1572 1573 1578 1582 1583 1588 1590\n",
      " 1593 1605 1610 1611 1619 1620 1624 1645 1646 1650 1651 1653 1667 1674\n",
      " 1675 1677 1686 1687 1692 1694 1699 1717 1740 1744 1745 1751 1754 1756\n",
      " 1765 1766 1768 1772 1775 1776 1780 1783 1789 1795 1797 1799 1806 1809\n",
      " 1817 1823 1827 1834 1847 1852 1855 1858 1867 1868 1876 1877 1881 1894\n",
      " 1896 1898 1900 1901 1905 1906 1913 1914 1915 1920 1925 1927 1929 1931\n",
      " 1933 1945 1953 1956 1964 1965 1966 1971 1993 1997 1998 2000 2001 2002\n",
      " 2012 2027 2032 2045 2048 2049 2050 2053 2055 2062 2070 2076 2080 2081\n",
      " 2087 2096 2106 2109 2114 2118 2122 2126 2128 2134 2136 2150 2153 2160\n",
      " 2162 2163 2165 2168 2169 2171 2173 2181 2183 2186 2187 2191 2198 2202\n",
      " 2207 2209 2214 2218 2225 2233 2238 2243 2253 2255 2258 2260 2263 2269\n",
      " 2273 2274 2277 2282 2284 2287 2288 2291 2292 2293 2296 2298 2307 2309\n",
      " 2310 2316 2317 2335 2343 2347 2352 2353 2355 2369 2374 2379 2387 2389\n",
      " 2390 2400 2401 2402 2403 2409 2410 2413 2415 2416 2426 2432 2434 2435\n",
      " 2442 2445 2447 2471 2476 2483 2485 2493 2495 2498 2505 2515 2516 2527\n",
      " 2530 2539 2540 2542 2545 2547 2549 2554 2558 2559 2561 2569 2576 2577\n",
      " 2586 2591 2601 2610 2611 2615 2618 2627 2639 2640 2643 2644 2648 2656\n",
      " 2660 2663 2669 2676 2682 2686 2687 2702 2705 2708 2713 2717 2720 2735\n",
      " 2744 2745 2748 2753 2762 2770 2779 2782 2787 2790 2791 2797 2799 2800\n",
      " 2807 2810 2815 2821 2822 2824 2826 2830 2840 2841 2848 2853 2865 2871\n",
      " 2875 2882 2892 2893 2904 2906 2913 2916 2930 2933 2935 2936 2940 2943\n",
      " 2947 2948 2955 2956 2962 2969 2971 2972 2974 2975 2981 2983 2984 2988\n",
      " 2993 2998 3001 3005 3008 3022 3023 3024 3038 3051 3059 3064 3065 3066\n",
      " 3067 3071 3076 3082 3091 3093 3113 3122 3128 3134 3135 3136 3146 3148\n",
      " 3152 3153 3154 3155 3156 3162 3163 3168 3169 3170 3171 3178 3181 3183\n",
      " 3185 3187 3192 3198 3209 3222 3223 3227 3231 3234 3239 3246 3247 3259\n",
      " 3260 3262 3264 3265 3269 3272 3275 3276 3278 3279 3286 3291 3293 3300\n",
      " 3308 3309 3310 3311 3315 3328 3330 3336 3342 3348 3351 3352 3375 3378\n",
      " 3383 3394 3397 3402 3405 3408 3412 3420 3429 3430 3441 3444 3456 3467\n",
      " 3471 3474 3476 3480 3496 3513 3517 3520 3524 3527 3529 3532 3541 3545\n",
      " 3555 3569 3592 3594 3596 3597 3625 3634 3642 3643 3647 3652 3656 3686\n",
      " 3687 3689 3695 3698 3701 3702 3703 3726 3734 3738 3745 3748 3749 3752\n",
      " 3755 3767 3784 3785 3788 3794 3797 3798 3799 3811 3817 3829 3834 3841\n",
      " 3842 3846 3847 3863 3870 3873 3880 3903 3906 3908 3911 3916 3918 3924\n",
      " 3926 3945 3949 3955 3957 3970 3974 3986 4005 4007 4013 4029 4032 4047\n",
      " 4050 4064 4069 4073 4074 4085 4089 4096 4101 4103 4107 4113 4123 4127\n",
      " 4139 4146 4149 4152 4172 4176 4194 4196 4201 4202 4204 4207 4211 4228\n",
      " 4231 4241 4243 4250 4254 4257 4271 4273 4277 4281 4285 4288 4292 4293\n",
      " 4298 4304 4306 4310 4316 4317 4324 4327 4331 4332 4338 4339 4342 4349\n",
      " 4356 4358 4360 4379 4384 4385 4389 4390 4392 4395 4396 4398 4410 4430\n",
      " 4437 4439 4440 4441 4442 4443 4445 4451 4457 4459 4468 4469 4473 4481\n",
      " 4484 4493 4496 4499 4503 4505 4511 4531 4536 4553 4557 4563 4568 4569\n",
      " 4570 4573 4580 4584 4587 4595 4599 4608 4610 4614 4618 4627 4636 4638\n",
      " 4641 4644 4646 4647 4651 4652 4654 4666 4667 4668 4670 4676 4677 4681\n",
      " 4682 4684 4699 4701 4702 4706 4708 4714 4736 4743 4746 4759 4760 4764\n",
      " 4766 4771 4775 4777 4786 4787 4792 4804 4810 4811 4812 4813 4817 4824\n",
      " 4825 4833 4837 4847 4855 4857]\n",
      "Number of samples for test set: 972\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 01:03:00.204139: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_320/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 3s - loss: 1.1000 - accuracy: 0.3359 - val_loss: 1.0994 - val_accuracy: 0.3416 - 3s/epoch - 11ms/step\n",
      "Epoch 2/250\n",
      "243/243 - 1s - loss: 1.0972 - accuracy: 0.3570 - val_loss: 1.1018 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 3/250\n",
      "243/243 - 1s - loss: 1.0946 - accuracy: 0.3611 - val_loss: 1.1000 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 4/250\n",
      "243/243 - 1s - loss: 1.0917 - accuracy: 0.3621 - val_loss: 1.1007 - val_accuracy: 0.3169 - 1s/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "243/243 - 1s - loss: 1.0880 - accuracy: 0.3639 - val_loss: 1.1000 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 6/250\n",
      "243/243 - 1s - loss: 1.0902 - accuracy: 0.3696 - val_loss: 1.0996 - val_accuracy: 0.3765 - 1s/epoch - 4ms/step\n",
      "Epoch 7/250\n",
      "243/243 - 1s - loss: 1.0880 - accuracy: 0.3807 - val_loss: 1.1014 - val_accuracy: 0.3683 - 1s/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "243/243 - 1s - loss: 1.0780 - accuracy: 0.3881 - val_loss: 1.1030 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "243/243 - 1s - loss: 1.0817 - accuracy: 0.3873 - val_loss: 1.1020 - val_accuracy: 0.3385 - 979ms/epoch - 4ms/step\n",
      "Epoch 10/250\n",
      "243/243 - 1s - loss: 1.0782 - accuracy: 0.3822 - val_loss: 1.1072 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 11/250\n",
      "243/243 - 1s - loss: 1.0778 - accuracy: 0.3917 - val_loss: 1.1006 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 12/250\n",
      "243/243 - 1s - loss: 1.0767 - accuracy: 0.3894 - val_loss: 1.1014 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 13/250\n",
      "243/243 - 1s - loss: 1.0767 - accuracy: 0.3961 - val_loss: 1.1028 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "243/243 - 1s - loss: 1.0690 - accuracy: 0.4046 - val_loss: 1.1079 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 15/250\n",
      "243/243 - 1s - loss: 1.0690 - accuracy: 0.4028 - val_loss: 1.1048 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 16/250\n",
      "243/243 - 1s - loss: 1.0732 - accuracy: 0.3897 - val_loss: 1.1034 - val_accuracy: 0.3735 - 1s/epoch - 4ms/step\n",
      "Epoch 17/250\n",
      "243/243 - 1s - loss: 1.0679 - accuracy: 0.3979 - val_loss: 1.1089 - val_accuracy: 0.3930 - 973ms/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "243/243 - 1s - loss: 1.0659 - accuracy: 0.3987 - val_loss: 1.1090 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 19/250\n",
      "243/243 - 1s - loss: 1.0649 - accuracy: 0.4015 - val_loss: 1.1184 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "243/243 - 1s - loss: 1.0634 - accuracy: 0.4138 - val_loss: 1.1101 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 21/250\n",
      "243/243 - 1s - loss: 1.0680 - accuracy: 0.4097 - val_loss: 1.1036 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 22/250\n",
      "243/243 - 1s - loss: 1.0619 - accuracy: 0.4156 - val_loss: 1.1041 - val_accuracy: 0.3395 - 995ms/epoch - 4ms/step\n",
      "Epoch 23/250\n",
      "243/243 - 1s - loss: 1.0636 - accuracy: 0.4141 - val_loss: 1.1009 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 24/250\n",
      "243/243 - 1s - loss: 1.0613 - accuracy: 0.4280 - val_loss: 1.1000 - val_accuracy: 0.3827 - 1s/epoch - 4ms/step\n",
      "Epoch 25/250\n",
      "243/243 - 1s - loss: 1.0611 - accuracy: 0.4097 - val_loss: 1.1026 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "243/243 - 1s - loss: 1.0545 - accuracy: 0.4262 - val_loss: 1.1042 - val_accuracy: 0.3827 - 1s/epoch - 4ms/step\n",
      "Epoch 27/250\n",
      "243/243 - 1s - loss: 1.0567 - accuracy: 0.4120 - val_loss: 1.1052 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 28/250\n",
      "243/243 - 1s - loss: 1.0562 - accuracy: 0.4198 - val_loss: 1.1055 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 29/250\n",
      "243/243 - 1s - loss: 1.0502 - accuracy: 0.4318 - val_loss: 1.1058 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 30/250\n",
      "243/243 - 1s - loss: 1.0527 - accuracy: 0.4262 - val_loss: 1.1193 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "243/243 - 1s - loss: 1.0570 - accuracy: 0.4252 - val_loss: 1.1022 - val_accuracy: 0.3786 - 1s/epoch - 4ms/step\n",
      "Epoch 32/250\n",
      "243/243 - 1s - loss: 1.0516 - accuracy: 0.4324 - val_loss: 1.1061 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 33/250\n",
      "243/243 - 1s - loss: 1.0558 - accuracy: 0.4362 - val_loss: 1.1058 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 34/250\n",
      "243/243 - 1s - loss: 1.0535 - accuracy: 0.4241 - val_loss: 1.0988 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 35/250\n",
      "243/243 - 1s - loss: 1.0479 - accuracy: 0.4295 - val_loss: 1.1091 - val_accuracy: 0.3488 - 1s/epoch - 4ms/step\n",
      "Epoch 36/250\n",
      "243/243 - 1s - loss: 1.0572 - accuracy: 0.4257 - val_loss: 1.1084 - val_accuracy: 0.3755 - 1s/epoch - 4ms/step\n",
      "Epoch 37/250\n",
      "243/243 - 1s - loss: 1.0471 - accuracy: 0.4367 - val_loss: 1.1041 - val_accuracy: 0.3663 - 1s/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "243/243 - 1s - loss: 1.0486 - accuracy: 0.4380 - val_loss: 1.1044 - val_accuracy: 0.3961 - 1s/epoch - 4ms/step\n",
      "Epoch 39/250\n",
      "243/243 - 1s - loss: 1.0502 - accuracy: 0.4257 - val_loss: 1.1062 - val_accuracy: 0.3560 - 1s/epoch - 4ms/step\n",
      "Epoch 40/250\n",
      "243/243 - 1s - loss: 1.0519 - accuracy: 0.4246 - val_loss: 1.1054 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "243/243 - 1s - loss: 1.0470 - accuracy: 0.4300 - val_loss: 1.1008 - val_accuracy: 0.3416 - 1s/epoch - 5ms/step\n",
      "Epoch 42/250\n",
      "243/243 - 1s - loss: 1.0424 - accuracy: 0.4432 - val_loss: 1.1039 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 43/250\n",
      "243/243 - 1s - loss: 1.0485 - accuracy: 0.4300 - val_loss: 1.1169 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 44/250\n",
      "243/243 - 1s - loss: 1.0475 - accuracy: 0.4223 - val_loss: 1.1218 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "243/243 - 1s - loss: 1.0414 - accuracy: 0.4437 - val_loss: 1.1051 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 46/250\n",
      "243/243 - 1s - loss: 1.0438 - accuracy: 0.4411 - val_loss: 1.1103 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 47/250\n",
      "243/243 - 1s - loss: 1.0380 - accuracy: 0.4506 - val_loss: 1.1063 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 48/250\n",
      "243/243 - 1s - loss: 1.0419 - accuracy: 0.4393 - val_loss: 1.1105 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 49/250\n",
      "243/243 - 1s - loss: 1.0440 - accuracy: 0.4313 - val_loss: 1.1074 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 50/250\n",
      "243/243 - 1s - loss: 1.0415 - accuracy: 0.4432 - val_loss: 1.1302 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 51/250\n",
      "243/243 - 1s - loss: 1.0444 - accuracy: 0.4416 - val_loss: 1.1433 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 52/250\n",
      "243/243 - 1s - loss: 1.0442 - accuracy: 0.4393 - val_loss: 1.1008 - val_accuracy: 0.3549 - 1s/epoch - 4ms/step\n",
      "Epoch 53/250\n",
      "243/243 - 1s - loss: 1.0462 - accuracy: 0.4378 - val_loss: 1.1044 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 54/250\n",
      "243/243 - 1s - loss: 1.0397 - accuracy: 0.4478 - val_loss: 1.1086 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 55/250\n",
      "243/243 - 1s - loss: 1.0400 - accuracy: 0.4362 - val_loss: 1.1406 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 56/250\n",
      "243/243 - 1s - loss: 1.0361 - accuracy: 0.4501 - val_loss: 1.1046 - val_accuracy: 0.3354 - 1s/epoch - 4ms/step\n",
      "Epoch 57/250\n",
      "243/243 - 1s - loss: 1.0341 - accuracy: 0.4444 - val_loss: 1.0999 - val_accuracy: 0.3580 - 1s/epoch - 4ms/step\n",
      "Epoch 58/250\n",
      "243/243 - 1s - loss: 1.0415 - accuracy: 0.4388 - val_loss: 1.1091 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 59/250\n",
      "243/243 - 1s - loss: 1.0402 - accuracy: 0.4491 - val_loss: 1.1078 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 60/250\n",
      "243/243 - 1s - loss: 1.0332 - accuracy: 0.4509 - val_loss: 1.1078 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 61/250\n",
      "243/243 - 1s - loss: 1.0376 - accuracy: 0.4390 - val_loss: 1.1051 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 62/250\n",
      "243/243 - 1s - loss: 1.0320 - accuracy: 0.4573 - val_loss: 1.1200 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "243/243 - 1s - loss: 1.0431 - accuracy: 0.4432 - val_loss: 1.1240 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 64/250\n",
      "243/243 - 1s - loss: 1.0405 - accuracy: 0.4421 - val_loss: 1.1139 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 65/250\n",
      "243/243 - 1s - loss: 1.0342 - accuracy: 0.4393 - val_loss: 1.1137 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 66/250\n",
      "243/243 - 1s - loss: 1.0356 - accuracy: 0.4606 - val_loss: 1.1103 - val_accuracy: 0.3395 - 997ms/epoch - 4ms/step\n",
      "Epoch 67/250\n",
      "243/243 - 1s - loss: 1.0371 - accuracy: 0.4450 - val_loss: 1.1085 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "243/243 - 1s - loss: 1.0268 - accuracy: 0.4545 - val_loss: 1.1148 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 69/250\n",
      "243/243 - 1s - loss: 1.0302 - accuracy: 0.4457 - val_loss: 1.1119 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 70/250\n",
      "243/243 - 1s - loss: 1.0284 - accuracy: 0.4496 - val_loss: 1.1182 - val_accuracy: 0.3374 - 984ms/epoch - 4ms/step\n",
      "Epoch 71/250\n",
      "243/243 - 1s - loss: 1.0327 - accuracy: 0.4424 - val_loss: 1.1229 - val_accuracy: 0.3570 - 1s/epoch - 4ms/step\n",
      "Epoch 72/250\n",
      "243/243 - 1s - loss: 1.0331 - accuracy: 0.4470 - val_loss: 1.1142 - val_accuracy: 0.3385 - 960ms/epoch - 4ms/step\n",
      "Epoch 73/250\n",
      "243/243 - 1s - loss: 1.0361 - accuracy: 0.4486 - val_loss: 1.1097 - val_accuracy: 0.3416 - 961ms/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "243/243 - 1s - loss: 1.0231 - accuracy: 0.4532 - val_loss: 1.1071 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 75/250\n",
      "243/243 - 1s - loss: 1.0274 - accuracy: 0.4547 - val_loss: 1.1163 - val_accuracy: 0.3395 - 978ms/epoch - 4ms/step\n",
      "Epoch 76/250\n",
      "243/243 - 1s - loss: 1.0323 - accuracy: 0.4563 - val_loss: 1.1250 - val_accuracy: 0.3385 - 999ms/epoch - 4ms/step\n",
      "Epoch 77/250\n",
      "243/243 - 1s - loss: 1.0271 - accuracy: 0.4627 - val_loss: 1.1123 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "243/243 - 1s - loss: 1.0325 - accuracy: 0.4648 - val_loss: 1.1102 - val_accuracy: 0.3580 - 1s/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "243/243 - 1s - loss: 1.0319 - accuracy: 0.4635 - val_loss: 1.1128 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "243/243 - 1s - loss: 1.0229 - accuracy: 0.4673 - val_loss: 1.1102 - val_accuracy: 0.3580 - 1s/epoch - 4ms/step\n",
      "Epoch 81/250\n",
      "243/243 - 1s - loss: 1.0325 - accuracy: 0.4617 - val_loss: 1.1168 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 82/250\n",
      "243/243 - 1s - loss: 1.0307 - accuracy: 0.4570 - val_loss: 1.1071 - val_accuracy: 0.3745 - 1s/epoch - 4ms/step\n",
      "Epoch 83/250\n",
      "243/243 - 1s - loss: 1.0295 - accuracy: 0.4565 - val_loss: 1.1067 - val_accuracy: 0.4095 - 1s/epoch - 4ms/step\n",
      "Epoch 84/250\n",
      "243/243 - 1s - loss: 1.0307 - accuracy: 0.4591 - val_loss: 1.1065 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 85/250\n",
      "243/243 - 1s - loss: 1.0243 - accuracy: 0.4663 - val_loss: 1.1130 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 86/250\n",
      "243/243 - 1s - loss: 1.0231 - accuracy: 0.4660 - val_loss: 1.1068 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 87/250\n",
      "243/243 - 1s - loss: 1.0254 - accuracy: 0.4609 - val_loss: 1.1103 - val_accuracy: 0.3735 - 1s/epoch - 4ms/step\n",
      "Epoch 88/250\n",
      "243/243 - 1s - loss: 1.0219 - accuracy: 0.4658 - val_loss: 1.1131 - val_accuracy: 0.3663 - 1s/epoch - 4ms/step\n",
      "Epoch 89/250\n",
      "243/243 - 1s - loss: 1.0229 - accuracy: 0.4712 - val_loss: 1.1084 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 90/250\n",
      "243/243 - 1s - loss: 1.0275 - accuracy: 0.4660 - val_loss: 1.1111 - val_accuracy: 0.3765 - 1s/epoch - 4ms/step\n",
      "Epoch 91/250\n",
      "243/243 - 1s - loss: 1.0230 - accuracy: 0.4640 - val_loss: 1.1156 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 92/250\n",
      "243/243 - 1s - loss: 1.0195 - accuracy: 0.4624 - val_loss: 1.1249 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "243/243 - 1s - loss: 1.0202 - accuracy: 0.4704 - val_loss: 1.1150 - val_accuracy: 0.3549 - 1s/epoch - 4ms/step\n",
      "Epoch 94/250\n",
      "243/243 - 1s - loss: 1.0256 - accuracy: 0.4565 - val_loss: 1.1123 - val_accuracy: 0.3549 - 1s/epoch - 4ms/step\n",
      "Epoch 95/250\n",
      "243/243 - 1s - loss: 1.0244 - accuracy: 0.4671 - val_loss: 1.1126 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "243/243 - 1s - loss: 1.0231 - accuracy: 0.4709 - val_loss: 1.1159 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "243/243 - 1s - loss: 1.0177 - accuracy: 0.4673 - val_loss: 1.1197 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "243/243 - 1s - loss: 1.0245 - accuracy: 0.4650 - val_loss: 1.1134 - val_accuracy: 0.3621 - 991ms/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "243/243 - 1s - loss: 1.0227 - accuracy: 0.4730 - val_loss: 1.1119 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 100/250\n",
      "243/243 - 1s - loss: 1.0243 - accuracy: 0.4632 - val_loss: 1.1152 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 101/250\n",
      "243/243 - 1s - loss: 1.0170 - accuracy: 0.4668 - val_loss: 1.1159 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 102/250\n",
      "243/243 - 1s - loss: 1.0127 - accuracy: 0.4812 - val_loss: 1.1091 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 103/250\n",
      "243/243 - 1s - loss: 1.0172 - accuracy: 0.4748 - val_loss: 1.1077 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 104/250\n",
      "243/243 - 1s - loss: 1.0218 - accuracy: 0.4771 - val_loss: 1.1048 - val_accuracy: 0.3961 - 1s/epoch - 4ms/step\n",
      "Epoch 105/250\n",
      "243/243 - 1s - loss: 1.0193 - accuracy: 0.4606 - val_loss: 1.1141 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "243/243 - 1s - loss: 1.0185 - accuracy: 0.4689 - val_loss: 1.1227 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 107/250\n",
      "243/243 - 1s - loss: 1.0165 - accuracy: 0.4740 - val_loss: 1.1114 - val_accuracy: 0.3591 - 1s/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "243/243 - 1s - loss: 1.0166 - accuracy: 0.4691 - val_loss: 1.1224 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 109/250\n",
      "243/243 - 1s - loss: 1.0165 - accuracy: 0.4781 - val_loss: 1.1177 - val_accuracy: 0.3560 - 1s/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "243/243 - 1s - loss: 1.0246 - accuracy: 0.4655 - val_loss: 1.1132 - val_accuracy: 0.3591 - 1s/epoch - 4ms/step\n",
      "Epoch 111/250\n",
      "243/243 - 1s - loss: 1.0210 - accuracy: 0.4684 - val_loss: 1.1121 - val_accuracy: 0.3745 - 1s/epoch - 4ms/step\n",
      "Epoch 112/250\n",
      "243/243 - 1s - loss: 1.0153 - accuracy: 0.4779 - val_loss: 1.1093 - val_accuracy: 0.4074 - 1s/epoch - 4ms/step\n",
      "Epoch 113/250\n",
      "243/243 - 1s - loss: 1.0244 - accuracy: 0.4655 - val_loss: 1.1209 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 114/250\n",
      "243/243 - 1s - loss: 1.0240 - accuracy: 0.4797 - val_loss: 1.1159 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 115/250\n",
      "243/243 - 1s - loss: 1.0244 - accuracy: 0.4630 - val_loss: 1.1097 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 116/250\n",
      "243/243 - 1s - loss: 1.0143 - accuracy: 0.4763 - val_loss: 1.1052 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "243/243 - 1s - loss: 1.0148 - accuracy: 0.4787 - val_loss: 1.1087 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 118/250\n",
      "243/243 - 1s - loss: 1.0118 - accuracy: 0.4784 - val_loss: 1.1142 - val_accuracy: 0.3405 - 1s/epoch - 4ms/step\n",
      "Epoch 119/250\n",
      "243/243 - 1s - loss: 1.0204 - accuracy: 0.4727 - val_loss: 1.1332 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 120/250\n",
      "243/243 - 1s - loss: 1.0189 - accuracy: 0.4619 - val_loss: 1.1147 - val_accuracy: 0.3951 - 1s/epoch - 4ms/step\n",
      "Epoch 121/250\n",
      "243/243 - 1s - loss: 1.0114 - accuracy: 0.4828 - val_loss: 1.1053 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 122/250\n",
      "243/243 - 1s - loss: 1.0148 - accuracy: 0.4784 - val_loss: 1.1023 - val_accuracy: 0.3560 - 1s/epoch - 4ms/step\n",
      "Epoch 123/250\n",
      "243/243 - 1s - loss: 1.0204 - accuracy: 0.4663 - val_loss: 1.1168 - val_accuracy: 0.3385 - 1s/epoch - 4ms/step\n",
      "Epoch 124/250\n",
      "243/243 - 1s - loss: 1.0116 - accuracy: 0.4866 - val_loss: 1.1297 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 125/250\n",
      "243/243 - 1s - loss: 1.0164 - accuracy: 0.4650 - val_loss: 1.1172 - val_accuracy: 0.3395 - 1s/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "243/243 - 1s - loss: 1.0176 - accuracy: 0.4856 - val_loss: 1.1154 - val_accuracy: 0.3447 - 1s/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "243/243 - 1s - loss: 1.0201 - accuracy: 0.4774 - val_loss: 1.1246 - val_accuracy: 0.3364 - 1s/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4838 - val_loss: 1.1163 - val_accuracy: 0.3652 - 1s/epoch - 4ms/step\n",
      "Epoch 129/250\n",
      "243/243 - 1s - loss: 1.0213 - accuracy: 0.4660 - val_loss: 1.1170 - val_accuracy: 0.3302 - 1s/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "243/243 - 1s - loss: 1.0115 - accuracy: 0.4699 - val_loss: 1.1279 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 131/250\n",
      "243/243 - 1s - loss: 1.0107 - accuracy: 0.4779 - val_loss: 1.1367 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 132/250\n",
      "243/243 - 1s - loss: 1.0073 - accuracy: 0.4823 - val_loss: 1.1231 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 133/250\n",
      "243/243 - 1s - loss: 1.0192 - accuracy: 0.4774 - val_loss: 1.1560 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "243/243 - 1s - loss: 1.0116 - accuracy: 0.4918 - val_loss: 1.1649 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 135/250\n",
      "243/243 - 1s - loss: 1.0184 - accuracy: 0.4866 - val_loss: 1.1281 - val_accuracy: 0.3220 - 1s/epoch - 5ms/step\n",
      "Epoch 136/250\n",
      "243/243 - 1s - loss: 1.0183 - accuracy: 0.4730 - val_loss: 1.1299 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 137/250\n",
      "243/243 - 1s - loss: 1.0133 - accuracy: 0.4805 - val_loss: 1.1303 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "243/243 - 1s - loss: 1.0131 - accuracy: 0.4712 - val_loss: 1.1097 - val_accuracy: 0.3570 - 1s/epoch - 4ms/step\n",
      "Epoch 139/250\n",
      "243/243 - 1s - loss: 1.0055 - accuracy: 0.4961 - val_loss: 1.1446 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 140/250\n",
      "243/243 - 1s - loss: 1.0118 - accuracy: 0.4763 - val_loss: 1.1356 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 141/250\n",
      "243/243 - 1s - loss: 1.0087 - accuracy: 0.4823 - val_loss: 1.1315 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "243/243 - 1s - loss: 1.0028 - accuracy: 0.4895 - val_loss: 1.1242 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 143/250\n",
      "243/243 - 1s - loss: 1.0105 - accuracy: 0.4846 - val_loss: 1.1042 - val_accuracy: 0.4033 - 1s/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "243/243 - 1s - loss: 1.0210 - accuracy: 0.4560 - val_loss: 1.1384 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "243/243 - 1s - loss: 1.0135 - accuracy: 0.4817 - val_loss: 1.1237 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 146/250\n",
      "243/243 - 1s - loss: 1.0094 - accuracy: 0.4766 - val_loss: 1.1101 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 147/250\n",
      "243/243 - 1s - loss: 1.0152 - accuracy: 0.4663 - val_loss: 1.1078 - val_accuracy: 0.3282 - 1s/epoch - 4ms/step\n",
      "Epoch 148/250\n",
      "243/243 - 1s - loss: 1.0082 - accuracy: 0.4859 - val_loss: 1.1208 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 149/250\n",
      "243/243 - 1s - loss: 1.0060 - accuracy: 0.4897 - val_loss: 1.1442 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 150/250\n",
      "243/243 - 1s - loss: 1.0062 - accuracy: 0.4833 - val_loss: 1.1322 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 151/250\n",
      "243/243 - 1s - loss: 1.0023 - accuracy: 0.4900 - val_loss: 1.1492 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 152/250\n",
      "243/243 - 1s - loss: 1.0036 - accuracy: 0.4792 - val_loss: 1.1310 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 153/250\n",
      "243/243 - 1s - loss: 1.0120 - accuracy: 0.4841 - val_loss: 1.1260 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 154/250\n",
      "243/243 - 1s - loss: 1.0058 - accuracy: 0.4841 - val_loss: 1.1162 - val_accuracy: 0.3477 - 1s/epoch - 4ms/step\n",
      "Epoch 155/250\n",
      "243/243 - 1s - loss: 1.0039 - accuracy: 0.4799 - val_loss: 1.1296 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 156/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4925 - val_loss: 1.1156 - val_accuracy: 0.3467 - 1s/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "243/243 - 1s - loss: 1.0098 - accuracy: 0.4864 - val_loss: 1.1291 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "243/243 - 1s - loss: 1.0022 - accuracy: 0.4925 - val_loss: 1.1325 - val_accuracy: 0.3272 - 996ms/epoch - 4ms/step\n",
      "Epoch 159/250\n",
      "243/243 - 1s - loss: 1.0101 - accuracy: 0.4802 - val_loss: 1.1527 - val_accuracy: 0.3210 - 957ms/epoch - 4ms/step\n",
      "Epoch 160/250\n",
      "243/243 - 1s - loss: 1.0094 - accuracy: 0.4874 - val_loss: 1.1254 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 161/250\n",
      "243/243 - 1s - loss: 0.9954 - accuracy: 0.4977 - val_loss: 1.1214 - val_accuracy: 0.3519 - 1s/epoch - 4ms/step\n",
      "Epoch 162/250\n",
      "243/243 - 1s - loss: 1.0070 - accuracy: 0.4848 - val_loss: 1.1158 - val_accuracy: 0.3951 - 1s/epoch - 4ms/step\n",
      "Epoch 163/250\n",
      "243/243 - 1s - loss: 1.0094 - accuracy: 0.4889 - val_loss: 1.1058 - val_accuracy: 0.3457 - 988ms/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "243/243 - 1s - loss: 1.0093 - accuracy: 0.4825 - val_loss: 1.1119 - val_accuracy: 0.3519 - 996ms/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "243/243 - 1s - loss: 1.0045 - accuracy: 0.4799 - val_loss: 1.1207 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "243/243 - 1s - loss: 1.0072 - accuracy: 0.4830 - val_loss: 1.1209 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "243/243 - 1s - loss: 1.0100 - accuracy: 0.4823 - val_loss: 1.1208 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "243/243 - 1s - loss: 1.0087 - accuracy: 0.4843 - val_loss: 1.1307 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "243/243 - 1s - loss: 1.0148 - accuracy: 0.4859 - val_loss: 1.1194 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "243/243 - 1s - loss: 1.0029 - accuracy: 0.4931 - val_loss: 1.1404 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "243/243 - 1s - loss: 1.0119 - accuracy: 0.4910 - val_loss: 1.1346 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "243/243 - 1s - loss: 1.0070 - accuracy: 0.4874 - val_loss: 1.1349 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "243/243 - 1s - loss: 1.0065 - accuracy: 0.4887 - val_loss: 1.1207 - val_accuracy: 0.3374 - 1s/epoch - 4ms/step\n",
      "Epoch 174/250\n",
      "243/243 - 1s - loss: 1.0002 - accuracy: 0.4913 - val_loss: 1.1266 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "243/243 - 1s - loss: 1.0036 - accuracy: 0.4689 - val_loss: 1.1340 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "243/243 - 1s - loss: 1.0075 - accuracy: 0.4812 - val_loss: 1.1175 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "243/243 - 1s - loss: 1.0081 - accuracy: 0.4812 - val_loss: 1.1199 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "243/243 - 1s - loss: 1.0067 - accuracy: 0.4892 - val_loss: 1.1283 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "243/243 - 1s - loss: 1.0029 - accuracy: 0.4869 - val_loss: 1.1178 - val_accuracy: 0.3611 - 1s/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "243/243 - 1s - loss: 1.0080 - accuracy: 0.4856 - val_loss: 1.1402 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "243/243 - 1s - loss: 1.0079 - accuracy: 0.4853 - val_loss: 1.1140 - val_accuracy: 0.4002 - 1s/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "243/243 - 1s - loss: 1.0109 - accuracy: 0.4887 - val_loss: 1.1109 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "243/243 - 1s - loss: 1.0108 - accuracy: 0.4838 - val_loss: 1.1238 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "243/243 - 1s - loss: 1.0066 - accuracy: 0.4835 - val_loss: 1.1125 - val_accuracy: 0.3508 - 1s/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "243/243 - 1s - loss: 1.0062 - accuracy: 0.4905 - val_loss: 1.1092 - val_accuracy: 0.3416 - 1s/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "243/243 - 1s - loss: 1.0119 - accuracy: 0.4902 - val_loss: 1.1124 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 187/250\n",
      "243/243 - 1s - loss: 1.0177 - accuracy: 0.4815 - val_loss: 1.1124 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "243/243 - 1s - loss: 1.0084 - accuracy: 0.4758 - val_loss: 1.1354 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "243/243 - 1s - loss: 1.0219 - accuracy: 0.4715 - val_loss: 1.1260 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "243/243 - 1s - loss: 1.0104 - accuracy: 0.4740 - val_loss: 1.1416 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "243/243 - 1s - loss: 1.0070 - accuracy: 0.4817 - val_loss: 1.1582 - val_accuracy: 0.3210 - 996ms/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "243/243 - 1s - loss: 1.0086 - accuracy: 0.4792 - val_loss: 1.1908 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "243/243 - 1s - loss: 1.0090 - accuracy: 0.4797 - val_loss: 1.1391 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "243/243 - 1s - loss: 1.0068 - accuracy: 0.4835 - val_loss: 1.1356 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "243/243 - 1s - loss: 1.0045 - accuracy: 0.4879 - val_loss: 1.1542 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "243/243 - 1s - loss: 1.0053 - accuracy: 0.4905 - val_loss: 1.1265 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "243/243 - 1s - loss: 1.0145 - accuracy: 0.4766 - val_loss: 1.1395 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "243/243 - 1s - loss: 1.0065 - accuracy: 0.4931 - val_loss: 1.1478 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "243/243 - 1s - loss: 1.0022 - accuracy: 0.4982 - val_loss: 1.1401 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "243/243 - 1s - loss: 1.0036 - accuracy: 0.4743 - val_loss: 1.1407 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "243/243 - 1s - loss: 1.0057 - accuracy: 0.4825 - val_loss: 1.1130 - val_accuracy: 0.3693 - 1s/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "243/243 - 1s - loss: 1.0014 - accuracy: 0.4907 - val_loss: 1.1270 - val_accuracy: 0.3323 - 1s/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "243/243 - 1s - loss: 1.0065 - accuracy: 0.4838 - val_loss: 1.1247 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "243/243 - 1s - loss: 1.0067 - accuracy: 0.4856 - val_loss: 1.1101 - val_accuracy: 0.3344 - 1s/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "243/243 - 1s - loss: 1.0010 - accuracy: 0.4925 - val_loss: 1.1677 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "243/243 - 1s - loss: 1.0149 - accuracy: 0.4722 - val_loss: 1.1486 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "243/243 - 1s - loss: 1.0065 - accuracy: 0.4907 - val_loss: 1.1659 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "243/243 - 1s - loss: 0.9995 - accuracy: 0.4907 - val_loss: 1.1418 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "243/243 - 1s - loss: 1.0035 - accuracy: 0.4861 - val_loss: 1.1263 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "243/243 - 1s - loss: 1.0009 - accuracy: 0.4974 - val_loss: 1.1415 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 211/250\n",
      "243/243 - 1s - loss: 1.0080 - accuracy: 0.4846 - val_loss: 1.1366 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "243/243 - 1s - loss: 0.9994 - accuracy: 0.4938 - val_loss: 1.1553 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 213/250\n",
      "243/243 - 1s - loss: 1.0000 - accuracy: 0.4866 - val_loss: 1.1393 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "243/243 - 1s - loss: 1.0028 - accuracy: 0.4820 - val_loss: 1.1292 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "243/243 - 1s - loss: 1.0020 - accuracy: 0.4853 - val_loss: 1.1144 - val_accuracy: 0.3663 - 1s/epoch - 4ms/step\n",
      "Epoch 216/250\n",
      "243/243 - 1s - loss: 0.9960 - accuracy: 0.4972 - val_loss: 1.1111 - val_accuracy: 0.3241 - 1s/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "243/243 - 1s - loss: 1.0008 - accuracy: 0.4871 - val_loss: 1.1289 - val_accuracy: 0.3230 - 1s/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "243/243 - 1s - loss: 0.9966 - accuracy: 0.4946 - val_loss: 1.1466 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "243/243 - 1s - loss: 0.9928 - accuracy: 0.4979 - val_loss: 1.1302 - val_accuracy: 0.4002 - 1s/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "243/243 - 1s - loss: 1.0018 - accuracy: 0.4961 - val_loss: 1.1204 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "243/243 - 1s - loss: 1.0004 - accuracy: 0.4884 - val_loss: 1.1155 - val_accuracy: 0.3436 - 1s/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "243/243 - 1s - loss: 0.9997 - accuracy: 0.5018 - val_loss: 1.1328 - val_accuracy: 0.3549 - 998ms/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "243/243 - 1s - loss: 1.0150 - accuracy: 0.4797 - val_loss: 1.1182 - val_accuracy: 0.3426 - 1s/epoch - 4ms/step\n",
      "Epoch 224/250\n",
      "243/243 - 1s - loss: 0.9918 - accuracy: 0.5026 - val_loss: 1.1221 - val_accuracy: 0.3519 - 1s/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "243/243 - 1s - loss: 1.0040 - accuracy: 0.4900 - val_loss: 1.1279 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "243/243 - 1s - loss: 1.0065 - accuracy: 0.4905 - val_loss: 1.1346 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "243/243 - 1s - loss: 1.0071 - accuracy: 0.4946 - val_loss: 1.1513 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "243/243 - 1s - loss: 1.0069 - accuracy: 0.4805 - val_loss: 1.1254 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "243/243 - 1s - loss: 1.0084 - accuracy: 0.4841 - val_loss: 1.1209 - val_accuracy: 0.3457 - 1s/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "243/243 - 1s - loss: 1.0016 - accuracy: 0.4843 - val_loss: 1.1243 - val_accuracy: 0.3539 - 1s/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "243/243 - 1s - loss: 0.9981 - accuracy: 0.4923 - val_loss: 1.1202 - val_accuracy: 0.3251 - 1s/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "243/243 - 1s - loss: 0.9960 - accuracy: 0.4997 - val_loss: 1.1375 - val_accuracy: 0.3189 - 1s/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "243/243 - 1s - loss: 1.0021 - accuracy: 0.4907 - val_loss: 1.1336 - val_accuracy: 0.3261 - 1s/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "243/243 - 1s - loss: 1.0008 - accuracy: 0.4884 - val_loss: 1.1236 - val_accuracy: 0.3333 - 1s/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "243/243 - 1s - loss: 1.0011 - accuracy: 0.4918 - val_loss: 1.1110 - val_accuracy: 0.3621 - 974ms/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "243/243 - 1s - loss: 1.0021 - accuracy: 0.4915 - val_loss: 1.1262 - val_accuracy: 0.3261 - 995ms/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "243/243 - 1s - loss: 1.0041 - accuracy: 0.4920 - val_loss: 1.1434 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "243/243 - 1s - loss: 0.9997 - accuracy: 0.4884 - val_loss: 1.1187 - val_accuracy: 0.3313 - 1s/epoch - 4ms/step\n",
      "Epoch 239/250\n",
      "243/243 - 1s - loss: 0.9976 - accuracy: 0.4835 - val_loss: 1.1331 - val_accuracy: 0.3220 - 983ms/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "243/243 - 1s - loss: 1.0060 - accuracy: 0.4871 - val_loss: 1.1299 - val_accuracy: 0.3683 - 1s/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "243/243 - 1s - loss: 0.9973 - accuracy: 0.4866 - val_loss: 1.1315 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "243/243 - 1s - loss: 1.0014 - accuracy: 0.4851 - val_loss: 1.1178 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "243/243 - 1s - loss: 0.9953 - accuracy: 0.4902 - val_loss: 1.1374 - val_accuracy: 0.3292 - 1s/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "243/243 - 1s - loss: 0.9991 - accuracy: 0.4977 - val_loss: 1.1297 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "243/243 - 1s - loss: 0.9984 - accuracy: 0.4828 - val_loss: 1.1303 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "243/243 - 1s - loss: 0.9983 - accuracy: 0.5010 - val_loss: 1.1215 - val_accuracy: 0.3220 - 1s/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "243/243 - 1s - loss: 0.9983 - accuracy: 0.4907 - val_loss: 1.1287 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "243/243 - 1s - loss: 1.0033 - accuracy: 0.4843 - val_loss: 1.1338 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "243/243 - 1s - loss: 0.9981 - accuracy: 0.5023 - val_loss: 1.1860 - val_accuracy: 0.3200 - 1s/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "243/243 - 1s - loss: 0.9981 - accuracy: 0.4995 - val_loss: 1.1574 - val_accuracy: 0.3210 - 1s/epoch - 4ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "152/152 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PER SUB \n",
    "# SUBJECTS=[1,2,3,4,5,6,7,8,9,11,12,13,14,16,17]\n",
    "# for temp_sub in SUBJECTS:\n",
    "# sub=\"{:02d}\".format(temp_sub)\n",
    "\n",
    "CLASSES= [2,3]\n",
    "for n_classes in CLASSES:\n",
    "    #Define loss function\n",
    "    loss_fn= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    LABELS= list(range(0,n_classes))\n",
    "    numero_classi=n_classes\n",
    "\n",
    "#         dir0= os.path.join(\"FINAL_motor_imagery_classification/2_sec_windows/powerbands/\"+str(n_classes)+\"class/output/\", \"sub_\"+str(sub))\n",
    "    dir0= os.path.join(\"FINAL_motor_imagery_classification/10_sec_windows/powerbands/\"+str(n_classes)+\"class/output/\", \"all\")\n",
    "\n",
    "    os.mkdir(dir0)\n",
    "    dir_input=(\"FINAL_motor_imagery_classification/10_sec_windows/powerbands/\"+str(n_classes)+\"class/input\")\n",
    "\n",
    "    evaluation=[]\n",
    "    iteration=[]\n",
    "    confusion_matrix_x_test=[]\n",
    "    confusion_matrix_y_test= []\n",
    "    validation_acc=[]\n",
    "    PERFORMANCE=[]\n",
    "\n",
    "    print(\"SUBJECT: \"+ str(sub))\n",
    "    print(\"N_CLASSES: \"+ str(n_classes))\n",
    "\n",
    "#     X=sio.loadmat(dir_input+\"/sub_\"+str(sub)+ \"_X.mat\")[\"array_X\"]\n",
    "#     y= sio.loadmat(dir_input+\"/sub_\"+str(sub)+\"_y.mat\")[\"array_y\"]\n",
    "\n",
    "    X=sio.loadmat(dir_input+\"/all_X.mat\")[\"array_X\"]\n",
    "    y= sio.loadmat(dir_input+\"/all_y.mat\")[\"array_y\"]\n",
    "    X= np.transpose(X, (0,1,3,2))\n",
    "#         X=np.clip(X,0,100)\n",
    "#         X= X.reshape(X.shape[0], X.shape[1], -1,1)\n",
    "\n",
    "    y=y.flatten()\n",
    "    print(\"New shape for X: \" + str(X.shape))\n",
    "    print(\"New shape for y: \"+str(y.shape))\n",
    "\n",
    "    dir1=os.path.join(dir0, \"comparison\")\n",
    "    dir2=os.path.join(dir0, \"temporal_convolution\")\n",
    "    dir3=os.path.join(dir0, \"spatial_convolution\")\n",
    "    os.mkdir(dir1)\n",
    "    os.mkdir(dir2)\n",
    "    os.mkdir(dir3)\n",
    "\n",
    "    ################################################################################################################################################################################################################################################################################\n",
    "\n",
    "    n_folds = 5\n",
    "    seed = 21\n",
    "    shuffle_test = True\n",
    "    EPOCHS=250\n",
    "\n",
    "    N_chan=31\n",
    "    N_samples_long=50\n",
    "    N_frequency_bins= 4\n",
    "\n",
    "    kfold = KFold(n_splits = n_folds, shuffle = shuffle_test, random_state = seed)\n",
    "    count=0\n",
    "    sommatoria=0\n",
    "\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        count=count+1\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        print(\"Train index for this split: \"+ str(train_index)) \n",
    "        print(\"Number of samples for train set: \"+str(train_index.shape[0]))\n",
    "        print(\"Test index for this split: \"+ str(test_index))\n",
    "        print(\"Number of samples for test set: \"+str(test_index.shape[0]))\n",
    "\n",
    "        # Define the model architecture - \n",
    "\n",
    "#             model= EEGNet(n_classes, Chans = N_chan, Samples = N_samples_long, \n",
    "#              dropoutRate = Drop_test, kernLength = KernLength_test, F1 = F1_test, \n",
    "#              D = D_test, F2 = F2_test, norm_rate = 0.25, dropoutType = 'Dropout', )\n",
    "\n",
    "        model=Sequential()\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "        model.add(Conv2D(8, (1, 64), padding = 'same',\n",
    "                                       input_shape = (N_chan, N_samples_long, 4),\n",
    "                                       use_bias = False, name=\"temporal_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_1\"))\n",
    "        model.add(DepthwiseConv2D((31, 1), use_bias = False, \n",
    "                                       depth_multiplier = 2,\n",
    "                                       depthwise_constraint = max_norm(1.), name=\"spatial_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_2\"))\n",
    "        model.add(Activation('elu', name=\"activation_1\"))\n",
    "        model.add(AveragePooling2D((1, 4), name=\"pooling_layer_1\"))\n",
    "        model.add(Dropout(0.5, name=\"dropout_1\"))\n",
    "\n",
    "        model.add(SeparableConv2D(16, (1, 16),\n",
    "                                       use_bias = False, padding = 'same', name=\"separable_conv\"))\n",
    "        model.add(BatchNormalization(name=\"batchnorm_3\"))\n",
    "        model.add(Activation('elu', name=\"activation_2\"))\n",
    "        model.add(AveragePooling2D((1, 8), name=\"pooling_layer_2\"))\n",
    "        model.add(Dropout(0.5, name=\"drpout_2\")) #QUI DROPOUT E' LASCIATO A 0.5 come in eegnet paper\n",
    "\n",
    "        model.add(Flatten(name = 'flatten'))\n",
    "\n",
    "        model.add(Dense(numero_classi, name = 'dense', \n",
    "                                 kernel_constraint = max_norm(0.25)))\n",
    "        model.add(Activation('softmax', name = 'softmax'))\n",
    "\n",
    "\n",
    "        # Define the optimizer\n",
    "        optimizer= optimizers.Adam(\n",
    "        learning_rate= 1e-3,\n",
    "        weight_decay= 0\n",
    "        )\n",
    "        model.compile(optimizer=optimizer,\n",
    "                       loss=loss_fn,\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "        evaluation.append(model.fit(X_train, y_train, batch_size=16,\n",
    "                  epochs=EPOCHS, \n",
    "                  validation_data=(X_test, y_test), \n",
    "                  verbose=2, workers=1)\n",
    "                     )\n",
    "\n",
    "\n",
    "        # Iteration = fold, i am just saving the model for that fold\n",
    "        iteration.append(model)\n",
    "\n",
    "        confusion_matrix_x_test.append(X_test)\n",
    "        confusion_matrix_y_test.append(y_test)\n",
    "\n",
    "        #Plotting confusion matrix\n",
    "        pred=model.predict(X_test)\n",
    "        y_test_pred= np.argmax(pred, axis=1)\n",
    "\n",
    "        confusion_matrix= metrics.confusion_matrix(y_test, y_test_pred, normalize='true')\n",
    "        plt.figure()\n",
    "        metrics.ConfusionMatrixDisplay(confusion_matrix).plot()\n",
    "        plt.savefig(dir1+\"/confusion_matrix_kfold_\"+str(count))\n",
    "        plt.close()\n",
    "\n",
    "        validation_acc.append(np.sum(y_test==y_test_pred)/y_test.shape[0])\n",
    "\n",
    "        PERFORMANCE.append(classification_report(y_test, y_test_pred, labels=LABELS, output_dict=True))\n",
    "\n",
    "        #Salvo risultati di singolo fold\n",
    "        sio.savemat(dir1+\"/y_pred_test_kfold\"+str(count), {\"array\": y_test_pred})\n",
    "        sio.savemat(dir1+\"/y_test_kfold\"+str(count), {\"array\": y_test})\n",
    "\n",
    "\n",
    "        # PLOTTO FILTRI TEMPORALI E SPAZIALI E LI SALVO\n",
    "        var= (model.get_layer(\"temporal_conv\").weights)\n",
    "        for lallo in range(8):\n",
    "            plt.figure()\n",
    "            plt.title(\"temp_conv_\"+str(lallo))\n",
    "            plt.plot(var[0][0,:,0][:,lallo]) #this way i access the temporal filters, cambiando ultimo zero\n",
    "            plt.savefig(dir2+\"/temp_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo))\n",
    "            temp= (var[0][0,:,0][:,lallo]).numpy()\n",
    "            sio.savemat(dir2+\"/temp_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo), {\"array\": temp})\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "        var_2= (model.get_layer(\"spatial_conv\").weights)\n",
    "        reshaped_var_2=tf.reshape(var_2[0][:,0,:,:],(31,16))\n",
    "        for lallo in range(16):\n",
    "            nump= reshaped_var_2[:,lallo].numpy()\n",
    "            sio.savemat(dir3+\"/spat_conv_kfold_\"+str(count)+\"_filter_\"+str(lallo), {\"array\": nump})\n",
    "\n",
    "    ###################################################################################################################\n",
    "\n",
    "    #plot accuracy and loss function across epochs\n",
    "    epoch_vec=np.linspace(1,EPOCHS,EPOCHS)\n",
    "    min_temp_loss=10\n",
    "    min_temp_acc=10\n",
    "    max_temp_loss=0\n",
    "    max_temp_acc=0\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        if (np.min(evaluation[idx].history['loss'])<min_temp_loss):\n",
    "            min_temp_loss=np.min(evaluation[idx].history['loss'])\n",
    "        if (np.min(evaluation[idx].history['val_loss'])<min_temp_loss):\n",
    "            min_temp_loss=np.min(evaluation[idx].history['val_loss'])\n",
    "        if (np.max(evaluation[idx].history['loss'])>max_temp_loss):\n",
    "            max_temp_loss=np.max(evaluation[idx].history['loss'])\n",
    "        if (np.max(evaluation[idx].history['val_loss'])>max_temp_loss):\n",
    "            max_temp_loss=np.max(evaluation[idx].history['val_loss'])\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        if (np.min(evaluation[idx].history['accuracy'])<min_temp_acc):\n",
    "            min_temp_acc=np.min(evaluation[idx].history['accuracy'])\n",
    "        if (np.min(evaluation[idx].history['val_accuracy'])<min_temp_acc):\n",
    "            min_temp_acc=np.min(evaluation[idx].history['val_accuracy'])\n",
    "        if (np.max(evaluation[idx].history['accuracy'])>max_temp_acc):\n",
    "            max_temp_acc=np.max(evaluation[idx].history['accuracy'])\n",
    "        if (np.max(evaluation[idx].history['val_accuracy'])>max_temp_acc):\n",
    "            max_temp_acc=np.max(evaluation[idx].history['val_accuracy'])\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        loss_vec_train= evaluation[idx].history['loss']\n",
    "        loss_vec_test= evaluation[idx].history['val_loss']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epoch_vec,loss_vec_test,'b-', label= 'test');\n",
    "        plt.plot(epoch_vec,loss_vec_train,'r-', label='train');\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss across epochs for fold: '+str(idx))\n",
    "        plt.ylim([min_temp_loss, max_temp_loss])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(dir1+\"/loss_kfold_\"+str(idx))\n",
    "        plt.close()\n",
    "\n",
    "    #plot accuracy and loss function across epochs\n",
    "    epoch_vec=np.linspace(1,EPOCHS,EPOCHS)\n",
    "\n",
    "    for idx in range(n_folds):\n",
    "        loss_vec_train= evaluation[idx].history['accuracy']\n",
    "        loss_vec_test= evaluation[idx].history['val_accuracy']\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epoch_vec,loss_vec_test,'b-', label= 'test');\n",
    "        plt.plot(epoch_vec,loss_vec_train,'r-', label='train');\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy across epochs for fold: '+str(idx))\n",
    "        plt.ylim([min_temp_acc, max_temp_acc])\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(dir1+\"/accuracy_kfold_\"+str(idx))\n",
    "        plt.close()\n",
    "\n",
    "    #SALVO VARIABILI STATISTICHE E MODELLO IN MODO DA PLOTTARLO\n",
    "\n",
    "#         acc_temp=[]\n",
    "    accuratezza=np.zeros(n_classes*2)\n",
    "#         for idx in range(n_folds):\n",
    "#             acc_temp.append(PERFORMANCE[idx][\"accuracy\"])\n",
    "    accuratezza[0]=(np.mean(validation_acc))\n",
    "    accuratezza[1]=(statistics.pstdev(validation_acc))\n",
    "\n",
    "\n",
    "    precisione=[]\n",
    "    recall=[]\n",
    "    f1_score=[]\n",
    "    support=[]\n",
    "    for classe in range(numero_classi):\n",
    "        precision_temp=[]\n",
    "        recall_temp=[]\n",
    "        f1_score_temp=[]\n",
    "        support_temp=[]\n",
    "        for idx in range(n_folds):\n",
    "            precision_temp.append(PERFORMANCE[idx][str(classe)][\"precision\"])\n",
    "            recall_temp.append(PERFORMANCE[idx][str(classe)][\"recall\"])\n",
    "            f1_score_temp.append(PERFORMANCE[idx][str(classe)][\"f1-score\"])\n",
    "            support_temp.append(PERFORMANCE[idx][str(classe)][\"support\"])\n",
    "\n",
    "        precisione.append(np.mean(precision_temp))\n",
    "        precisione.append(statistics.pstdev(precision_temp))\n",
    "        recall.append(np.mean(recall_temp))\n",
    "        recall.append(statistics.pstdev(recall_temp))\n",
    "        f1_score.append(np.mean(f1_score_temp))\n",
    "        f1_score.append(statistics.pstdev(f1_score_temp))    \n",
    "        support.append(np.mean(support_temp))\n",
    "        support.append(statistics.pstdev(support_temp)) \n",
    "\n",
    "    sommario=[]\n",
    "    sommario=np.vstack((accuratezza,precisione,recall,f1_score,support))\n",
    "    sio.savemat(dir0+\"/sommario.mat\", {\"array\": sommario})\n",
    "\n",
    "    gianfranco=model.predict(X)\n",
    "    gianfranco2=np.argmax(gianfranco, axis=1)\n",
    "    sio.savemat(dir0+\"/predizione_totale.mat\", {\"array\": gianfranco2})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
